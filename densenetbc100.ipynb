{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ReduceLROnPlateau\n",
    "#torch.multiprocessing.set_start_method(\"spawn\")\n",
    "import densenetBC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import progress_bar\n",
    "from skimage import transform as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_dir = 'data/processed/'\n",
    "\n",
    "train = pd.read_json(BASE_dir + 'train.json')\n",
    "test = pd.read_json(BASE_dir + 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAKuCAYAAACljQSXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHf4H2EUM2jUy3ToAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50ba490f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(train) # 1604 obs\n",
    "train.head(3)\n",
    "#randomly draw some of them\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "gs = gridspec.GridSpec(4,4)\n",
    "\n",
    "index = np.random.choice(list(range(len(train))),size=8, replace=False)\n",
    "for num,i in enumerate(index):\n",
    "    for j in range(2):\n",
    "        ax = plt.subplot(gs[num*2+j])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title('Image index:%d, Band:%d' % (i, j%2+1))\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(np.array(train.iloc[i,j%2]).reshape(75,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "use_cuda= True if torch.cuda.is_available() else False\n",
    "#use_cuda =False\n",
    "#dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor \n",
    "dtype = torch.FloatTensor \n",
    "data=  pd.read_json(BASE_dir + 'train.json')\n",
    "\n",
    "class iceberg_dataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None, test=False): #data: 1604 * 3 *75* 75\n",
    "        self.data =data\n",
    "        self.label = torch.from_numpy(label).type(torch.LongTensor)\n",
    "        self.transform= transform\n",
    "        self.test= test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img, label=  self.data[idx], self.label[idx]\n",
    "        if self.transform is not None:\n",
    "            #Random Horizontal Flip and Vertical Flip \n",
    "            #https://discuss.pytorch.org/t/torch-from-numpy-not-support-negative-strides/3663\n",
    "            \n",
    "            #rotate, scale, shear, translation\n",
    "#             if self.test is False:\n",
    "#                 angle = np.random.uniform(0,360)\n",
    "#                 img = tf.rotate(img,angle=angle,resize=False)\n",
    "#                 scale1 = np.exp(np.random.uniform(np.log(1/1.2), np.log(1.2)))\n",
    "#                 scale2 = np.exp(np.random.uniform(np.log(1/1.2), np.log(1.2)))\n",
    "#                 #shear = np.random.uniform(-np.pi/18, np.pi/18)\n",
    "#                 #tran = np.random.uniform(-5, 5)\n",
    "#                 #aug = tf.AffineTransform(shear = shear, translation=tran, scale= (scale1, scale2))\n",
    "#                 aug = tf.AffineTransform(scale= (scale1, scale2))\n",
    "#                 img = tf.warp(img, inverse_map=aug)\n",
    "            \n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=1).copy()\n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=2).copy()\n",
    "            \n",
    "            if self.test is False:\n",
    "                if np.random.uniform()>0.5:\n",
    "                    img = np.flip(img,axis=1).copy()\n",
    "                if np.random.uniform()>0.5:\n",
    "                    img = np.flip(img,axis=2).copy()\n",
    "                rotate = np.random.randint(4, size=1)\n",
    "                if rotate:\n",
    "                    img = np.rot90(img,k=rotate,axes=(1,2)).copy()\n",
    "            img = torch.from_numpy(img).type(dtype)\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "def stack(row):\n",
    "    return np.stack(row[['c1','c2','c3']]).reshape(3,75,75)\n",
    "\n",
    "def raw_to_numpy(data):\n",
    "    img = []\n",
    "    data['c1'] = data['band_1'].apply(np.array)\n",
    "    data['c2'] = data['band_2'].apply(np.array)\n",
    "    data['c3'] = (data['c1'] + data['c2'])/2\n",
    "#     data['c3'] = (data['c1'] + data['c2'])/2\n",
    "    for _, row in data.iterrows():\n",
    "        img.append(stack(row))\n",
    "    return np.stack(img)\n",
    "\n",
    "def transform_compute(img):\n",
    "    train_mean = img.mean(axis=(0,2,3))\n",
    "    train_std = img.std(axis=(0,2,3))\n",
    "    return train_mean, train_std\n",
    "\n",
    "train_X = raw_to_numpy(data)#.transpose(0,2,3,1)\n",
    "train_X.shape     #1604 * 3 *75* 75   N*c*H*W\n",
    "train_y = data['is_iceberg'].values # if iceberg then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=list(range(1300))\n",
    "val_index= list(range(1300,1604))\n",
    "# train_index=list(range(304,1604)) \n",
    "# val_index= list(range(304))\n",
    "train_X[train_index].shape\n",
    "\n",
    "train_mean, train_std = transform_compute(train_X[train_index])\n",
    "train_transform = T.Compose([\n",
    "    T.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "train_dataset = iceberg_dataset(data= train_X[train_index], label=train_y[train_index], transform=train_transform)\n",
    "val_dataset = iceberg_dataset(data= train_X[val_index], label=train_y[val_index], transform=train_transform, test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.from_numpy(train_X).type(torch.FloatTensor)[1].shape\n",
    "train_X[1]\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,early_stopping = None):\n",
    "    global train_data#,out,y,predicted\n",
    "    best_acc =0\n",
    "    best_val_loss= 100\n",
    "    loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    train_data={}\n",
    "    train_data['loss_hist'] = loss_hist\n",
    "    train_data['val_loss_hist'] = val_loss_hist\n",
    "    train_data['train_acc_hist'] = train_acc_hist\n",
    "    train_data['val_acc_hist'] =  val_acc_hist\n",
    "    e_s= 0\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        print('\\nThis is epoch:{}'.format(i+1))\n",
    "        total= 0\n",
    "        correct=0\n",
    "        loss_avg= 0\n",
    "        scheduler.step()\n",
    "        net.train()\n",
    "        for j,(batch_x, batch_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "            x = Variable(batch_x)\n",
    "            y = Variable(batch_y)\n",
    "            out = net(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y.data).cpu().sum()\n",
    "            progress_bar(j, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "            if j % 5==0:\n",
    "                loss_hist.append(loss_avg/total)\n",
    "            \n",
    "        train_acc_hist.append(100.*correct/total)\n",
    "        e_s+=1\n",
    "        if i %1 == 0:\n",
    "            acc, val_loss = test(val_loader)\n",
    "            val_acc_hist.append(acc)\n",
    "            if acc >=best_acc:\n",
    "                best_acc= acc\n",
    "                e_s = 0\n",
    "                torch.save(net.state_dict(), 'densenetbc100.pth')\n",
    "#             if best_val_loss >= val_loss:\n",
    "#                 best_val_loss= val_loss\n",
    "#                 torch.save(net.state_dict(), 'resnet34_loss%d.pth'%i)\n",
    "        if early_stopping is not None and e_s >= early_stopping:\n",
    "            return best_acc,i\n",
    "\n",
    "    return best_acc,i\n",
    "#         if i%50==0 and save:\n",
    "#             torch.save(net.state_dict(), 'resnet50.pth')\n",
    "        \n",
    "def test(val_load):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_avg= 0\n",
    "    for k, (val_x, val_y) in enumerate(val_load):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "        #print(out.size())\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += predicted.eq(y.data).cpu().sum()\n",
    "        total += out.size()[0]\n",
    "        progress_bar(k, len(val_load), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "    train_data['val_loss_hist'].append(loss_avg/total) #also keep track of loss of val set\n",
    "    acc =  (correct*100.0)/total\n",
    "    return acc,loss_avg/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 236ms | Tot: 13s873ms | Loss: 0.656 | Acc: 64.846% (843/1300)\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 664ms | Loss: 0.935 | Acc: 53.618% (163/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 237ms | Tot: 13s919ms | Loss: 0.508 | Acc: 76.308% (992/1300)\n",
      "[=================== 5/5 ============>........]  Step: 140ms | Tot: 669ms | Loss: 1.496 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 240ms | Tot: 13s914ms | Loss: 0.467 | Acc: 78.231% (1017/1300)\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 664ms | Loss: 1.558 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 236ms | Tot: 13s915ms | Loss: 0.444 | Acc: 79.846% (1038/1300)\n",
      "[=================== 5/5 ============>........]  Step: 140ms | Tot: 669ms | Loss: 0.874 | Acc: 46.711% (142/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 235ms | Tot: 13s920ms | Loss: 0.454 | Acc: 79.846% (1038/1300)\n",
      "[=================== 5/5 ============>........]  Step: 139ms | Tot: 666ms | Loss: 1.805 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 238ms | Tot: 14s50ms | Loss: 0.422 | Acc: 81.154% (1055/1300))\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 664ms | Loss: 1.520 | Acc: 33.882% (103/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 237ms | Tot: 13s901ms | Loss: 0.383 | Acc: 82.385% (1071/1300)\n",
      "[=================== 5/5 ============>........]  Step: 140ms | Tot: 669ms | Loss: 1.783 | Acc: 42.434% (129/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 240ms | Tot: 13s912ms | Loss: 0.389 | Acc: 83.385% (1084/1300)\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 661ms | Loss: 1.372 | Acc: 40.461% (123/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 240ms | Tot: 13s910ms | Loss: 0.384 | Acc: 83.385% (1084/1300)\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 668ms | Loss: 2.652 | Acc: 34.868% (106/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 237ms | Tot: 13s930ms | Loss: 0.388 | Acc: 82.923% (1078/1300)\n",
      "[=================== 5/5 ============>........]  Step: 138ms | Tot: 666ms | Loss: 1.954 | Acc: 41.118% (125/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 235ms | Tot: 13s910ms | Loss: 0.375 | Acc: 82.923% (1078/1300)\n",
      "[=================== 5/5 ============>........]  Step: 139ms | Tot: 665ms | Loss: 1.208 | Acc: 46.053% (140/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 240ms | Tot: 13s939ms | Loss: 0.330 | Acc: 85.154% (1107/1300)\n",
      "[=================== 5/5 ============>........]  Step: 140ms | Tot: 666ms | Loss: 1.190 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 236ms | Tot: 14s49ms | Loss: 0.360 | Acc: 84.846% (1103/1300))\n",
      "[=================== 5/5 ============>........]  Step: 137ms | Tot: 664ms | Loss: 2.181 | Acc: 39.474% (120/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 34/41 ==========>........]  Step: 352ms | Tot: 11s563ms | Loss: 0.305 | Acc: 86.029% (936/1088)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-406:\n",
      "KeyboardInterrupt\n",
      "Process Process-408:\n",
      "Process Process-407:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbad5809390c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     cudnn.benchmark = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fd77ad76f8ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, early_stopping)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    }
   ],
   "source": [
    "densebc100 = densenetBC.DenseNet3(depth=100,num_classes=2,dropRate=0.2)\n",
    "net= densebc100\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Adam does not perform so good here   \n",
    "#(0.1, 0.0001) (50, 80, 110, 170) 52 epoch reaches the maximum.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov= True)\n",
    "scheduler = MultiStepLR(optimizer, [100, 150,200], gamma=0.1)\n",
    "#5e-3 86\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "    net.cuda()\n",
    "#     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "#     cudnn.benchmark = True   \n",
    "\n",
    "train(epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 511ms | Tot: 17s521ms | Loss: 0.130 | Acc: 94.692% (1231/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 842ms | Loss: 0.193 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 503ms | Tot: 17s566ms | Loss: 0.119 | Acc: 95.308% (1239/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 843ms | Loss: 0.195 | Acc: 93.421% (284/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 503ms | Tot: 17s546ms | Loss: 0.120 | Acc: 95.000% (1235/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 845ms | Loss: 0.199 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 505ms | Tot: 17s535ms | Loss: 0.119 | Acc: 95.538% (1242/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 840ms | Loss: 0.199 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 514ms | Tot: 17s535ms | Loss: 0.114 | Acc: 95.308% (1239/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 841ms | Loss: 0.204 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s544ms | Loss: 0.108 | Acc: 95.692% (1244/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 841ms | Loss: 0.205 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s562ms | Loss: 0.119 | Acc: 95.692% (1244/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 840ms | Loss: 0.206 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 511ms | Tot: 17s532ms | Loss: 0.119 | Acc: 95.385% (1240/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 843ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 510ms | Tot: 17s522ms | Loss: 0.117 | Acc: 96.000% (1248/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 835ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 510ms | Tot: 17s512ms | Loss: 0.113 | Acc: 95.615% (1243/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 841ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 506ms | Tot: 17s520ms | Loss: 0.129 | Acc: 94.462% (1228/1300)\n",
      "[=================== 5/5 ============>........]  Step: 186ms | Tot: 837ms | Loss: 0.210 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 505ms | Tot: 17s521ms | Loss: 0.114 | Acc: 96.923% (1260/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 850ms | Loss: 0.204 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s536ms | Loss: 0.115 | Acc: 95.385% (1240/1300)\n",
      "[=================== 5/5 ============>........]  Step: 186ms | Tot: 834ms | Loss: 0.200 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s507ms | Loss: 0.110 | Acc: 95.923% (1247/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 843ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s529ms | Loss: 0.121 | Acc: 95.615% (1243/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 839ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 506ms | Tot: 17s540ms | Loss: 0.117 | Acc: 95.231% (1238/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 844ms | Loss: 0.210 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s529ms | Loss: 0.108 | Acc: 96.154% (1250/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 838ms | Loss: 0.207 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 511ms | Tot: 17s521ms | Loss: 0.113 | Acc: 95.923% (1247/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 840ms | Loss: 0.210 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s540ms | Loss: 0.114 | Acc: 95.769% (1245/1300)\n",
      "[=================== 5/5 ============>........]  Step: 185ms | Tot: 840ms | Loss: 0.208 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 504ms | Tot: 17s518ms | Loss: 0.121 | Acc: 95.154% (1237/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 843ms | Loss: 0.209 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s518ms | Loss: 0.128 | Acc: 94.923% (1234/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 842ms | Loss: 0.210 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 510ms | Tot: 17s551ms | Loss: 0.105 | Acc: 95.692% (1244/1300)\n",
      "[=================== 5/5 ============>........]  Step: 191ms | Tot: 845ms | Loss: 0.207 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s528ms | Loss: 0.108 | Acc: 96.154% (1250/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 841ms | Loss: 0.213 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 502ms | Tot: 17s522ms | Loss: 0.112 | Acc: 96.000% (1248/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 833ms | Loss: 0.204 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s529ms | Loss: 0.113 | Acc: 95.846% (1246/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 840ms | Loss: 0.208 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 506ms | Tot: 17s516ms | Loss: 0.116 | Acc: 95.769% (1245/1300)\n",
      "[=================== 5/5 ============>........]  Step: 186ms | Tot: 840ms | Loss: 0.210 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s519ms | Loss: 0.118 | Acc: 95.385% (1240/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 834ms | Loss: 0.207 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 510ms | Tot: 17s547ms | Loss: 0.135 | Acc: 94.923% (1234/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 843ms | Loss: 0.208 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 502ms | Tot: 17s526ms | Loss: 0.118 | Acc: 95.231% (1238/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 850ms | Loss: 0.208 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 515ms | Tot: 17s532ms | Loss: 0.111 | Acc: 96.154% (1250/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 841ms | Loss: 0.207 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s540ms | Loss: 0.111 | Acc: 95.846% (1246/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 838ms | Loss: 0.209 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s533ms | Loss: 0.116 | Acc: 95.692% (1244/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 843ms | Loss: 0.207 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s530ms | Loss: 0.112 | Acc: 96.077% (1249/1300)\n",
      "[=================== 5/5 ============>........]  Step: 186ms | Tot: 837ms | Loss: 0.209 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 504ms | Tot: 17s546ms | Loss: 0.117 | Acc: 95.385% (1240/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 840ms | Loss: 0.201 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s535ms | Loss: 0.117 | Acc: 95.615% (1243/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 836ms | Loss: 0.212 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s538ms | Loss: 0.111 | Acc: 95.846% (1246/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 842ms | Loss: 0.210 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s566ms | Loss: 0.119 | Acc: 95.231% (1238/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 844ms | Loss: 0.202 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 504ms | Tot: 17s517ms | Loss: 0.107 | Acc: 96.385% (1253/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 842ms | Loss: 0.209 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 506ms | Tot: 17s529ms | Loss: 0.120 | Acc: 95.692% (1244/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 843ms | Loss: 0.207 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s541ms | Loss: 0.112 | Acc: 95.769% (1245/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 843ms | Loss: 0.206 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 510ms | Tot: 17s524ms | Loss: 0.122 | Acc: 94.846% (1233/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 844ms | Loss: 0.212 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s524ms | Loss: 0.117 | Acc: 96.077% (1249/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 847ms | Loss: 0.208 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 507ms | Tot: 17s542ms | Loss: 0.114 | Acc: 96.000% (1248/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 839ms | Loss: 0.206 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s527ms | Loss: 0.118 | Acc: 95.846% (1246/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 841ms | Loss: 0.210 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 508ms | Tot: 17s511ms | Loss: 0.114 | Acc: 95.308% (1239/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 845ms | Loss: 0.203 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 502ms | Tot: 17s536ms | Loss: 0.124 | Acc: 95.308% (1239/1300)\n",
      "[=================== 5/5 ============>........]  Step: 187ms | Tot: 843ms | Loss: 0.211 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 512ms | Tot: 17s531ms | Loss: 0.108 | Acc: 95.769% (1245/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 839ms | Loss: 0.207 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 504ms | Tot: 17s535ms | Loss: 0.122 | Acc: 94.846% (1233/1300)\n",
      "[=================== 5/5 ============>........]  Step: 188ms | Tot: 840ms | Loss: 0.206 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 509ms | Tot: 17s537ms | Loss: 0.114 | Acc: 95.769% (1245/1300)\n",
      "[=================== 5/5 ============>........]  Step: 189ms | Tot: 844ms | Loss: 0.204 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 511ms | Tot: 17s533ms | Loss: 0.115 | Acc: 95.308% (1239/1300)\n",
      "[=================== 5/5 ============>........]  Step: 190ms | Tot: 843ms | Loss: 0.213 | Acc: 92.105% (280/304)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.42105263157895, 49)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##For continue training\n",
    "resnet34 = resnet.resnet34(num_classes=2)\n",
    "net= resnet34\n",
    "net.load_state_dict(torch.load('resnet34_acc117.pth'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Adam does not perform so good here\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov= True)\n",
    "scheduler = MultiStepLR(optimizer, [20,40], gamma=0.1)\n",
    "#5e-3 86\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "    net.cuda()\n",
    "#     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "#     cudnn.benchmark = True   \n",
    "\n",
    "train(epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8UAAAJwCAYAAACgQsMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njgrOrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82c8077358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "\n",
    "gs = gridspec.GridSpec(2,1)\n",
    "gs.update(hspace=0.5)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "fig1 = fig.add_subplot(gs[0,0])\n",
    "fig2 = fig.add_subplot(gs[1,0])\n",
    "fig1.spines['right'].set_visible(False)\n",
    "fig1.spines['top'].set_visible(False)\n",
    "# for item in [fig1.xaxis.label, fig1.yaxis.label,fig2.xaxis.label, fig2.yaxis.label]:\n",
    "#     item.set_fontsize(10)\n",
    "\n",
    "\n",
    "# fig1.plot([i * 0.005 for i in range(1,len(train_data['loss_hist'])+1)],train_data['loss_hist'],color='black')\n",
    "fig1.plot([i * 0.005 for i in range(1,len(train_data['val_loss_hist'])+1)],train_data['val_loss_hist'],color='red')\n",
    "fig1.set(title= 'Loss trajectory of training',ylabel='Loss',xlabel='Iter.(1e4)',ylim=(0,0.4))\n",
    "\n",
    "fig2.plot([100-i for i in train_data['train_acc_hist']], color='red',linestyle='-.',label = 'train')\n",
    "fig2.plot([100-i for i in train_data['val_acc_hist']], color='green',linestyle='-',label='val')\n",
    "fig2.legend(frameon=True)\n",
    "fig2.spines['right'].set_visible(False)\n",
    "fig2.spines['top'].set_visible(False)\n",
    "fig2.axhline(y=[5],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "fig2.axhline(y=[10],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "_=fig2.set(title= 'Top-1 Accuracy of Resnet18',ylim=(0,20),xlabel='Epoch',ylabel='Error(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8UAAAJwCAYAAACgQsMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngwOZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82cb8d6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "\n",
    "gs = gridspec.GridSpec(2,1)\n",
    "gs.update(hspace=0.5)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "fig1 = fig.add_subplot(gs[0,0])\n",
    "fig2 = fig.add_subplot(gs[1,0])\n",
    "fig1.spines['right'].set_visible(False)\n",
    "fig1.spines['top'].set_visible(False)\n",
    "# for item in [fig1.xaxis.label, fig1.yaxis.label,fig2.xaxis.label, fig2.yaxis.label]:\n",
    "#     item.set_fontsize(10)\n",
    "\n",
    "\n",
    "# fig1.plot([i * 0.005 for i in range(1,len(train_data['loss_hist'])+1)],train_data['loss_hist'],color='black')\n",
    "fig1.plot([i * 0.005 for i in range(1,len(train_data['val_loss_hist'])+1)],train_data['val_loss_hist'],color='red')\n",
    "fig1.set(title= 'Loss trajectory of training',ylabel='Loss',xlabel='Iter.(1e4)',ylim=(0,0.4))\n",
    "\n",
    "fig2.plot([100-i for i in train_data['train_acc_hist']], color='red',linestyle='-.',label = 'train')\n",
    "fig2.plot([100-i for i in train_data['val_acc_hist']], color='green',linestyle='-',label='val')\n",
    "fig2.legend(frameon=True)\n",
    "fig2.spines['right'].set_visible(False)\n",
    "fig2.spines['top'].set_visible(False)\n",
    "fig2.axhline(y=[5],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "fig2.axhline(y=[10],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "_=fig2.set(title= 'Top-1 Accuracy of Resnet18',ylim=(0,20),xlabel='Epoch',ylabel='Error(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |        lr |        wd | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s44ms | Loss: 3.181 | Acc: 57.462% (747/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 45.076 | Acc: 35.526% (108/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.792 | Acc: 61.154% (795/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.824 | Acc: 46.711% (142/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s27ms | Loss: 0.662 | Acc: 64.385% (837/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.670 | Acc: 55.592% (169/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s4ms | Loss: 0.744 | Acc: 62.923% (818/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.667 | Acc: 57.237% (174/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.568 | Acc: 69.846% (908/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.758 | Acc: 48.026% (146/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s19ms | Loss: 0.589 | Acc: 69.000% (897/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.635 | Acc: 59.211% (180/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 0.606 | Acc: 68.231% (887/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.791 | Acc: 58.224% (177/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s994ms | Loss: 0.610 | Acc: 68.769% (894/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.544 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s37ms | Loss: 0.584 | Acc: 68.923% (896/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.569 | Acc: 64.474% (196/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.565 | Acc: 72.154% (938/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.564 | Acc: 64.803% (197/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s1ms | Loss: 0.552 | Acc: 71.692% (932/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.646 | Acc: 62.171% (189/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s8ms | Loss: 0.555 | Acc: 71.769% (933/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.663 | Acc: 62.171% (189/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s14ms | Loss: 0.526 | Acc: 73.769% (959/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.549 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s7ms | Loss: 0.512 | Acc: 73.462% (955/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.580 | Acc: 63.158% (192/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.521 | Acc: 72.308% (940/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.561 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s6ms | Loss: 0.508 | Acc: 74.000% (962/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.660 | Acc: 60.197% (183/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.493 | Acc: 75.385% (980/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.710 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.461 | Acc: 77.000% (1001/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.511 | Acc: 72.039% (219/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s13ms | Loss: 0.424 | Acc: 79.385% (1032/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.535 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s5ms | Loss: 0.449 | Acc: 80.846% (1051/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 1.117 | Acc: 64.803% (197/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.411 | Acc: 80.846% (1051/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.591 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.389 | Acc: 82.154% (1068/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.737 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s13ms | Loss: 0.395 | Acc: 82.538% (1073/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.462 | Acc: 74.342% (226/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s15ms | Loss: 0.361 | Acc: 84.846% (1103/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.402 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.375 | Acc: 83.231% (1082/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 0.485 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.375 | Acc: 83.077% (1080/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.382 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.329 | Acc: 84.769% (1102/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.356 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.346 | Acc: 83.231% (1082/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.454 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s21ms | Loss: 0.332 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 638ms | Loss: 0.423 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.327 | Acc: 85.385% (1110/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.496 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.298 | Acc: 85.385% (1110/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.369 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.309 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.331 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s30ms | Loss: 0.292 | Acc: 87.538% (1138/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.320 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.273 | Acc: 88.538% (1151/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.348 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.271 | Acc: 88.231% (1147/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.337 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 0.279 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.341 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.286 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.353 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.272 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.302 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.266 | Acc: 87.846% (1142/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.304 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.266 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.316 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s13ms | Loss: 0.264 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.297 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.280 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.305 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.261 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 630ms | Loss: 0.361 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s22ms | Loss: 0.261 | Acc: 88.308% (1148/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.337 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.274 | Acc: 87.154% (1133/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.335 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s34ms | Loss: 0.261 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.351 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.256 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.298 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s24ms | Loss: 0.265 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.327 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.266 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.302 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.263 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.319 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.283 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.326 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s23ms | Loss: 0.263 | Acc: 88.846% (1155/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.334 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.260 | Acc: 88.538% (1151/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.368 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s19ms | Loss: 0.258 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.321 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s13ms | Loss: 0.252 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.349 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.242 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.352 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.241 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.370 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.257 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.350 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.259 | Acc: 88.846% (1155/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.296 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.269 | Acc: 88.692% (1153/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.335 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.255 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.318 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s15ms | Loss: 0.251 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.310 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.238 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.338 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s31ms | Loss: 0.224 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.297 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.241 | Acc: 89.769% (1167/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.297 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.237 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.307 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.243 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.318 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.249 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.299 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.245 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.285 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.232 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.288 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s25ms | Loss: 0.252 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.307 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.235 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.232 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.281 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.231 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.288 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.239 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.298 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s31ms | Loss: 0.246 | Acc: 89.462% (1163/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.284 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.225 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.282 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.229 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.295 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:79\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.228 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.290 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:80\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s4ms | Loss: 0.240 | Acc: 90.308% (1174/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.305 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:81\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s19ms | Loss: 0.235 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.286 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:82\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.239 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.297 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:83\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.226 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.293 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:84\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.250 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.277 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:85\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s36ms | Loss: 0.229 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.287 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:86\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.229 | Acc: 89.769% (1167/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.286 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:87\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s7ms | Loss: 0.223 | Acc: 90.462% (1176/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.277 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:88\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s5ms | Loss: 0.229 | Acc: 90.077% (1171/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.296 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:89\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s13ms | Loss: 0.244 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.294 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:90\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s20ms | Loss: 0.222 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.289 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:91\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s12ms | Loss: 0.216 | Acc: 91.769% (1193/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.296 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:92\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.228 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.288 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:93\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s4ms | Loss: 0.246 | Acc: 90.154% (1172/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.287 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:94\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.227 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.282 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:95\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.234 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.295 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:96\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s27ms | Loss: 0.229 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.280 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:97\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.218 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.288 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:98\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.228 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:99\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.228 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.304 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:100\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 0.230 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.272 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:101\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.229 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.286 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:102\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.235 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.286 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:103\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s24ms | Loss: 0.225 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.286 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:104\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.228 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.286 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:105\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.224 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.288 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:106\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.231 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.285 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:107\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s20ms | Loss: 0.223 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.282 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:108\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.242 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.298 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:109\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.235 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.284 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:110\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s38ms | Loss: 0.228 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.284 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:111\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.242 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.287 | Acc: 88.158% (268/304)\n",
      "    1 | 30m48s | \u001b[35m  88.15789\u001b[0m | \u001b[32m   0.1000\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s32ms | Loss: 0.537 | Acc: 72.308% (940/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.941 | Acc: 70.724% (215/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.474 | Acc: 77.231% (1004/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.700 | Acc: 74.671% (227/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.397 | Acc: 82.846% (1077/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.482 | Acc: 74.671% (227/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.380 | Acc: 83.077% (1080/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.454 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s31ms | Loss: 0.341 | Acc: 84.538% (1099/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 638ms | Loss: 0.363 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.315 | Acc: 85.923% (1117/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.353 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.302 | Acc: 86.615% (1126/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.399 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.312 | Acc: 86.077% (1119/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.429 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.286 | Acc: 88.231% (1147/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.373 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.278 | Acc: 88.154% (1146/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.624 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.264 | Acc: 88.692% (1153/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.376 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s52ms | Loss: 0.259 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.521 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.238 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.849 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s39ms | Loss: 0.267 | Acc: 88.615% (1152/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.497 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s24ms | Loss: 0.236 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.511 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.328 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.328 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.263 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.283 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.235 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.279 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.230 | Acc: 90.462% (1176/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.250 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s45ms | Loss: 0.184 | Acc: 93.077% (1210/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.394 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.209 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.571 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.208 | Acc: 91.692% (1192/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.444 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s41ms | Loss: 0.191 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.264 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.202 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.284 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.176 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.352 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.162 | Acc: 93.308% (1213/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.386 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s48ms | Loss: 0.343 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.398 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 432ms | Tot: 15s52ms | Loss: 0.207 | Acc: 92.231% (1199/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.305 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s52ms | Loss: 0.170 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.241 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.161 | Acc: 93.615% (1217/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.334 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.145 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.340 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s53ms | Loss: 0.125 | Acc: 95.385% (1240/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.322 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.118 | Acc: 95.692% (1244/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.359 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.109 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 639ms | Loss: 0.330 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.119 | Acc: 95.077% (1236/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.362 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.102 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.359 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.098 | Acc: 96.231% (1251/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.322 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.108 | Acc: 95.923% (1247/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 639ms | Loss: 0.330 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.085 | Acc: 96.923% (1260/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.315 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.071 | Acc: 97.692% (1270/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.354 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s78ms | Loss: 0.091 | Acc: 97.077% (1262/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.381 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.066 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.375 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.064 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.411 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s52ms | Loss: 0.072 | Acc: 97.462% (1267/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.360 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s44ms | Loss: 0.063 | Acc: 98.000% (1274/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.347 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s50ms | Loss: 0.073 | Acc: 97.538% (1268/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.407 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.051 | Acc: 98.615% (1282/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.455 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s51ms | Loss: 0.059 | Acc: 98.154% (1276/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.410 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s59ms | Loss: 0.056 | Acc: 98.077% (1275/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.377 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.057 | Acc: 98.231% (1277/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.456 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.056 | Acc: 97.846% (1272/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.398 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s36ms | Loss: 0.050 | Acc: 98.308% (1278/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.465 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.040 | Acc: 98.923% (1286/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.408 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s34ms | Loss: 0.048 | Acc: 98.462% (1280/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.401 | Acc: 87.829% (267/304)\n",
      "    2 | 15m01s | \u001b[35m  89.47368\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s55ms | Loss: 0.606 | Acc: 64.846% (843/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.662 | Acc: 57.895% (176/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.519 | Acc: 72.769% (946/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.557 | Acc: 66.776% (203/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s52ms | Loss: 0.498 | Acc: 76.385% (993/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.543 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s59ms | Loss: 0.437 | Acc: 79.769% (1037/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.546 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.420 | Acc: 81.538% (1060/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.517 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.387 | Acc: 83.231% (1082/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.461 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.388 | Acc: 82.615% (1074/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.547 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.387 | Acc: 83.000% (1079/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.459 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.368 | Acc: 84.385% (1097/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.505 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.357 | Acc: 85.077% (1106/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.404 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.348 | Acc: 85.000% (1105/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.450 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.321 | Acc: 86.923% (1130/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.483 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.319 | Acc: 86.000% (1118/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.337 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.311 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.498 | Acc: 77.632% (236/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.314 | Acc: 86.385% (1123/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.391 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.307 | Acc: 86.846% (1129/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.320 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.299 | Acc: 87.846% (1142/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.470 | Acc: 75.329% (229/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.270 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.352 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.265 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.307 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.271 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.446 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.275 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.341 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.268 | Acc: 88.538% (1151/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.512 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.235 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.310 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.228 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.302 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.235 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.340 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.222 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.328 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.229 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.300 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.207 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.333 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.203 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.280 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.218 | Acc: 91.154% (1185/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.300 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.178 | Acc: 93.462% (1215/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.346 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.182 | Acc: 92.923% (1208/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.317 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.177 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.332 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.175 | Acc: 93.462% (1215/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.299 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s54ms | Loss: 0.163 | Acc: 93.385% (1214/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.303 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.171 | Acc: 93.077% (1210/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.303 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.186 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.314 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.157 | Acc: 94.692% (1231/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.326 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.164 | Acc: 93.846% (1220/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.335 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.163 | Acc: 93.846% (1220/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.314 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s59ms | Loss: 0.157 | Acc: 94.077% (1223/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.327 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.155 | Acc: 94.538% (1229/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.313 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.166 | Acc: 94.154% (1224/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.362 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.153 | Acc: 94.692% (1231/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.312 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.141 | Acc: 95.462% (1241/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.322 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s52ms | Loss: 0.154 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.299 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.154 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.289 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s32ms | Loss: 0.152 | Acc: 94.308% (1226/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.310 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.147 | Acc: 94.769% (1232/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.388 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.149 | Acc: 95.000% (1235/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.332 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s28ms | Loss: 0.143 | Acc: 95.769% (1245/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.319 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.146 | Acc: 95.077% (1236/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.339 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.143 | Acc: 94.462% (1228/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.320 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.181 | Acc: 93.231% (1212/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.360 | Acc: 83.882% (255/304)\n",
      "    3 | 15m01s |   88.48684 |    0.0010 |    0.0001 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 2.836 | Acc: 58.462% (760/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 2.024 | Acc: 50.658% (154/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.637 | Acc: 64.923% (844/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.621 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s75ms | Loss: 0.666 | Acc: 69.615% (905/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 2.353 | Acc: 50.329% (153/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s47ms | Loss: 0.592 | Acc: 65.923% (857/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.733 | Acc: 46.711% (142/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s28ms | Loss: 0.570 | Acc: 68.615% (892/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.613 | Acc: 57.237% (174/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s18ms | Loss: 0.498 | Acc: 74.308% (966/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.653 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.473 | Acc: 76.154% (990/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.646 | Acc: 61.842% (188/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.535 | Acc: 73.538% (956/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.544 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.439 | Acc: 79.077% (1028/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.539 | Acc: 70.066% (213/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.372 | Acc: 83.231% (1082/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.528 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.362 | Acc: 83.308% (1083/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.465 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s28ms | Loss: 0.317 | Acc: 86.231% (1121/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.532 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.367 | Acc: 82.615% (1074/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.488 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.315 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.378 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.335 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.600 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.318 | Acc: 84.385% (1097/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.369 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.295 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.612 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.286 | Acc: 88.231% (1147/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.363 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.288 | Acc: 86.846% (1129/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.398 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s49ms | Loss: 0.296 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.398 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.305 | Acc: 86.000% (1118/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.583 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.274 | Acc: 87.538% (1138/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.440 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.304 | Acc: 86.769% (1128/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.304 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.267 | Acc: 88.077% (1145/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.288 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.281 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.283 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s25ms | Loss: 0.282 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.281 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.268 | Acc: 87.615% (1139/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.303 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.269 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.402 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.330 | Acc: 86.462% (1124/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.398 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.262 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.793 | Acc: 63.487% (193/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.261 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.371 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.225 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.272 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.246 | Acc: 89.000% (1157/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.275 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.228 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.281 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s39ms | Loss: 0.214 | Acc: 91.769% (1193/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.256 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.221 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.261 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.217 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.279 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.217 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.286 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s48ms | Loss: 0.215 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.261 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.207 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.256 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.198 | Acc: 91.385% (1188/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.258 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.213 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.246 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s52ms | Loss: 0.209 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.269 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.211 | Acc: 91.769% (1193/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.287 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.200 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.248 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.201 | Acc: 92.231% (1199/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.262 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.207 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.250 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.200 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.278 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.207 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 638ms | Loss: 0.258 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s53ms | Loss: 0.202 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.267 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.197 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.280 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.212 | Acc: 91.692% (1192/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.286 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.192 | Acc: 92.385% (1201/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.291 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.201 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.280 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.189 | Acc: 92.385% (1201/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 638ms | Loss: 0.280 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s39ms | Loss: 0.195 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.308 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.197 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.293 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s25ms | Loss: 0.184 | Acc: 93.000% (1209/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.253 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.200 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.280 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.195 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.250 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.177 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.271 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.185 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.267 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.170 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.266 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.182 | Acc: 92.769% (1206/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.263 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.173 | Acc: 94.077% (1223/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.254 | Acc: 90.132% (274/304)\n",
      "    4 | 18m05s | \u001b[35m  91.11842\u001b[0m | \u001b[32m   0.1000\u001b[0m | \u001b[32m   0.0010\u001b[0m | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.665 | Acc: 68.538% (891/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.617 | Acc: 63.158% (192/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s62ms | Loss: 0.440 | Acc: 80.462% (1046/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.507 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.399 | Acc: 81.308% (1057/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.632 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.374 | Acc: 83.769% (1089/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.482 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.348 | Acc: 85.077% (1106/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.744 | Acc: 58.882% (179/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.327 | Acc: 85.385% (1110/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.346 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.289 | Acc: 87.154% (1133/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.311 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.296 | Acc: 87.077% (1132/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.397 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.284 | Acc: 87.385% (1136/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.416 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.263 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.476 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.254 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.324 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.265 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.301 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s27ms | Loss: 0.240 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.256 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s38ms | Loss: 0.238 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 1.587 | Acc: 52.632% (160/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s41ms | Loss: 0.268 | Acc: 88.923% (1156/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.361 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s51ms | Loss: 0.245 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.672 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.288 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.291 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.238 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.319 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.267 | Acc: 88.615% (1152/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.631 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.267 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 643ms | Loss: 0.318 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.217 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.366 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.221 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.351 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.205 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.490 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.210 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.752 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.216 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.411 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.213 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.309 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.183 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.311 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.190 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.814 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.205 | Acc: 92.308% (1200/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.255 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s44ms | Loss: 0.175 | Acc: 93.308% (1213/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.410 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.166 | Acc: 92.769% (1206/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.274 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.145 | Acc: 94.462% (1228/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.309 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s54ms | Loss: 0.131 | Acc: 95.385% (1240/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.298 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.113 | Acc: 95.615% (1243/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.295 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.102 | Acc: 95.923% (1247/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.295 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.122 | Acc: 95.462% (1241/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.315 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.105 | Acc: 95.923% (1247/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.313 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.097 | Acc: 96.692% (1257/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.273 | Acc: 88.816% (270/304)\n",
      "    5 | 10m34s |   89.47368 |    0.0100 |    0.0020 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s52ms | Loss: 0.582 | Acc: 67.308% (875/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.737 | Acc: 56.250% (171/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.518 | Acc: 73.154% (951/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.610 | Acc: 64.474% (196/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.486 | Acc: 76.538% (995/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.589 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.443 | Acc: 79.923% (1039/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.496 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.426 | Acc: 80.462% (1046/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.473 | Acc: 74.342% (226/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.389 | Acc: 83.077% (1080/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.485 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.376 | Acc: 83.385% (1084/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.514 | Acc: 71.382% (217/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.368 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.465 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.365 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.428 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.330 | Acc: 86.462% (1124/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.355 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.325 | Acc: 85.692% (1114/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.381 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.319 | Acc: 85.846% (1116/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.364 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.325 | Acc: 86.538% (1125/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.449 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s40ms | Loss: 0.294 | Acc: 88.692% (1153/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.400 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.286 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.610 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.292 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.355 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.286 | Acc: 88.308% (1148/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.323 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.271 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.609 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.269 | Acc: 88.846% (1155/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.395 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.269 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.406 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.264 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.458 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s49ms | Loss: 0.244 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.271 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s45ms | Loss: 0.235 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.310 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.224 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.386 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.226 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.359 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s52ms | Loss: 0.216 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.294 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.206 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.339 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s25ms | Loss: 0.216 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.489 | Acc: 75.987% (231/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s59ms | Loss: 0.185 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.412 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.212 | Acc: 92.231% (1199/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.603 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.183 | Acc: 93.000% (1209/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.319 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s15ms | Loss: 0.169 | Acc: 93.769% (1219/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.321 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.162 | Acc: 94.154% (1224/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.322 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s57ms | Loss: 0.161 | Acc: 93.462% (1215/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.306 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.149 | Acc: 94.385% (1227/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.305 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s33ms | Loss: 0.149 | Acc: 94.538% (1229/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.287 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s59ms | Loss: 0.184 | Acc: 93.231% (1212/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.345 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s67ms | Loss: 0.167 | Acc: 93.769% (1219/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.310 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.148 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.320 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.146 | Acc: 95.000% (1235/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.340 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s58ms | Loss: 0.155 | Acc: 94.385% (1227/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.309 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.157 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.318 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.163 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.327 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.157 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.313 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.156 | Acc: 94.000% (1222/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.316 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s34ms | Loss: 0.153 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.332 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.144 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.315 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s43ms | Loss: 0.146 | Acc: 95.077% (1236/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.324 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s45ms | Loss: 0.132 | Acc: 95.154% (1237/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.319 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s47ms | Loss: 0.142 | Acc: 94.385% (1227/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.314 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.143 | Acc: 94.692% (1231/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.294 | Acc: 86.513% (263/304)\n",
      "    6 | 14m11s |   88.15789 |    0.0010 |    0.0030 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 1.168 | Acc: 63.077% (820/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.765 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.517 | Acc: 75.231% (978/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.706 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.657 | Acc: 63.000% (819/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.702 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s24ms | Loss: 0.620 | Acc: 65.846% (856/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 81.578 | Acc: 65.461% (199/304))\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s18ms | Loss: 0.634 | Acc: 63.385% (824/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.691 | Acc: 45.066% (137/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.585 | Acc: 69.308% (901/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.731 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s15ms | Loss: 0.604 | Acc: 65.538% (852/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.717 | Acc: 41.118% (125/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s17ms | Loss: 0.624 | Acc: 66.615% (866/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 12.983 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.626 | Acc: 66.154% (860/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.739 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.620 | Acc: 66.385% (863/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.772 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.638 | Acc: 59.231% (770/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.685 | Acc: 61.184% (186/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s4ms | Loss: 0.689 | Acc: 51.769% (673/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.663 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s10ms | Loss: 0.692 | Acc: 50.923% (662/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.702 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.694 | Acc: 49.923% (649/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.713 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.696 | Acc: 48.692% (633/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.691 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s6ms | Loss: 0.694 | Acc: 47.923% (623/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 637ms | Loss: 0.700 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s7ms | Loss: 0.696 | Acc: 49.462% (643/1300)0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.708 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.694 | Acc: 52.385% (681/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.740 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.698 | Acc: 48.846% (635/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.683 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.695 | Acc: 50.231% (653/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.687 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.696 | Acc: 51.308% (667/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.658 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s27ms | Loss: 0.697 | Acc: 48.538% (631/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.678 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s1ms | Loss: 0.694 | Acc: 46.692% (607/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.697 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s | Loss: 0.694 | Acc: 49.462% (643/1300)1280)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.687 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s7ms | Loss: 0.695 | Acc: 46.231% (601/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.685 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.693 | Acc: 51.615% (671/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.738 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s11ms | Loss: 0.696 | Acc: 48.692% (633/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.697 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s999ms | Loss: 0.694 | Acc: 49.308% (641/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.705 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s6ms | Loss: 0.695 | Acc: 49.000% (637/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.688 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s13ms | Loss: 0.694 | Acc: 49.154% (639/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.679 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.694 | Acc: 49.923% (649/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.689 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.693 | Acc: 47.923% (623/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.693 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s17ms | Loss: 0.694 | Acc: 49.308% (641/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.692 | Acc: 66.447% (202/304)\n",
      "    7 | 09m10s |   66.44737 |    0.0471 |    0.0626 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 1.867 | Acc: 57.077% (742/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.756 | Acc: 39.803% (121/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s53ms | Loss: 0.574 | Acc: 69.308% (901/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.763 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.532 | Acc: 73.615% (957/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.880 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.485 | Acc: 76.923% (1000/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 1.161 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s24ms | Loss: 0.697 | Acc: 61.538% (800/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.641 | Acc: 56.908% (173/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s53ms | Loss: 0.633 | Acc: 65.231% (848/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.678 | Acc: 49.671% (151/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 0.594 | Acc: 67.538% (878/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.712 | Acc: 54.605% (166/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.530 | Acc: 73.846% (960/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.692 | Acc: 56.579% (172/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.501 | Acc: 75.231% (978/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.954 | Acc: 56.908% (173/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s5ms | Loss: 0.479 | Acc: 78.000% (1014/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 1.022 | Acc: 41.776% (127/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s20ms | Loss: 0.497 | Acc: 76.538% (995/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.571 | Acc: 68.421% (208/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s995ms | Loss: 0.476 | Acc: 78.769% (1024/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.934 | Acc: 41.118% (125/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.538 | Acc: 72.846% (947/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 12.886 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s15ms | Loss: 0.605 | Acc: 64.077% (833/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.653 | Acc: 50.658% (154/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s2ms | Loss: 0.579 | Acc: 69.385% (902/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 0.656 | Acc: 51.645% (157/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s4ms | Loss: 0.560 | Acc: 70.000% (910/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.951 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s998ms | Loss: 0.540 | Acc: 71.846% (934/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.830 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s997ms | Loss: 0.534 | Acc: 73.077% (950/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.718 | Acc: 40.789% (124/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s6ms | Loss: 0.587 | Acc: 68.846% (895/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.838 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.551 | Acc: 71.692% (932/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.556 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s989ms | Loss: 0.480 | Acc: 78.615% (1022/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.769 | Acc: 57.895% (176/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.494 | Acc: 76.692% (997/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 639ms | Loss: 0.971 | Acc: 35.526% (108/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s999ms | Loss: 0.491 | Acc: 77.538% (1008/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.944 | Acc: 34.868% (106/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s | Loss: 0.496 | Acc: 76.692% (997/1300)1280)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.531 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s986ms | Loss: 0.481 | Acc: 78.154% (1016/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.742 | Acc: 55.921% (170/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s988ms | Loss: 0.473 | Acc: 77.692% (1010/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 628ms | Loss: 25.159 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s994ms | Loss: 0.548 | Acc: 71.846% (934/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.549 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s998ms | Loss: 0.483 | Acc: 78.615% (1022/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.715 | Acc: 60.855% (185/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s995ms | Loss: 0.491 | Acc: 77.462% (1007/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.766 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s997ms | Loss: 0.535 | Acc: 72.846% (947/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.848 | Acc: 36.842% (112/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s992ms | Loss: 0.523 | Acc: 72.769% (946/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.605 | Acc: 58.553% (178/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s1ms | Loss: 0.491 | Acc: 76.615% (996/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.608 | Acc: 60.526% (184/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s995ms | Loss: 0.478 | Acc: 77.923% (1013/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.727 | Acc: 52.961% (161/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 14s984ms | Loss: 0.470 | Acc: 78.769% (1024/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 638ms | Loss: 0.660 | Acc: 61.184% (186/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s959ms | Loss: 0.444 | Acc: 80.000% (1040/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.514 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s981ms | Loss: 0.423 | Acc: 81.923% (1065/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.478 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s989ms | Loss: 0.415 | Acc: 82.308% (1070/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.565 | Acc: 70.066% (213/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s982ms | Loss: 0.412 | Acc: 82.538% (1073/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.429 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s991ms | Loss: 0.417 | Acc: 82.000% (1066/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.534 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s979ms | Loss: 0.410 | Acc: 82.231% (1069/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.441 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s989ms | Loss: 0.402 | Acc: 83.462% (1085/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.755 | Acc: 55.263% (168/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s3ms | Loss: 0.389 | Acc: 83.538% (1086/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 628ms | Loss: 0.507 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s976ms | Loss: 0.381 | Acc: 83.538% (1086/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.641 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s980ms | Loss: 0.393 | Acc: 82.769% (1076/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.856 | Acc: 49.342% (150/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s993ms | Loss: 0.404 | Acc: 83.077% (1080/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.417 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s978ms | Loss: 0.404 | Acc: 82.615% (1074/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.472 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s987ms | Loss: 0.396 | Acc: 83.077% (1080/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.716 | Acc: 61.513% (187/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s985ms | Loss: 0.406 | Acc: 82.769% (1076/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.406 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s991ms | Loss: 0.402 | Acc: 83.462% (1085/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.459 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s989ms | Loss: 0.397 | Acc: 83.615% (1087/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.783 | Acc: 56.908% (173/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s989ms | Loss: 0.388 | Acc: 82.923% (1078/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.495 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s9ms | Loss: 0.409 | Acc: 82.308% (1070/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.507 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s987ms | Loss: 0.383 | Acc: 84.385% (1097/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.511 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s1ms | Loss: 0.381 | Acc: 83.846% (1090/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.467 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s987ms | Loss: 0.386 | Acc: 83.846% (1090/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.448 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s980ms | Loss: 0.388 | Acc: 83.462% (1085/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.424 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 14s990ms | Loss: 0.380 | Acc: 84.000% (1092/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.440 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s990ms | Loss: 0.385 | Acc: 84.154% (1094/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.561 | Acc: 70.066% (213/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s983ms | Loss: 0.385 | Acc: 83.692% (1088/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.682 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s978ms | Loss: 0.415 | Acc: 82.077% (1067/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.528 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s971ms | Loss: 0.389 | Acc: 83.154% (1081/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.516 | Acc: 74.342% (226/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s995ms | Loss: 0.376 | Acc: 85.231% (1108/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.462 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s993ms | Loss: 0.365 | Acc: 84.769% (1102/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.459 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s985ms | Loss: 0.373 | Acc: 85.154% (1107/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.442 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s972ms | Loss: 0.362 | Acc: 86.077% (1119/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.445 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s984ms | Loss: 0.355 | Acc: 85.000% (1105/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.463 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s988ms | Loss: 0.363 | Acc: 84.846% (1103/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.441 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s973ms | Loss: 0.350 | Acc: 86.615% (1126/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.436 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s982ms | Loss: 0.353 | Acc: 85.846% (1116/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.419 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s984ms | Loss: 0.347 | Acc: 86.692% (1127/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.459 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s989ms | Loss: 0.358 | Acc: 86.538% (1125/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.459 | Acc: 77.632% (236/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 14s979ms | Loss: 0.361 | Acc: 85.231% (1108/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.420 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s985ms | Loss: 0.351 | Acc: 86.308% (1122/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.442 | Acc: 78.947% (240/304)\n",
      "    8 | 20m14s |   80.92105 |    0.0980 |    0.0116 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s33ms | Loss: 0.583 | Acc: 69.692% (906/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.950 | Acc: 41.776% (127/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.457 | Acc: 78.923% (1026/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.968 | Acc: 38.816% (118/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.421 | Acc: 80.846% (1051/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 1.144 | Acc: 33.882% (103/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s32ms | Loss: 0.380 | Acc: 82.538% (1073/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.984 | Acc: 44.079% (134/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s31ms | Loss: 0.348 | Acc: 84.692% (1101/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 1.229 | Acc: 34.868% (106/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s32ms | Loss: 0.336 | Acc: 84.538% (1099/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.534 | Acc: 35.197% (107/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.317 | Acc: 84.923% (1104/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.767 | Acc: 51.974% (158/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s49ms | Loss: 0.336 | Acc: 86.308% (1122/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 1.308 | Acc: 33.882% (103/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 432ms | Tot: 15s58ms | Loss: 0.348 | Acc: 85.462% (1111/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 1.443 | Acc: 35.526% (108/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s56ms | Loss: 0.328 | Acc: 86.462% (1124/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.479 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.329 | Acc: 85.769% (1115/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.558 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.330 | Acc: 85.077% (1106/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.931 | Acc: 51.316% (156/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.353 | Acc: 83.615% (1087/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.420 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s59ms | Loss: 0.322 | Acc: 85.538% (1112/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 1.094 | Acc: 46.382% (141/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s50ms | Loss: 0.340 | Acc: 85.154% (1107/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.685 | Acc: 58.882% (179/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.350 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.392 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.349 | Acc: 84.385% (1097/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.846 | Acc: 47.368% (144/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.347 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.896 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.342 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.780 | Acc: 59.211% (180/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.351 | Acc: 84.538% (1099/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 2.251 | Acc: 37.829% (115/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.363 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.962 | Acc: 53.947% (164/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.366 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.460 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s49ms | Loss: 0.359 | Acc: 83.923% (1091/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 638ms | Loss: 0.659 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s51ms | Loss: 0.347 | Acc: 84.846% (1103/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.473 | Acc: 75.329% (229/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.344 | Acc: 85.615% (1113/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.470 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s47ms | Loss: 0.355 | Acc: 84.385% (1097/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.527 | Acc: 75.987% (231/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.353 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.754 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s47ms | Loss: 0.346 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.417 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s34ms | Loss: 0.338 | Acc: 85.692% (1114/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 638ms | Loss: 0.349 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.384 | Acc: 82.538% (1073/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.729 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.356 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.453 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.318 | Acc: 86.923% (1130/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.363 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.309 | Acc: 88.154% (1146/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.321 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.289 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.418 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s38ms | Loss: 0.297 | Acc: 87.846% (1142/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 629ms | Loss: 0.377 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.279 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.279 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 432ms | Tot: 15s34ms | Loss: 0.283 | Acc: 89.769% (1167/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.307 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.276 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.323 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s42ms | Loss: 0.278 | Acc: 89.000% (1157/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.296 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s48ms | Loss: 0.271 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.314 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 0.276 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.304 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.264 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.335 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.279 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.279 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.268 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.369 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s53ms | Loss: 0.264 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.515 | Acc: 75.987% (231/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.266 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.297 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.269 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.308 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.256 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.294 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.256 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.343 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.275 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.271 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s43ms | Loss: 0.256 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.456 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s55ms | Loss: 0.271 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.250 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.264 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.414 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.254 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.417 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s42ms | Loss: 0.263 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.345 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s56ms | Loss: 0.263 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.633 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.259 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.281 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.249 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.308 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.262 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.255 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.274 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.287 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s34ms | Loss: 0.255 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.293 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.244 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.282 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.237 | Acc: 91.846% (1194/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.290 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.233 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.268 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.242 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.276 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.219 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.227 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.279 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.224 | Acc: 92.231% (1199/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.287 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.229 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.273 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.224 | Acc: 92.538% (1203/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.276 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.238 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.264 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.233 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.263 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.226 | Acc: 92.615% (1204/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.279 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.225 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.260 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.220 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.268 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.234 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.275 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.226 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.280 | Acc: 87.829% (267/304)\n",
      "    9 | 21m24s |   91.11842 |    0.0091 |    0.0481 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |        lr |        wd | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 1.786 | Acc: 63.846% (830/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.828 | Acc: 46.711% (142/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s29ms | Loss: 0.663 | Acc: 67.462% (877/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.746 | Acc: 34.211% (104/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.548 | Acc: 70.615% (918/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.849 | Acc: 35.197% (107/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.493 | Acc: 75.923% (987/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.711 | Acc: 55.592% (169/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.459 | Acc: 78.846% (1025/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.221 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.453 | Acc: 79.000% (1027/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.812 | Acc: 37.829% (115/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.416 | Acc: 81.615% (1061/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 1.374 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.374 | Acc: 83.692% (1088/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 632ms | Loss: 0.764 | Acc: 50.987% (155/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.391 | Acc: 81.385% (1058/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.628 | Acc: 54.934% (167/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.370 | Acc: 82.077% (1067/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.542 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s22ms | Loss: 0.367 | Acc: 83.923% (1091/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.582 | Acc: 64.145% (195/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.357 | Acc: 83.462% (1085/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.947 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.359 | Acc: 83.462% (1085/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.491 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.418 | Acc: 81.385% (1058/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.384 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.393 | Acc: 82.769% (1076/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.534 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.372 | Acc: 83.615% (1087/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 0.372 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.366 | Acc: 82.923% (1078/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.797 | Acc: 54.605% (166/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s7ms | Loss: 0.370 | Acc: 83.615% (1087/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.456 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s7ms | Loss: 0.353 | Acc: 83.308% (1083/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 639ms | Loss: 0.704 | Acc: 64.474% (196/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s5ms | Loss: 0.373 | Acc: 81.769% (1063/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.754 | Acc: 53.947% (164/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.400 | Acc: 81.308% (1057/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.769 | Acc: 61.513% (187/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s19ms | Loss: 0.414 | Acc: 81.615% (1061/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.599 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s17ms | Loss: 0.392 | Acc: 82.077% (1067/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.152 | Acc: 44.079% (134/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.389 | Acc: 83.538% (1086/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 638ms | Loss: 0.567 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.415 | Acc: 81.692% (1062/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.233 | Acc: 52.303% (159/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.430 | Acc: 79.385% (1032/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.476 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.378 | Acc: 82.923% (1078/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.545 | Acc: 67.105% (204/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s22ms | Loss: 0.527 | Acc: 75.308% (979/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.908 | Acc: 33.882% (103/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s17ms | Loss: 0.470 | Acc: 78.769% (1024/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.559 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s24ms | Loss: 0.439 | Acc: 80.692% (1049/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.826 | Acc: 51.316% (156/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.441 | Acc: 80.077% (1041/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.592 | Acc: 66.776% (203/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s10ms | Loss: 0.399 | Acc: 83.308% (1083/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.469 | Acc: 74.671% (227/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.370 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.560 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.381 | Acc: 82.615% (1074/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 637ms | Loss: 0.448 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s9ms | Loss: 0.380 | Acc: 83.615% (1087/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.468 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s18ms | Loss: 0.363 | Acc: 83.923% (1091/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.407 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.352 | Acc: 85.000% (1105/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.518 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s36ms | Loss: 0.347 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.437 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s10ms | Loss: 0.336 | Acc: 85.615% (1113/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.473 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s20ms | Loss: 0.334 | Acc: 86.077% (1119/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.346 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.323 | Acc: 86.538% (1125/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.297 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.305 | Acc: 86.308% (1122/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.399 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.295 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.695 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s16ms | Loss: 0.294 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.510 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s17ms | Loss: 0.281 | Acc: 87.538% (1138/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.978 | Acc: 60.526% (184/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.302 | Acc: 85.692% (1114/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.321 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.303 | Acc: 87.077% (1132/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.446 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s1ms | Loss: 0.292 | Acc: 86.692% (1127/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.506 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.298 | Acc: 86.615% (1126/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.806 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s6ms | Loss: 0.289 | Acc: 88.154% (1146/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.287 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s986ms | Loss: 0.287 | Acc: 87.769% (1141/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.272 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.366 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.286 | Acc: 87.923% (1143/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.292 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.274 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.324 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s | Loss: 0.262 | Acc: 89.154% (1159/1300)1280)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.333 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s15ms | Loss: 0.279 | Acc: 87.154% (1133/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.287 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.272 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.343 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.264 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.213 | Acc: 59.868% (182/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.267 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.262 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.269 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.311 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.247 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.294 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.248 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.286 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.236 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.330 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 0.222 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.316 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s20ms | Loss: 0.223 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.275 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.223 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.293 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s18ms | Loss: 0.234 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.303 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.241 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.281 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s6ms | Loss: 0.216 | Acc: 91.462% (1189/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.325 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s15ms | Loss: 0.224 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.298 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s31ms | Loss: 0.246 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.288 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s22ms | Loss: 0.230 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.289 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s24ms | Loss: 0.222 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.290 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s20ms | Loss: 0.232 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.323 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.225 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.297 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.228 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.268 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s18ms | Loss: 0.210 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.309 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.207 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.290 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:79\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s38ms | Loss: 0.220 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.293 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:80\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.219 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.308 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:81\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.205 | Acc: 92.385% (1201/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.291 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:82\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s19ms | Loss: 0.213 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.281 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:83\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.215 | Acc: 91.846% (1194/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.353 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:84\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.204 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 641ms | Loss: 0.275 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:85\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.203 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.249 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:86\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s17ms | Loss: 0.214 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.282 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:87\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s18ms | Loss: 0.200 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.321 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:88\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.217 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.272 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:89\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.232 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.263 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:90\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.214 | Acc: 91.846% (1194/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.331 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:91\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s38ms | Loss: 0.195 | Acc: 92.385% (1201/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.312 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:92\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.191 | Acc: 92.385% (1201/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.276 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:93\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.215 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.294 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:94\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.213 | Acc: 91.462% (1189/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.261 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:95\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.198 | Acc: 92.308% (1200/1300))\n",
      "[=================== 5/5 ============>........]  Step: 148ms | Tot: 641ms | Loss: 0.270 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:96\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s997ms | Loss: 0.189 | Acc: 92.923% (1208/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.292 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:97\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.205 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.283 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:98\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.203 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.272 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:99\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s15ms | Loss: 0.208 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.271 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:100\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.203 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.279 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:101\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s25ms | Loss: 0.186 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.271 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:102\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.193 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.267 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:103\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.200 | Acc: 91.692% (1192/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.289 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:104\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.198 | Acc: 92.538% (1203/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.282 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:105\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s6ms | Loss: 0.197 | Acc: 92.462% (1202/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.271 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:106\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s25ms | Loss: 0.207 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.272 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:107\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.197 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.290 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:108\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.205 | Acc: 92.538% (1203/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.267 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:109\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.201 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.281 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:110\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.195 | Acc: 92.538% (1203/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.278 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:111\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s11ms | Loss: 0.206 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.289 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:112\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s8ms | Loss: 0.200 | Acc: 92.385% (1201/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.277 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:113\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s18ms | Loss: 0.202 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.278 | Acc: 88.816% (270/304)\n",
      "   10 | 31m22s |   90.78947 |    0.1000 |    0.0049 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.551 | Acc: 71.308% (927/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.587 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s28ms | Loss: 0.444 | Acc: 80.231% (1043/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.763 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.390 | Acc: 83.000% (1079/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.528 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.367 | Acc: 83.769% (1089/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.534 | Acc: 75.987% (231/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.326 | Acc: 86.000% (1118/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.330 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s56ms | Loss: 0.332 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.440 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.311 | Acc: 86.769% (1128/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.434 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.308 | Acc: 86.769% (1128/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.336 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.299 | Acc: 88.154% (1146/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.346 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s39ms | Loss: 0.297 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.294 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.253 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.510 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.255 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.377 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.267 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.398 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.284 | Acc: 88.538% (1151/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.354 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.264 | Acc: 88.538% (1151/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 637ms | Loss: 0.492 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.250 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.366 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.242 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.235 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.243 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.284 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.207 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.313 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.232 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 0.352 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.202 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.321 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.201 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.393 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s44ms | Loss: 0.186 | Acc: 92.308% (1200/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.314 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.204 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.277 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.189 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.444 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.174 | Acc: 92.769% (1206/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.478 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.202 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.324 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.172 | Acc: 92.462% (1202/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.418 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s25ms | Loss: 0.161 | Acc: 93.308% (1213/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.272 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.196 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.443 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.147 | Acc: 94.538% (1229/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.298 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.120 | Acc: 95.615% (1243/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.304 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s27ms | Loss: 0.117 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.302 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.107 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.275 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.102 | Acc: 96.615% (1256/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.298 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.111 | Acc: 95.923% (1247/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.299 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.094 | Acc: 96.385% (1253/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.266 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.094 | Acc: 97.077% (1262/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.291 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s33ms | Loss: 0.079 | Acc: 97.308% (1265/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.291 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.083 | Acc: 96.846% (1259/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.345 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s56ms | Loss: 0.076 | Acc: 97.769% (1271/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.362 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.090 | Acc: 96.692% (1257/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.300 | Acc: 88.816% (270/304)\n",
      "   11 | 11m41s | \u001b[35m  91.44737\u001b[0m | \u001b[32m   0.0056\u001b[0m | \u001b[32m   0.0012\u001b[0m | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 1.978 | Acc: 60.077% (781/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.610 | Acc: 56.579% (172/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.703 | Acc: 63.462% (825/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.785 | Acc: 46.711% (142/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.645 | Acc: 65.154% (847/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.645 | Acc: 59.868% (182/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.574 | Acc: 68.769% (894/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.715 | Acc: 46.382% (141/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s37ms | Loss: 0.541 | Acc: 71.615% (931/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.784 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.524 | Acc: 73.385% (954/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.737 | Acc: 44.079% (134/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.471 | Acc: 77.769% (1011/1300)\n",
      "[=================== 5/5 ============>........]  Step: 147ms | Tot: 638ms | Loss: 0.843 | Acc: 40.461% (123/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.462 | Acc: 79.000% (1027/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.881 | Acc: 43.421% (132/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s42ms | Loss: 0.444 | Acc: 79.846% (1038/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.666 | Acc: 59.868% (182/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.423 | Acc: 81.154% (1055/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.615 | Acc: 62.829% (191/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.418 | Acc: 81.615% (1061/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 641ms | Loss: 0.859 | Acc: 43.750% (133/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.399 | Acc: 82.385% (1071/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.618 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.378 | Acc: 85.154% (1107/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.924 | Acc: 48.026% (146/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.367 | Acc: 84.385% (1097/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.882 | Acc: 44.079% (134/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.381 | Acc: 83.385% (1084/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.671 | Acc: 69.079% (210/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s39ms | Loss: 0.378 | Acc: 82.385% (1071/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.465 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.344 | Acc: 84.846% (1103/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 1.507 | Acc: 34.211% (104/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.375 | Acc: 83.692% (1088/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.472 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.363 | Acc: 84.769% (1102/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.424 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.352 | Acc: 84.077% (1093/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 1.266 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s47ms | Loss: 0.403 | Acc: 82.462% (1072/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.462 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.339 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.840 | Acc: 55.263% (168/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.356 | Acc: 83.308% (1083/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 1.276 | Acc: 40.132% (122/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.351 | Acc: 83.615% (1087/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.542 | Acc: 69.737% (212/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.347 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.354 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.355 | Acc: 82.308% (1070/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.499 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s50ms | Loss: 0.390 | Acc: 83.077% (1080/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.837 | Acc: 62.171% (189/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s17ms | Loss: 0.382 | Acc: 82.231% (1069/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 1.065 | Acc: 40.789% (124/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.351 | Acc: 83.000% (1079/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.638 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 0.337 | Acc: 84.308% (1096/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.780 | Acc: 61.842% (188/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.288 | Acc: 88.308% (1148/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.319 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.281 | Acc: 88.154% (1146/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.329 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.272 | Acc: 87.846% (1142/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.339 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.274 | Acc: 87.923% (1143/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.275 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.257 | Acc: 88.692% (1153/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.297 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.269 | Acc: 88.154% (1146/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.353 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s54ms | Loss: 0.251 | Acc: 89.077% (1158/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.328 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s72ms | Loss: 0.245 | Acc: 88.923% (1156/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.294 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s50ms | Loss: 0.238 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.286 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.241 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.301 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.232 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.433 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s25ms | Loss: 0.243 | Acc: 89.462% (1163/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 637ms | Loss: 0.289 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.262 | Acc: 88.692% (1153/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.273 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.236 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.275 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s34ms | Loss: 0.219 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.269 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s14ms | Loss: 0.232 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.267 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.244 | Acc: 89.769% (1167/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.255 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.219 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.306 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.231 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.248 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s25ms | Loss: 0.223 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.293 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.241 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.236 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.221 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.291 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s31ms | Loss: 0.232 | Acc: 89.846% (1168/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.279 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.213 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.275 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.220 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.382 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s30ms | Loss: 0.226 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.270 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.220 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.264 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.218 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.342 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.208 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.315 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.207 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.311 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s28ms | Loss: 0.206 | Acc: 91.692% (1192/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.290 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s28ms | Loss: 0.190 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.272 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.189 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.271 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.198 | Acc: 92.231% (1199/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.270 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s19ms | Loss: 0.183 | Acc: 92.615% (1204/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.276 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.179 | Acc: 93.077% (1210/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.288 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.192 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.295 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.183 | Acc: 92.923% (1208/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.278 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.175 | Acc: 93.077% (1210/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.287 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.175 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.284 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.184 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.290 | Acc: 87.500% (266/304)\n",
      "   12 | 19m43s |   89.80263 |    0.0992 |    0.0027 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 1.412 | Acc: 64.846% (843/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.848 | Acc: 47.368% (144/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s40ms | Loss: 0.618 | Acc: 69.231% (900/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.652 | Acc: 57.237% (174/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.519 | Acc: 75.692% (984/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 635ms | Loss: 0.569 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.482 | Acc: 77.385% (1006/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.815 | Acc: 48.355% (147/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.420 | Acc: 80.308% (1044/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.833 | Acc: 51.645% (157/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.403 | Acc: 82.231% (1069/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.886 | Acc: 48.026% (146/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s24ms | Loss: 0.438 | Acc: 80.923% (1052/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 1.031 | Acc: 38.816% (118/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.400 | Acc: 82.615% (1074/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.853 | Acc: 60.526% (184/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.368 | Acc: 84.000% (1092/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.666 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s58ms | Loss: 0.397 | Acc: 82.154% (1068/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.471 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.362 | Acc: 83.769% (1089/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.555 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s26ms | Loss: 0.354 | Acc: 84.000% (1092/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 632ms | Loss: 0.796 | Acc: 48.026% (146/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.341 | Acc: 85.077% (1106/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.379 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.344 | Acc: 85.692% (1114/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.529 | Acc: 69.737% (212/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.342 | Acc: 84.077% (1093/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.381 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s19ms | Loss: 0.333 | Acc: 85.385% (1110/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.400 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s21ms | Loss: 0.336 | Acc: 85.769% (1115/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.393 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s19ms | Loss: 0.331 | Acc: 85.846% (1116/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.351 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.295 | Acc: 86.846% (1129/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.431 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s30ms | Loss: 0.340 | Acc: 83.538% (1086/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.549 | Acc: 74.671% (227/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.322 | Acc: 85.923% (1117/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 1.005 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s20ms | Loss: 0.332 | Acc: 85.154% (1107/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.308 | Acc: 48.355% (147/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s34ms | Loss: 0.389 | Acc: 81.385% (1058/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.226 | Acc: 48.355% (147/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s34ms | Loss: 0.298 | Acc: 85.462% (1111/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.318 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.341 | Acc: 84.077% (1093/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.350 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.306 | Acc: 85.923% (1117/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.566 | Acc: 67.105% (204/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.288 | Acc: 86.385% (1123/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 1.014 | Acc: 61.184% (186/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s25ms | Loss: 0.341 | Acc: 84.769% (1102/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 1.089 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s5ms | Loss: 0.320 | Acc: 84.769% (1102/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.455 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.324 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.378 | Acc: 77.632% (236/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.305 | Acc: 85.769% (1115/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.295 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s34ms | Loss: 0.252 | Acc: 88.846% (1155/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.290 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.249 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.283 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.232 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.259 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.256 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.243 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.316 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.238 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.312 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.229 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.290 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.239 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.261 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.229 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.260 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.233 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.271 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.230 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.335 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s36ms | Loss: 0.238 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.247 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.227 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 641ms | Loss: 0.294 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.228 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.290 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.207 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.284 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.213 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 630ms | Loss: 0.396 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.218 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.273 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.221 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.405 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.208 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.248 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s37ms | Loss: 0.221 | Acc: 90.769% (1180/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.279 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s30ms | Loss: 0.210 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 641ms | Loss: 0.316 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 0.220 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.276 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.215 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 147ms | Tot: 638ms | Loss: 0.449 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.220 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.359 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.206 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.288 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.208 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.229 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.198 | Acc: 91.462% (1189/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.307 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s17ms | Loss: 0.193 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 635ms | Loss: 0.342 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.213 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.440 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.184 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.266 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s54ms | Loss: 0.177 | Acc: 93.000% (1209/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 645ms | Loss: 0.254 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.180 | Acc: 92.846% (1207/1300))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.292 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s55ms | Loss: 0.176 | Acc: 93.308% (1213/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.287 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.171 | Acc: 93.846% (1220/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.272 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s18ms | Loss: 0.160 | Acc: 93.692% (1218/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.271 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s16ms | Loss: 0.169 | Acc: 93.231% (1212/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.264 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s22ms | Loss: 0.172 | Acc: 93.846% (1220/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.294 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.173 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.279 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s38ms | Loss: 0.160 | Acc: 93.923% (1221/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.263 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.153 | Acc: 94.692% (1231/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.271 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s33ms | Loss: 0.154 | Acc: 94.615% (1230/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.275 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.147 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.276 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.155 | Acc: 93.385% (1214/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.262 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.156 | Acc: 93.769% (1219/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.277 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s23ms | Loss: 0.161 | Acc: 93.692% (1218/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.252 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.155 | Acc: 94.538% (1229/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.266 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.149 | Acc: 93.769% (1219/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.255 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:79\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s27ms | Loss: 0.142 | Acc: 94.385% (1227/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.283 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:80\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.135 | Acc: 95.000% (1235/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.287 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:81\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s37ms | Loss: 0.148 | Acc: 94.154% (1224/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.285 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:82\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.157 | Acc: 94.000% (1222/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.252 | Acc: 89.145% (271/304)\n",
      "   13 | 22m47s |   90.13158 |    0.1000 |    0.0025 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s24ms | Loss: 2.306 | Acc: 60.846% (791/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.848 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.565 | Acc: 68.923% (896/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 628ms | Loss: 0.921 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.560 | Acc: 72.462% (942/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.865 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.525 | Acc: 73.462% (955/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.850 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s27ms | Loss: 0.495 | Acc: 76.308% (992/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.687 | Acc: 56.908% (173/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.486 | Acc: 77.769% (1011/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.920 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.448 | Acc: 80.462% (1046/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.960 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.437 | Acc: 81.231% (1056/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.950 | Acc: 34.539% (105/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s52ms | Loss: 0.437 | Acc: 79.769% (1037/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 634ms | Loss: 1.003 | Acc: 35.197% (107/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s18ms | Loss: 0.479 | Acc: 76.923% (1000/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.669 | Acc: 62.500% (190/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.449 | Acc: 79.769% (1037/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.571 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s7ms | Loss: 0.437 | Acc: 80.538% (1047/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.608 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.453 | Acc: 79.154% (1029/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.609 | Acc: 67.763% (206/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.520 | Acc: 75.692% (984/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.675 | Acc: 55.921% (170/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s19ms | Loss: 0.458 | Acc: 78.923% (1026/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.821 | Acc: 47.697% (145/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s26ms | Loss: 0.481 | Acc: 77.923% (1013/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.681 | Acc: 59.211% (180/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.459 | Acc: 80.231% (1043/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.601 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s13ms | Loss: 0.553 | Acc: 73.000% (949/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.587 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s10ms | Loss: 0.464 | Acc: 78.000% (1014/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.584 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.453 | Acc: 80.000% (1040/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 1.001 | Acc: 40.132% (122/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.472 | Acc: 77.923% (1013/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.502 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.463 | Acc: 79.692% (1036/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.541 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s31ms | Loss: 0.422 | Acc: 82.077% (1067/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 635ms | Loss: 1.135 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s999ms | Loss: 0.465 | Acc: 78.846% (1025/1300)\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 637ms | Loss: 0.840 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s13ms | Loss: 0.477 | Acc: 77.462% (1007/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.821 | Acc: 35.197% (107/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s992ms | Loss: 0.464 | Acc: 78.385% (1019/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.636 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s995ms | Loss: 0.495 | Acc: 77.231% (1004/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 8.577 | Acc: 66.447% (202/304))\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 14s997ms | Loss: 0.688 | Acc: 57.308% (745/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.769 | Acc: 59.211% (180/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.674 | Acc: 60.000% (780/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.716 | Acc: 33.553% (102/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s6ms | Loss: 0.659 | Acc: 60.923% (792/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.689 | Acc: 57.237% (174/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s2ms | Loss: 0.638 | Acc: 66.077% (859/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.698 | Acc: 55.592% (169/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.624 | Acc: 66.846% (869/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.701 | Acc: 55.592% (169/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s8ms | Loss: 0.612 | Acc: 67.308% (875/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.845 | Acc: 36.513% (111/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s7ms | Loss: 0.558 | Acc: 71.769% (933/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.854 | Acc: 39.145% (119/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s16ms | Loss: 0.507 | Acc: 76.385% (993/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 630ms | Loss: 0.653 | Acc: 58.882% (179/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s6ms | Loss: 0.487 | Acc: 76.538% (995/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.556 | Acc: 68.421% (208/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.448 | Acc: 79.846% (1038/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.501 | Acc: 74.342% (226/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s8ms | Loss: 0.425 | Acc: 81.231% (1056/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.579 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s5ms | Loss: 0.408 | Acc: 82.385% (1071/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.498 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s998ms | Loss: 0.403 | Acc: 81.846% (1064/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.523 | Acc: 68.092% (207/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.371 | Acc: 83.462% (1085/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.888 | Acc: 61.842% (188/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s997ms | Loss: 0.336 | Acc: 84.385% (1097/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.354 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s12ms | Loss: 0.343 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 142ms | Tot: 633ms | Loss: 0.373 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s1ms | Loss: 0.346 | Acc: 84.000% (1092/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.930 | Acc: 63.487% (193/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.335 | Acc: 83.769% (1089/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.323 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.320 | Acc: 84.538% (1099/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.674 | Acc: 66.776% (203/304)\n",
      "\n",
      "This is epoch:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s10ms | Loss: 0.336 | Acc: 83.846% (1090/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.675 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s4ms | Loss: 0.329 | Acc: 84.154% (1094/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.321 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s998ms | Loss: 0.338 | Acc: 84.308% (1096/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.352 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s10ms | Loss: 0.301 | Acc: 87.231% (1134/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.321 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s13ms | Loss: 0.311 | Acc: 85.462% (1111/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.330 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s998ms | Loss: 0.314 | Acc: 85.923% (1117/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.566 | Acc: 72.039% (219/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s5ms | Loss: 0.315 | Acc: 85.385% (1110/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.662 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s29ms | Loss: 0.312 | Acc: 85.538% (1112/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.334 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s1ms | Loss: 0.300 | Acc: 86.538% (1125/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.387 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s1ms | Loss: 0.295 | Acc: 87.077% (1132/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.378 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.303 | Acc: 86.385% (1123/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 1.499 | Acc: 41.118% (125/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.315 | Acc: 85.077% (1106/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.822 | Acc: 53.289% (162/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s8ms | Loss: 0.297 | Acc: 86.769% (1128/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.511 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s13ms | Loss: 0.278 | Acc: 88.231% (1147/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.337 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s8ms | Loss: 0.275 | Acc: 88.231% (1147/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.336 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s5ms | Loss: 0.264 | Acc: 88.615% (1152/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.352 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s3ms | Loss: 0.270 | Acc: 89.154% (1159/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.334 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s7ms | Loss: 0.265 | Acc: 89.000% (1157/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.302 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s993ms | Loss: 0.251 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.331 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s985ms | Loss: 0.258 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.281 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s23ms | Loss: 0.254 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.320 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s998ms | Loss: 0.263 | Acc: 88.769% (1154/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.296 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s15ms | Loss: 0.252 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.331 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s10ms | Loss: 0.256 | Acc: 88.769% (1154/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.316 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s997ms | Loss: 0.238 | Acc: 89.769% (1167/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.319 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s993ms | Loss: 0.248 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.276 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 14s986ms | Loss: 0.252 | Acc: 88.615% (1152/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.290 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.251 | Acc: 89.077% (1158/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.260 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s14ms | Loss: 0.252 | Acc: 89.538% (1164/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.366 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s997ms | Loss: 0.237 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.303 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s | Loss: 0.253 | Acc: 88.923% (1156/1300)1280)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.268 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s12ms | Loss: 0.245 | Acc: 89.385% (1162/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.304 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:79\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.246 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.318 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:80\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s7ms | Loss: 0.244 | Acc: 89.615% (1165/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.286 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:81\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.242 | Acc: 90.231% (1173/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.317 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:82\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s20ms | Loss: 0.250 | Acc: 89.462% (1163/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.294 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:83\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 14s997ms | Loss: 0.249 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.338 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:84\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s21ms | Loss: 0.243 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.272 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:85\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s26ms | Loss: 0.237 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 641ms | Loss: 0.286 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:86\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s7ms | Loss: 0.245 | Acc: 89.846% (1168/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.270 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:87\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 14s995ms | Loss: 0.243 | Acc: 90.231% (1173/1300)\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.310 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:88\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s6ms | Loss: 0.246 | Acc: 89.385% (1162/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.294 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:89\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s2ms | Loss: 0.243 | Acc: 89.769% (1167/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.270 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:90\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s9ms | Loss: 0.231 | Acc: 90.385% (1175/1300)0)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.334 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:91\n",
      "[=================== 41/41 =================>.]  Step: 425ms | Tot: 15s11ms | Loss: 0.232 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.297 | Acc: 86.842% (264/304)\n",
      "   14 | 25m15s |   89.47368 |    0.0994 |    0.0071 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.575 | Acc: 67.077% (872/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.597 | Acc: 62.171% (189/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.468 | Acc: 77.692% (1010/1300)\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.490 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s24ms | Loss: 0.425 | Acc: 81.077% (1054/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.512 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 426ms | Tot: 15s24ms | Loss: 0.394 | Acc: 82.538% (1073/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.419 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.377 | Acc: 84.000% (1092/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.408 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.360 | Acc: 85.000% (1105/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.421 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.363 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.356 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.322 | Acc: 87.000% (1131/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.468 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s44ms | Loss: 0.313 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.442 | Acc: 77.632% (236/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.333 | Acc: 86.231% (1121/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.381 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.296 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.685 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.279 | Acc: 88.000% (1144/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.377 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.286 | Acc: 88.308% (1148/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.518 | Acc: 72.039% (219/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s31ms | Loss: 0.256 | Acc: 89.077% (1158/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.476 | Acc: 75.329% (229/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.255 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.850 | Acc: 64.145% (195/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.264 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.468 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.230 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.352 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s26ms | Loss: 0.257 | Acc: 89.615% (1165/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.353 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s18ms | Loss: 0.226 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.520 | Acc: 76.316% (232/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.221 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.592 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.219 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.668 | Acc: 68.421% (208/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.221 | Acc: 91.538% (1190/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.249 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.193 | Acc: 92.769% (1206/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.301 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.225 | Acc: 91.154% (1185/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.363 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.189 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.443 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.171 | Acc: 94.154% (1224/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.295 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.157 | Acc: 93.846% (1220/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.344 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.144 | Acc: 94.308% (1226/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.575 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s40ms | Loss: 0.193 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.638 | Acc: 70.395% (214/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s37ms | Loss: 0.173 | Acc: 93.385% (1214/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.379 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.149 | Acc: 94.308% (1226/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.338 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.135 | Acc: 96.000% (1248/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.316 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.123 | Acc: 95.615% (1243/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.337 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.097 | Acc: 96.769% (1258/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.348 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.109 | Acc: 96.462% (1254/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.314 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.107 | Acc: 96.538% (1255/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.371 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.116 | Acc: 95.615% (1243/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.319 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.105 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.313 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s36ms | Loss: 0.103 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.313 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.090 | Acc: 97.462% (1267/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.351 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.095 | Acc: 96.846% (1259/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.289 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.088 | Acc: 97.231% (1264/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.341 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.084 | Acc: 97.077% (1262/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.344 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s32ms | Loss: 0.084 | Acc: 97.000% (1261/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.386 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.083 | Acc: 97.154% (1263/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.309 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s28ms | Loss: 0.068 | Acc: 97.846% (1272/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.327 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.081 | Acc: 97.385% (1266/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.359 | Acc: 85.197% (259/304)\n",
      "   15 | 13m04s |   91.11842 |    0.0026 |    0.0015 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.596 | Acc: 67.000% (871/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.544 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s22ms | Loss: 0.432 | Acc: 78.692% (1023/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.408 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.380 | Acc: 83.231% (1082/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.537 | Acc: 71.053% (216/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s25ms | Loss: 0.375 | Acc: 84.846% (1103/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.489 | Acc: 72.039% (219/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.365 | Acc: 84.154% (1094/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.344 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s58ms | Loss: 0.335 | Acc: 85.692% (1114/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.376 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s24ms | Loss: 0.317 | Acc: 86.308% (1122/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.428 | Acc: 80.592% (245/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s47ms | Loss: 0.302 | Acc: 87.385% (1136/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.874 | Acc: 58.882% (179/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.293 | Acc: 87.692% (1140/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.535 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s31ms | Loss: 0.263 | Acc: 87.923% (1143/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.305 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.266 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.307 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.275 | Acc: 87.846% (1142/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 635ms | Loss: 0.305 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s30ms | Loss: 0.258 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.451 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s27ms | Loss: 0.273 | Acc: 88.308% (1148/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 1.314 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s21ms | Loss: 0.294 | Acc: 87.385% (1136/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.402 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.238 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.476 | Acc: 77.632% (236/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.233 | Acc: 90.077% (1171/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 1.036 | Acc: 64.145% (195/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.226 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.468 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.239 | Acc: 89.308% (1161/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.302 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s27ms | Loss: 0.216 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 633ms | Loss: 0.381 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s43ms | Loss: 0.216 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.890 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.205 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 630ms | Loss: 0.332 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.203 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.272 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.219 | Acc: 90.846% (1181/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.355 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.201 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.408 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.214 | Acc: 91.308% (1187/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.322 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.201 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 629ms | Loss: 0.311 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s29ms | Loss: 0.183 | Acc: 93.308% (1213/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 631ms | Loss: 0.242 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.191 | Acc: 93.385% (1214/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.252 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.172 | Acc: 93.462% (1215/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.499 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.147 | Acc: 94.538% (1229/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.315 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s53ms | Loss: 0.128 | Acc: 95.923% (1247/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.286 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.121 | Acc: 95.077% (1236/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 640ms | Loss: 0.307 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s25ms | Loss: 0.112 | Acc: 96.385% (1253/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.305 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.094 | Acc: 97.154% (1263/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 632ms | Loss: 0.290 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.111 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 631ms | Loss: 0.322 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.101 | Acc: 96.385% (1253/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.284 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.101 | Acc: 96.538% (1255/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.297 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.072 | Acc: 97.846% (1272/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.345 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.092 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.359 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.079 | Acc: 97.000% (1261/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.309 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.074 | Acc: 97.615% (1269/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.363 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.075 | Acc: 96.846% (1259/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.350 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.063 | Acc: 98.308% (1278/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.397 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s32ms | Loss: 0.059 | Acc: 98.231% (1277/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.363 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.062 | Acc: 98.154% (1276/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.349 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s14ms | Loss: 0.072 | Acc: 97.615% (1269/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.387 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.054 | Acc: 98.615% (1282/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 640ms | Loss: 0.362 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.043 | Acc: 99.000% (1287/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.388 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.059 | Acc: 98.000% (1274/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.430 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.051 | Acc: 98.308% (1278/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.428 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s33ms | Loss: 0.046 | Acc: 98.769% (1284/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.377 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s48ms | Loss: 0.048 | Acc: 98.538% (1281/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.304 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.058 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 632ms | Loss: 0.349 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.046 | Acc: 98.538% (1281/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.381 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.054 | Acc: 98.385% (1279/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 630ms | Loss: 0.351 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.044 | Acc: 98.692% (1283/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 633ms | Loss: 0.394 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.049 | Acc: 98.154% (1276/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.370 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.034 | Acc: 98.692% (1283/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.395 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.045 | Acc: 98.846% (1285/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.358 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.031 | Acc: 99.231% (1290/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.411 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.034 | Acc: 99.154% (1289/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.405 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.033 | Acc: 98.769% (1284/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.395 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s35ms | Loss: 0.035 | Acc: 98.923% (1286/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.413 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.028 | Acc: 99.692% (1296/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 639ms | Loss: 0.423 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.028 | Acc: 99.308% (1291/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.432 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.039 | Acc: 98.692% (1283/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.399 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.036 | Acc: 98.615% (1282/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.378 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s46ms | Loss: 0.027 | Acc: 99.077% (1288/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.402 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.029 | Acc: 99.231% (1290/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.411 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s31ms | Loss: 0.032 | Acc: 99.154% (1289/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.388 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.047 | Acc: 98.462% (1280/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.426 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.031 | Acc: 99.154% (1289/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.393 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.024 | Acc: 99.308% (1291/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.416 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s39ms | Loss: 0.025 | Acc: 99.154% (1289/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.409 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s58ms | Loss: 0.028 | Acc: 99.077% (1288/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.399 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s52ms | Loss: 0.019 | Acc: 99.769% (1297/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.393 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s50ms | Loss: 0.020 | Acc: 99.538% (1294/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.365 | Acc: 89.145% (271/304)\n",
      "   16 | 21m40s |   90.78947 |    0.0082 |    0.0013 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.603 | Acc: 67.385% (876/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.592 | Acc: 59.868% (182/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s48ms | Loss: 0.459 | Acc: 78.769% (1024/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.500 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s58ms | Loss: 0.406 | Acc: 81.462% (1059/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.454 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s68ms | Loss: 0.377 | Acc: 83.308% (1083/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 640ms | Loss: 0.470 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s55ms | Loss: 0.367 | Acc: 82.923% (1078/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.387 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s61ms | Loss: 0.333 | Acc: 84.923% (1104/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.583 | Acc: 72.697% (221/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.329 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.563 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s59ms | Loss: 0.310 | Acc: 86.308% (1122/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 642ms | Loss: 0.360 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 432ms | Tot: 15s47ms | Loss: 0.284 | Acc: 87.923% (1143/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.369 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s55ms | Loss: 0.305 | Acc: 87.385% (1136/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 1.267 | Acc: 40.789% (124/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.299 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.271 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.262 | Acc: 88.923% (1156/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.289 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.254 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 642ms | Loss: 0.337 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.259 | Acc: 89.077% (1158/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.382 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.246 | Acc: 90.385% (1175/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.368 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s46ms | Loss: 0.230 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.257 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.236 | Acc: 90.615% (1178/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.511 | Acc: 75.987% (231/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s57ms | Loss: 0.244 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.468 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s40ms | Loss: 0.209 | Acc: 91.000% (1183/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.390 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s39ms | Loss: 0.234 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 636ms | Loss: 0.529 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s50ms | Loss: 0.214 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.269 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.204 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.469 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s54ms | Loss: 0.210 | Acc: 92.077% (1197/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.324 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.192 | Acc: 92.692% (1205/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.269 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s49ms | Loss: 0.165 | Acc: 92.769% (1206/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.289 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.179 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.271 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s58ms | Loss: 0.186 | Acc: 92.000% (1196/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.416 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s48ms | Loss: 0.178 | Acc: 93.385% (1214/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.374 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s63ms | Loss: 0.196 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 638ms | Loss: 0.718 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s48ms | Loss: 0.223 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.285 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.138 | Acc: 94.462% (1228/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 640ms | Loss: 0.332 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.111 | Acc: 96.385% (1253/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.297 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s58ms | Loss: 0.106 | Acc: 96.154% (1250/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.293 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s63ms | Loss: 0.119 | Acc: 95.462% (1241/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.315 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s52ms | Loss: 0.101 | Acc: 96.462% (1254/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.296 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.110 | Acc: 96.769% (1258/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.297 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s53ms | Loss: 0.107 | Acc: 96.538% (1255/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.290 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s57ms | Loss: 0.093 | Acc: 96.231% (1251/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.319 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s51ms | Loss: 0.088 | Acc: 97.077% (1262/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.307 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s46ms | Loss: 0.093 | Acc: 96.538% (1255/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.317 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s55ms | Loss: 0.072 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.345 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s34ms | Loss: 0.084 | Acc: 97.231% (1264/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.307 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.073 | Acc: 97.077% (1262/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.334 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s53ms | Loss: 0.059 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.320 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s55ms | Loss: 0.080 | Acc: 96.923% (1260/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.340 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s49ms | Loss: 0.063 | Acc: 98.462% (1280/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.348 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s50ms | Loss: 0.061 | Acc: 98.154% (1276/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.327 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.058 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.371 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.051 | Acc: 98.615% (1282/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 640ms | Loss: 0.310 | Acc: 88.487% (269/304)\n",
      "   17 | 13m39s |   90.78947 |    0.0048 |    0.0012 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s36ms | Loss: 0.605 | Acc: 68.923% (896/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.803 | Acc: 63.487% (193/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.454 | Acc: 79.308% (1031/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.568 | Acc: 66.776% (203/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s68ms | Loss: 0.384 | Acc: 83.462% (1085/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.430 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s53ms | Loss: 0.348 | Acc: 84.692% (1101/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.379 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s39ms | Loss: 0.335 | Acc: 86.000% (1118/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.341 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s55ms | Loss: 0.323 | Acc: 85.231% (1108/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.539 | Acc: 75.000% (228/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.309 | Acc: 86.308% (1122/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.324 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.310 | Acc: 86.462% (1124/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.611 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s52ms | Loss: 0.290 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.413 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s48ms | Loss: 0.286 | Acc: 88.462% (1150/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 630ms | Loss: 0.332 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s29ms | Loss: 0.285 | Acc: 88.077% (1145/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.553 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s48ms | Loss: 0.245 | Acc: 90.308% (1174/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.440 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s51ms | Loss: 0.229 | Acc: 90.231% (1173/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.308 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.239 | Acc: 89.923% (1169/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.348 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.242 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.318 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s60ms | Loss: 0.227 | Acc: 90.692% (1179/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.302 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.256 | Acc: 88.846% (1155/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.463 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.223 | Acc: 90.231% (1173/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.320 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s56ms | Loss: 0.235 | Acc: 91.615% (1191/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.328 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s50ms | Loss: 0.239 | Acc: 89.077% (1158/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.362 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s47ms | Loss: 0.209 | Acc: 91.769% (1193/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.650 | Acc: 73.355% (223/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s47ms | Loss: 0.212 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.520 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s57ms | Loss: 0.205 | Acc: 91.231% (1186/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.310 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s44ms | Loss: 0.191 | Acc: 93.077% (1210/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.611 | Acc: 74.671% (227/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.199 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.277 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.182 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.392 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.163 | Acc: 94.000% (1222/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.312 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s50ms | Loss: 0.180 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.330 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s25ms | Loss: 0.173 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.294 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s32ms | Loss: 0.188 | Acc: 92.846% (1207/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.467 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s40ms | Loss: 0.130 | Acc: 95.231% (1238/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.319 | Acc: 84.211% (256/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.117 | Acc: 96.231% (1251/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.321 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s38ms | Loss: 0.125 | Acc: 95.154% (1237/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.334 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 431ms | Tot: 15s50ms | Loss: 0.097 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.360 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s23ms | Loss: 0.098 | Acc: 97.000% (1261/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.321 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.091 | Acc: 97.000% (1261/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.359 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.081 | Acc: 97.231% (1264/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 632ms | Loss: 0.323 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.083 | Acc: 97.308% (1265/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 634ms | Loss: 0.387 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.082 | Acc: 97.538% (1268/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.387 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s41ms | Loss: 0.071 | Acc: 97.846% (1272/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.349 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.076 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.338 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s28ms | Loss: 0.065 | Acc: 97.615% (1269/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.346 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s35ms | Loss: 0.064 | Acc: 98.000% (1274/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.354 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.086 | Acc: 97.462% (1267/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.334 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s48ms | Loss: 0.063 | Acc: 97.846% (1272/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.384 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s34ms | Loss: 0.068 | Acc: 97.692% (1270/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.390 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s45ms | Loss: 0.068 | Acc: 97.769% (1271/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 636ms | Loss: 0.350 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s44ms | Loss: 0.041 | Acc: 98.538% (1281/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.399 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.049 | Acc: 98.308% (1278/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.369 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 427ms | Tot: 15s35ms | Loss: 0.056 | Acc: 97.923% (1273/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.402 | Acc: 85.526% (260/304)\n",
      "   18 | 13m55s |   88.48684 |    0.0065 |    0.0013 | \n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.577 | Acc: 69.692% (906/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 638ms | Loss: 0.511 | Acc: 69.737% (212/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.427 | Acc: 80.000% (1040/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.404 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.358 | Acc: 84.538% (1099/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.537 | Acc: 72.368% (220/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.354 | Acc: 84.615% (1100/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 639ms | Loss: 0.444 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s47ms | Loss: 0.353 | Acc: 84.692% (1101/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 631ms | Loss: 0.468 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.302 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.399 | Acc: 82.566% (251/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.320 | Acc: 84.769% (1102/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.305 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s36ms | Loss: 0.313 | Acc: 87.308% (1135/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.386 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.300 | Acc: 87.462% (1137/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.316 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.283 | Acc: 87.615% (1139/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 634ms | Loss: 0.390 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s35ms | Loss: 0.253 | Acc: 88.385% (1149/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.336 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s44ms | Loss: 0.254 | Acc: 89.154% (1159/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.374 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s43ms | Loss: 0.255 | Acc: 89.000% (1157/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.406 | Acc: 78.618% (239/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s45ms | Loss: 0.226 | Acc: 90.462% (1176/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.362 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.265 | Acc: 89.692% (1166/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.712 | Acc: 68.750% (209/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s43ms | Loss: 0.236 | Acc: 90.538% (1177/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.347 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s39ms | Loss: 0.250 | Acc: 90.231% (1173/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 634ms | Loss: 0.381 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s38ms | Loss: 0.231 | Acc: 90.000% (1170/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.297 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s38ms | Loss: 0.219 | Acc: 90.923% (1182/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.220 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.248 | Acc: 89.231% (1160/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.605 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.254 | Acc: 90.154% (1172/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.329 | Acc: 83.224% (253/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s55ms | Loss: 0.225 | Acc: 91.077% (1184/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.272 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s37ms | Loss: 0.219 | Acc: 91.385% (1188/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.314 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.190 | Acc: 92.615% (1204/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.414 | Acc: 80.263% (244/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.197 | Acc: 92.154% (1198/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.347 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s33ms | Loss: 0.202 | Acc: 91.692% (1192/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 635ms | Loss: 0.262 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.193 | Acc: 92.615% (1204/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.279 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s46ms | Loss: 0.192 | Acc: 91.923% (1195/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.370 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s51ms | Loss: 0.191 | Acc: 93.154% (1211/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.355 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s54ms | Loss: 0.179 | Acc: 92.538% (1203/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 634ms | Loss: 0.300 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.132 | Acc: 94.231% (1225/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 633ms | Loss: 0.293 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s42ms | Loss: 0.109 | Acc: 95.615% (1243/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.306 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s33ms | Loss: 0.126 | Acc: 94.846% (1233/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.315 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s42ms | Loss: 0.109 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 639ms | Loss: 0.297 | Acc: 89.145% (271/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s41ms | Loss: 0.113 | Acc: 96.231% (1251/1300))\n",
      "[=================== 5/5 ============>........]  Step: 146ms | Tot: 636ms | Loss: 0.320 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.098 | Acc: 96.308% (1252/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 638ms | Loss: 0.323 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s41ms | Loss: 0.094 | Acc: 96.846% (1259/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 637ms | Loss: 0.322 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s39ms | Loss: 0.098 | Acc: 96.077% (1249/1300))\n",
      "[=================== 5/5 ============>........]  Step: 143ms | Tot: 635ms | Loss: 0.301 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s33ms | Loss: 0.094 | Acc: 96.692% (1257/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.358 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 429ms | Tot: 15s43ms | Loss: 0.088 | Acc: 96.923% (1260/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.320 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s52ms | Loss: 0.086 | Acc: 96.769% (1258/1300))\n",
      "[=================== 5/5 ============>........]  Step: 145ms | Tot: 637ms | Loss: 0.351 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 428ms | Tot: 15s30ms | Loss: 0.079 | Acc: 97.231% (1264/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 635ms | Loss: 0.324 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s52ms | Loss: 0.081 | Acc: 97.154% (1263/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 633ms | Loss: 0.374 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 430ms | Tot: 15s42ms | Loss: 0.067 | Acc: 98.000% (1274/1300))\n",
      "[=================== 5/5 ============>........]  Step: 144ms | Tot: 636ms | Loss: 0.343 | Acc: 88.487% (269/304)\n",
      "   19 | 12m15s |   90.78947 |    0.0091 |    0.0010 | \n"
     ]
    }
   ],
   "source": [
    "#Bayesian optimization\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "opt_hist=[]\n",
    "def resnet_evaluate(lr,wd):\n",
    "    global net,criterion, optimizer,scheduler\n",
    "    \n",
    "    net = resnet.resnet18(num_classes=2)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Adam does not perform so good here\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd, nesterov= True)\n",
    "    scheduler = MultiStepLR(optimizer, [30,60,90], gamma=0.1)\n",
    "    #5e-3 86\n",
    "    if use_cuda:\n",
    "        criterion.cuda()\n",
    "        net.cuda()\n",
    "    result = train(epoch=120,early_stopping=25)\n",
    "    opt_hist.append(result)\n",
    "    return result[0]\n",
    "\n",
    "resnetOB = BayesianOptimization(resnet_evaluate, {'lr': (0.0001, 0.1),\n",
    "                                                   'wd':(0.0001, 0.1)\n",
    "                                                 })\n",
    "\n",
    "resnetOB.explore({\n",
    "'lr': (0.1, 0.01,0.001,0.1, 0.01,0.001),\n",
    "'wd':(0.0001, 0.0001,0.0001,0.001,0.002,0.003)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "resnetOB.maximize(init_points=3, n_iter=10,acq='ei', xi=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': {'params': [{'lr': 0.099969837126105854, 'wd': 0.0048768157841404631},\n",
       "   {'lr': 0.005636454096473553, 'wd': 0.0012221947368002359},\n",
       "   {'lr': 0.099246510214096528, 'wd': 0.0027344024076647543},\n",
       "   {'lr': 0.099959725736288932, 'wd': 0.0024664062526430623},\n",
       "   {'lr': 0.099422206390654952, 'wd': 0.0071210893402104142},\n",
       "   {'lr': 0.0026487236284499088, 'wd': 0.0015270389790467936},\n",
       "   {'lr': 0.0082483652834426258, 'wd': 0.0012592003869237804},\n",
       "   {'lr': 0.0048465324038598672, 'wd': 0.0012104365001951837},\n",
       "   {'lr': 0.0064880244084614732, 'wd': 0.0012612161415386236},\n",
       "   {'lr': 0.0090556414439709517, 'wd': 0.0010343458814944075}],\n",
       "  'values': [90.78947368421052,\n",
       "   91.44736842105263,\n",
       "   89.80263157894737,\n",
       "   90.131578947368425,\n",
       "   89.473684210526315,\n",
       "   91.118421052631575,\n",
       "   90.78947368421052,\n",
       "   90.78947368421052,\n",
       "   88.486842105263165,\n",
       "   90.78947368421052]},\n",
       " 'max': {'max_params': {'lr': 0.005636454096473553,\n",
       "   'wd': 0.0012221947368002359},\n",
       "  'max_val': 91.44736842105263}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#30,60, 90 learning rate decay\n",
    "#\n",
    "resnetOB.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.cuda.DoubleTensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = torch.cat((out.data,out.data),1)\n",
    "out1.size()\n",
    "# out\n",
    "criterion(out,y.long())\n",
    "type(predicted)\n",
    "type(y.data)\n",
    "#predicted.eq(y.data).cpu().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 132/132 ================>]  Step: 162ms | Tot: 27s166ms\n"
     ]
    }
   ],
   "source": [
    "net = resnet.resnet34(num_classes=2)\n",
    "net.load_state_dict(torch.load('resnet34_acc_add_tran.pth'))\n",
    "net.cuda()\n",
    "\n",
    "test = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test)\n",
    "test_X.shape \n",
    "fake_label = np.zeros(len(test_X))\n",
    "\n",
    "test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "prob = [] \n",
    "net.eval()\n",
    "for k, (val_x, val_y) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    x = Variable(val_x)\n",
    "    y = Variable(val_y)\n",
    "    out = net(x)\n",
    "    #prevent overflow\n",
    "    temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "    ans= temp[:,1]/(temp.sum(axis=1))\n",
    "    prob.append(ans)\n",
    "    #print(out.size())\n",
    "    progress_bar(k, len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(prob).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['is_iceberg'] = np.concatenate(prob)\n",
    "sub.shape\n",
    "sub.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg</th>\n",
       "      <th>is_iceberg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg2</th>\n",
       "      <td>0.886197</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_iceberg  is_iceberg2\n",
       "is_iceberg     1.000000     0.886197\n",
       "is_iceberg2    0.886197     1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp= pd.read_csv('submission3.csv') #0.0001 wd one\n",
    "sub['is_iceberg2'] = temp['is_iceberg']\n",
    "sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s242ms | Loss: 4.618 | Acc: 56.231% (731/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 421.466 | Acc: 50.658% (154/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s191ms | Loss: 2.397 | Acc: 59.308% (771/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 767ms | Loss: 1032.273 | Acc: 49.342% (150/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s228ms | Loss: 1.995 | Acc: 58.154% (756/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 766ms | Loss: 522.733 | Acc: 59.539% (181/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 469ms | Tot: 16s205ms | Loss: 5.970 | Acc: 52.615% (684/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 9.002 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s191ms | Loss: 3.195 | Acc: 54.462% (708/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.840 | Acc: 52.961% (161/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s179ms | Loss: 1.515 | Acc: 52.154% (678/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.748 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s195ms | Loss: 0.984 | Acc: 56.231% (731/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.692 | Acc: 50.329% (153/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s187ms | Loss: 0.867 | Acc: 53.769% (699/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.699 | Acc: 53.289% (162/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s196ms | Loss: 0.785 | Acc: 52.846% (687/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.682 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s211ms | Loss: 0.799 | Acc: 51.077% (664/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.677 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s200ms | Loss: 0.724 | Acc: 52.385% (681/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.682 | Acc: 57.895% (176/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s189ms | Loss: 0.731 | Acc: 54.308% (706/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 762ms | Loss: 0.682 | Acc: 56.908% (173/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s203ms | Loss: 0.708 | Acc: 54.308% (706/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.669 | Acc: 60.197% (183/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s204ms | Loss: 0.697 | Acc: 54.385% (707/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.690 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s214ms | Loss: 0.704 | Acc: 54.692% (711/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.696 | Acc: 50.329% (153/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s185ms | Loss: 0.693 | Acc: 52.462% (682/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 768ms | Loss: 0.696 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s197ms | Loss: 0.695 | Acc: 54.308% (706/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 773ms | Loss: 0.681 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s211ms | Loss: 0.686 | Acc: 56.615% (736/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.667 | Acc: 60.855% (185/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s187ms | Loss: 0.694 | Acc: 55.385% (720/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 762ms | Loss: 0.674 | Acc: 55.921% (170/304)  Step: 200ms | Tot: 591ms | Loss: 0.678 | Acc: 55.859% (143/256)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s183ms | Loss: 0.682 | Acc: 58.231% (757/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.678 | Acc: 61.842% (188/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s168ms | Loss: 0.690 | Acc: 56.385% (733/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.669 | Acc: 56.579% (172/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s214ms | Loss: 0.690 | Acc: 52.846% (687/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.667 | Acc: 54.276% (165/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s217ms | Loss: 0.684 | Acc: 56.308% (732/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.681 | Acc: 61.513% (187/304)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s195ms | Loss: 0.674 | Acc: 58.385% (759/1300)\n",
      "[=================== 5/5 ============>........]  Step: 170ms | Tot: 764ms | Loss: 0.658 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s189ms | Loss: 0.681 | Acc: 57.923% (753/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.643 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s215ms | Loss: 0.677 | Acc: 57.462% (747/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 774ms | Loss: 0.656 | Acc: 66.447% (202/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s175ms | Loss: 0.686 | Acc: 57.692% (750/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.654 | Acc: 64.803% (197/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s206ms | Loss: 0.672 | Acc: 57.692% (750/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.661 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s210ms | Loss: 0.681 | Acc: 57.538% (748/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 769ms | Loss: 0.640 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s205ms | Loss: 0.677 | Acc: 58.615% (762/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.646 | Acc: 66.776% (203/304) Step: 199ms | Tot: 394ms | Loss: 0.658 | Acc: 63.542% (122/192)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s191ms | Loss: 0.659 | Acc: 59.692% (776/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 819ms | Loss: 0.626 | Acc: 67.105% (204/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s152ms | Loss: 0.675 | Acc: 60.000% (780/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.656 | Acc: 54.605% (166/304) Step: 200ms | Tot: 394ms | Loss: 0.668 | Acc: 53.646% (103/192)\n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s176ms | Loss: 0.671 | Acc: 58.231% (757/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 771ms | Loss: 0.680 | Acc: 55.263% (168/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s202ms | Loss: 0.662 | Acc: 60.385% (785/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.692 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s224ms | Loss: 0.662 | Acc: 59.769% (777/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 770ms | Loss: 0.646 | Acc: 67.763% (206/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s205ms | Loss: 0.669 | Acc: 58.769% (764/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.646 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s197ms | Loss: 0.670 | Acc: 58.154% (756/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.665 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s195ms | Loss: 0.669 | Acc: 58.231% (757/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.668 | Acc: 64.474% (196/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s200ms | Loss: 0.674 | Acc: 59.231% (770/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 765ms | Loss: 0.660 | Acc: 54.276% (165/304) Step: 199ms | Tot: 390ms | Loss: 0.665 | Acc: 53.125% (102/192)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s196ms | Loss: 0.666 | Acc: 60.385% (785/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 764ms | Loss: 0.670 | Acc: 50.329% (153/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s201ms | Loss: 0.661 | Acc: 59.231% (770/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.638 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s187ms | Loss: 0.657 | Acc: 59.846% (778/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.657 | Acc: 64.145% (195/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s189ms | Loss: 0.652 | Acc: 60.769% (790/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.638 | Acc: 66.118% (201/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s195ms | Loss: 0.688 | Acc: 54.462% (708/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.675 | Acc: 57.237% (174/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s160ms | Loss: 0.687 | Acc: 55.077% (716/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.675 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s188ms | Loss: 0.667 | Acc: 59.538% (774/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.655 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s177ms | Loss: 0.671 | Acc: 59.538% (774/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.647 | Acc: 58.882% (179/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s194ms | Loss: 0.659 | Acc: 61.385% (798/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.635 | Acc: 65.461% (199/304) 3/5 \n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s180ms | Loss: 0.659 | Acc: 59.538% (774/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.675 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s175ms | Loss: 0.655 | Acc: 60.154% (782/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.669 | Acc: 55.921% (170/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s190ms | Loss: 0.643 | Acc: 61.769% (803/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 776ms | Loss: 0.634 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s200ms | Loss: 0.648 | Acc: 60.308% (784/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.617 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s173ms | Loss: 0.639 | Acc: 61.154% (795/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.648 | Acc: 63.816% (194/304)\n",
      "\n",
      "This is epoch:54\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s211ms | Loss: 0.650 | Acc: 60.615% (788/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 765ms | Loss: 0.665 | Acc: 66.776% (203/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s203ms | Loss: 0.637 | Acc: 62.385% (811/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 770ms | Loss: 0.674 | Acc: 56.250% (171/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s188ms | Loss: 0.633 | Acc: 61.385% (798/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.620 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s207ms | Loss: 0.633 | Acc: 60.308% (784/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.820 | Acc: 69.737% (212/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s180ms | Loss: 0.627 | Acc: 62.615% (814/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.651 | Acc: 61.184% (186/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s211ms | Loss: 0.628 | Acc: 62.308% (810/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.603 | Acc: 69.408% (211/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s186ms | Loss: 0.607 | Acc: 63.231% (822/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.626 | Acc: 62.500% (190/304)  Step: 200ms | Tot: 593ms | Loss: 0.628 | Acc: 62.891% (161/256)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s170ms | Loss: 0.614 | Acc: 64.000% (832/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 861ms | Loss: 0.613 | Acc: 61.842% (188/304)\n",
      "\n",
      "This is epoch:62\n",
      "[=================== 41/41 =================>.]  Step: 466ms | Tot: 16s171ms | Loss: 0.647 | Acc: 58.923% (766/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.618 | Acc: 62.171% (189/304)\n",
      "\n",
      "This is epoch:63\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s151ms | Loss: 0.612 | Acc: 62.769% (816/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.616 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:64\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s178ms | Loss: 0.612 | Acc: 63.615% (827/1300)\n",
      "[=================== 5/5 ============>........]  Step: 170ms | Tot: 762ms | Loss: 0.656 | Acc: 58.553% (178/304)\n",
      "\n",
      "This is epoch:65\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s200ms | Loss: 0.619 | Acc: 63.846% (830/1300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 1.166 | Acc: 54.605% (166/304)\n",
      "\n",
      "This is epoch:66\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s185ms | Loss: 0.602 | Acc: 65.538% (852/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 837ms | Loss: 0.596 | Acc: 69.079% (210/304)\n",
      "\n",
      "This is epoch:67\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s185ms | Loss: 0.594 | Acc: 64.769% (842/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.633 | Acc: 63.487% (193/304)\n",
      "\n",
      "This is epoch:68\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s184ms | Loss: 0.610 | Acc: 63.308% (823/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.650 | Acc: 68.421% (208/304)\n",
      "\n",
      "This is epoch:69\n",
      "[=================== 41/41 =================>.]  Step: 466ms | Tot: 16s189ms | Loss: 0.606 | Acc: 65.077% (846/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 763ms | Loss: 0.641 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:70\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s189ms | Loss: 0.601 | Acc: 66.538% (865/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 767ms | Loss: 0.573 | Acc: 70.724% (215/304) Step: 200ms | Tot: 391ms | Loss: 0.588 | Acc: 67.188% (129/192)\n",
      "\n",
      "This is epoch:71\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s206ms | Loss: 0.584 | Acc: 67.692% (880/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 771ms | Loss: 0.641 | Acc: 64.145% (195/304)\n",
      "\n",
      "This is epoch:72\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s242ms | Loss: 0.592 | Acc: 65.769% (855/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.571 | Acc: 64.474% (196/304)\n",
      "\n",
      "This is epoch:73\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s193ms | Loss: 0.574 | Acc: 66.769% (868/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.560 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:74\n",
      "[=================== 41/41 =================>.]  Step: 455ms | Tot: 16s277ms | Loss: 0.560 | Acc: 69.231% (900/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.594 | Acc: 65.789% (200/304)\n",
      "\n",
      "This is epoch:75\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s178ms | Loss: 0.554 | Acc: 68.769% (894/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.524 | Acc: 74.013% (225/304)  Step: 200ms | Tot: 591ms | Loss: 0.531 | Acc: 72.656% (186/256)\n",
      "\n",
      "This is epoch:76\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s291ms | Loss: 0.540 | Acc: 72.308% (940/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.486 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:77\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s200ms | Loss: 0.520 | Acc: 72.846% (947/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 766ms | Loss: 0.477 | Acc: 76.645% (233/304)\n",
      "\n",
      "This is epoch:78\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s194ms | Loss: 0.500 | Acc: 73.000% (949/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.443 | Acc: 78.618% (239/304)  Step: 200ms | Tot: 592ms | Loss: 0.456 | Acc: 77.734% (199/256)\n",
      "\n",
      "This is epoch:79\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s197ms | Loss: 0.468 | Acc: 76.000% (988/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.552 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:80\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s207ms | Loss: 0.446 | Acc: 78.615% (1022/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.369 | Acc: 85.855% (261/304)\n",
      "\n",
      "This is epoch:81\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s187ms | Loss: 0.440 | Acc: 78.769% (1024/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 769ms | Loss: 0.369 | Acc: 85.526% (260/304)  Step: 200ms | Tot: 393ms | Loss: 0.379 | Acc: 85.938% (165/192)  Step: 200ms | Tot: 594ms | Loss: 0.368 | Acc: 85.547% (219/256)\n",
      "\n",
      "This is epoch:82\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s238ms | Loss: 0.405 | Acc: 80.154% (1042/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.377 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:83\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s279ms | Loss: 0.425 | Acc: 80.385% (1045/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 768ms | Loss: 0.446 | Acc: 80.921% (246/304)\n",
      "\n",
      "This is epoch:84\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s366ms | Loss: 0.391 | Acc: 82.077% (1067/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.350 | Acc: 82.566% (251/304)  Step: 200ms | Tot: 396ms | Loss: 0.378 | Acc: 80.208% (154/192)\n",
      "\n",
      "This is epoch:85\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s274ms | Loss: 0.403 | Acc: 81.923% (1065/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.325 | Acc: 86.184% (262/304)\n",
      "\n",
      "This is epoch:86\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s204ms | Loss: 0.386 | Acc: 81.538% (1060/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.343 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:87\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s197ms | Loss: 0.382 | Acc: 81.154% (1055/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.335 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:88\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s197ms | Loss: 0.373 | Acc: 81.769% (1063/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.389 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:89\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s185ms | Loss: 0.361 | Acc: 81.846% (1064/1300)\n",
      "[=================== 5/5 ============>........]  Step: 170ms | Tot: 765ms | Loss: 0.337 | Acc: 84.868% (258/304)  Step: 200ms | Tot: 393ms | Loss: 0.348 | Acc: 82.812% (159/192)\n",
      "\n",
      "This is epoch:90\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s185ms | Loss: 0.338 | Acc: 84.462% (1098/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.366 | Acc: 83.553% (254/304)\n",
      "\n",
      "This is epoch:91\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s174ms | Loss: 0.334 | Acc: 83.385% (1084/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.311 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:92\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s162ms | Loss: 0.350 | Acc: 84.154% (1094/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.280 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:93\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s171ms | Loss: 0.362 | Acc: 83.077% (1080/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 766ms | Loss: 0.406 | Acc: 81.250% (247/304)\n",
      "\n",
      "This is epoch:94\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s208ms | Loss: 0.342 | Acc: 84.154% (1094/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.276 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:95\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s201ms | Loss: 0.393 | Acc: 81.692% (1062/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.493 | Acc: 75.658% (230/304)\n",
      "\n",
      "This is epoch:96\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s200ms | Loss: 0.330 | Acc: 83.154% (1081/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.268 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:97\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s205ms | Loss: 0.328 | Acc: 84.923% (1104/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.268 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:98\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s191ms | Loss: 0.328 | Acc: 83.462% (1085/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.289 | Acc: 84.868% (258/304)\n",
      "\n",
      "This is epoch:99\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s188ms | Loss: 0.345 | Acc: 84.385% (1097/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 774ms | Loss: 0.433 | Acc: 81.579% (248/304)\n",
      "\n",
      "This is epoch:100\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s169ms | Loss: 0.320 | Acc: 85.385% (1110/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.278 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:101\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s187ms | Loss: 0.306 | Acc: 86.615% (1126/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.251 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:102\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s215ms | Loss: 0.275 | Acc: 87.846% (1142/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 764ms | Loss: 0.254 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:103\n",
      "[=================== 41/41 =================>.]  Step: 455ms | Tot: 16s197ms | Loss: 0.301 | Acc: 86.154% (1120/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.248 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:104\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s196ms | Loss: 0.282 | Acc: 87.000% (1131/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.247 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:105\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s192ms | Loss: 0.285 | Acc: 87.462% (1137/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.243 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:106\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s205ms | Loss: 0.275 | Acc: 87.154% (1133/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 768ms | Loss: 0.241 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:107\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s196ms | Loss: 0.302 | Acc: 87.462% (1137/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 769ms | Loss: 0.252 | Acc: 90.132% (274/304)  Step: 199ms | Tot: 393ms | Loss: 0.252 | Acc: 89.062% (171/192)\n",
      "\n",
      "This is epoch:108\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s197ms | Loss: 0.280 | Acc: 88.077% (1145/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 765ms | Loss: 0.247 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:109\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s136ms | Loss: 0.274 | Acc: 87.846% (1142/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.236 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:110\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s195ms | Loss: 0.279 | Acc: 87.769% (1141/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.243 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:111\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s164ms | Loss: 0.300 | Acc: 86.308% (1122/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.261 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:112\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s196ms | Loss: 0.266 | Acc: 88.000% (1144/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 762ms | Loss: 0.255 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:113\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s201ms | Loss: 0.278 | Acc: 87.462% (1137/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 850ms | Loss: 0.236 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:114\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s200ms | Loss: 0.273 | Acc: 87.385% (1136/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.256 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:115\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s200ms | Loss: 0.283 | Acc: 86.769% (1128/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.232 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:116\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s199ms | Loss: 0.264 | Acc: 87.308% (1135/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 763ms | Loss: 0.255 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:117\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s188ms | Loss: 0.271 | Acc: 87.692% (1140/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 771ms | Loss: 0.255 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:118\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s197ms | Loss: 0.291 | Acc: 87.077% (1132/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 762ms | Loss: 0.258 | Acc: 90.789% (276/304)  Step: 200ms | Tot: 590ms | Loss: 0.242 | Acc: 91.406% (234/256)\n",
      "\n",
      "This is epoch:119\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s204ms | Loss: 0.259 | Acc: 88.692% (1153/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.247 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:120\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s279ms | Loss: 0.268 | Acc: 88.154% (1146/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.256 | Acc: 88.158% (268/304)\n",
      "\n",
      "This is epoch:121\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s187ms | Loss: 0.269 | Acc: 87.692% (1140/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.246 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:122\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s199ms | Loss: 0.264 | Acc: 87.692% (1140/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 767ms | Loss: 0.239 | Acc: 91.447% (278/304)  Step: 199ms | Tot: 595ms | Loss: 0.226 | Acc: 91.797% (235/256)\n",
      "\n",
      "This is epoch:123\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s181ms | Loss: 0.261 | Acc: 88.692% (1153/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 761ms | Loss: 0.234 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:124\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s200ms | Loss: 0.258 | Acc: 88.154% (1146/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.256 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:125\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s196ms | Loss: 0.289 | Acc: 87.308% (1135/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 764ms | Loss: 0.232 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:126\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s190ms | Loss: 0.260 | Acc: 88.154% (1146/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.244 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:127\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s270ms | Loss: 0.269 | Acc: 88.308% (1148/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.227 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:128\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s186ms | Loss: 0.257 | Acc: 87.846% (1142/1300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 775ms | Loss: 0.245 | Acc: 89.474% (272/304)  Step: 200ms | Tot: 400ms | Loss: 0.246 | Acc: 88.021% (169/192)\n",
      "\n",
      "This is epoch:129\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s203ms | Loss: 0.266 | Acc: 87.154% (1133/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.238 | Acc: 91.447% (278/304)  Step: 200ms | Tot: 596ms | Loss: 0.224 | Acc: 91.797% (235/256)\n",
      "\n",
      "This is epoch:130\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s211ms | Loss: 0.272 | Acc: 87.923% (1143/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.230 | Acc: 90.461% (275/304)\n",
      "\n",
      "This is epoch:131\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s205ms | Loss: 0.252 | Acc: 88.000% (1144/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 775ms | Loss: 0.231 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:132\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s227ms | Loss: 0.280 | Acc: 87.308% (1135/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.237 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:133\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s210ms | Loss: 0.247 | Acc: 89.077% (1158/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 774ms | Loss: 0.232 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:134\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s207ms | Loss: 0.276 | Acc: 88.769% (1154/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.229 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:135\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s183ms | Loss: 0.254 | Acc: 87.615% (1139/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.238 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:136\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s198ms | Loss: 0.246 | Acc: 89.154% (1159/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.222 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:137\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s194ms | Loss: 0.253 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.238 | Acc: 90.132% (274/304)  Step: 200ms | Tot: 593ms | Loss: 0.222 | Acc: 91.016% (233/256)\n",
      "\n",
      "This is epoch:138\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s196ms | Loss: 0.252 | Acc: 88.769% (1154/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.251 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:139\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s190ms | Loss: 0.265 | Acc: 88.154% (1146/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.238 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:140\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s171ms | Loss: 0.259 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 775ms | Loss: 0.235 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:141\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s199ms | Loss: 0.251 | Acc: 89.000% (1157/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.243 | Acc: 90.132% (274/304)\n",
      "\n",
      "This is epoch:142\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s201ms | Loss: 0.257 | Acc: 89.000% (1157/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 762ms | Loss: 0.233 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:143\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s194ms | Loss: 0.264 | Acc: 88.000% (1144/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.227 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:144\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s211ms | Loss: 0.255 | Acc: 88.923% (1156/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.224 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:145\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s183ms | Loss: 0.257 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.224 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:146\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s201ms | Loss: 0.256 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.220 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:147\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s173ms | Loss: 0.260 | Acc: 88.692% (1153/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 772ms | Loss: 0.236 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:148\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s181ms | Loss: 0.246 | Acc: 89.000% (1157/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.228 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:149\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s194ms | Loss: 0.271 | Acc: 87.692% (1140/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.223 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:150\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s202ms | Loss: 0.258 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:151\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s188ms | Loss: 0.251 | Acc: 88.846% (1155/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.212 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:152\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s210ms | Loss: 0.243 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.215 | Acc: 92.763% (282/304)  Step: 199ms | Tot: 397ms | Loss: 0.213 | Acc: 93.229% (179/192)\n",
      "\n",
      "This is epoch:153\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s202ms | Loss: 0.248 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 775ms | Loss: 0.222 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:154\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s197ms | Loss: 0.254 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.219 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:155\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s194ms | Loss: 0.227 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 762ms | Loss: 0.221 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:156\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s200ms | Loss: 0.222 | Acc: 91.077% (1184/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:157\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s306ms | Loss: 0.254 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.225 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:158\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s212ms | Loss: 0.244 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.225 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:159\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s307ms | Loss: 0.247 | Acc: 88.923% (1156/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.215 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:160\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s304ms | Loss: 0.231 | Acc: 90.462% (1176/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.225 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:161\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s281ms | Loss: 0.236 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.219 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:162\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s176ms | Loss: 0.230 | Acc: 90.385% (1175/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.219 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:163\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s202ms | Loss: 0.246 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.218 | Acc: 91.118% (277/304)\n",
      "\n",
      "This is epoch:164\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s213ms | Loss: 0.243 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 774ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:165\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s196ms | Loss: 0.240 | Acc: 90.154% (1172/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.218 | Acc: 91.776% (279/304)  Step: 200ms | Tot: 595ms | Loss: 0.205 | Acc: 92.578% (237/256)\n",
      "\n",
      "This is epoch:166\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s219ms | Loss: 0.244 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.220 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:167\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s210ms | Loss: 0.236 | Acc: 88.538% (1151/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.213 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:168\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s195ms | Loss: 0.240 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 854ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:169\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s210ms | Loss: 0.234 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.221 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:170\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s196ms | Loss: 0.229 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 761ms | Loss: 0.213 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:171\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s213ms | Loss: 0.247 | Acc: 88.615% (1152/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.215 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:172\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s198ms | Loss: 0.253 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 775ms | Loss: 0.215 | Acc: 92.434% (281/304)  Step: 200ms | Tot: 396ms | Loss: 0.204 | Acc: 93.229% (179/192)\n",
      "\n",
      "This is epoch:173\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s203ms | Loss: 0.238 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.213 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:174\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s210ms | Loss: 0.246 | Acc: 89.154% (1159/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 764ms | Loss: 0.213 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:175\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s203ms | Loss: 0.253 | Acc: 88.923% (1156/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.215 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:176\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s193ms | Loss: 0.241 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.215 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:177\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s192ms | Loss: 0.238 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 762ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:178\n",
      "[=================== 41/41 =================>.]  Step: 456ms | Tot: 16s185ms | Loss: 0.234 | Acc: 90.154% (1172/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.216 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:179\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s204ms | Loss: 0.231 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.217 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:180\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s165ms | Loss: 0.222 | Acc: 90.846% (1181/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.215 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:181\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s204ms | Loss: 0.243 | Acc: 89.692% (1166/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 764ms | Loss: 0.213 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:182\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s169ms | Loss: 0.222 | Acc: 90.538% (1177/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.217 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:183\n",
      "[=================== 41/41 =================>.]  Step: 455ms | Tot: 16s178ms | Loss: 0.242 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:184\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s202ms | Loss: 0.226 | Acc: 91.231% (1186/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 774ms | Loss: 0.217 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:185\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s257ms | Loss: 0.237 | Acc: 88.923% (1156/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 773ms | Loss: 0.220 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:186\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s198ms | Loss: 0.264 | Acc: 89.308% (1161/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 761ms | Loss: 0.211 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:187\n",
      "[=================== 41/41 =================>.]  Step: 455ms | Tot: 16s192ms | Loss: 0.239 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.226 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:188\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s202ms | Loss: 0.241 | Acc: 90.154% (1172/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 823ms | Loss: 0.217 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:189\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s184ms | Loss: 0.241 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 764ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:190\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s262ms | Loss: 0.237 | Acc: 90.154% (1172/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.216 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:191\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s191ms | Loss: 0.241 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.219 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s195ms | Loss: 0.239 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 769ms | Loss: 0.215 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:193\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s206ms | Loss: 0.239 | Acc: 89.846% (1168/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.214 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:194\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s207ms | Loss: 0.230 | Acc: 90.231% (1173/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.215 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:195\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s180ms | Loss: 0.230 | Acc: 90.385% (1175/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.216 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:196\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s179ms | Loss: 0.241 | Acc: 89.769% (1167/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 765ms | Loss: 0.216 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:197\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s188ms | Loss: 0.228 | Acc: 90.231% (1173/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.218 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:198\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s214ms | Loss: 0.236 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.220 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:199\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s198ms | Loss: 0.221 | Acc: 90.769% (1180/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.216 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:200\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s213ms | Loss: 0.251 | Acc: 89.538% (1164/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 771ms | Loss: 0.220 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:201\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s169ms | Loss: 0.235 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:202\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s214ms | Loss: 0.232 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.219 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:203\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s204ms | Loss: 0.238 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.217 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:204\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s189ms | Loss: 0.226 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.217 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:205\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s209ms | Loss: 0.230 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.215 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:206\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s207ms | Loss: 0.245 | Acc: 89.538% (1164/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.216 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:207\n",
      "[=================== 41/41 =================>.]  Step: 464ms | Tot: 16s213ms | Loss: 0.230 | Acc: 90.615% (1178/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 773ms | Loss: 0.219 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:208\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s190ms | Loss: 0.246 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.216 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:209\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s199ms | Loss: 0.236 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 772ms | Loss: 0.217 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:210\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s195ms | Loss: 0.220 | Acc: 91.231% (1186/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.213 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:211\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s169ms | Loss: 0.238 | Acc: 89.692% (1166/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.212 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:212\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s171ms | Loss: 0.238 | Acc: 89.846% (1168/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.220 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:213\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s173ms | Loss: 0.236 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.220 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:214\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s185ms | Loss: 0.226 | Acc: 90.462% (1176/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.217 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:215\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s213ms | Loss: 0.242 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.216 | Acc: 92.105% (280/304)  Step: 199ms | Tot: 396ms | Loss: 0.206 | Acc: 92.708% (178/192)\n",
      "\n",
      "This is epoch:216\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s206ms | Loss: 0.243 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.216 | Acc: 93.421% (284/304)\n",
      "\n",
      "This is epoch:217\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s198ms | Loss: 0.230 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.212 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:218\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s207ms | Loss: 0.240 | Acc: 89.538% (1164/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 768ms | Loss: 0.220 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:219\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s218ms | Loss: 0.238 | Acc: 89.231% (1160/1300)\n",
      "[=================== 5/5 ============>........]  Step: 174ms | Tot: 770ms | Loss: 0.217 | Acc: 93.421% (284/304)\n",
      "\n",
      "This is epoch:220\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s235ms | Loss: 0.236 | Acc: 89.154% (1159/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 769ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:221\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s196ms | Loss: 0.229 | Acc: 90.462% (1176/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.220 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:222\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s217ms | Loss: 0.237 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.220 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:223\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s213ms | Loss: 0.222 | Acc: 90.615% (1178/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.215 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:224\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s210ms | Loss: 0.240 | Acc: 90.231% (1173/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.215 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:225\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s206ms | Loss: 0.233 | Acc: 91.077% (1184/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 768ms | Loss: 0.217 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:226\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s206ms | Loss: 0.239 | Acc: 89.154% (1159/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.216 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:227\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s195ms | Loss: 0.261 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.215 | Acc: 93.421% (284/304)  Step: 199ms | Tot: 394ms | Loss: 0.204 | Acc: 94.792% (182/192)\n",
      "\n",
      "This is epoch:228\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s186ms | Loss: 0.242 | Acc: 89.538% (1164/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 769ms | Loss: 0.216 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:229\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s176ms | Loss: 0.231 | Acc: 89.769% (1167/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 767ms | Loss: 0.217 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:230\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s183ms | Loss: 0.224 | Acc: 91.000% (1183/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 764ms | Loss: 0.214 | Acc: 92.763% (282/304) 3/5 \n",
      "\n",
      "This is epoch:231\n",
      "[=================== 41/41 =================>.]  Step: 465ms | Tot: 16s266ms | Loss: 0.238 | Acc: 89.385% (1162/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 770ms | Loss: 0.225 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:232\n",
      "[=================== 41/41 =================>.]  Step: 460ms | Tot: 16s195ms | Loss: 0.244 | Acc: 90.385% (1175/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 765ms | Loss: 0.215 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:233\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s194ms | Loss: 0.253 | Acc: 88.923% (1156/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 769ms | Loss: 0.218 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:234\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s181ms | Loss: 0.235 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 772ms | Loss: 0.217 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:235\n",
      "[=================== 41/41 =================>.]  Step: 462ms | Tot: 16s198ms | Loss: 0.223 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 766ms | Loss: 0.218 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:236\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s194ms | Loss: 0.233 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 761ms | Loss: 0.217 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:237\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s198ms | Loss: 0.233 | Acc: 90.308% (1174/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 763ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:238\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s203ms | Loss: 0.236 | Acc: 90.846% (1181/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 766ms | Loss: 0.213 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:239\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s198ms | Loss: 0.230 | Acc: 90.385% (1175/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 770ms | Loss: 0.219 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:240\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s179ms | Loss: 0.244 | Acc: 89.000% (1157/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 769ms | Loss: 0.218 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:241\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s173ms | Loss: 0.232 | Acc: 90.615% (1178/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 766ms | Loss: 0.213 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:242\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s195ms | Loss: 0.230 | Acc: 91.000% (1183/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 774ms | Loss: 0.215 | Acc: 93.092% (283/304)\n",
      "\n",
      "This is epoch:243\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s183ms | Loss: 0.234 | Acc: 89.462% (1163/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 770ms | Loss: 0.215 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:244\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s169ms | Loss: 0.229 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 763ms | Loss: 0.216 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:245\n",
      "[=================== 41/41 =================>.]  Step: 458ms | Tot: 16s190ms | Loss: 0.235 | Acc: 89.846% (1168/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 763ms | Loss: 0.212 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:246\n",
      "[=================== 41/41 =================>.]  Step: 459ms | Tot: 16s192ms | Loss: 0.243 | Acc: 90.385% (1175/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 765ms | Loss: 0.214 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:247\n",
      "[=================== 41/41 =================>.]  Step: 461ms | Tot: 16s212ms | Loss: 0.245 | Acc: 89.154% (1159/1300)\n",
      "[=================== 5/5 ============>........]  Step: 172ms | Tot: 767ms | Loss: 0.222 | Acc: 92.763% (282/304)\n",
      "\n",
      "This is epoch:248\n",
      "[=================== 41/41 =================>.]  Step: 463ms | Tot: 16s204ms | Loss: 0.230 | Acc: 90.000% (1170/1300)\n",
      "[=================== 5/5 ============>........]  Step: 170ms | Tot: 765ms | Loss: 0.215 | Acc: 92.434% (281/304)\n",
      "\n",
      "This is epoch:249\n",
      "[=================== 41/41 =================>.]  Step: 467ms | Tot: 16s224ms | Loss: 0.239 | Acc: 90.077% (1171/1300)\n",
      "[=================== 5/5 ============>........]  Step: 171ms | Tot: 769ms | Loss: 0.215 | Acc: 92.434% (281/304)  Step: 200ms | Tot: 395ms | Loss: 0.203 | Acc: 93.229% (179/192)\n",
      "\n",
      "This is epoch:250\n",
      "[=================== 41/41 =================>.]  Step: 457ms | Tot: 16s224ms | Loss: 0.237 | Acc: 89.615% (1165/1300)\n",
      "[=================== 5/5 ============>........]  Step: 173ms | Tot: 771ms | Loss: 0.216 | Acc: 92.105% (280/304)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.42105263157895, 249)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try dropout 0.5 on the last fc\n",
    "resnet34 = resnet.resnet34(num_classes=2)\n",
    "net= resnet34\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Adam does not perform so good here   \n",
    "#(0.1, 0.0001) (50, 80, 110, 170) 52 epoch reaches the maximum.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov= True)\n",
    "scheduler = MultiStepLR(optimizer, [100, 150,200], gamma=0.1)\n",
    "#5e-3 86\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "    net.cuda()\n",
    "#     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "#     cudnn.benchmark = True   \n",
    "\n",
    "train(epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 478ms | Tot: 16s635ms | Loss: 4.453 | Acc: 57.231% (744/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 790ms | Loss: 21.757 | Acc: 56.579% (172/304)\n",
      "\n",
      "This is epoch:2\n",
      "[=================== 41/41 =================>.]  Step: 478ms | Tot: 16s717ms | Loss: 0.712 | Acc: 60.000% (780/1300)\n",
      "[=================== 5/5 ============>........]  Step: 178ms | Tot: 800ms | Loss: 0.643 | Acc: 65.461% (199/304)\n",
      "\n",
      "This is epoch:3\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s821ms | Loss: 0.594 | Acc: 63.154% (821/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 810ms | Loss: 0.605 | Acc: 67.434% (205/304)\n",
      "\n",
      "This is epoch:4\n",
      "[=================== 41/41 =================>.]  Step: 492ms | Tot: 16s913ms | Loss: 0.571 | Acc: 63.077% (820/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 808ms | Loss: 0.570 | Acc: 68.421% (208/304)\n",
      "\n",
      "This is epoch:5\n",
      "[=================== 41/41 =================>.]  Step: 481ms | Tot: 16s910ms | Loss: 0.545 | Acc: 68.308% (888/1300)\n",
      "[=================== 5/5 ============>........]  Step: 178ms | Tot: 804ms | Loss: 0.547 | Acc: 71.382% (217/304)\n",
      "\n",
      "This is epoch:6\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s918ms | Loss: 0.544 | Acc: 70.000% (910/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 806ms | Loss: 0.585 | Acc: 70.066% (213/304)\n",
      "\n",
      "This is epoch:7\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s910ms | Loss: 0.546 | Acc: 67.615% (879/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 807ms | Loss: 0.640 | Acc: 71.382% (217/304)\n",
      "\n",
      "This is epoch:8\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s915ms | Loss: 0.524 | Acc: 71.000% (923/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 811ms | Loss: 0.473 | Acc: 77.303% (235/304)\n",
      "\n",
      "This is epoch:9\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s924ms | Loss: 0.452 | Acc: 78.462% (1020/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 807ms | Loss: 0.456 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:10\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s911ms | Loss: 0.656 | Acc: 74.769% (972/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 806ms | Loss: 4.408 | Acc: 55.592% (169/304)\n",
      "\n",
      "This is epoch:11\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s891ms | Loss: 0.597 | Acc: 64.385% (837/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 811ms | Loss: 0.687 | Acc: 65.132% (198/304)\n",
      "\n",
      "This is epoch:12\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s915ms | Loss: 0.694 | Acc: 65.462% (851/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 804ms | Loss: 0.581 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:13\n",
      "[=================== 41/41 =================>.]  Step: 491ms | Tot: 16s926ms | Loss: 0.576 | Acc: 68.923% (896/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 804ms | Loss: 0.566 | Acc: 73.026% (222/304)\n",
      "\n",
      "This is epoch:14\n",
      "[=================== 41/41 =================>.]  Step: 484ms | Tot: 16s930ms | Loss: 0.533 | Acc: 71.308% (927/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 806ms | Loss: 0.503 | Acc: 76.974% (234/304)\n",
      "\n",
      "This is epoch:15\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s922ms | Loss: 0.523 | Acc: 72.462% (942/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 806ms | Loss: 0.469 | Acc: 78.947% (240/304)\n",
      "\n",
      "This is epoch:16\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s922ms | Loss: 0.512 | Acc: 74.077% (963/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 806ms | Loss: 0.461 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:17\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s938ms | Loss: 0.511 | Acc: 73.077% (950/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 810ms | Loss: 0.615 | Acc: 50.000% (152/304)\n",
      "\n",
      "This is epoch:18\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s925ms | Loss: 0.479 | Acc: 75.231% (978/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 807ms | Loss: 0.553 | Acc: 69.737% (212/304)\n",
      "\n",
      "This is epoch:19\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s932ms | Loss: 0.476 | Acc: 76.385% (993/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 812ms | Loss: 0.483 | Acc: 73.684% (224/304)\n",
      "\n",
      "This is epoch:20\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s915ms | Loss: 0.520 | Acc: 76.077% (989/1300)\n",
      "[=================== 5/5 ============>........]  Step: 184ms | Tot: 807ms | Loss: 0.653 | Acc: 57.895% (176/304)\n",
      "\n",
      "This is epoch:21\n",
      "[=================== 41/41 =================>.]  Step: 484ms | Tot: 16s905ms | Loss: 0.569 | Acc: 67.846% (882/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 800ms | Loss: 0.532 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:22\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s880ms | Loss: 0.531 | Acc: 71.000% (923/1300)\n",
      "[=================== 5/5 ============>........]  Step: 183ms | Tot: 806ms | Loss: 0.520 | Acc: 74.013% (225/304)\n",
      "\n",
      "This is epoch:23\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s908ms | Loss: 0.514 | Acc: 72.538% (943/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 801ms | Loss: 0.524 | Acc: 72.697% (221/304)ep: 200ms | Tot: 201ms | Loss: 0.525 | Acc: 75.000% (96/128)\n",
      "\n",
      "This is epoch:24\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s916ms | Loss: 0.466 | Acc: 77.385% (1006/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 807ms | Loss: 0.524 | Acc: 74.342% (226/304)\n",
      "\n",
      "This is epoch:25\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s939ms | Loss: 0.428 | Acc: 78.923% (1026/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 809ms | Loss: 0.428 | Acc: 79.605% (242/304)\n",
      "\n",
      "This is epoch:26\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s913ms | Loss: 0.408 | Acc: 81.231% (1056/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 809ms | Loss: 0.381 | Acc: 82.895% (252/304)\n",
      "\n",
      "This is epoch:27\n",
      "[=================== 41/41 =================>.]  Step: 482ms | Tot: 16s908ms | Loss: 0.473 | Acc: 77.615% (1009/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 815ms | Loss: 0.553 | Acc: 71.711% (218/304)\n",
      "\n",
      "This is epoch:28\n",
      "[=================== 41/41 =================>.]  Step: 482ms | Tot: 16s898ms | Loss: 0.462 | Acc: 78.385% (1019/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 801ms | Loss: 0.679 | Acc: 59.868% (182/304)\n",
      "\n",
      "This is epoch:29\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s920ms | Loss: 0.386 | Acc: 82.385% (1071/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 805ms | Loss: 0.338 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:30\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s922ms | Loss: 0.376 | Acc: 83.769% (1089/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 809ms | Loss: 0.329 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:31\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s938ms | Loss: 0.346 | Acc: 84.692% (1101/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 813ms | Loss: 0.303 | Acc: 87.171% (265/304)\n",
      "\n",
      "This is epoch:32\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s940ms | Loss: 0.293 | Acc: 86.077% (1119/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 806ms | Loss: 0.247 | Acc: 89.145% (271/304) 2/5 \n",
      "\n",
      "This is epoch:33\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s940ms | Loss: 0.322 | Acc: 86.385% (1123/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 806ms | Loss: 0.303 | Acc: 85.197% (259/304)\n",
      "\n",
      "This is epoch:34\n",
      "[=================== 41/41 =================>.]  Step: 489ms | Tot: 16s939ms | Loss: 0.284 | Acc: 87.692% (1140/1300)\n",
      "[=================== 5/5 ============>........]  Step: 184ms | Tot: 807ms | Loss: 0.250 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:35\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s924ms | Loss: 0.255 | Acc: 88.462% (1150/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 799ms | Loss: 0.234 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:36\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s951ms | Loss: 0.236 | Acc: 89.538% (1164/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 806ms | Loss: 0.453 | Acc: 81.908% (249/304)\n",
      "\n",
      "This is epoch:37\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s926ms | Loss: 0.243 | Acc: 88.692% (1153/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 810ms | Loss: 0.258 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:38\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s900ms | Loss: 0.234 | Acc: 89.923% (1169/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 808ms | Loss: 0.308 | Acc: 85.526% (260/304)\n",
      "\n",
      "This is epoch:39\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s919ms | Loss: 0.221 | Acc: 91.154% (1185/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 810ms | Loss: 0.331 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:40\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s950ms | Loss: 0.212 | Acc: 91.000% (1183/1300)\n",
      "[=================== 5/5 ============>........]  Step: 184ms | Tot: 813ms | Loss: 0.443 | Acc: 79.934% (243/304)\n",
      "\n",
      "This is epoch:41\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s957ms | Loss: 0.188 | Acc: 92.538% (1203/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 813ms | Loss: 0.433 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:42\n",
      "[=================== 41/41 =================>.]  Step: 491ms | Tot: 16s964ms | Loss: 0.220 | Acc: 91.846% (1194/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 809ms | Loss: 0.277 | Acc: 89.474% (272/304)\n",
      "\n",
      "This is epoch:43\n",
      "[=================== 41/41 =================>.]  Step: 489ms | Tot: 16s954ms | Loss: 0.162 | Acc: 93.692% (1218/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 811ms | Loss: 0.386 | Acc: 84.539% (257/304)\n",
      "\n",
      "This is epoch:44\n",
      "[=================== 41/41 =================>.]  Step: 491ms | Tot: 16s960ms | Loss: 0.164 | Acc: 93.769% (1219/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 808ms | Loss: 0.502 | Acc: 83.882% (255/304)\n",
      "\n",
      "This is epoch:45\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s974ms | Loss: 0.196 | Acc: 92.846% (1207/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 810ms | Loss: 0.252 | Acc: 88.816% (270/304)\n",
      "\n",
      "This is epoch:46\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s973ms | Loss: 0.162 | Acc: 93.385% (1214/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 805ms | Loss: 0.707 | Acc: 78.289% (238/304)\n",
      "\n",
      "This is epoch:47\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s966ms | Loss: 0.136 | Acc: 94.923% (1234/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 801ms | Loss: 0.383 | Acc: 82.237% (250/304)\n",
      "\n",
      "This is epoch:48\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s963ms | Loss: 0.128 | Acc: 94.769% (1232/1300)\n",
      "[=================== 5/5 ============>........]  Step: 179ms | Tot: 804ms | Loss: 0.722 | Acc: 79.276% (241/304)\n",
      "\n",
      "This is epoch:49\n",
      "[=================== 41/41 =================>.]  Step: 484ms | Tot: 16s966ms | Loss: 0.166 | Acc: 93.385% (1214/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 809ms | Loss: 0.661 | Acc: 77.961% (237/304)\n",
      "\n",
      "This is epoch:50\n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s948ms | Loss: 0.117 | Acc: 95.615% (1243/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 810ms | Loss: 0.438 | Acc: 87.829% (267/304)\n",
      "\n",
      "This is epoch:51\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s949ms | Loss: 0.138 | Acc: 95.077% (1236/1300)\n",
      "[=================== 5/5 ============>........]  Step: 180ms | Tot: 810ms | Loss: 0.332 | Acc: 87.500% (266/304)\n",
      "\n",
      "This is epoch:52\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s966ms | Loss: 0.140 | Acc: 94.308% (1226/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 810ms | Loss: 0.368 | Acc: 86.513% (263/304)\n",
      "\n",
      "This is epoch:53\n",
      "[=================== 41/41 =================>.]  Step: 489ms | Tot: 16s955ms | Loss: 0.079 | Acc: 97.077% (1262/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 811ms | Loss: 0.373 | Acc: 86.842% (264/304)\n",
      "\n",
      "This is epoch:54\n",
      "We change learning rate from 0.100000 to 0.010000 \n",
      "[=================== 41/41 =================>.]  Step: 486ms | Tot: 16s929ms | Loss: 0.056 | Acc: 98.154% (1276/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 808ms | Loss: 0.274 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:55\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s927ms | Loss: 0.024 | Acc: 99.231% (1290/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 814ms | Loss: 0.316 | Acc: 92.105% (280/304)\n",
      "\n",
      "This is epoch:56\n",
      "[=================== 41/41 =================>.]  Step: 489ms | Tot: 16s932ms | Loss: 0.013 | Acc: 99.692% (1296/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 807ms | Loss: 0.319 | Acc: 91.776% (279/304)\n",
      "\n",
      "This is epoch:57\n",
      "[=================== 41/41 =================>.]  Step: 488ms | Tot: 16s936ms | Loss: 0.015 | Acc: 99.615% (1295/1300)\n",
      "[=================== 5/5 ============>........]  Step: 183ms | Tot: 811ms | Loss: 0.339 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:58\n",
      "[=================== 41/41 =================>.]  Step: 487ms | Tot: 16s952ms | Loss: 0.008 | Acc: 99.923% (1299/1300))\n",
      "[=================== 5/5 ============>........]  Step: 183ms | Tot: 811ms | Loss: 0.362 | Acc: 90.789% (276/304)\n",
      "\n",
      "This is epoch:59\n",
      "[=================== 41/41 =================>.]  Step: 490ms | Tot: 16s946ms | Loss: 0.013 | Acc: 99.692% (1296/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 812ms | Loss: 0.370 | Acc: 91.447% (278/304)\n",
      "\n",
      "This is epoch:60\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s948ms | Loss: 0.012 | Acc: 99.692% (1296/1300)\n",
      "[=================== 5/5 ============>........]  Step: 182ms | Tot: 801ms | Loss: 0.450 | Acc: 89.803% (273/304)\n",
      "\n",
      "This is epoch:61\n",
      "[=================== 41/41 =================>.]  Step: 485ms | Tot: 16s930ms | Loss: 0.011 | Acc: 99.615% (1295/1300)\n",
      "[=================== 5/5 ============>........]  Step: 181ms | Tot: 815ms | Loss: 0.478 | Acc: 88.487% (269/304)\n",
      "\n",
      "This is epoch:62\n",
      "[==========>........ 11/41 ...................]  Step: 420ms | Tot: 4s221ms | Loss: 0.006 | Acc: 100.000% (352/352)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1813:\n",
      "Process Process-1814:\n",
      "Process Process-1815:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-13a90b3d1cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m#     cudnn.benchmark = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-13a90b3d1cbf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, early_stopping)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             progress_bar(j, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n\u001b[1;32m     45\u001b[0m                 % (loss_avg/total, 100.*correct/total, correct, total))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"\"\"Returns a CPU copy of this tensor if it's not already on the CPU\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch,early_stopping = None):\n",
    "    global train_data, lr#,out,y,predicted\n",
    "    best_acc =0\n",
    "    val_loss =0\n",
    "    acc= 0\n",
    "    best_val_loss= 100\n",
    "    loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    train_data={}\n",
    "    train_data['loss_hist'] = loss_hist\n",
    "    train_data['val_loss_hist'] = val_loss_hist\n",
    "    train_data['train_acc_hist'] = train_acc_hist\n",
    "    train_data['val_acc_hist'] =  val_acc_hist\n",
    "    e_s= 0\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        print('\\nThis is epoch:{}'.format(i+1))\n",
    "        total= 0\n",
    "        correct=0\n",
    "        loss_avg= 0\n",
    "        scheduler.step(acc)\n",
    "        if lr != optimizer.param_groups[0]['lr']:\n",
    "            print('We change learning rate from %f to %f '%(lr, optimizer.param_groups[0]['lr']))\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        net.train()\n",
    "        for j,(batch_x, batch_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "            x = Variable(batch_x)\n",
    "            y = Variable(batch_y)\n",
    "            out = net(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y.data).cpu().sum()\n",
    "            progress_bar(j, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "            if j % 5==0:\n",
    "                loss_hist.append(loss_avg/total)\n",
    "            \n",
    "        train_acc_hist.append(100.*correct/total)\n",
    "        e_s+=1\n",
    "        if i %1 == 0:\n",
    "            acc, val_loss = test(val_loader)\n",
    "            val_acc_hist.append(acc)\n",
    "            if acc >=best_acc:\n",
    "                best_acc= acc\n",
    "                e_s = 0\n",
    "                torch.save(net.state_dict(), 'resnet34_acc_add_tran.pth')\n",
    "#             if best_val_loss >= val_loss:\n",
    "#                 best_val_loss= val_loss\n",
    "#                 torch.save(net.state_dict(), 'resnet34_loss%d.pth'%i)\n",
    "        if early_stopping is not None and e_s >= early_stopping:\n",
    "            return best_acc,i\n",
    "\n",
    "    return best_acc,i\n",
    "#         if i%50==0 and save:\n",
    "#             torch.save(net.state_dict(), 'resnet50.pth')\n",
    "        \n",
    "def test(val_load):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_avg= 0\n",
    "    for k, (val_x, val_y) in enumerate(val_load):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "        #print(out.size())\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += predicted.eq(y.data).cpu().sum()\n",
    "        total += out.size()[0]\n",
    "        progress_bar(k, len(val_load), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "    train_data['val_loss_hist'].append(loss_avg/total) #also keep track of loss of val set\n",
    "    acc =  (correct*100.0)/total\n",
    "    return acc,loss_avg/total\n",
    "\n",
    "\n",
    "#Try different transformation\n",
    "resnet34 = resnet.resnet34(num_classes=2)\n",
    "net= resnet34\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Adam does not perform so good here   \n",
    "#(0.1, 0.0001) (50, 80, 110, 170) 52 epoch reaches the maximum.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.001, nesterov= True)\n",
    "#scheduler = MultiStepLR(optimizer, [100, 150,200], gamma=0.1)\n",
    "\n",
    "#\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience =18)\n",
    "#5e-3 86\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "    net.cuda()\n",
    "#     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "#     cudnn.benchmark = True   \n",
    "\n",
    "train(epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dampening': 0,\n",
       " 'initial_lr': 0.1,\n",
       " 'lr': 0.1,\n",
       " 'momentum': 0.9,\n",
       " 'nesterov': True,\n",
       " 'params': [Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "   -2.2901e-02  6.1813e-02  1.9551e-01  ...  -7.1914e-03 -1.3620e-01 -2.4737e-01\n",
       "   -5.4197e-03  8.4023e-02  8.6920e-02  ...   8.9451e-02 -9.9681e-02 -1.0701e-01\n",
       "   -5.0794e-02  2.4462e-02 -1.2995e-01  ...   7.8643e-02 -3.9287e-02 -8.9895e-02\n",
       "                   ...                                      ...                \n",
       "   -7.3950e-02 -1.5521e-01  4.1557e-02  ...   2.4214e-01 -1.9369e-02 -1.8621e-01\n",
       "   -4.8914e-02 -1.5521e-01 -1.5129e-02  ...   1.2534e-01  2.7240e-02 -1.7526e-01\n",
       "    8.2879e-02 -9.2941e-03  8.4399e-02  ...  -2.1688e-02  3.8746e-02 -9.4733e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "   -4.8592e-02 -2.9135e-02  4.1493e-02  ...   1.1822e-01 -7.7242e-02 -1.7292e-01\n",
       "   -1.7032e-01 -1.2939e-02  6.2679e-02  ...   1.9804e-01 -9.5107e-02 -1.3492e-01\n",
       "   -4.7517e-02  1.7279e-01 -1.0843e-03  ...   1.0205e-01 -1.6402e-01 -2.5440e-02\n",
       "                   ...                                      ...                \n",
       "   -6.1226e-02  8.6236e-02  2.1486e-01  ...   3.7592e-01  1.2758e-01 -5.0045e-02\n",
       "    2.2749e-05 -7.1311e-02  4.7203e-02  ...   3.7559e-01  2.0735e-01 -1.2339e-01\n",
       "    7.5946e-02 -1.5613e-02 -6.4580e-02  ...   3.3334e-01  8.3379e-02 -8.4864e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "   -6.2347e-02  2.3969e-02  1.8729e-01  ...   2.5694e-02 -1.0059e-01 -2.3706e-01\n",
       "   -1.1015e-01  1.4210e-02  8.3053e-02  ...   1.3837e-01 -9.3536e-02 -1.0681e-01\n",
       "   -4.1404e-02  1.0902e-01 -7.4440e-02  ...   1.2511e-01 -4.6669e-02 -4.8633e-02\n",
       "                   ...                                      ...                \n",
       "   -1.2285e-01 -7.7107e-02  1.0876e-01  ...   3.1817e-01  3.8711e-02 -1.5125e-01\n",
       "   -8.7671e-03 -1.1639e-01  1.2465e-02  ...   3.0103e-01  1.1884e-01 -1.8641e-01\n",
       "    9.4111e-02  1.5859e-02  7.1805e-02  ...   1.3705e-01  8.7213e-02 -1.4344e-01\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "    8.4410e-02 -9.6271e-02 -8.7688e-02  ...  -1.8953e-02  5.3142e-02  1.8279e-01\n",
       "    7.5554e-02  2.1777e-02 -4.3040e-02  ...  -5.1815e-02 -4.2530e-02  2.1688e-02\n",
       "   -3.9009e-02  3.0182e-02 -1.7556e-02  ...  -3.3045e-02 -2.6480e-02  9.9135e-02\n",
       "                   ...                                      ...                \n",
       "   -8.5147e-03  3.2892e-02  5.8863e-02  ...   9.3288e-02  2.1157e-02  1.5213e-03\n",
       "    7.8160e-02  7.1458e-02  1.3247e-01  ...   7.3056e-02 -3.0619e-02  5.3179e-02\n",
       "    8.9079e-02  5.3851e-02  7.6628e-02  ...   1.1040e-01  1.5613e-01  9.2508e-03\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "   -3.1172e-02  3.6073e-02  1.0192e-01  ...  -1.0802e-02 -3.8555e-02  1.8873e-01\n",
       "    1.2467e-01  8.6270e-02  2.9031e-03  ...  -1.1545e-01 -7.7078e-03  1.5372e-01\n",
       "    1.2543e-01  8.2104e-02 -7.3150e-03  ...   9.2302e-02 -7.7433e-02  5.3621e-02\n",
       "                   ...                                      ...                \n",
       "    1.2013e-01  2.0734e-01  2.2036e-01  ...  -3.7005e-02  5.7764e-02  2.1502e-02\n",
       "    2.7050e-02  2.4613e-01  1.5476e-01  ...   1.1354e-01  1.8456e-01  4.0403e-02\n",
       "    1.6020e-02  6.5646e-02 -8.8492e-02  ...   1.8630e-01  1.5106e-01  5.4764e-02\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "    3.4567e-02 -5.3197e-02  1.4638e-03  ...  -7.1737e-02  6.9040e-03  1.7772e-01\n",
       "    1.0711e-01  5.9302e-02 -3.4641e-02  ...  -1.1221e-01 -3.0296e-02  1.2670e-01\n",
       "    9.3056e-02  5.8619e-02  6.4266e-03  ...   6.1589e-02 -5.2272e-02  1.0632e-01\n",
       "                   ...                                      ...                \n",
       "    1.3285e-01  1.0245e-01  1.3503e-01  ...   4.4721e-02  5.0004e-03  1.4602e-02\n",
       "    8.8453e-02  1.1228e-01  1.5754e-01  ...   5.2336e-02  1.0389e-01  3.8802e-02\n",
       "    7.9155e-02  8.1623e-02  4.6320e-02  ...   1.4795e-01  1.5453e-01  6.5375e-02\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "    3.6029e-01  1.1388e-01 -1.7434e-02  ...  -3.2851e-01  2.4811e-02 -2.2818e-01\n",
       "    2.5317e-01  2.3641e-01  2.9315e-02  ...   3.4912e-02  2.1805e-01  2.5831e-01\n",
       "    1.5814e-01 -2.7959e-02 -1.2236e-02  ...   3.5520e-01  6.8439e-01  3.3917e-02\n",
       "                   ...                                      ...                \n",
       "    4.6581e-01 -6.9953e-02 -5.9709e-01  ...  -1.3501e-01 -2.6067e-02 -5.2770e-01\n",
       "    7.3541e-01  4.0569e-02 -5.3302e-01  ...  -4.6717e-01 -1.4973e-01 -8.0186e-01\n",
       "    3.8571e-01  4.8338e-02 -4.0675e-01  ...  -5.4392e-01 -5.5903e-01 -1.0887e+00\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "   -1.0446e-01 -6.3225e-01 -1.9864e-01  ...  -8.2336e-03  1.8477e-01  1.7353e-02\n",
       "   -9.2906e-02 -3.2503e-01 -8.5872e-02  ...   2.2741e-01  5.9574e-01  1.1203e-01\n",
       "   -1.1548e-02 -9.3287e-02 -4.5823e-01  ...   5.4163e-01  5.4568e-01  5.8262e-01\n",
       "                   ...                                      ...                \n",
       "   -1.1751e-01  1.8118e-01 -5.3361e-01  ...   5.2650e-01  7.1064e-01  1.2531e-01\n",
       "   -1.8365e-02 -2.2919e-01 -2.8498e-01  ...  -6.9670e-02  2.1074e-01 -2.2947e-01\n",
       "   -7.0269e-01 -7.1144e-01 -6.8178e-01  ...   8.4192e-02  3.6765e-01 -2.0978e-01\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "    1.9885e-01 -1.9300e-01 -1.2268e-01  ...  -2.1153e-01  1.0785e-01 -1.5012e-01\n",
       "    1.2597e-01 -9.1845e-03 -1.3855e-02  ...   1.6886e-01  3.8517e-01  2.0770e-01\n",
       "    1.0889e-01 -1.5120e-03 -2.0836e-01  ...   4.8085e-01  6.8431e-01  2.9554e-01\n",
       "                   ...                                      ...                \n",
       "    2.5164e-01  1.1380e-02 -6.4275e-01  ...   1.3423e-01  3.0984e-01 -3.0403e-01\n",
       "    4.8075e-01 -4.9657e-02 -4.6346e-01  ...  -3.7742e-01 -3.2488e-02 -6.2001e-01\n",
       "   -2.5880e-02 -3.0893e-01 -6.1263e-01  ...  -3.2067e-01 -1.9476e-01 -8.4409e-01\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "   -1.3582e-01 -2.0986e-01 -1.8959e-01  ...  -2.6132e-01 -3.6759e-01 -4.1528e-01\n",
       "   -2.0945e-01 -3.2710e-01 -2.4515e-01  ...  -2.5663e-01 -3.5349e-01 -3.5336e-01\n",
       "   -1.5551e-01 -2.0500e-01 -1.4527e-01  ...  -1.9174e-01 -2.5732e-01 -2.6724e-01\n",
       "                   ...                                      ...                \n",
       "   -1.9194e-01 -1.4230e-01 -2.5971e-01  ...  -3.0112e-01 -2.8703e-01 -1.6149e-01\n",
       "   -2.1095e-01 -1.0743e-01 -1.2247e-01  ...  -1.6410e-01 -1.7435e-01 -1.9903e-01\n",
       "   -1.8455e-01 -1.1271e-01 -5.2415e-02  ...  -1.5716e-01 -1.2333e-01 -1.1236e-01\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "   -4.1786e-01 -3.5277e-01 -2.5016e-01  ...  -2.3951e-01 -2.4334e-01 -2.4932e-01\n",
       "   -3.2462e-01 -2.5820e-01 -2.0397e-01  ...  -1.6569e-01 -1.7751e-01 -2.2850e-01\n",
       "   -1.5774e-01 -3.4695e-01 -2.8609e-01  ...  -2.7787e-01 -3.2567e-01 -3.6295e-01\n",
       "                   ...                                      ...                \n",
       "   -2.7988e-01 -1.5114e-01 -1.1501e-01  ...   3.1713e-03 -4.4590e-03  1.6991e-02\n",
       "   -3.2785e-01 -1.4287e-01  3.0133e-02  ...   8.5060e-02  8.7182e-02 -5.0643e-02\n",
       "   -3.6790e-01 -2.7612e-01 -3.7950e-03  ...   5.7919e-02 -2.3212e-02 -6.9609e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "   -2.3497e-01 -3.5971e-01 -2.5934e-01  ...  -2.5650e-01 -3.5116e-01 -4.3338e-01\n",
       "   -3.1227e-01 -3.3022e-01 -2.4416e-01  ...  -2.7643e-01 -3.2330e-01 -3.2490e-01\n",
       "   -1.5841e-01 -3.2096e-01 -2.1840e-01  ...  -2.4439e-01 -3.8323e-01 -3.7376e-01\n",
       "                   ...                                      ...                \n",
       "   -2.8059e-01 -1.9700e-01 -2.3599e-01  ...  -2.2273e-01 -2.0070e-01 -7.8880e-02\n",
       "   -2.7067e-01 -1.2350e-01 -8.7622e-02  ...  -5.6266e-02 -8.8721e-02 -1.2826e-01\n",
       "   -2.9295e-01 -2.1962e-01 -5.7431e-02  ...  -1.1471e-01 -5.7778e-02 -1.0070e-01\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "   -1.7990e-01 -3.9740e-01 -3.2407e-01  ...  -1.7641e-01 -1.1817e-01 -1.8194e-01\n",
       "   -1.9210e-01 -1.9122e-01 -1.3991e-01  ...  -4.5735e-02 -2.0860e-01 -1.3210e-01\n",
       "   -5.4056e-02 -4.5549e-02 -1.7440e-01  ...   6.9538e-02  1.0267e-02 -3.5132e-02\n",
       "                   ...                                      ...                \n",
       "   -4.1347e-02 -8.5480e-03 -1.1156e-01  ...  -1.1742e-01 -2.1563e-01 -3.9824e-01\n",
       "    2.2229e-02 -1.0683e-01 -1.4396e-01  ...  -1.9384e-01 -1.6582e-01 -1.5199e-01\n",
       "   -2.6556e-01 -2.8646e-01 -3.0899e-01  ...   4.9060e-02  6.5935e-04 -1.1432e-01\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "   -3.0441e-01 -1.7423e-01 -3.3612e-01  ...  -6.3617e-02  2.1950e-01 -1.1729e-01\n",
       "   -1.5175e-01 -3.9073e-01 -2.6874e-01  ...  -1.0732e-02 -4.1102e-02  2.0622e-01\n",
       "   -1.4475e-01 -1.3244e-01 -1.6576e-01  ...  -1.3008e-01  2.3985e-01  2.4335e-01\n",
       "                   ...                                      ...                \n",
       "   -2.9335e-01 -2.9183e-01 -1.8414e-01  ...   1.5139e-01  5.8862e-02 -5.1402e-03\n",
       "   -2.3450e-01 -3.2794e-01 -2.4028e-01  ...   2.4034e-01  4.3901e-02  2.4896e-01\n",
       "   -3.4404e-01 -5.0085e-01 -4.1937e-01  ...   1.7038e-01  3.4482e-02  2.4572e-01\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "   -2.2338e-01 -3.2361e-01 -3.6249e-01  ...  -1.2447e-01 -2.8189e-03 -1.2604e-01\n",
       "   -1.9793e-01 -2.9308e-01 -2.1913e-01  ...  -2.8814e-02 -1.6180e-01  2.3849e-03\n",
       "   -8.8524e-02 -6.8806e-02 -1.7886e-01  ...  -3.1975e-02  1.3278e-01  6.5995e-02\n",
       "                   ...                                      ...                \n",
       "   -1.6414e-01 -1.3099e-01 -1.4578e-01  ...  -1.9051e-02 -9.1331e-02 -2.5335e-01\n",
       "   -4.8128e-02 -2.0472e-01 -2.4442e-01  ...  -1.2589e-02 -9.0595e-02  1.6702e-02\n",
       "   -3.6646e-01 -4.4187e-01 -4.6224e-01  ...   9.9034e-02 -6.2710e-02  4.5560e-02\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "   -5.7269e-02 -8.3113e-02 -1.3802e-02  ...  -5.2693e-02 -1.3331e-01 -3.5548e-02\n",
       "   -3.5895e-02 -2.8908e-02 -2.1874e-02  ...  -4.2394e-02 -4.8193e-02  2.3689e-02\n",
       "   -1.2887e-01 -1.8974e-02  6.6205e-02  ...  -7.1028e-02  5.6098e-02  1.4204e-01\n",
       "                   ...                                      ...                \n",
       "   -1.7284e-01 -1.6569e-01 -1.5887e-01  ...  -2.7106e-01 -1.4047e-03  1.8622e-02\n",
       "   -1.9892e-01 -1.8327e-01 -2.1957e-01  ...  -2.3925e-01 -1.0794e-01 -4.2436e-02\n",
       "   -2.2926e-01 -2.0196e-01 -1.7138e-01  ...  -2.2057e-01 -1.3486e-01 -2.0383e-01\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "   -8.2292e-03 -1.2490e-01 -2.5897e-02  ...  -1.9982e-02  2.3984e-02 -1.4343e-01\n",
       "   -7.6378e-02  1.3718e-02  5.4356e-02  ...  -2.7651e-01 -2.5090e-01 -5.6219e-02\n",
       "   -1.1466e-01 -7.2123e-02 -1.7948e-01  ...  -9.6326e-02 -1.3665e-01  1.1254e-01\n",
       "                   ...                                      ...                \n",
       "   -9.1677e-02 -9.6394e-02 -2.2360e-01  ...   1.9362e-02 -1.9358e-01 -6.8758e-02\n",
       "    1.0366e-02 -2.2667e-03  5.3721e-02  ...   4.4100e-02  5.3174e-02 -7.0424e-02\n",
       "   -6.8962e-02  4.9073e-02  7.7890e-02  ...   3.1493e-02  6.6566e-02 -9.9163e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -5.1043e-02 -4.8631e-02 -2.8806e-02  ...  -5.1037e-02 -6.4456e-02 -8.4513e-02\n",
       "   -8.2459e-02  2.4288e-02  2.3444e-02  ...  -1.9144e-01 -1.7236e-01 -5.8335e-03\n",
       "   -1.2046e-01 -8.0991e-02 -1.0434e-02  ...  -6.5505e-02 -5.5526e-02  1.0791e-01\n",
       "                   ...                                      ...                \n",
       "   -1.5430e-01 -1.7658e-01 -1.9154e-01  ...  -1.4938e-01 -4.2309e-02 -5.9507e-02\n",
       "   -1.3124e-01 -1.1501e-01 -1.3030e-01  ...  -1.3342e-01 -2.5480e-02 -6.3391e-02\n",
       "   -1.7854e-01 -7.9403e-02 -9.0858e-02  ...  -1.2891e-01 -1.9435e-02 -1.9970e-01\n",
       "  [torch.cuda.FloatTensor of size 64x3x7x7 (GPU 0)], Parameter containing:\n",
       "   0.7868\n",
       "   0.9435\n",
       "   3.0614\n",
       "   0.9840\n",
       "   0.4319\n",
       "   0.7649\n",
       "   1.3329\n",
       "   1.3467\n",
       "   0.2602\n",
       "   0.5480\n",
       "   0.5862\n",
       "   0.5720\n",
       "   0.5353\n",
       "   0.4663\n",
       "   0.5866\n",
       "   0.8283\n",
       "   1.4241\n",
       "   0.6767\n",
       "   0.8578\n",
       "   0.7281\n",
       "   0.9679\n",
       "   0.7567\n",
       "  -0.6002\n",
       "   0.0387\n",
       "   1.3098\n",
       "   0.4198\n",
       "   1.5164\n",
       "   0.4177\n",
       "   0.8126\n",
       "   1.0981\n",
       "   1.9549\n",
       "   0.9279\n",
       "   0.6824\n",
       "   0.4550\n",
       "   1.4545\n",
       "   0.9483\n",
       "   1.7730\n",
       "   1.1812\n",
       "   1.0685\n",
       "   0.3547\n",
       "   0.1619\n",
       "   1.0471\n",
       "   0.8260\n",
       "   0.2506\n",
       "   0.5413\n",
       "   1.3771\n",
       "   0.5134\n",
       "  -0.5021\n",
       "   1.8308\n",
       "   2.1103\n",
       "   1.4018\n",
       "   1.5348\n",
       "   1.3188\n",
       "   2.6697\n",
       "   0.5391\n",
       "   0.6570\n",
       "   0.6935\n",
       "   1.0771\n",
       "   0.2946\n",
       "   2.7015\n",
       "   1.2126\n",
       "   1.1832\n",
       "   1.0991\n",
       "   1.0146\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "   0.0271\n",
       "   0.1811\n",
       "   0.0597\n",
       "   0.0207\n",
       "   0.1460\n",
       "   0.0336\n",
       "  -0.0238\n",
       "  -0.4572\n",
       "  -0.1108\n",
       "   0.0163\n",
       "  -0.2992\n",
       "  -0.1599\n",
       "  -0.1689\n",
       "   0.1687\n",
       "  -0.2736\n",
       "  -0.1195\n",
       "  -0.1038\n",
       "  -0.1198\n",
       "  -0.3058\n",
       "  -0.1005\n",
       "  -0.1462\n",
       "   0.0186\n",
       "  -0.0218\n",
       "   0.0514\n",
       "  -0.2864\n",
       "  -0.0647\n",
       "   0.2197\n",
       "  -0.0148\n",
       "   0.0797\n",
       "  -0.0486\n",
       "  -0.1659\n",
       "  -0.2539\n",
       "  -0.1128\n",
       "  -0.1208\n",
       "   0.0026\n",
       "  -0.1292\n",
       "  -0.1220\n",
       "  -0.0423\n",
       "  -0.0430\n",
       "  -0.2078\n",
       "   0.3172\n",
       "  -0.0708\n",
       "  -0.2558\n",
       "  -0.3093\n",
       "  -0.3600\n",
       "  -0.3027\n",
       "   0.0268\n",
       "   0.0426\n",
       "  -0.0092\n",
       "  -0.1959\n",
       "  -0.4551\n",
       "   0.1276\n",
       "  -1.2703\n",
       "  -0.2612\n",
       "  -0.1341\n",
       "  -0.2151\n",
       "  -0.0274\n",
       "  -0.3088\n",
       "   0.1089\n",
       "   0.4879\n",
       "  -0.0997\n",
       "   0.0915\n",
       "  -0.2534\n",
       "  -0.0125\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "    7.9339e-02 -3.2332e-03 -3.8145e-02\n",
       "    3.8436e-02  7.9570e-02  4.5399e-02\n",
       "   -6.1657e-02  1.6181e-02 -3.8386e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "   -7.1796e-02  1.3183e-03  6.4075e-03\n",
       "    8.8250e-02 -1.9174e-02 -2.7507e-02\n",
       "   -1.2454e-01 -2.2365e-02  5.2248e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "    3.6036e-02  6.2268e-02  9.7977e-02\n",
       "    5.7827e-02  7.9904e-02  1.2242e-01\n",
       "    1.0731e-01  5.5658e-02 -1.9592e-03\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "    1.9621e-01  4.6873e-02 -1.0809e-02\n",
       "    8.7168e-02  8.3088e-04 -4.8122e-02\n",
       "    2.4920e-02 -6.2730e-03 -5.1057e-02\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "    1.9859e-02 -6.1068e-02  1.9075e-03\n",
       "   -2.9913e-02 -1.3134e-03  7.0673e-03\n",
       "    7.2464e-02 -1.8327e-02 -5.4823e-02\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "   -4.1566e-02 -8.2675e-02  2.8962e-03\n",
       "   -6.5057e-02 -3.9780e-02 -4.8243e-02\n",
       "    1.0127e-02 -7.9013e-02  3.2206e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "   -1.2460e-02  6.0705e-02 -1.2315e-04\n",
       "   -4.1136e-02 -1.4418e-02  3.7207e-02\n",
       "    3.3225e-04  4.7428e-02  1.0117e-01\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "    5.8677e-02  3.2961e-02 -5.8062e-03\n",
       "   -4.4639e-02  6.3601e-02  5.9750e-02\n",
       "   -3.4515e-02 -1.0220e-01 -6.6679e-03\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "   -1.7936e-02 -1.0492e-01 -6.1026e-02\n",
       "    1.5738e-01  4.3311e-02  1.1694e-02\n",
       "    1.1695e-01  9.4381e-02 -8.2528e-03\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "   -5.5780e-03 -4.1568e-02  2.9134e-02\n",
       "   -4.3845e-02  1.7783e-02  2.7436e-02\n",
       "   -7.8148e-02  1.0188e-02 -5.8859e-04\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "    6.8773e-02 -6.3320e-02 -4.2082e-02\n",
       "   -6.0541e-03  1.2547e-01  5.6894e-02\n",
       "    1.5310e-01 -8.0296e-02  4.9754e-02\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "   -1.0066e-02 -2.9383e-02 -3.5436e-02\n",
       "   -5.8071e-02 -4.5051e-02  2.9672e-02\n",
       "   -2.6050e-02  6.3741e-03 -3.6413e-02\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "   -1.7894e-02 -3.6170e-02 -3.8635e-02\n",
       "   -9.0578e-03 -5.7210e-02 -4.4101e-02\n",
       "   -2.2812e-02  1.0423e-02 -4.3618e-02\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "   -3.4207e-02  9.8896e-03  2.5937e-02\n",
       "    3.6076e-02  2.8577e-02  4.4603e-02\n",
       "    3.2161e-02 -3.9283e-02  1.8734e-02\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "   -1.1781e-01  2.7356e-02  1.1981e-02\n",
       "   -6.3926e-02 -3.1649e-02 -4.1254e-02\n",
       "    1.8037e-02  9.6826e-02  5.1852e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "    3.7415e-02 -3.8377e-02 -1.8124e-02\n",
       "    1.0210e-02 -5.3398e-02 -3.0538e-02\n",
       "   -4.8205e-03  4.3816e-02 -1.9185e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "   -8.9291e-02 -1.1601e-02 -1.7093e-02\n",
       "   -5.4128e-02 -8.2608e-02  2.8555e-02\n",
       "    3.6051e-02 -5.0068e-03  4.7023e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "    2.2855e-02 -4.5323e-02 -5.6629e-03\n",
       "   -1.1191e-01  1.1427e-02  7.2334e-02\n",
       "   -5.2234e-02  2.0660e-02 -3.1819e-02\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "   -1.3764e-01 -1.4268e-01  2.6711e-02\n",
       "   -8.5926e-02 -1.5343e-01 -3.0445e-02\n",
       "   -6.4300e-02 -4.6232e-02 -2.0919e-01\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "   -6.1339e-02  9.8504e-02  4.0234e-02\n",
       "    5.2437e-02  1.2397e-01  2.5552e-02\n",
       "    4.8214e-02  8.0994e-02 -4.9424e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "   -2.6682e-01 -1.7446e-01 -1.6589e-01\n",
       "   -1.2738e-01 -1.4412e-01 -1.4162e-01\n",
       "   -5.6799e-02 -1.7402e-01 -1.1786e-01\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "   -8.7244e-02 -1.4194e-01 -1.4444e-01\n",
       "    3.2898e-03 -1.6782e-01 -4.0159e-02\n",
       "   -9.7786e-02 -8.7721e-02 -4.2027e-02\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "   -3.1767e-02 -4.0284e-02 -1.7705e-02\n",
       "   -1.1296e-02  1.1345e-02  7.2400e-02\n",
       "   -1.9454e-02 -5.3151e-03 -2.1845e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "    5.1635e-02 -1.0930e-01 -3.3982e-02\n",
       "   -1.0770e-01  1.7292e-04  2.1481e-02\n",
       "    4.6225e-02  3.6675e-02  1.1966e-02\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "   -1.0204e-01 -1.6575e-01 -8.8983e-02\n",
       "   -9.5164e-02 -6.4697e-02 -4.7197e-02\n",
       "   -1.3611e-01 -5.8071e-02  5.0660e-02\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "   -4.5675e-02 -4.6621e-02  5.3123e-04\n",
       "   -3.0517e-02 -5.8936e-02 -9.9635e-03\n",
       "    7.9011e-02  3.3572e-04 -9.0697e-03\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "    3.4290e-03 -4.2707e-02 -2.6286e-03\n",
       "   -6.3520e-02 -6.6422e-02 -6.9615e-02\n",
       "    5.0679e-02 -2.7520e-02 -6.7346e-02\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "   -6.3016e-02 -1.3347e-01 -8.8943e-02\n",
       "   -1.1439e-01 -2.3097e-02 -1.3236e-01\n",
       "   -1.5152e-01 -1.3228e-02 -7.3857e-02\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "   -1.4336e-02  3.9696e-02  1.0364e-02\n",
       "   -1.4635e-01 -1.2727e-01 -5.2566e-02\n",
       "    2.6498e-02  4.5164e-02 -4.0920e-02\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "   -2.6137e-02 -1.1429e-01 -6.7770e-02\n",
       "   -4.3306e-02  1.0971e-01  6.5643e-03\n",
       "   -1.1232e-01 -2.4149e-02  3.5714e-02\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "   -8.5024e-03  2.8737e-02  2.1285e-02\n",
       "    4.4145e-03 -1.0992e-02 -1.0082e-01\n",
       "   -3.8855e-02  3.2623e-04  3.7515e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "   -1.4893e-01 -6.6639e-02 -8.0904e-02\n",
       "    1.4473e-02 -5.5947e-02 -8.7889e-02\n",
       "   -8.2802e-02 -3.2442e-02 -8.7031e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -9.8613e-02 -4.0789e-02 -1.7494e-02\n",
       "   -7.7920e-02 -7.1783e-03 -5.4828e-02\n",
       "   -2.9600e-02  4.2165e-02  5.1283e-02\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "    3.2965e-03 -1.5828e-02  1.0630e-01\n",
       "    4.3006e-03 -1.1152e-02 -5.4201e-02\n",
       "   -5.9079e-02  1.4134e-02 -5.1786e-04\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "    5.3998e-02 -9.0628e-03  4.7425e-02\n",
       "    3.6426e-02 -1.4356e-02 -2.6768e-04\n",
       "    5.6362e-02 -1.8603e-02 -1.1760e-01\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "    1.3620e-02 -4.7913e-03  1.6744e-02\n",
       "    3.2685e-02 -7.1736e-02 -4.4065e-02\n",
       "    2.8491e-02  9.2742e-02  1.0950e-02\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.6820\n",
       "   0.7588\n",
       "   0.7421\n",
       "   0.7576\n",
       "   0.9307\n",
       "   0.8323\n",
       "   1.3844\n",
       "   0.6308\n",
       "   0.7616\n",
       "   0.8675\n",
       "   0.8337\n",
       "   1.3058\n",
       "   0.6986\n",
       "   0.6541\n",
       "   0.8312\n",
       "   0.7984\n",
       "   0.5371\n",
       "   0.8976\n",
       "   0.6611\n",
       "   0.8271\n",
       "   1.1356\n",
       "   0.9314\n",
       "   0.8382\n",
       "   0.9301\n",
       "   0.7628\n",
       "   0.6921\n",
       "   0.4829\n",
       "   0.7500\n",
       "   0.6691\n",
       "   1.0441\n",
       "   0.6711\n",
       "   0.6369\n",
       "   0.8837\n",
       "   0.7449\n",
       "   0.8451\n",
       "   0.7958\n",
       "   0.8253\n",
       "   1.0331\n",
       "   0.8681\n",
       "   0.7757\n",
       "   0.6714\n",
       "   1.0313\n",
       "   0.7189\n",
       "   0.6033\n",
       "   0.7978\n",
       "   0.6350\n",
       "   0.6318\n",
       "   0.8042\n",
       "   0.6966\n",
       "   0.8027\n",
       "   0.8560\n",
       "   0.7591\n",
       "   0.7762\n",
       "   0.9337\n",
       "   0.8720\n",
       "   0.6164\n",
       "   0.7315\n",
       "   0.7764\n",
       "   0.7688\n",
       "   0.7063\n",
       "   0.8232\n",
       "   0.7557\n",
       "   0.6659\n",
       "   0.8458\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.1752\n",
       "  -0.1700\n",
       "  -0.1414\n",
       "   0.0533\n",
       "  -0.1347\n",
       "  -0.0216\n",
       "   0.1571\n",
       "  -0.0781\n",
       "  -0.2298\n",
       "  -0.0639\n",
       "  -0.1273\n",
       "  -0.1984\n",
       "   0.1340\n",
       "  -0.1339\n",
       "   0.0838\n",
       "  -0.1154\n",
       "  -0.0271\n",
       "  -0.2309\n",
       "   0.0668\n",
       "   0.0012\n",
       "   0.1534\n",
       "  -0.1455\n",
       "  -0.1823\n",
       "  -0.1818\n",
       "  -0.1459\n",
       "  -0.0761\n",
       "  -0.1448\n",
       "   0.2291\n",
       "   0.0752\n",
       "  -0.2032\n",
       "   0.3017\n",
       "  -0.2152\n",
       "  -0.1143\n",
       "  -0.2139\n",
       "  -0.0741\n",
       "   0.1376\n",
       "   0.0699\n",
       "  -0.2541\n",
       "  -0.3025\n",
       "  -0.1462\n",
       "  -0.0624\n",
       "  -0.3058\n",
       "  -0.0893\n",
       "  -0.1154\n",
       "   0.0049\n",
       "  -0.1050\n",
       "  -0.1492\n",
       "   0.1049\n",
       "  -0.1086\n",
       "  -0.1385\n",
       "  -0.2072\n",
       "   0.1097\n",
       "   0.0423\n",
       "  -0.0447\n",
       "  -0.0676\n",
       "  -0.1218\n",
       "  -0.1869\n",
       "   0.1385\n",
       "  -0.1294\n",
       "   0.0398\n",
       "  -0.2289\n",
       "  -0.0309\n",
       "  -0.0830\n",
       "   0.0007\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "   -2.6845e-03  4.6591e-02  2.4686e-02\n",
       "    1.1202e-02  5.1290e-02  9.6896e-03\n",
       "    1.2026e-01 -5.3514e-02  5.5360e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "    6.4232e-02 -9.8338e-02 -1.5150e-02\n",
       "    3.7018e-02 -1.5187e-02 -1.5171e-02\n",
       "   -4.4132e-02  5.5001e-02  5.4486e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "   -9.7729e-03  3.2167e-02 -2.2895e-02\n",
       "    2.4374e-02  9.5091e-02 -2.7412e-02\n",
       "   -1.8167e-02 -1.4090e-02 -7.4372e-02\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "    5.7538e-02 -1.4557e-02  4.6821e-02\n",
       "   -4.6944e-02  4.6605e-02 -5.2254e-02\n",
       "   -1.6811e-02 -8.8489e-02 -3.9655e-03\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "    1.2165e-01  5.4355e-02 -4.6626e-02\n",
       "    9.0231e-02 -7.1880e-02  5.5665e-02\n",
       "    6.5623e-04 -9.6072e-03  3.0170e-03\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "    1.6924e-02  1.0903e-02  2.8423e-02\n",
       "   -3.8461e-02  5.5751e-02  2.3789e-02\n",
       "    2.6845e-02 -5.7962e-02 -5.0964e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "   -2.7363e-02  7.1558e-02  2.5865e-02\n",
       "    9.3509e-02 -3.6451e-02 -5.0224e-03\n",
       "    4.3566e-02  1.0025e-01 -2.4958e-02\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "   -5.1529e-03 -4.6762e-02  1.2216e-02\n",
       "    8.6284e-02 -4.5694e-02 -4.1971e-02\n",
       "    1.2815e-01  2.1045e-01  1.2278e-01\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "   -1.0929e-02  9.8582e-02  4.4689e-02\n",
       "   -3.3812e-02  8.4499e-03  3.6150e-02\n",
       "   -5.3515e-02 -2.4172e-02 -1.3595e-01\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "   -1.5015e-02 -6.7839e-03  4.7573e-02\n",
       "    2.9021e-02  4.4537e-03 -1.7542e-02\n",
       "   -2.5705e-02  4.7377e-02  3.4071e-02\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "   -4.8347e-02 -1.1112e-02  1.1430e-02\n",
       "   -2.8794e-02  3.2574e-02  4.3545e-02\n",
       "   -3.9090e-02  3.6463e-03 -1.7479e-03\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "    7.7421e-02  2.4124e-02  5.5126e-02\n",
       "   -1.6442e-02 -1.2597e-01 -3.4298e-02\n",
       "   -8.1645e-02 -1.8278e-02 -1.4587e-01\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "    3.0494e-02  1.7603e-02 -6.2349e-02\n",
       "   -4.6303e-02  1.0385e-01  1.5106e-02\n",
       "    1.0860e-01 -6.0540e-02 -1.7728e-02\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "    3.9464e-02 -2.6310e-02  1.4860e-01\n",
       "    1.3054e-01 -7.7824e-02  5.3072e-02\n",
       "   -3.2106e-02 -1.4740e-02 -4.5149e-02\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "   -4.9585e-02 -9.2642e-02 -2.7053e-02\n",
       "    2.1809e-02 -6.8323e-02 -6.7529e-02\n",
       "   -1.3184e-01 -8.8318e-03  6.7406e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "    2.2547e-02  7.8803e-03  8.2379e-02\n",
       "    8.1673e-02  7.2988e-02 -3.2330e-02\n",
       "    1.6627e-01  8.5331e-02  3.4978e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "   -1.1385e-01 -9.1796e-02 -2.0391e-02\n",
       "   -9.6833e-02 -4.4759e-02 -5.6160e-02\n",
       "    4.0158e-02 -9.2215e-02 -1.2758e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "    1.4504e-02 -1.7846e-02 -4.7810e-02\n",
       "   -5.5130e-03  1.2328e-01 -3.2175e-02\n",
       "    5.5824e-03  7.4170e-02 -6.3851e-02\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "    7.9009e-02 -3.0907e-02 -1.4337e-02\n",
       "    2.5966e-02 -4.6057e-02  3.0701e-03\n",
       "    8.2262e-02  2.0460e-02 -1.1101e-01\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "   -1.1637e-01 -2.9013e-02 -3.1161e-02\n",
       "   -5.9916e-02 -2.4632e-02 -9.0704e-02\n",
       "   -7.7687e-02 -1.1247e-01 -3.7691e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "   -8.4434e-02  1.4808e-02  5.7621e-02\n",
       "   -2.2002e-02  8.8931e-02  3.7123e-02\n",
       "   -3.9007e-02  1.7431e-02  1.1622e-03\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "    8.8068e-02  1.3493e-03  2.4773e-02\n",
       "   -6.4133e-03 -1.9783e-02 -1.6603e-01\n",
       "    8.0204e-02  3.1256e-02  5.8228e-03\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "    2.9095e-02 -2.2235e-02 -6.3588e-02\n",
       "   -7.0855e-02 -1.8580e-02 -4.1595e-02\n",
       "   -5.0322e-02 -4.2148e-02  2.9315e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "    9.4185e-02  3.1420e-02 -5.8673e-02\n",
       "   -3.1697e-02  1.8017e-02 -3.8818e-02\n",
       "    2.8641e-02 -2.9594e-02 -8.7151e-03\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "   -3.8132e-02 -7.1724e-02 -3.6743e-02\n",
       "   -8.7707e-02 -3.2734e-02 -1.3800e-01\n",
       "    5.6810e-03 -1.0896e-01 -1.2866e-01\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "    1.0588e-02 -5.6090e-02 -4.3879e-02\n",
       "   -1.1714e-01 -1.8594e-01 -3.2532e-02\n",
       "   -7.6358e-02 -9.3527e-02 -4.8137e-03\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "    8.3326e-02 -1.6681e-02  6.1456e-02\n",
       "    5.6787e-02  1.9240e-02 -2.0044e-02\n",
       "   -3.5305e-03  4.9743e-02  5.7432e-03\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "   -1.5339e-02 -8.5182e-02 -1.5972e-02\n",
       "   -2.1666e-02  1.5703e-02 -7.6218e-04\n",
       "   -7.2428e-02 -2.7200e-02 -1.4398e-02\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "    6.6073e-02 -6.1858e-03 -2.7207e-02\n",
       "    5.6420e-02  1.1285e-01 -1.3143e-02\n",
       "    3.5160e-02  6.3099e-03  6.5790e-02\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "    1.5521e-01  5.5452e-03  2.6550e-02\n",
       "    1.8961e-02  9.0630e-02  8.5728e-02\n",
       "    3.7259e-02  5.7576e-02  1.2263e-01\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "   -2.8429e-02  5.4339e-02  6.7923e-02\n",
       "    6.7875e-02 -3.1995e-02 -2.6968e-02\n",
       "    3.0537e-02 -1.3542e-02  6.7284e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "    3.7676e-02 -2.5647e-02  6.9042e-02\n",
       "   -5.7135e-02 -1.7129e-03  3.0745e-02\n",
       "   -5.2686e-02 -6.6991e-02 -1.0217e-01\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -3.8089e-02  5.1376e-02  2.6587e-02\n",
       "   -2.0230e-03 -5.9080e-02 -5.8775e-02\n",
       "   -3.7285e-02  3.1077e-02  3.3275e-02\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "    8.1471e-02  5.6562e-02  1.0879e-02\n",
       "    6.4965e-03 -1.6793e-02  2.7615e-03\n",
       "    1.0330e-01 -2.5944e-03  1.5131e-02\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "   -1.1025e-02  2.8458e-02 -6.5987e-02\n",
       "    6.5335e-02  2.3694e-02 -1.8629e-02\n",
       "    7.9368e-02  4.2976e-02 -3.5981e-02\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "   -3.4917e-02 -6.5001e-02  2.4827e-03\n",
       "    6.3153e-02 -8.5520e-02 -1.8432e-02\n",
       "   -6.0645e-03  2.9012e-03  5.0042e-03\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.4076\n",
       "   0.7172\n",
       "   0.9205\n",
       "   0.8173\n",
       "   0.8291\n",
       "   0.8418\n",
       "   0.8528\n",
       "   0.9449\n",
       "   0.8689\n",
       "   1.0803\n",
       "   0.6411\n",
       "   0.1992\n",
       "   0.5288\n",
       "   0.7962\n",
       "   0.4726\n",
       "   0.7927\n",
       "   0.4523\n",
       "   0.8580\n",
       "   0.6471\n",
       "   0.4945\n",
       "   0.8091\n",
       "   0.6683\n",
       "   1.4389\n",
       "   0.4943\n",
       "   0.4302\n",
       "   0.4056\n",
       "   0.7047\n",
       "   0.8128\n",
       "   0.7761\n",
       "   0.7802\n",
       "   0.6544\n",
       "   0.6946\n",
       "   0.6115\n",
       "   0.9674\n",
       "   0.6999\n",
       "   0.8464\n",
       "   0.8700\n",
       "   0.8322\n",
       "   0.6609\n",
       "   0.4901\n",
       "   0.7210\n",
       "   0.7325\n",
       "   0.9211\n",
       "   0.5821\n",
       "   0.5891\n",
       "   0.6726\n",
       "   0.7767\n",
       "   0.5036\n",
       "   0.5502\n",
       "   0.5146\n",
       "   0.7353\n",
       "   0.7776\n",
       "   0.4611\n",
       "   0.5230\n",
       "   0.5718\n",
       "   0.7230\n",
       "   0.7895\n",
       "   0.6321\n",
       "   0.9041\n",
       "   0.8182\n",
       "   0.8796\n",
       "   0.7408\n",
       "   0.4394\n",
       "   0.8210\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.1030\n",
       "   0.1697\n",
       "  -0.0906\n",
       "  -0.0720\n",
       "   0.0878\n",
       "  -0.0436\n",
       "   0.2550\n",
       "  -0.4133\n",
       "  -0.0028\n",
       "   0.0957\n",
       "  -0.1628\n",
       "  -0.0916\n",
       "   0.0553\n",
       "  -0.0738\n",
       "  -0.3319\n",
       "   0.1410\n",
       "  -0.0289\n",
       "   0.1239\n",
       "  -0.1819\n",
       "   0.0031\n",
       "   0.0753\n",
       "  -0.0767\n",
       "  -0.0493\n",
       "  -0.2765\n",
       "  -0.1440\n",
       "  -0.1556\n",
       "   0.1945\n",
       "   0.1694\n",
       "   0.2152\n",
       "   0.0419\n",
       "  -0.0832\n",
       "  -0.1700\n",
       "  -0.0461\n",
       "   0.1651\n",
       "  -0.0628\n",
       "   0.0721\n",
       "  -0.1803\n",
       "   0.0765\n",
       "  -0.0950\n",
       "  -0.1508\n",
       "   0.0915\n",
       "  -0.0310\n",
       "  -0.2968\n",
       "  -0.4168\n",
       "  -0.1624\n",
       "  -0.2635\n",
       "   0.0745\n",
       "  -0.0514\n",
       "  -0.0356\n",
       "  -0.1136\n",
       "  -0.4550\n",
       "   0.0468\n",
       "  -0.6615\n",
       "  -0.0491\n",
       "  -0.0594\n",
       "  -0.0624\n",
       "  -0.0765\n",
       "  -0.1944\n",
       "  -0.0515\n",
       "   0.3873\n",
       "   0.0273\n",
       "   0.1203\n",
       "  -0.2338\n",
       "   0.0557\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "    3.8257e-02 -4.9750e-03  6.9206e-02\n",
       "    8.5916e-02 -7.1218e-03  9.6233e-02\n",
       "    2.4924e-02  4.5136e-02  3.8107e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "    9.0403e-03 -7.6561e-02  4.0375e-02\n",
       "   -1.0848e-02  7.7837e-02 -3.4196e-02\n",
       "   -1.1881e-02 -1.5414e-02 -6.3849e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "    1.0867e-02 -1.4023e-03  1.7826e-02\n",
       "   -1.0915e-01  1.4139e-01  1.0555e-01\n",
       "    9.4747e-02  1.8082e-01  1.3757e-01\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "   -2.4660e-02 -5.1301e-02 -2.4418e-03\n",
       "   -7.7816e-04  6.8519e-03  3.4368e-02\n",
       "    1.1694e-02 -1.3959e-02 -2.2914e-02\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "   -1.2332e-01  7.4058e-03  7.3909e-02\n",
       "    1.9839e-02  9.2416e-03 -2.6617e-02\n",
       "    3.4247e-02  5.9557e-02  9.3942e-02\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "   -3.1953e-02 -1.5572e-02  6.5592e-02\n",
       "    7.5927e-02  4.6695e-02  4.8200e-02\n",
       "    4.4364e-02  6.3817e-02  4.6709e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "    3.4405e-02  5.3463e-02 -5.7564e-03\n",
       "    5.0374e-02  4.9237e-02 -5.1507e-02\n",
       "    4.8005e-02  1.1781e-01  1.0374e-01\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "   -3.6196e-02 -6.4084e-02 -4.8828e-02\n",
       "   -1.8065e-02 -8.3809e-02  1.9662e-02\n",
       "   -1.3962e-02 -5.2689e-02 -4.7172e-02\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "    2.1848e-02  1.0366e-01  3.3511e-02\n",
       "   -1.3931e-02  2.3221e-02  2.6943e-03\n",
       "   -7.1858e-02 -3.6392e-02  6.6487e-02\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "    6.3522e-02 -7.2463e-02 -1.0621e-01\n",
       "   -1.9378e-02 -3.4574e-02 -2.1953e-02\n",
       "   -6.2319e-02 -3.0326e-02 -4.5278e-02\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "   -7.6702e-02  3.8192e-02  4.7202e-02\n",
       "   -1.0328e-02  5.1239e-02 -1.2829e-01\n",
       "    6.1225e-02  3.9250e-02 -8.4613e-03\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "    1.2192e-02  1.4274e-02 -1.1860e-01\n",
       "    1.2278e-02 -1.4383e-02 -3.5589e-02\n",
       "    1.4914e-03  7.5994e-05 -7.9966e-02\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "    4.6717e-02 -4.5687e-02 -3.4893e-02\n",
       "    1.6113e-02 -7.5118e-02 -1.2285e-01\n",
       "    3.4322e-02  4.8613e-02 -4.5821e-02\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "    3.8272e-02 -6.6684e-02 -7.2063e-02\n",
       "    4.2037e-02 -7.0205e-02  3.8779e-03\n",
       "   -7.1685e-02  3.7515e-02 -5.3731e-02\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "   -1.7524e-02 -9.4184e-03  1.3443e-02\n",
       "    5.2975e-02  4.0352e-02 -1.3395e-01\n",
       "    2.1218e-02  5.1088e-02 -5.8821e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "    3.8077e-02  4.5206e-02  1.2442e-02\n",
       "    7.1760e-02  5.4003e-02 -3.6945e-02\n",
       "    8.2667e-02 -3.1138e-02  9.7184e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "    1.2028e-01  1.2798e-02  5.8678e-02\n",
       "    6.3050e-02  1.1764e-01  1.1183e-01\n",
       "    8.4799e-02  9.9756e-02  4.1974e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "    3.6180e-02  2.8424e-02  3.6105e-02\n",
       "    8.0479e-02  3.1121e-02  5.4753e-02\n",
       "    2.4406e-02  7.6094e-02  3.1769e-02\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "   -8.1973e-02 -2.5528e-02  1.3048e-02\n",
       "   -2.6789e-03 -1.7942e-02 -8.0116e-02\n",
       "    1.1776e-01 -3.7182e-02 -7.2111e-02\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "    1.3755e-01  1.3458e-02  2.5327e-02\n",
       "    2.6156e-02  1.1919e-02 -1.1851e-01\n",
       "   -7.1494e-02 -3.1996e-03 -1.3477e-01\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "   -2.5877e-03 -1.1834e-01 -1.3220e-01\n",
       "    1.4092e-02 -7.2987e-02 -1.2828e-01\n",
       "   -3.0207e-02  5.8945e-02 -7.6750e-02\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "    6.7513e-02 -2.1227e-02 -4.8741e-02\n",
       "    6.8902e-03 -5.6568e-02 -3.8729e-02\n",
       "   -2.1343e-02 -1.5618e-02  4.0413e-02\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "    1.8908e-02  4.0336e-02 -3.6629e-02\n",
       "    1.2917e-02 -1.7865e-02 -2.1421e-02\n",
       "    8.1431e-02  1.9493e-02 -2.0810e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "   -4.1667e-02 -4.7604e-03 -5.6425e-02\n",
       "   -3.0248e-02 -6.9762e-02  1.0225e-02\n",
       "    5.6018e-02  7.9682e-02 -1.4011e-03\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "   -6.4144e-02 -1.0026e-01 -6.2763e-02\n",
       "   -2.4662e-02 -7.4156e-02 -3.7152e-02\n",
       "    1.3808e-02 -5.5364e-03 -2.0837e-02\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "   -6.2921e-02 -3.9394e-03  3.2920e-02\n",
       "   -5.3677e-03  2.6091e-02  1.5847e-02\n",
       "    3.0833e-02  3.6438e-02  4.5055e-03\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "    9.1533e-02  1.1279e-02  6.3988e-02\n",
       "   -3.0713e-02 -1.2605e-01 -4.8239e-02\n",
       "   -3.2712e-02  3.5984e-02  4.9488e-02\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "    6.8589e-02  5.6680e-02 -8.0950e-02\n",
       "   -1.6763e-02  1.0186e-02  1.0670e-02\n",
       "   -4.6630e-02  4.8127e-02 -7.9320e-03\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "    1.0144e-01  6.6484e-02 -1.4971e-02\n",
       "    9.5091e-02  8.4357e-02  1.4149e-02\n",
       "   -1.2668e-02  3.3660e-02  6.7612e-02\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "    4.1914e-03  3.1893e-02  1.1426e-01\n",
       "    3.2430e-02  1.4737e-02  8.5480e-03\n",
       "    3.1323e-02  1.5465e-01  6.9949e-02\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "   -7.9692e-02 -9.9673e-02 -6.4300e-02\n",
       "    2.7518e-04 -9.2571e-02 -5.6628e-02\n",
       "   -9.7098e-02 -6.8543e-02 -8.8264e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "   -2.0863e-02 -7.4374e-03 -4.9240e-04\n",
       "   -5.4129e-02 -2.1773e-02 -2.0944e-02\n",
       "   -4.2194e-03 -2.0752e-04 -5.1472e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -3.3836e-03  8.3938e-03  5.4948e-02\n",
       "   -1.2144e-01  1.4211e-01  8.5361e-02\n",
       "   -5.3989e-02  1.9715e-02  1.4976e-01\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "    1.0456e-02 -7.9691e-02  9.6059e-02\n",
       "    1.5832e-01  3.5280e-02 -7.4511e-02\n",
       "   -4.9416e-02 -7.4501e-03 -9.9691e-03\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "   -3.2988e-03 -8.7536e-02  2.5814e-02\n",
       "   -9.7765e-02  3.4165e-02 -8.2854e-03\n",
       "    2.3145e-02 -1.4931e-02 -7.0192e-02\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "    6.9205e-02 -6.4576e-02  1.0058e-01\n",
       "   -1.3574e-02  7.8935e-02 -4.6188e-03\n",
       "   -3.5020e-02 -1.7713e-02  7.6672e-03\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7831\n",
       "   0.6362\n",
       "   0.6402\n",
       "   0.6869\n",
       "   0.7276\n",
       "   0.8636\n",
       "   0.7959\n",
       "   0.7758\n",
       "   0.8766\n",
       "   0.7556\n",
       "   0.6893\n",
       "   0.8238\n",
       "   0.9467\n",
       "   0.7744\n",
       "   0.8408\n",
       "   0.8398\n",
       "   0.8383\n",
       "   0.6585\n",
       "   0.7675\n",
       "   0.7819\n",
       "   0.7538\n",
       "   0.8404\n",
       "   0.7316\n",
       "   0.8526\n",
       "   0.7959\n",
       "   0.7791\n",
       "   1.1595\n",
       "   0.6337\n",
       "   1.0312\n",
       "   0.7236\n",
       "   0.7407\n",
       "   0.6531\n",
       "   0.7510\n",
       "   0.8231\n",
       "   0.9328\n",
       "   0.8921\n",
       "   0.7602\n",
       "   0.8152\n",
       "   0.8890\n",
       "   0.6051\n",
       "   0.7347\n",
       "   0.6979\n",
       "   0.8763\n",
       "   0.7932\n",
       "   0.7963\n",
       "   0.8029\n",
       "   0.8063\n",
       "   0.9602\n",
       "   0.6041\n",
       "   0.7001\n",
       "   0.7125\n",
       "   0.7749\n",
       "   0.7550\n",
       "   0.9849\n",
       "   0.6753\n",
       "   0.7418\n",
       "   0.7639\n",
       "   0.7787\n",
       "   0.6482\n",
       "   0.6808\n",
       "   0.8038\n",
       "   0.8293\n",
       "   0.6743\n",
       "   0.8179\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.0471\n",
       "   0.0233\n",
       "  -0.1191\n",
       "   0.0249\n",
       "   0.0571\n",
       "   0.0841\n",
       "   0.0410\n",
       "   0.0338\n",
       "   0.1484\n",
       "  -0.2342\n",
       "  -0.0736\n",
       "  -0.0471\n",
       "  -0.3102\n",
       "   0.0335\n",
       "  -0.0591\n",
       "  -0.1430\n",
       "  -0.2992\n",
       "   0.1533\n",
       "  -0.0839\n",
       "   0.0487\n",
       "  -0.0267\n",
       "   0.2009\n",
       "  -0.1340\n",
       "   0.0950\n",
       "  -0.1260\n",
       "   0.0097\n",
       "  -0.4524\n",
       "  -0.1872\n",
       "   0.2683\n",
       "  -0.0022\n",
       "  -0.1355\n",
       "  -0.0111\n",
       "  -0.2211\n",
       "   0.1962\n",
       "   0.0045\n",
       "  -0.0365\n",
       "  -0.0100\n",
       "   0.0426\n",
       "   0.0144\n",
       "   0.0456\n",
       "   0.0260\n",
       "  -0.0702\n",
       "   0.2215\n",
       "   0.1686\n",
       "  -0.2222\n",
       "  -0.1982\n",
       "   0.0785\n",
       "  -0.2020\n",
       "  -0.1462\n",
       "  -0.0724\n",
       "   0.0523\n",
       "  -0.0891\n",
       "   0.0517\n",
       "   0.0727\n",
       "   0.0082\n",
       "  -0.0799\n",
       "  -0.0764\n",
       "  -0.0158\n",
       "  -0.1556\n",
       "  -0.0372\n",
       "   0.0411\n",
       "   0.0119\n",
       "  -0.1231\n",
       "   0.1281\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "   -3.4087e-02 -6.2563e-03  1.1761e-01\n",
       "   -5.9553e-03  7.9569e-02  3.8051e-02\n",
       "    6.0940e-02  1.5193e-02 -1.0950e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "    1.1434e-01  6.5799e-02  4.9788e-02\n",
       "    2.9925e-02  5.6155e-02  1.9722e-02\n",
       "   -1.4600e-03  1.2804e-01  8.4357e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "    2.1683e-02  7.4201e-02  3.8903e-02\n",
       "    5.0511e-02  1.0766e-01  8.0314e-02\n",
       "    9.0264e-02 -2.7359e-02  1.0453e-01\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "   -1.0829e-02  1.7940e-02  5.9619e-02\n",
       "    1.2371e-02  4.0478e-02  7.3648e-02\n",
       "    3.8170e-02  2.0652e-02 -2.0167e-02\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "    8.7359e-02 -1.5407e-02  3.8877e-02\n",
       "    6.6333e-02 -6.1863e-02  4.3488e-02\n",
       "    5.3824e-02 -5.3382e-02  2.2423e-02\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "   -1.0615e-03  1.0768e-01  5.2262e-02\n",
       "    8.7696e-02 -2.7870e-02 -4.4979e-03\n",
       "    4.4662e-02  2.5257e-02  1.9294e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "   -9.1120e-02  5.1690e-02 -2.2151e-02\n",
       "   -3.8981e-02  5.8703e-02  1.4171e-01\n",
       "   -2.5807e-02 -5.4139e-02  2.7385e-02\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "    6.2360e-02 -4.9297e-03 -2.4345e-02\n",
       "   -6.2893e-02 -4.0214e-02 -2.8486e-03\n",
       "   -1.5038e-02 -3.7583e-02 -7.8064e-02\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "    2.7103e-03 -6.3506e-02 -3.1369e-02\n",
       "   -3.5850e-02  1.8266e-02 -2.9264e-02\n",
       "   -1.3210e-01  3.4475e-03 -8.2693e-02\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "   -9.5865e-02 -1.8711e-02 -7.2953e-03\n",
       "   -4.1320e-02 -5.4491e-02  5.4724e-02\n",
       "    3.4581e-02 -3.0956e-02  3.7974e-04\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "   -5.0935e-02  3.5497e-02 -4.2073e-02\n",
       "    2.4632e-02  3.5078e-02  6.8613e-02\n",
       "    4.0498e-02  8.9194e-02 -1.0251e-01\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "    5.2440e-02  4.2507e-03 -2.2942e-02\n",
       "    4.8050e-02  1.8495e-03 -6.0449e-02\n",
       "   -8.6145e-02  1.1026e-02 -3.9286e-02\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "    1.9579e-03  5.2371e-02  5.9788e-02\n",
       "    6.1031e-02 -4.2883e-02 -7.5983e-02\n",
       "   -1.5111e-01 -9.0999e-02 -1.2818e-01\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "   -9.1920e-02 -4.5919e-02  2.4637e-02\n",
       "   -6.1542e-02  3.6921e-02 -3.6036e-02\n",
       "   -7.7756e-02 -8.5545e-03 -5.9755e-03\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "    2.6002e-02 -1.2497e-03 -5.2614e-02\n",
       "   -6.0576e-02 -6.8290e-02 -3.6807e-02\n",
       "   -1.8765e-02 -2.3021e-02 -5.4930e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "   -3.9713e-02  5.1715e-02 -5.2628e-02\n",
       "   -3.7794e-02  3.3919e-02 -6.2009e-02\n",
       "    2.5962e-02 -2.1275e-02 -1.1603e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "    8.7728e-03 -7.6024e-03 -1.0907e-01\n",
       "   -1.0789e-01  3.6013e-02 -7.0374e-02\n",
       "   -3.7808e-02 -8.4602e-02 -4.0710e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "   -4.3021e-02 -1.0806e-01  4.7601e-03\n",
       "   -3.9025e-02 -1.1985e-01 -1.9249e-01\n",
       "   -9.7994e-02 -1.5136e-01 -1.2911e-01\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "   -4.9225e-02 -1.4997e-01 -8.5511e-02\n",
       "   -6.2805e-02 -4.5196e-02 -2.0307e-02\n",
       "   -1.3065e-01 -8.0308e-02 -8.7736e-02\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "    2.3279e-02 -4.6247e-02  3.6177e-03\n",
       "   -1.1592e-02 -3.2258e-02 -2.1170e-02\n",
       "    3.7662e-02  2.4282e-02 -1.3241e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "   -6.6973e-03 -9.1253e-02  3.0615e-03\n",
       "   -4.3249e-02 -2.6181e-03 -1.2361e-01\n",
       "   -1.0242e-01 -4.0124e-02 -2.6288e-02\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "   -6.1372e-02 -1.2225e-01 -4.3357e-03\n",
       "   -6.6630e-02 -4.2330e-02  5.1946e-03\n",
       "   -1.1078e-02  7.4767e-02 -2.5445e-02\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "    7.9967e-04 -5.4562e-02  4.4896e-02\n",
       "   -4.3900e-02  1.9329e-02  3.4324e-02\n",
       "   -2.6372e-02 -5.8001e-02  4.1631e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "    6.7759e-02 -1.6191e-02  7.0545e-02\n",
       "   -2.4840e-02  1.5417e-02  9.5259e-02\n",
       "    2.7203e-02  1.0482e-01  1.2262e-01\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "    4.4686e-02  3.1442e-02 -2.6092e-02\n",
       "    4.2337e-03  5.5295e-02  9.8648e-03\n",
       "   -6.2100e-02 -5.0917e-02 -1.9787e-02\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "    1.0371e-01  8.5373e-02 -1.2860e-02\n",
       "    1.1842e-01  8.4218e-02  7.1404e-02\n",
       "    1.2077e-01  1.2997e-01  1.8506e-02\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "   -1.1217e-02 -8.6829e-02  3.8816e-02\n",
       "    2.7605e-02  5.4188e-02 -6.9722e-03\n",
       "   -2.7097e-02 -2.7131e-02 -9.9428e-03\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "    4.4529e-02  4.4445e-02  6.3424e-02\n",
       "    2.5667e-02 -8.3615e-04 -3.8465e-02\n",
       "   -4.1258e-02  6.2343e-02 -7.6095e-03\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "    5.8250e-02  8.9951e-02  4.2291e-02\n",
       "    5.9900e-02  1.3868e-02  5.4463e-02\n",
       "   -2.6558e-02  2.3302e-02  6.3254e-02\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "    4.2410e-02  1.6425e-02  1.9052e-01\n",
       "   -9.3352e-02 -3.6514e-02  1.5079e-02\n",
       "    4.5182e-02  4.5710e-02  1.4514e-02\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "    2.5367e-03 -1.4616e-02  1.1411e-02\n",
       "   -1.5721e-02 -3.8197e-02 -1.7330e-02\n",
       "    9.6777e-02 -1.0240e-02 -7.9147e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "   -6.8042e-02 -1.5024e-02  3.8065e-02\n",
       "   -2.5535e-02 -2.6534e-03  2.0064e-02\n",
       "   -8.7134e-02  5.6235e-02  2.8258e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -6.5468e-02 -6.7476e-02 -5.9334e-02\n",
       "   -5.8220e-02 -3.2691e-02 -4.4107e-02\n",
       "    3.1123e-03 -8.5400e-02 -1.1849e-02\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "   -7.6171e-02  4.5340e-02  1.7559e-02\n",
       "    2.9798e-02 -1.0102e-01 -2.4113e-02\n",
       "   -3.7658e-02 -1.4634e-03 -3.4493e-02\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "    5.0226e-03 -3.8130e-03 -1.0801e-02\n",
       "    8.5798e-04  5.5213e-03 -6.9698e-02\n",
       "    3.9923e-03 -6.1806e-03 -3.2409e-02\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "    9.3106e-03  1.9291e-02  1.9048e-02\n",
       "   -2.3289e-02 -1.1037e-01 -2.4476e-02\n",
       "   -4.2823e-02 -6.1696e-02  4.1754e-02\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.5812\n",
       "   0.8563\n",
       "   0.9034\n",
       "   0.7459\n",
       "   0.8003\n",
       "   0.5698\n",
       "   0.6259\n",
       "   0.9239\n",
       "   0.8552\n",
       "   0.7450\n",
       "   0.6096\n",
       "   0.9799\n",
       "   0.4734\n",
       "   0.5561\n",
       "   0.5837\n",
       "   0.8532\n",
       "   0.7968\n",
       "   0.9053\n",
       "   0.8965\n",
       "   0.6030\n",
       "   0.7419\n",
       "   0.7243\n",
       "   0.4679\n",
       "   0.7131\n",
       "   0.5293\n",
       "   0.4176\n",
       "   0.6862\n",
       "   0.8246\n",
       "   0.7477\n",
       "   0.6652\n",
       "   0.7022\n",
       "   0.9038\n",
       "   0.6611\n",
       "   0.8403\n",
       "   0.4893\n",
       "   0.6949\n",
       "   0.6976\n",
       "   0.6439\n",
       "   0.7963\n",
       "   0.6083\n",
       "   0.8983\n",
       "   0.7440\n",
       "   0.8250\n",
       "   0.4613\n",
       "   0.7948\n",
       "   0.5317\n",
       "   0.8463\n",
       "   0.8058\n",
       "   0.9196\n",
       "   0.6224\n",
       "   0.6556\n",
       "   0.7095\n",
       "   0.7683\n",
       "   0.1154\n",
       "   0.6919\n",
       "   0.6502\n",
       "   0.9159\n",
       "   0.5333\n",
       "   0.5925\n",
       "   0.7608\n",
       "   0.7537\n",
       "   0.7173\n",
       "   0.9142\n",
       "   0.7332\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.1248\n",
       "   0.0705\n",
       "  -0.0746\n",
       "   0.1109\n",
       "   0.0320\n",
       "  -0.2462\n",
       "   0.0500\n",
       "  -0.2896\n",
       "   0.1820\n",
       "   0.0084\n",
       "  -0.1837\n",
       "  -0.0784\n",
       "   0.0416\n",
       "  -0.1990\n",
       "  -0.2505\n",
       "   0.0563\n",
       "   0.0444\n",
       "  -0.0037\n",
       "  -0.1060\n",
       "  -0.0809\n",
       "  -0.1302\n",
       "  -0.0302\n",
       "  -0.1108\n",
       "  -0.2278\n",
       "  -0.1324\n",
       "  -0.0904\n",
       "   0.0412\n",
       "   0.0159\n",
       "   0.1412\n",
       "  -0.1219\n",
       "  -0.1885\n",
       "  -0.0138\n",
       "  -0.0732\n",
       "   0.0343\n",
       "  -0.0037\n",
       "   0.0244\n",
       "  -0.0897\n",
       "   0.0857\n",
       "  -0.1444\n",
       "  -0.1024\n",
       "   0.0264\n",
       "  -0.0431\n",
       "  -0.0304\n",
       "  -0.3254\n",
       "  -0.1746\n",
       "  -0.1641\n",
       "   0.0661\n",
       "  -0.0190\n",
       "  -0.0778\n",
       "  -0.0030\n",
       "  -0.3051\n",
       "  -0.0095\n",
       "  -0.3601\n",
       "  -0.0692\n",
       "  -0.1561\n",
       "  -0.2322\n",
       "   0.0589\n",
       "  -0.1287\n",
       "   0.0281\n",
       "   0.0772\n",
       "   0.0319\n",
       "   0.0441\n",
       "  -0.2808\n",
       "  -0.0227\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "    8.2475e-02  1.8441e-02  7.3545e-02\n",
       "   -1.8903e-02  1.6227e-01  7.9523e-02\n",
       "    1.5122e-01  6.1444e-02  1.7930e-01\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "    3.2992e-02 -1.2321e-02  2.6030e-02\n",
       "   -1.3000e-02  3.0115e-02  2.8910e-02\n",
       "   -1.0726e-02 -3.5939e-03  7.5570e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "   -8.4863e-02  1.5068e-02  8.0401e-02\n",
       "   -6.8805e-02  5.1354e-03  1.9525e-02\n",
       "   -6.0784e-02  3.0702e-02  2.3452e-02\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "    5.2524e-02 -1.8722e-02  4.9975e-03\n",
       "    4.2138e-02  6.0279e-02  1.1766e-01\n",
       "    1.3232e-01  8.5544e-02  9.6003e-02\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "    4.1692e-02  6.1408e-02 -7.2518e-02\n",
       "    4.7431e-02  9.3576e-02 -4.7355e-02\n",
       "    4.6906e-02  1.5562e-02 -1.0986e-01\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "   -1.7558e-04 -7.5375e-03  4.6767e-02\n",
       "    1.3958e-01 -2.5055e-02 -5.2906e-05\n",
       "    4.4293e-02  1.6483e-01  2.6046e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "    1.1137e-02 -5.2908e-02 -6.3176e-02\n",
       "    1.2294e-02  5.5867e-02 -3.9744e-02\n",
       "   -2.4916e-02  7.5236e-02  7.5798e-02\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "   -8.9785e-02  7.9926e-02 -2.6182e-02\n",
       "   -3.2209e-02  4.7812e-02  3.3918e-02\n",
       "    9.9195e-02 -6.6676e-03  7.3533e-03\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "   -2.7127e-02 -4.7819e-02  7.5500e-03\n",
       "    3.0192e-02 -1.1585e-01 -1.3247e-02\n",
       "    4.4768e-02  2.4750e-02  2.0393e-03\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "    1.0947e-01  3.1996e-02  3.6546e-02\n",
       "   -4.6068e-02  4.6605e-02  5.5151e-02\n",
       "    4.0002e-02  8.3693e-02  4.8412e-02\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "    1.5019e-01  4.9884e-02  1.7099e-01\n",
       "    6.1169e-02  4.2166e-02 -4.4726e-02\n",
       "   -5.1857e-02  1.1983e-01  2.8784e-02\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "   -2.3572e-02  2.4063e-02 -6.0117e-02\n",
       "   -6.2715e-03  7.5437e-02 -1.3655e-02\n",
       "   -4.6918e-02 -6.3598e-03 -4.7168e-02\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "   -6.6309e-02 -4.7962e-02  7.8678e-03\n",
       "   -1.1165e-01 -7.4533e-03  1.7387e-02\n",
       "   -7.3087e-02 -5.1296e-02 -1.0112e-02\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "    5.3056e-02 -7.3249e-03 -4.2624e-02\n",
       "   -2.4804e-02  3.5819e-02 -4.3911e-02\n",
       "   -4.5085e-02  4.1424e-02  6.6544e-02\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "    1.5368e-02  7.5919e-02  1.1735e-01\n",
       "    1.1273e-01  2.3355e-02  4.7697e-02\n",
       "    6.4288e-02 -2.0525e-02 -9.4335e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "   -2.9949e-02 -6.4411e-02 -3.6355e-02\n",
       "   -1.0052e-01  5.1773e-02  1.1954e-03\n",
       "    1.7937e-03  5.9473e-02  4.7363e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "   -6.8626e-02 -1.4622e-01 -1.7759e-01\n",
       "   -2.0237e-01 -8.3248e-02 -1.7684e-01\n",
       "   -6.9886e-02 -1.2086e-01  3.9168e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "    6.3653e-02  3.0831e-02  1.2027e-02\n",
       "   -3.1621e-02 -2.2906e-02  8.6890e-02\n",
       "   -2.5771e-02  1.7900e-02  1.0112e-01\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "    1.2688e-01  6.8961e-02  2.8774e-02\n",
       "    4.9041e-02 -2.0606e-02 -1.2129e-01\n",
       "    1.0895e-01 -1.9020e-02 -3.5018e-02\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "   -4.3293e-02  3.0859e-02 -2.8613e-02\n",
       "   -3.4598e-02 -5.9175e-03 -4.4963e-02\n",
       "   -3.1425e-03  5.4556e-02 -2.6217e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "    2.3242e-02 -9.2619e-04 -1.1920e-02\n",
       "    6.7061e-02 -5.4645e-02 -3.3536e-02\n",
       "    4.1410e-02 -8.0685e-02 -3.4319e-02\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "   -9.5426e-02  1.7764e-02  6.2244e-02\n",
       "    3.2098e-02 -2.9611e-02 -2.1920e-02\n",
       "    3.8391e-02  4.7149e-02  4.8903e-02\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "    8.8738e-02  5.5605e-02  4.5470e-02\n",
       "    3.6159e-02  5.6434e-02  5.5492e-02\n",
       "    9.7311e-02  8.6830e-02  4.2662e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "    7.0553e-02  4.5332e-02 -4.2834e-02\n",
       "    6.7338e-02  4.3408e-02  2.3438e-02\n",
       "    1.1330e-01  7.7004e-02 -2.6095e-02\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "   -5.0283e-02 -1.4466e-01 -1.2910e-01\n",
       "   -7.3279e-02 -6.2936e-02 -1.2428e-01\n",
       "   -1.2523e-01 -1.8293e-02 -7.3863e-02\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "    1.3888e-01  9.5127e-02  9.2164e-02\n",
       "    8.3481e-02 -2.2588e-02 -5.4759e-03\n",
       "    2.2663e-02  7.8510e-02  6.6796e-02\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "    3.0391e-02  6.8280e-02  1.0141e-01\n",
       "   -6.4560e-03  1.3904e-01  2.2921e-02\n",
       "    6.3698e-02  6.2969e-02  2.5570e-03\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "   -2.5516e-02 -5.4163e-02 -1.3882e-01\n",
       "   -2.0909e-02 -4.8162e-02 -1.1425e-01\n",
       "   -6.2406e-02 -1.1520e-02 -8.5659e-03\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "    3.7953e-02 -8.0529e-02 -4.1469e-02\n",
       "   -5.8057e-02 -1.0466e-01 -1.0252e-01\n",
       "   -5.0743e-02 -1.8146e-01 -1.5307e-01\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "    2.4915e-02  1.0439e-01  6.1308e-02\n",
       "    9.6650e-03  7.6108e-02  4.4929e-02\n",
       "    1.2305e-01  1.0206e-01  1.3295e-01\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "    1.2545e-01  2.3191e-02 -6.9766e-02\n",
       "    1.0649e-01  9.2086e-02  8.0789e-02\n",
       "    1.2295e-01  9.8513e-02  8.7500e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "   -1.1010e-01  7.2430e-02 -2.5350e-06\n",
       "   -7.3736e-02  4.5964e-02 -3.0784e-02\n",
       "   -4.9569e-02 -3.0080e-02 -2.0178e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -6.8353e-02 -7.7377e-02 -6.8400e-02\n",
       "   -3.9442e-02  1.4933e-02  3.6129e-02\n",
       "   -9.9223e-02 -3.8350e-02 -1.3456e-01\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "    9.1726e-02  7.3778e-02 -1.6260e-02\n",
       "   -1.1352e-02  2.7364e-02  9.2110e-02\n",
       "    5.2281e-02  1.5119e-02  1.0642e-01\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "    8.8728e-02  6.5226e-02 -3.0551e-02\n",
       "    3.8929e-02 -5.5272e-03  5.4839e-02\n",
       "    9.7079e-02  9.3762e-04  4.4803e-02\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "   -5.7142e-02  4.0576e-02  3.5925e-02\n",
       "    1.3629e-03 -3.9736e-02  1.2339e-02\n",
       "    1.1801e-03  3.2988e-02 -1.0241e-02\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.6563\n",
       "   0.6760\n",
       "   0.8169\n",
       "   0.8552\n",
       "   0.8272\n",
       "   0.6607\n",
       "   0.5821\n",
       "   0.9919\n",
       "   0.7012\n",
       "   0.8595\n",
       "   0.9393\n",
       "   0.7877\n",
       "   0.7034\n",
       "   0.6454\n",
       "   0.7688\n",
       "   0.7933\n",
       "   0.7696\n",
       "   0.7453\n",
       "   0.7885\n",
       "   0.8305\n",
       "   1.0217\n",
       "   0.7710\n",
       "   0.5002\n",
       "   0.7624\n",
       "   0.7937\n",
       "   0.6708\n",
       "   0.8087\n",
       "   0.7875\n",
       "   0.6590\n",
       "   0.8429\n",
       "   0.8390\n",
       "   0.8010\n",
       "   0.7656\n",
       "   0.7668\n",
       "   0.6539\n",
       "   0.8397\n",
       "   0.6969\n",
       "   0.7387\n",
       "   0.7283\n",
       "   0.7529\n",
       "   0.8156\n",
       "   0.7248\n",
       "   0.9641\n",
       "   0.7804\n",
       "   0.7383\n",
       "   0.9908\n",
       "   0.7087\n",
       "   0.7725\n",
       "   0.8183\n",
       "   0.8309\n",
       "   0.8300\n",
       "   0.7057\n",
       "   0.8804\n",
       "   0.7067\n",
       "   0.9069\n",
       "   0.7967\n",
       "   0.6465\n",
       "   0.5263\n",
       "   0.7680\n",
       "   0.8820\n",
       "   0.8904\n",
       "   0.6787\n",
       "   0.9290\n",
       "   0.8524\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.1715\n",
       "  -0.0963\n",
       "   0.1563\n",
       "   0.1701\n",
       "   0.0170\n",
       "   0.0989\n",
       "  -0.2643\n",
       "   0.2608\n",
       "  -0.1646\n",
       "   0.1972\n",
       "   0.2673\n",
       "   0.3080\n",
       "   0.1782\n",
       "  -0.1010\n",
       "   0.0601\n",
       "   0.3049\n",
       "  -0.0613\n",
       "   0.0194\n",
       "   0.0526\n",
       "   0.0540\n",
       "   0.3400\n",
       "   0.0288\n",
       "  -0.3499\n",
       "  -0.0294\n",
       "  -0.1964\n",
       "   0.0631\n",
       "  -0.1569\n",
       "   0.1011\n",
       "  -0.1999\n",
       "  -0.0236\n",
       "   0.0917\n",
       "  -0.0284\n",
       "   0.0419\n",
       "  -0.0543\n",
       "  -0.3018\n",
       "   0.1026\n",
       "  -0.0932\n",
       "   0.1097\n",
       "  -0.0832\n",
       "  -0.0927\n",
       "   0.0757\n",
       "  -0.1679\n",
       "  -0.1508\n",
       "   0.0339\n",
       "  -0.0734\n",
       "   0.1482\n",
       "  -0.1299\n",
       "   0.1403\n",
       "  -0.1988\n",
       "  -0.3370\n",
       "   0.2077\n",
       "  -0.1143\n",
       "   0.2740\n",
       "   0.0299\n",
       "   0.0379\n",
       "   0.0724\n",
       "   0.0816\n",
       "  -0.3492\n",
       "   0.0444\n",
       "   0.1384\n",
       "   0.1632\n",
       "  -0.1322\n",
       "   0.0952\n",
       "  -0.2136\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  (0 ,0 ,.,.) = \n",
       "    1.9412e-01  9.9006e-02  6.8865e-02\n",
       "    9.7236e-02  1.0329e-01  5.8259e-02\n",
       "    1.1752e-01  7.8399e-03  7.8270e-02\n",
       "  \n",
       "  (0 ,1 ,.,.) = \n",
       "   -9.5953e-02 -8.9977e-02 -7.8092e-02\n",
       "    4.5084e-02  2.3786e-02 -4.7098e-03\n",
       "    1.5479e-03 -5.7720e-02 -1.5835e-02\n",
       "  \n",
       "  (0 ,2 ,.,.) = \n",
       "    3.2275e-02  9.5476e-02  8.3762e-02\n",
       "    1.0508e-01  1.5057e-01  3.5568e-02\n",
       "    9.8396e-02  6.1604e-02  1.1209e-01\n",
       "     ...\n",
       "  \n",
       "  (0 ,61,.,.) = \n",
       "    8.5033e-02  9.4260e-02  2.0328e-02\n",
       "    1.1167e-01  1.0392e-01  2.9021e-03\n",
       "    1.0849e-01  1.1641e-01  1.4070e-01\n",
       "  \n",
       "  (0 ,62,.,.) = \n",
       "    1.6752e-01  1.6408e-01  1.6282e-01\n",
       "    1.3935e-01  1.5636e-01  1.9787e-01\n",
       "    1.1873e-01  1.8959e-01  2.0761e-01\n",
       "  \n",
       "  (0 ,63,.,.) = \n",
       "    1.1702e-01  4.2109e-02  7.3573e-02\n",
       "    6.0255e-02  8.6716e-02  1.1673e-01\n",
       "    6.1164e-02  1.0077e-01  3.7898e-02\n",
       "        \n",
       "  \n",
       "  (1 ,0 ,.,.) = \n",
       "    5.9926e-02  5.7600e-02  2.6894e-02\n",
       "   -2.3316e-03 -2.9731e-02  9.1868e-02\n",
       "    1.4332e-02  5.0699e-02  2.2306e-02\n",
       "  \n",
       "  (1 ,1 ,.,.) = \n",
       "    5.1282e-02  1.9274e-02  2.3385e-02\n",
       "    6.3445e-02 -3.4152e-02  1.9621e-02\n",
       "    7.0876e-02  2.9235e-02 -1.1754e-02\n",
       "  \n",
       "  (1 ,2 ,.,.) = \n",
       "    6.9717e-03  3.3669e-02 -6.4051e-02\n",
       "   -3.6489e-02  9.5661e-02 -4.3884e-02\n",
       "   -1.6386e-02  5.8209e-02 -2.8427e-02\n",
       "     ...\n",
       "  \n",
       "  (1 ,61,.,.) = \n",
       "    1.7803e-01  2.5947e-03  3.9683e-03\n",
       "   -2.6227e-02  7.6514e-02 -4.4720e-03\n",
       "   -5.2547e-03  3.2058e-02 -3.3635e-02\n",
       "  \n",
       "  (1 ,62,.,.) = \n",
       "   -1.0729e-02 -4.4664e-03  8.8469e-02\n",
       "    2.3704e-02  2.0708e-02  8.1984e-02\n",
       "    5.0738e-02  7.7328e-02 -2.1162e-02\n",
       "  \n",
       "  (1 ,63,.,.) = \n",
       "    7.4524e-02 -1.9000e-02  3.1063e-02\n",
       "    6.0405e-02  5.3419e-03 -5.8662e-03\n",
       "    3.2823e-02 -4.8355e-02 -1.0135e-01\n",
       "        \n",
       "  \n",
       "  (2 ,0 ,.,.) = \n",
       "    7.4217e-02  3.9103e-02  3.1845e-02\n",
       "    1.3868e-01  1.8158e-02 -6.2113e-02\n",
       "    3.7078e-02  5.6056e-03 -3.5721e-02\n",
       "  \n",
       "  (2 ,1 ,.,.) = \n",
       "    8.4785e-02 -4.7187e-02  2.4132e-02\n",
       "    2.6008e-02 -8.4585e-02 -3.2698e-02\n",
       "   -1.0610e-02  2.1736e-03  4.1294e-02\n",
       "  \n",
       "  (2 ,2 ,.,.) = \n",
       "   -4.8214e-02  6.3565e-02  2.0456e-02\n",
       "    4.9847e-02  2.8799e-02 -6.6884e-02\n",
       "    5.9517e-02  5.5839e-02  6.1143e-02\n",
       "     ...\n",
       "  \n",
       "  (2 ,61,.,.) = \n",
       "   -7.4737e-03 -1.1870e-02  1.2095e-01\n",
       "   -2.5418e-02  5.3321e-02  4.4063e-02\n",
       "    4.5485e-02  2.5552e-03  7.1288e-02\n",
       "  \n",
       "  (2 ,62,.,.) = \n",
       "    9.2883e-02  4.9471e-02  6.7473e-02\n",
       "    1.8099e-01  1.5526e-01  4.4227e-02\n",
       "    1.3680e-01  1.1639e-01  4.3107e-02\n",
       "  \n",
       "  (2 ,63,.,.) = \n",
       "    8.6078e-02  1.4062e-02  9.1297e-04\n",
       "    1.2223e-02  1.6322e-02  7.9704e-02\n",
       "    3.6374e-02 -4.3049e-03  1.4312e-02\n",
       "  ...   \n",
       "        \n",
       "  \n",
       "  (61,0 ,.,.) = \n",
       "    2.1357e-02  3.9416e-02  2.6662e-02\n",
       "    2.5195e-02  4.2041e-02  4.2442e-02\n",
       "   -5.0253e-02 -4.5893e-02  2.3625e-02\n",
       "  \n",
       "  (61,1 ,.,.) = \n",
       "    2.6570e-02 -3.7368e-03  2.4568e-02\n",
       "   -4.9445e-03  1.2244e-02  1.4100e-02\n",
       "   -3.6263e-02  5.2553e-02  8.3391e-02\n",
       "  \n",
       "  (61,2 ,.,.) = \n",
       "    1.0002e-01  1.1857e-01  1.0524e-01\n",
       "    1.1480e-01  2.5495e-02  1.1490e-01\n",
       "    1.1939e-01  5.4655e-02  4.6511e-02\n",
       "     ...\n",
       "  \n",
       "  (61,61,.,.) = \n",
       "    2.5326e-02  1.1531e-01  1.9951e-03\n",
       "   -1.9416e-02  5.9060e-02 -1.0980e-02\n",
       "   -5.3675e-03  8.3510e-03  8.0542e-02\n",
       "  \n",
       "  (61,62,.,.) = \n",
       "    3.3235e-02 -1.2182e-02  6.6457e-02\n",
       "    6.1493e-02  6.5699e-02 -2.8415e-02\n",
       "    7.8970e-02 -3.2283e-03  8.9222e-02\n",
       "  \n",
       "  (61,63,.,.) = \n",
       "   -2.0501e-02  3.2045e-02 -2.4625e-02\n",
       "    2.2001e-02 -1.3210e-02  9.5975e-03\n",
       "    3.7013e-02 -3.5857e-02 -8.1672e-02\n",
       "        \n",
       "  \n",
       "  (62,0 ,.,.) = \n",
       "    4.2304e-02 -6.7065e-02  7.4223e-02\n",
       "   -2.3645e-02  3.7068e-03 -7.4914e-02\n",
       "    3.7170e-02  1.1821e-02 -1.8666e-02\n",
       "  \n",
       "  (62,1 ,.,.) = \n",
       "   -4.6122e-02 -7.1695e-04 -1.7538e-02\n",
       "    2.1932e-02  3.5277e-02 -1.1373e-01\n",
       "    4.9598e-02  5.0724e-02 -2.8890e-02\n",
       "  \n",
       "  (62,2 ,.,.) = \n",
       "    5.0309e-02  6.3511e-02  4.5999e-02\n",
       "    7.6059e-03  6.5357e-02  6.8852e-02\n",
       "    4.5333e-02  8.6287e-02 -3.3277e-02\n",
       "     ...\n",
       "  \n",
       "  (62,61,.,.) = \n",
       "   -4.2697e-02 -8.7901e-03 -3.7937e-02\n",
       "   -6.0695e-02 -1.7581e-02 -7.3276e-02\n",
       "    2.0214e-02 -4.4930e-02 -2.4143e-02\n",
       "  \n",
       "  (62,62,.,.) = \n",
       "    8.0661e-02  4.7290e-02  7.6892e-02\n",
       "    4.5788e-02  8.5199e-02  1.6348e-01\n",
       "   -3.0494e-02 -2.0408e-02  1.0134e-01\n",
       "  \n",
       "  (62,63,.,.) = \n",
       "   -5.7687e-02  5.5773e-02 -8.9258e-03\n",
       "   -1.0296e-02  3.5995e-02  4.7000e-03\n",
       "   -6.6607e-02  1.1496e-02  5.3510e-03\n",
       "        \n",
       "  \n",
       "  (63,0 ,.,.) = \n",
       "    2.2752e-02  4.7255e-02 -4.3353e-02\n",
       "    3.3867e-03 -4.1383e-03 -3.4742e-02\n",
       "   -1.1266e-02 -8.5748e-02 -7.7282e-02\n",
       "  \n",
       "  (63,1 ,.,.) = \n",
       "    2.0278e-03 -1.2000e-01 -2.4473e-02\n",
       "   -5.0676e-03 -1.0670e-02 -3.2523e-02\n",
       "   -6.5887e-03  3.2812e-02  4.5708e-02\n",
       "  \n",
       "  (63,2 ,.,.) = \n",
       "   -1.8174e-02 -1.2362e-02  5.5788e-02\n",
       "   -6.5017e-03 -7.0541e-03 -1.1075e-02\n",
       "   -3.3080e-02 -3.5149e-02 -5.5327e-02\n",
       "     ...\n",
       "  \n",
       "  (63,61,.,.) = \n",
       "   -2.3968e-02 -5.9011e-03 -8.0109e-05\n",
       "    6.0570e-02 -2.9489e-02 -1.9005e-02\n",
       "   -5.6971e-02  1.8550e-02 -6.7681e-02\n",
       "  \n",
       "  (63,62,.,.) = \n",
       "    1.8315e-02 -4.0356e-02  4.9827e-02\n",
       "   -7.4907e-02  4.1596e-02  8.6511e-02\n",
       "    7.8987e-03 -2.2806e-02 -4.2880e-02\n",
       "  \n",
       "  (63,63,.,.) = \n",
       "   -8.0395e-02 -6.0439e-02 -5.9064e-02\n",
       "    2.8851e-02 -4.1924e-03  2.5127e-02\n",
       "    2.1272e-02 -5.1428e-03 -4.8197e-02\n",
       "  [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.6304\n",
       "   0.7996\n",
       "   0.5793\n",
       "   0.8912\n",
       "   0.6704\n",
       "   0.7701\n",
       "   0.8060\n",
       "   0.6500\n",
       "   0.7869\n",
       "   0.7112\n",
       "   0.6633\n",
       "   0.6880\n",
       "   0.5044\n",
       "   0.6079\n",
       "   0.7310\n",
       "   0.7078\n",
       "   0.7822\n",
       "   0.6810\n",
       "   0.6028\n",
       "   0.9205\n",
       "   0.5827\n",
       "   0.6874\n",
       "   0.6899\n",
       "   0.5677\n",
       "   0.6617\n",
       "   0.4643\n",
       "   0.7621\n",
       "   0.7569\n",
       "   0.9138\n",
       "   0.6507\n",
       "   0.5115\n",
       "   0.7044\n",
       "   0.7636\n",
       "   0.8380\n",
       "   0.7622\n",
       "   0.7886\n",
       "   0.5619\n",
       "   0.7234\n",
       "   0.7280\n",
       "   0.6104\n",
       "   0.6839\n",
       "   0.6726\n",
       "   0.8586\n",
       "   0.6927\n",
       "   0.8807\n",
       "   0.9266\n",
       "   0.7510\n",
       "   0.5920\n",
       "   0.6395\n",
       "   0.6063\n",
       "   0.7171\n",
       "   0.7186\n",
       "   0.8988\n",
       "   0.3548\n",
       "   0.6463\n",
       "   0.7721\n",
       "   0.6690\n",
       "   0.8478\n",
       "   0.7472\n",
       "   0.6709\n",
       "   0.8310\n",
       "   0.5665\n",
       "   0.8971\n",
       "   0.7162\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  -0.2509\n",
       "  -0.0090\n",
       "  -0.0771\n",
       "   0.0545\n",
       "   0.0223\n",
       "  -0.1509\n",
       "   0.0294\n",
       "  -0.2194\n",
       "   0.1218\n",
       "  -0.0940\n",
       "  -0.2024\n",
       "  -0.1166\n",
       "  -0.1318\n",
       "  -0.1030\n",
       "  -0.1823\n",
       "  -0.0303\n",
       "   0.0454\n",
       "  -0.1862\n",
       "  -0.1519\n",
       "  -0.0449\n",
       "  -0.0889\n",
       "  -0.0588\n",
       "  -0.1012\n",
       "  -0.1735\n",
       "  -0.0726\n",
       "  -0.0141\n",
       "  -0.0020\n",
       "   0.0643\n",
       "   0.0927\n",
       "  -0.1009\n",
       "  -0.1925\n",
       "  -0.1247\n",
       "   0.0934\n",
       "   0.1254\n",
       "  -0.0475\n",
       "   0.0207\n",
       "  -0.1766\n",
       "  -0.0490\n",
       "  -0.0803\n",
       "  -0.0722\n",
       "  -0.0270\n",
       "  -0.0479\n",
       "  -0.0698\n",
       "  -0.2474\n",
       "  -0.1135\n",
       "  -0.0045\n",
       "   0.1065\n",
       "  -0.1066\n",
       "   0.0128\n",
       "  -0.2029\n",
       "  -0.1959\n",
       "   0.0357\n",
       "  -0.1319\n",
       "  -0.0638\n",
       "  -0.1912\n",
       "  -0.0821\n",
       "   0.0527\n",
       "  -0.0941\n",
       "   0.0075\n",
       "   0.0017\n",
       "   0.0329\n",
       "   0.0485\n",
       "   0.0063\n",
       "  -0.0704\n",
       "  [torch.cuda.FloatTensor of size 64 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    1.3531e-02  2.3897e-03  4.6126e-02\n",
       "   -5.4119e-02 -6.0477e-02 -6.2857e-03\n",
       "    3.1671e-03 -2.0417e-02 -4.6208e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    4.0453e-02  3.1769e-02  2.3612e-02\n",
       "    7.4886e-02  8.2134e-03  3.4174e-02\n",
       "    6.1657e-02  1.0126e-01  8.2498e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -3.8968e-02  7.6438e-02 -1.6143e-02\n",
       "   -8.5654e-03  1.0390e-02  5.0052e-02\n",
       "   -5.4428e-04  7.2130e-02  6.5511e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,61 ,.,.) = \n",
       "    9.6964e-02  3.6824e-02 -3.4392e-02\n",
       "    5.3591e-02  4.7148e-02 -1.8495e-02\n",
       "   -1.3536e-02  1.4216e-02  1.2301e-02\n",
       "  \n",
       "  ( 0 ,62 ,.,.) = \n",
       "   -4.3079e-02 -1.9599e-02 -4.8464e-03\n",
       "    1.4969e-02  2.4200e-03 -5.4429e-02\n",
       "   -6.5020e-03 -4.3332e-04  8.8139e-03\n",
       "  \n",
       "  ( 0 ,63 ,.,.) = \n",
       "   -2.9625e-02 -4.6048e-02 -2.9335e-02\n",
       "   -1.7117e-02 -8.5245e-03 -6.3627e-02\n",
       "   -6.0795e-04 -3.8655e-02 -5.9677e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -1.1132e-03  5.7948e-03  4.2810e-02\n",
       "    2.7203e-02 -5.7477e-02 -7.7810e-04\n",
       "   -4.0160e-02  4.2485e-02 -3.2760e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -7.5136e-02  5.7803e-02  8.3178e-02\n",
       "    6.8889e-02  7.6526e-02  1.4514e-02\n",
       "   -1.4545e-02  5.4843e-02  6.9157e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -2.7295e-03 -6.7250e-03 -7.6140e-02\n",
       "    4.0814e-04 -4.6041e-02  7.7700e-02\n",
       "   -8.2485e-02  1.2709e-01  7.8344e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,61 ,.,.) = \n",
       "    1.6746e-03 -4.6682e-02  8.0764e-02\n",
       "   -5.1460e-02  4.5537e-02  9.2413e-02\n",
       "   -1.2560e-02  2.7791e-02  8.0081e-02\n",
       "  \n",
       "  ( 1 ,62 ,.,.) = \n",
       "   -1.3566e-02  5.7681e-02  9.0577e-02\n",
       "    2.0130e-02  1.1442e-01  6.8678e-02\n",
       "   -2.9732e-02  7.6454e-02  4.5663e-02\n",
       "  \n",
       "  ( 1 ,63 ,.,.) = \n",
       "    3.1011e-03  2.5672e-02  6.4434e-03\n",
       "   -4.7515e-03 -2.9499e-02  2.5814e-02\n",
       "   -4.3028e-03 -3.5334e-02 -4.2668e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -2.2495e-02  9.8651e-03 -1.1563e-01\n",
       "   -8.3620e-02 -5.9890e-02 -4.3593e-02\n",
       "   -7.9746e-02 -5.1389e-02 -9.9148e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    3.5684e-02 -6.2074e-02  1.6356e-02\n",
       "    7.2532e-02  2.0299e-03  3.6652e-02\n",
       "    5.6860e-02 -2.3751e-03 -1.4656e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    1.1908e-02  2.3089e-02 -3.2215e-02\n",
       "    4.7055e-02 -8.2423e-03 -3.0892e-02\n",
       "   -4.4736e-02 -3.4660e-02 -8.7724e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,61 ,.,.) = \n",
       "    3.0726e-02  5.3788e-04 -2.7108e-02\n",
       "   -9.4455e-02  4.0178e-02 -8.3302e-02\n",
       "   -1.1031e-02 -6.1057e-02 -5.6894e-02\n",
       "  \n",
       "  ( 2 ,62 ,.,.) = \n",
       "   -3.2126e-02 -4.0667e-02 -6.8502e-02\n",
       "   -1.0358e-01 -6.1539e-02 -6.0382e-02\n",
       "   -7.8438e-02 -2.9383e-02  6.0500e-03\n",
       "  \n",
       "  ( 2 ,63 ,.,.) = \n",
       "    4.5977e-02 -4.6995e-03 -6.4747e-03\n",
       "    8.7030e-02  9.3560e-02  1.0121e-02\n",
       "   -1.0641e-02  4.3437e-02  1.0043e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "    2.7822e-02 -2.4222e-02  1.0670e-02\n",
       "    1.5207e-03  3.7362e-03  1.5564e-02\n",
       "   -5.6628e-04 -4.8951e-02  3.3616e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "   -3.4712e-02 -1.7986e-03 -2.8316e-02\n",
       "    1.7674e-02 -9.9178e-03 -3.6794e-02\n",
       "   -2.5156e-02  2.5690e-02 -2.7435e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "    8.6033e-03  3.5497e-02 -4.1306e-02\n",
       "    6.3098e-02 -8.5669e-02 -1.3938e-01\n",
       "   -4.4746e-02 -1.0126e-01 -1.3736e-01\n",
       "      ... \n",
       "  \n",
       "  (125,61 ,.,.) = \n",
       "   -8.8627e-03  3.3950e-02  5.1662e-02\n",
       "    3.9951e-02  4.4547e-02  4.8142e-02\n",
       "   -6.2856e-02 -4.7915e-03  1.3989e-02\n",
       "  \n",
       "  (125,62 ,.,.) = \n",
       "   -4.8222e-02  2.0633e-02  1.3322e-02\n",
       "   -1.9376e-03 -1.2850e-02  3.8661e-02\n",
       "    9.9045e-02 -2.7454e-02  7.4618e-03\n",
       "  \n",
       "  (125,63 ,.,.) = \n",
       "    2.9255e-04  7.1165e-03 -3.6234e-02\n",
       "    6.5641e-02 -3.5017e-02  1.7745e-02\n",
       "    1.4240e-02 -3.7635e-02  2.0462e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "   -2.6903e-02  6.1880e-03 -3.0383e-02\n",
       "   -8.2726e-02 -5.5273e-02 -3.6612e-02\n",
       "   -9.0661e-03 -4.3712e-02 -4.4920e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "   -3.3714e-04  7.9013e-02 -1.1712e-02\n",
       "   -2.4625e-02  7.6628e-02 -5.7676e-02\n",
       "    4.0775e-02  1.7425e-02  2.6416e-03\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "   -2.6441e-03  3.3710e-02 -1.0520e-01\n",
       "   -2.5920e-02 -2.0116e-02 -9.8409e-02\n",
       "   -6.2631e-02 -2.3006e-02  1.7381e-02\n",
       "      ... \n",
       "  \n",
       "  (126,61 ,.,.) = \n",
       "   -2.1942e-02 -1.6146e-01  2.8333e-02\n",
       "   -8.2192e-02 -2.3984e-02 -7.6430e-02\n",
       "   -6.4370e-02  8.2925e-03 -6.9296e-02\n",
       "  \n",
       "  (126,62 ,.,.) = \n",
       "   -6.3154e-02  3.2737e-02  4.3347e-02\n",
       "   -2.8336e-02 -9.2251e-03  5.4502e-02\n",
       "   -5.2114e-02  1.4281e-02  5.7103e-02\n",
       "  \n",
       "  (126,63 ,.,.) = \n",
       "   -1.4065e-02 -2.9803e-02 -5.7417e-02\n",
       "    5.1431e-03  9.4791e-03 -5.2849e-02\n",
       "   -8.8398e-03 -2.4129e-02  7.6527e-03\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "   -3.7042e-02 -8.7954e-02 -1.5862e-01\n",
       "   -5.8607e-02 -1.8054e-02 -8.1906e-02\n",
       "   -1.0006e-01 -4.1041e-02 -5.5230e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    5.0321e-03 -8.5448e-02 -3.5869e-04\n",
       "    4.6647e-03 -1.0789e-02 -2.7606e-03\n",
       "   -5.6699e-02 -3.1490e-02  5.1087e-03\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "   -4.1995e-02 -7.4903e-02 -1.9649e-03\n",
       "   -1.7299e-02  1.4812e-02 -1.2196e-02\n",
       "    8.3617e-03 -1.3082e-01 -7.1407e-02\n",
       "      ... \n",
       "  \n",
       "  (127,61 ,.,.) = \n",
       "   -8.6222e-02  3.4274e-02 -5.6227e-02\n",
       "   -5.3167e-02 -5.6043e-02 -3.4334e-02\n",
       "   -1.5777e-02  1.1611e-02 -1.5569e-02\n",
       "  \n",
       "  (127,62 ,.,.) = \n",
       "   -5.5913e-02 -1.8492e-02 -7.3038e-03\n",
       "   -9.1130e-02 -5.9534e-02 -7.4893e-02\n",
       "   -7.1888e-02 -1.0713e-01 -8.7400e-02\n",
       "  \n",
       "  (127,63 ,.,.) = \n",
       "    2.9135e-03 -2.2537e-02 -4.5684e-02\n",
       "   -5.8713e-02  3.4875e-02 -1.6813e-02\n",
       "   -1.7953e-03 -2.8137e-02 -5.7064e-02\n",
       "  [torch.cuda.FloatTensor of size 128x64x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7500\n",
       "   0.6805\n",
       "   0.7458\n",
       "   0.7662\n",
       "   0.7591\n",
       "   0.7666\n",
       "   0.8926\n",
       "   0.7276\n",
       "   0.7574\n",
       "   0.7585\n",
       "   0.9293\n",
       "   0.8145\n",
       "   0.6722\n",
       "   0.6285\n",
       "   0.6898\n",
       "   0.9042\n",
       "   0.7836\n",
       "   0.7583\n",
       "   0.9265\n",
       "   0.8533\n",
       "   1.1043\n",
       "   0.9039\n",
       "   0.7469\n",
       "   0.7256\n",
       "   0.7759\n",
       "   0.7774\n",
       "   0.7600\n",
       "   0.7739\n",
       "   0.8257\n",
       "   0.7139\n",
       "   0.8300\n",
       "   0.8275\n",
       "   0.8286\n",
       "   0.7354\n",
       "   0.7494\n",
       "   0.7220\n",
       "   0.8042\n",
       "   0.8388\n",
       "   0.7341\n",
       "   0.7938\n",
       "   0.6816\n",
       "   0.7568\n",
       "   0.8344\n",
       "   0.7434\n",
       "   0.7647\n",
       "   0.6677\n",
       "   0.8043\n",
       "   0.7107\n",
       "   0.7914\n",
       "   0.6491\n",
       "   0.9087\n",
       "   0.7376\n",
       "   0.7311\n",
       "   0.6991\n",
       "   0.6997\n",
       "   0.7397\n",
       "   0.6668\n",
       "   0.7951\n",
       "   0.8229\n",
       "   0.8299\n",
       "   0.8640\n",
       "   0.8924\n",
       "   0.7733\n",
       "   0.8004\n",
       "   0.6739\n",
       "   0.8852\n",
       "   0.8354\n",
       "   0.8704\n",
       "   0.7593\n",
       "   0.9607\n",
       "   0.6227\n",
       "   0.8167\n",
       "   0.7151\n",
       "   0.7267\n",
       "   0.9528\n",
       "   0.7620\n",
       "   0.7160\n",
       "   0.7236\n",
       "   0.7801\n",
       "   0.7372\n",
       "   0.7386\n",
       "   0.7976\n",
       "   0.8548\n",
       "   0.7281\n",
       "   0.6900\n",
       "   0.6575\n",
       "   0.8429\n",
       "   0.6811\n",
       "   0.8123\n",
       "   0.7278\n",
       "   0.6710\n",
       "   0.8537\n",
       "   0.7303\n",
       "   0.7854\n",
       "   0.7871\n",
       "   0.7828\n",
       "   0.8953\n",
       "   0.8358\n",
       "   0.7190\n",
       "   0.8151\n",
       "   0.8659\n",
       "   0.6711\n",
       "   0.7699\n",
       "   0.7483\n",
       "   0.7303\n",
       "   0.6467\n",
       "   0.6932\n",
       "   0.8633\n",
       "   0.7812\n",
       "   0.7629\n",
       "   0.7073\n",
       "   0.7893\n",
       "   0.8545\n",
       "   0.8006\n",
       "   0.7942\n",
       "   0.8397\n",
       "   0.6976\n",
       "   0.7686\n",
       "   0.7564\n",
       "   0.8133\n",
       "   0.7720\n",
       "   0.8165\n",
       "   0.7695\n",
       "   0.9207\n",
       "   0.7987\n",
       "   0.7908\n",
       "   0.8167\n",
       "   0.7349\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.0215\n",
       "  -0.2769\n",
       "  -0.0207\n",
       "   0.0730\n",
       "  -0.0395\n",
       "  -0.2222\n",
       "   0.1469\n",
       "  -0.0230\n",
       "   0.0021\n",
       "  -0.0161\n",
       "   0.1500\n",
       "  -0.0979\n",
       "  -0.1260\n",
       "  -0.1657\n",
       "  -0.1637\n",
       "   0.1233\n",
       "  -0.1006\n",
       "  -0.2900\n",
       "   0.1467\n",
       "   0.1075\n",
       "   0.1991\n",
       "   0.0093\n",
       "  -0.0146\n",
       "  -0.2570\n",
       "   0.0327\n",
       "   0.0138\n",
       "  -0.0512\n",
       "  -0.0868\n",
       "   0.1102\n",
       "  -0.1219\n",
       "   0.0641\n",
       "   0.1166\n",
       "  -0.0796\n",
       "   0.0054\n",
       "   0.0929\n",
       "  -0.1144\n",
       "   0.1103\n",
       "   0.1073\n",
       "  -0.1156\n",
       "   0.0958\n",
       "  -0.0369\n",
       "  -0.0781\n",
       "   0.1056\n",
       "  -0.0637\n",
       "  -0.0061\n",
       "  -0.0261\n",
       "  -0.0409\n",
       "  -0.0886\n",
       "   0.0079\n",
       "  -0.1701\n",
       "   0.0056\n",
       "  -0.0043\n",
       "  -0.0812\n",
       "  -0.0908\n",
       "  -0.1092\n",
       "  -0.0867\n",
       "  -0.2049\n",
       "  -0.1108\n",
       "   0.0718\n",
       "   0.0159\n",
       "  -0.2003\n",
       "   0.2059\n",
       "  -0.1577\n",
       "   0.0561\n",
       "  -0.1999\n",
       "   0.0759\n",
       "  -0.2441\n",
       "   0.1337\n",
       "  -0.2077\n",
       "   0.1050\n",
       "  -0.1584\n",
       "  -0.0031\n",
       "  -0.0363\n",
       "  -0.1579\n",
       "   0.1567\n",
       "  -0.0340\n",
       "  -0.0590\n",
       "  -0.1290\n",
       "  -0.0399\n",
       "  -0.0721\n",
       "  -0.0398\n",
       "   0.0305\n",
       "  -0.0109\n",
       "   0.0208\n",
       "  -0.2289\n",
       "  -0.1647\n",
       "  -0.0555\n",
       "  -0.1615\n",
       "  -0.0081\n",
       "  -0.0046\n",
       "   0.0954\n",
       "   0.1613\n",
       "  -0.1791\n",
       "  -0.0094\n",
       "   0.0326\n",
       "   0.0074\n",
       "   0.1712\n",
       "  -0.0401\n",
       "  -0.1086\n",
       "   0.1363\n",
       "  -0.0913\n",
       "  -0.1003\n",
       "   0.0455\n",
       "  -0.0600\n",
       "  -0.0602\n",
       "  -0.2894\n",
       "  -0.2715\n",
       "   0.0511\n",
       "  -0.0619\n",
       "   0.0618\n",
       "  -0.0310\n",
       "   0.0465\n",
       "   0.1143\n",
       "  -0.1356\n",
       "   0.0553\n",
       "   0.0678\n",
       "  -0.1968\n",
       "  -0.0439\n",
       "  -0.2082\n",
       "  -0.0163\n",
       "  -0.1172\n",
       "  -0.1374\n",
       "  -0.0223\n",
       "  -0.0397\n",
       "   0.0399\n",
       "  -0.0043\n",
       "   0.0749\n",
       "  -0.0067\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -4.9762e-02 -3.2356e-02 -2.7774e-02\n",
       "   -7.9433e-02  4.1032e-02 -6.4911e-02\n",
       "   -4.4963e-02  5.3650e-02  1.2949e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    8.2878e-03 -2.1858e-02  5.1359e-03\n",
       "    1.6062e-02 -5.6337e-03 -6.1725e-02\n",
       "    6.3209e-02 -2.9361e-03  2.8633e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.5446e-02  2.4101e-02 -3.8664e-02\n",
       "   -4.7482e-02 -3.9150e-02 -6.0605e-03\n",
       "   -6.1066e-03  1.2328e-02  4.8593e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "    2.6320e-02  5.9752e-02  5.9567e-02\n",
       "    6.7301e-03  8.1031e-02  1.0996e-01\n",
       "    3.5628e-02  9.1065e-02  2.0439e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "    3.1532e-02  4.8190e-02  2.3969e-02\n",
       "    2.8029e-02  3.5355e-03  1.1523e-02\n",
       "    2.7686e-02  1.1334e-01  2.0923e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "    2.3564e-02  6.3477e-02 -2.9334e-02\n",
       "    5.1894e-02 -4.2206e-04  5.2801e-02\n",
       "   -2.2055e-02  1.0788e-02 -5.7642e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -5.6014e-02 -6.7216e-02  7.3159e-02\n",
       "    3.5847e-03 -4.1853e-02  3.0995e-03\n",
       "    2.2291e-02 -5.9332e-03 -4.5289e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    3.7430e-02  9.2632e-03  3.1893e-02\n",
       "   -1.7250e-03  3.6063e-02  4.4341e-02\n",
       "    7.0607e-02  5.7458e-02  1.4029e-01\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -2.6424e-02 -3.5955e-02 -8.3182e-03\n",
       "   -5.2020e-02 -3.7939e-02 -1.5795e-02\n",
       "    2.1988e-03 -9.1059e-03 -8.6933e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    4.3819e-02  4.1082e-02  1.2153e-03\n",
       "    3.1294e-02  9.6636e-02  4.3540e-03\n",
       "    4.8370e-03  5.2135e-02  3.5830e-02\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    8.4712e-02 -1.9451e-02 -5.2212e-02\n",
       "    2.6038e-02 -2.3922e-03  3.8493e-02\n",
       "    8.6351e-02  1.3331e-02  4.1029e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "    7.4669e-02  3.1144e-02  3.1893e-02\n",
       "    2.3319e-02  5.1475e-03  2.5624e-02\n",
       "    2.2100e-02  4.9425e-02 -1.9401e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    7.2712e-03 -2.5171e-02 -7.2193e-03\n",
       "   -1.2841e-02 -2.7089e-02 -1.8066e-02\n",
       "    9.1191e-03  2.0624e-02 -4.9667e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -4.4340e-02 -5.1163e-02 -5.5621e-02\n",
       "   -7.7897e-03 -2.9511e-03  1.4785e-02\n",
       "   -1.7409e-02 -4.0625e-02  4.3092e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    1.0168e-02 -2.6319e-02  9.4101e-03\n",
       "    3.8056e-02  3.2840e-02 -3.1765e-02\n",
       "   -3.7124e-02 -1.7899e-03 -2.4250e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    6.4558e-02  6.5961e-02  1.0103e-01\n",
       "    7.3850e-03 -1.3287e-02  2.6434e-03\n",
       "    3.2092e-02 -5.8869e-02 -4.8279e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    9.0109e-02 -4.6624e-02  3.6424e-02\n",
       "   -2.1990e-02  5.6811e-02  1.0912e-02\n",
       "    9.7591e-03  2.5578e-02  3.3430e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -8.4707e-03  7.4367e-03  1.2264e-02\n",
       "    1.8305e-02  1.2044e-02 -1.0781e-02\n",
       "   -1.0481e-02  2.2815e-02 -6.0693e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -3.8564e-02  8.9923e-02  2.5920e-02\n",
       "   -1.6846e-02 -2.6029e-02  9.1635e-02\n",
       "   -5.1073e-02 -9.0535e-03  1.2009e-01\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "    1.1039e-01  7.1281e-02  2.5616e-02\n",
       "    2.9056e-02 -8.0369e-03 -1.3447e-02\n",
       "   -8.7707e-03  8.2050e-03 -1.9510e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "   -4.7932e-03  3.7036e-02 -1.7252e-02\n",
       "   -2.6554e-02  3.7160e-02  5.4015e-02\n",
       "    3.9855e-02 -3.3226e-02 -2.0461e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    9.4192e-02  7.4540e-02 -5.4620e-02\n",
       "    1.6859e-02  1.6182e-02 -1.1577e-02\n",
       "    4.8879e-02 -2.7301e-02 -7.0607e-02\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "   -1.3322e-03 -2.8478e-03 -2.2102e-02\n",
       "   -9.0151e-02 -1.0122e-02  1.0119e-02\n",
       "   -4.2961e-02  4.4538e-02  1.4722e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "   -1.3116e-02  5.9286e-03  1.0437e-02\n",
       "   -4.9811e-02 -1.3607e-02 -2.6281e-02\n",
       "   -2.0577e-02 -1.5454e-02 -3.7631e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "    4.0567e-02 -4.5178e-02  1.9200e-02\n",
       "    2.9210e-02 -1.7458e-02 -1.2535e-02\n",
       "   -4.2315e-02  2.6279e-02 -4.1907e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "    5.0335e-02  9.0534e-03  6.4830e-02\n",
       "    3.9664e-02 -1.7550e-02 -1.4419e-02\n",
       "    2.6252e-02  3.3662e-02  2.4664e-02\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "    1.8353e-02 -4.0840e-02  4.0466e-03\n",
       "   -5.9984e-03  4.3251e-02 -3.2353e-02\n",
       "    3.5333e-02  1.2078e-02 -4.9420e-02\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "    7.6654e-02  4.6372e-02  2.0467e-03\n",
       "    1.4635e-03 -1.8891e-03  1.6198e-02\n",
       "   -1.7919e-02  3.0772e-02 -8.6657e-03\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "   -4.7566e-02  1.8538e-02  4.7868e-02\n",
       "    4.4790e-02  5.7733e-02 -4.5933e-02\n",
       "    4.9363e-03 -4.9657e-02  3.1905e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "   -7.6594e-03  2.4830e-02 -3.4239e-02\n",
       "   -1.9763e-03  5.3811e-02 -2.2559e-02\n",
       "    7.2436e-02 -1.8708e-02 -1.3054e-02\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "    1.2530e-02  4.5344e-02  1.2185e-02\n",
       "    4.7997e-02  4.9818e-02  5.9739e-02\n",
       "    4.3015e-02  1.4774e-02  4.6983e-03\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    4.9754e-02  1.1779e-01  8.7261e-02\n",
       "    8.1166e-02  7.8658e-02  4.1789e-02\n",
       "    3.2146e-02  1.5321e-02  6.2928e-02\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "   -3.7063e-03  5.9800e-02  2.1939e-02\n",
       "   -8.2328e-02  7.1382e-02  5.2988e-02\n",
       "   -4.3140e-02 -2.8450e-02 -6.6498e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "    4.2946e-02  7.3559e-03 -2.9124e-02\n",
       "   -1.7450e-02 -1.5010e-02  9.0615e-03\n",
       "    5.7514e-02  2.1788e-02 -7.8921e-02\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    1.5322e-02  1.2649e-01  1.7635e-01\n",
       "   -8.2646e-03  6.9940e-02  1.3574e-01\n",
       "    2.4129e-02  2.4371e-02 -1.1837e-02\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "   -2.8690e-02 -4.6443e-02  7.2110e-03\n",
       "    3.1435e-02 -3.7245e-02 -7.0183e-02\n",
       "    1.0707e-02 -6.9340e-03 -5.0857e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7014\n",
       "   0.5219\n",
       "   0.9363\n",
       "   0.5418\n",
       "   0.6474\n",
       "   0.9158\n",
       "   0.7928\n",
       "   0.6950\n",
       "   0.7664\n",
       "   0.8651\n",
       "   0.9364\n",
       "   0.8112\n",
       "   0.8514\n",
       "   0.7808\n",
       "   0.9369\n",
       "   0.7675\n",
       "   0.7861\n",
       "   0.5476\n",
       "   0.8148\n",
       "   0.6575\n",
       "   0.7542\n",
       "   0.7270\n",
       "   0.8005\n",
       "   0.7670\n",
       "   0.6978\n",
       "   0.7289\n",
       "   0.7122\n",
       "   0.8483\n",
       "   0.7631\n",
       "   0.7865\n",
       "   0.6120\n",
       "   0.7508\n",
       "   0.8462\n",
       "   0.6603\n",
       "   0.7158\n",
       "   0.7865\n",
       "   0.8281\n",
       "   0.6084\n",
       "   0.8252\n",
       "   0.8100\n",
       "   0.7497\n",
       "   0.6785\n",
       "   0.6117\n",
       "   0.7756\n",
       "   0.8069\n",
       "   0.7397\n",
       "   0.6793\n",
       "   0.6071\n",
       "   0.7174\n",
       "   0.6935\n",
       "   0.7967\n",
       "   0.7790\n",
       "   0.6600\n",
       "   0.7293\n",
       "   0.7440\n",
       "   0.6586\n",
       "   0.8184\n",
       "   0.8248\n",
       "   0.6242\n",
       "   0.8305\n",
       "   0.7345\n",
       "   0.7007\n",
       "   0.8036\n",
       "   0.7551\n",
       "   0.7930\n",
       "   0.8226\n",
       "   0.6609\n",
       "   0.7308\n",
       "   0.8276\n",
       "   0.8757\n",
       "   0.7818\n",
       "   0.7777\n",
       "   0.8806\n",
       "   0.8694\n",
       "   0.6787\n",
       "   0.8287\n",
       "   0.8434\n",
       "   0.6926\n",
       "   0.6627\n",
       "   0.6917\n",
       "   0.5481\n",
       "   0.8776\n",
       "   0.8922\n",
       "   0.6324\n",
       "   0.6833\n",
       "   0.2347\n",
       "   0.8007\n",
       "   0.8363\n",
       "   0.7588\n",
       "   0.8209\n",
       "   0.6089\n",
       "   0.7234\n",
       "   0.7027\n",
       "   0.7454\n",
       "   0.8131\n",
       "   0.8857\n",
       "   0.7402\n",
       "   0.7254\n",
       "   0.8243\n",
       "   0.6438\n",
       "   0.7233\n",
       "   0.8138\n",
       "   0.7380\n",
       "   0.7519\n",
       "   0.7863\n",
       "   0.7606\n",
       "   0.9127\n",
       "   0.6567\n",
       "   0.7921\n",
       "   0.7868\n",
       "   0.7389\n",
       "   0.7521\n",
       "   0.8598\n",
       "   0.7746\n",
       "   0.7048\n",
       "   0.7669\n",
       "   0.7783\n",
       "   0.5722\n",
       "   0.7431\n",
       "   0.7991\n",
       "   0.8260\n",
       "   0.7544\n",
       "   0.8252\n",
       "   0.6761\n",
       "   0.7489\n",
       "   0.9361\n",
       "   0.7650\n",
       "   0.4710\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.1294\n",
       "  -0.3478\n",
       "   0.0073\n",
       "  -0.0872\n",
       "  -0.2801\n",
       "  -0.0751\n",
       "   0.1905\n",
       "  -0.2400\n",
       "  -0.0613\n",
       "   0.0208\n",
       "  -0.3425\n",
       "   0.0748\n",
       "   0.2051\n",
       "  -0.0001\n",
       "  -0.2073\n",
       "   0.0716\n",
       "  -0.1324\n",
       "  -0.1399\n",
       "   0.0738\n",
       "   0.0113\n",
       "  -0.1201\n",
       "  -0.0140\n",
       "  -0.2271\n",
       "   0.0792\n",
       "  -0.0256\n",
       "  -0.0246\n",
       "  -0.0218\n",
       "   0.1530\n",
       "   0.2385\n",
       "  -0.0077\n",
       "  -0.1758\n",
       "  -0.0434\n",
       "  -0.1699\n",
       "  -0.2149\n",
       "   0.0082\n",
       "   0.0390\n",
       "   0.0774\n",
       "  -0.1091\n",
       "   0.1170\n",
       "   0.1061\n",
       "  -0.0681\n",
       "  -0.2003\n",
       "  -0.1843\n",
       "  -0.0471\n",
       "   0.0103\n",
       "   0.0656\n",
       "  -0.0233\n",
       "  -0.0707\n",
       "  -0.1664\n",
       "  -0.1442\n",
       "   0.0332\n",
       "   0.0468\n",
       "  -0.1822\n",
       "  -0.2417\n",
       "   0.0602\n",
       "  -0.3925\n",
       "  -0.0175\n",
       "   0.2426\n",
       "  -0.1334\n",
       "   0.0183\n",
       "  -0.0245\n",
       "  -0.1011\n",
       "  -0.0001\n",
       "  -0.0341\n",
       "  -0.1518\n",
       "   0.1660\n",
       "   0.1347\n",
       "  -0.2344\n",
       "  -0.0270\n",
       "  -0.0270\n",
       "  -0.0067\n",
       "  -0.3043\n",
       "   0.0415\n",
       "   0.3708\n",
       "  -0.0393\n",
       "  -0.0021\n",
       "   0.1681\n",
       "   0.2999\n",
       "  -0.2455\n",
       "   0.0197\n",
       "  -0.2321\n",
       "   0.1508\n",
       "  -0.1148\n",
       "  -0.3047\n",
       "  -0.2169\n",
       "  -0.1884\n",
       "  -0.0093\n",
       "   0.2029\n",
       "  -0.2138\n",
       "   0.0212\n",
       "   0.2021\n",
       "  -0.0291\n",
       "  -0.1209\n",
       "  -0.0458\n",
       "  -0.0185\n",
       "  -0.0180\n",
       "  -0.0688\n",
       "  -0.2953\n",
       "  -0.2307\n",
       "   0.0182\n",
       "  -0.2787\n",
       "  -0.0555\n",
       "  -0.0829\n",
       "  -0.0491\n",
       "  -0.0496\n",
       "  -0.0664\n",
       "  -0.1087\n",
       "  -0.2182\n",
       "  -0.1038\n",
       "   0.0439\n",
       "  -0.1271\n",
       "  -0.2784\n",
       "  -0.0205\n",
       "   0.0868\n",
       "  -0.1371\n",
       "   0.0316\n",
       "   0.0322\n",
       "  -0.0305\n",
       "  -0.0893\n",
       "   0.0220\n",
       "  -0.0230\n",
       "  -0.1193\n",
       "   0.1843\n",
       "  -0.1482\n",
       "  -0.0868\n",
       "  -0.0683\n",
       "  -0.1714\n",
       "  -0.2282\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    2.2787e-01\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    1.8474e-01\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    1.5403e-01\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,61 ,.,.) = \n",
       "   -1.5745e-01\n",
       "  \n",
       "  ( 0 ,62 ,.,.) = \n",
       "    3.6086e-01\n",
       "  \n",
       "  ( 0 ,63 ,.,.) = \n",
       "   -4.1671e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    1.7438e-01\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -1.8308e-01\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    3.9219e-01\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,61 ,.,.) = \n",
       "    1.4129e-01\n",
       "  \n",
       "  ( 1 ,62 ,.,.) = \n",
       "   -4.8861e-03\n",
       "  \n",
       "  ( 1 ,63 ,.,.) = \n",
       "   -1.4428e-01\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.3744e-01\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    5.3195e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    1.8022e-01\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,61 ,.,.) = \n",
       "   -7.8900e-02\n",
       "  \n",
       "  ( 2 ,62 ,.,.) = \n",
       "   -2.5960e-01\n",
       "  \n",
       "  ( 2 ,63 ,.,.) = \n",
       "    1.7088e-01\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -7.1122e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "   -1.0913e-03\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "    8.0304e-02\n",
       "      ... \n",
       "  \n",
       "  (125,61 ,.,.) = \n",
       "   -7.8181e-02\n",
       "  \n",
       "  (125,62 ,.,.) = \n",
       "   -2.3566e-01\n",
       "  \n",
       "  (125,63 ,.,.) = \n",
       "   -1.5291e-05\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "   -4.9192e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "   -1.3748e-01\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "   -6.4558e-02\n",
       "      ... \n",
       "  \n",
       "  (126,61 ,.,.) = \n",
       "    4.1185e-04\n",
       "  \n",
       "  (126,62 ,.,.) = \n",
       "   -9.7835e-02\n",
       "  \n",
       "  (126,63 ,.,.) = \n",
       "   -1.1637e-01\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "    1.4160e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    1.4975e-01\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "    3.8412e-02\n",
       "      ... \n",
       "  \n",
       "  (127,61 ,.,.) = \n",
       "   -9.8536e-02\n",
       "  \n",
       "  (127,62 ,.,.) = \n",
       "    1.3690e-01\n",
       "  \n",
       "  (127,63 ,.,.) = \n",
       "   -1.1252e-01\n",
       "  [torch.cuda.FloatTensor of size 128x64x1x1 (GPU 0)], Parameter containing:\n",
       "   0.6719\n",
       "   0.6652\n",
       "   0.9169\n",
       "   0.5677\n",
       "   0.6808\n",
       "   0.7453\n",
       "   0.9865\n",
       "   0.6718\n",
       "   0.7674\n",
       "   0.9812\n",
       "   0.8172\n",
       "   0.8954\n",
       "   0.8637\n",
       "   0.7930\n",
       "   0.8605\n",
       "   0.8048\n",
       "   0.6190\n",
       "   0.4633\n",
       "   0.7757\n",
       "   0.8686\n",
       "   0.8986\n",
       "   0.8223\n",
       "   0.8735\n",
       "   0.9614\n",
       "   0.8713\n",
       "   0.8951\n",
       "   0.9051\n",
       "   0.9412\n",
       "   0.9760\n",
       "   0.7782\n",
       "   0.5102\n",
       "   0.8610\n",
       "   0.9490\n",
       "   0.9196\n",
       "   0.9120\n",
       "   0.8777\n",
       "   0.7823\n",
       "   0.6679\n",
       "   0.8512\n",
       "   0.9825\n",
       "   0.9046\n",
       "   0.6497\n",
       "   0.4384\n",
       "   0.7737\n",
       "   0.8579\n",
       "   0.9766\n",
       "   1.2072\n",
       "   0.6344\n",
       "   0.6936\n",
       "   0.8030\n",
       "   0.7919\n",
       "   0.8660\n",
       "   0.6406\n",
       "   0.7610\n",
       "   1.2811\n",
       "   0.9172\n",
       "   0.8390\n",
       "   0.7903\n",
       "   0.6199\n",
       "   0.8263\n",
       "   0.8328\n",
       "   1.0485\n",
       "   0.8352\n",
       "   0.8602\n",
       "   0.9078\n",
       "   0.8309\n",
       "   1.1417\n",
       "   0.6606\n",
       "   0.8271\n",
       "   0.8280\n",
       "   0.8298\n",
       "   0.8295\n",
       "   0.7712\n",
       "   1.1704\n",
       "   0.9482\n",
       "   0.8313\n",
       "   0.6722\n",
       "   0.8912\n",
       "   0.8889\n",
       "   0.8919\n",
       "   0.4525\n",
       "   0.8984\n",
       "   1.0760\n",
       "   0.8116\n",
       "   0.9403\n",
       "   0.5295\n",
       "   0.8271\n",
       "   0.8487\n",
       "   0.5998\n",
       "   0.9027\n",
       "   1.1585\n",
       "   0.7538\n",
       "   0.8316\n",
       "   0.8910\n",
       "   1.2616\n",
       "   0.8256\n",
       "   0.8057\n",
       "   0.8509\n",
       "   0.8384\n",
       "   1.1297\n",
       "   0.5857\n",
       "   0.8663\n",
       "   0.7970\n",
       "   0.8372\n",
       "   0.7295\n",
       "   0.8743\n",
       "   0.7883\n",
       "   0.7276\n",
       "   0.6905\n",
       "   0.8990\n",
       "   0.7686\n",
       "   0.7163\n",
       "   0.9584\n",
       "   0.8213\n",
       "   0.7093\n",
       "   0.8408\n",
       "   0.8404\n",
       "   0.7411\n",
       "   0.9843\n",
       "   0.7732\n",
       "   0.8062\n",
       "   0.8132\n",
       "   0.8756\n",
       "   0.7070\n",
       "   1.0146\n",
       "   0.7118\n",
       "   0.8049\n",
       "   0.5236\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.1294\n",
       "  -0.3478\n",
       "   0.0073\n",
       "  -0.0872\n",
       "  -0.2801\n",
       "  -0.0751\n",
       "   0.1905\n",
       "  -0.2400\n",
       "  -0.0613\n",
       "   0.0208\n",
       "  -0.3425\n",
       "   0.0748\n",
       "   0.2051\n",
       "  -0.0001\n",
       "  -0.2073\n",
       "   0.0716\n",
       "  -0.1324\n",
       "  -0.1399\n",
       "   0.0738\n",
       "   0.0113\n",
       "  -0.1201\n",
       "  -0.0140\n",
       "  -0.2271\n",
       "   0.0792\n",
       "  -0.0256\n",
       "  -0.0246\n",
       "  -0.0218\n",
       "   0.1530\n",
       "   0.2385\n",
       "  -0.0077\n",
       "  -0.1758\n",
       "  -0.0434\n",
       "  -0.1699\n",
       "  -0.2149\n",
       "   0.0082\n",
       "   0.0390\n",
       "   0.0774\n",
       "  -0.1091\n",
       "   0.1170\n",
       "   0.1061\n",
       "  -0.0681\n",
       "  -0.2003\n",
       "  -0.1843\n",
       "  -0.0471\n",
       "   0.0103\n",
       "   0.0656\n",
       "  -0.0233\n",
       "  -0.0707\n",
       "  -0.1664\n",
       "  -0.1442\n",
       "   0.0332\n",
       "   0.0468\n",
       "  -0.1822\n",
       "  -0.2417\n",
       "   0.0602\n",
       "  -0.3925\n",
       "  -0.0175\n",
       "   0.2426\n",
       "  -0.1334\n",
       "   0.0183\n",
       "  -0.0245\n",
       "  -0.1011\n",
       "  -0.0001\n",
       "  -0.0341\n",
       "  -0.1518\n",
       "   0.1660\n",
       "   0.1347\n",
       "  -0.2344\n",
       "  -0.0270\n",
       "  -0.0270\n",
       "  -0.0067\n",
       "  -0.3043\n",
       "   0.0415\n",
       "   0.3708\n",
       "  -0.0393\n",
       "  -0.0021\n",
       "   0.1681\n",
       "   0.2999\n",
       "  -0.2455\n",
       "   0.0197\n",
       "  -0.2321\n",
       "   0.1508\n",
       "  -0.1148\n",
       "  -0.3047\n",
       "  -0.2169\n",
       "  -0.1884\n",
       "  -0.0093\n",
       "   0.2029\n",
       "  -0.2138\n",
       "   0.0212\n",
       "   0.2021\n",
       "  -0.0291\n",
       "  -0.1209\n",
       "  -0.0458\n",
       "  -0.0185\n",
       "  -0.0180\n",
       "  -0.0688\n",
       "  -0.2953\n",
       "  -0.2307\n",
       "   0.0182\n",
       "  -0.2787\n",
       "  -0.0555\n",
       "  -0.0829\n",
       "  -0.0491\n",
       "  -0.0496\n",
       "  -0.0664\n",
       "  -0.1087\n",
       "  -0.2182\n",
       "  -0.1038\n",
       "   0.0439\n",
       "  -0.1271\n",
       "  -0.2784\n",
       "  -0.0205\n",
       "   0.0868\n",
       "  -0.1371\n",
       "   0.0316\n",
       "   0.0322\n",
       "  -0.0305\n",
       "  -0.0893\n",
       "   0.0220\n",
       "  -0.0230\n",
       "  -0.1193\n",
       "   0.1843\n",
       "  -0.1482\n",
       "  -0.0868\n",
       "  -0.0683\n",
       "  -0.1714\n",
       "  -0.2282\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.0961e-02 -6.4577e-02 -1.2323e-02\n",
       "   -7.8008e-02 -6.3341e-02 -8.1517e-02\n",
       "   -6.3767e-02 -1.9321e-02  1.4942e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    6.9545e-02  3.7999e-02  1.1383e-02\n",
       "   -4.0938e-02 -1.0056e-01  1.2787e-02\n",
       "   -8.6929e-02 -1.6484e-01 -4.0839e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -6.6723e-03 -1.6785e-02  2.6667e-02\n",
       "   -7.0896e-03 -8.5883e-03  5.6368e-02\n",
       "    6.0683e-02 -1.5339e-03  9.1607e-04\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "    4.3815e-02  2.0735e-02 -3.0055e-02\n",
       "   -1.9149e-03 -2.4665e-02 -1.5576e-02\n",
       "   -1.4192e-02  7.4605e-02  1.3520e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "    2.4041e-02 -3.7392e-02  1.4801e-02\n",
       "    4.9578e-02 -6.2877e-03 -1.3968e-02\n",
       "   -2.3344e-02 -3.9312e-02 -1.8950e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "   -2.1611e-02  5.5536e-02  4.3716e-02\n",
       "    2.3467e-02 -5.2036e-03  6.1618e-03\n",
       "   -7.4358e-02 -1.5357e-02  1.2890e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    6.4331e-02  3.7952e-02  1.0099e-02\n",
       "    1.2509e-01  8.4423e-02  3.1186e-02\n",
       "    1.3245e-01  4.7675e-02  2.5138e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    6.3675e-02  5.6757e-02  5.1551e-02\n",
       "    1.7936e-02  3.9246e-03  2.7642e-02\n",
       "    5.6481e-02 -2.1763e-02 -4.7824e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    4.8688e-04 -5.8018e-03  5.3926e-02\n",
       "   -5.8517e-02 -1.9299e-02 -4.5408e-02\n",
       "   -1.9432e-02  3.3544e-02 -2.6092e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    3.8425e-02  4.8022e-02 -1.8121e-02\n",
       "    1.7673e-02  2.6256e-02  3.1859e-02\n",
       "    3.9102e-02  4.7797e-02 -7.8728e-03\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    5.4401e-02 -7.2254e-03  6.0835e-02\n",
       "    2.4445e-02  2.7095e-03  2.2086e-02\n",
       "    2.4431e-02  4.9503e-02  4.4811e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "    1.2996e-01  7.3203e-02 -3.6633e-02\n",
       "    9.5811e-02  1.0051e-01  6.4767e-02\n",
       "    8.4825e-02  1.1197e-01  7.4622e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -7.6113e-02 -1.9008e-02 -8.4492e-03\n",
       "   -8.2712e-03 -3.9690e-02 -6.6812e-02\n",
       "   -1.5761e-02 -6.0140e-02 -3.4907e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -3.3829e-02 -1.6331e-02  8.6715e-03\n",
       "   -8.0548e-03  2.5164e-02  3.8135e-02\n",
       "   -6.5356e-04 -4.1530e-02 -3.9914e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.6653e-02  1.9654e-02  1.0275e-01\n",
       "    2.4927e-02 -2.0450e-03  3.5777e-02\n",
       "    7.2803e-02  2.4480e-02  7.6718e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    3.9444e-03  5.0088e-02 -1.9375e-02\n",
       "   -8.6849e-03 -6.3166e-03 -4.3170e-02\n",
       "   -7.9922e-02  1.2909e-02  4.1198e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    4.6953e-03 -9.9699e-03 -5.9731e-02\n",
       "   -3.2031e-02  2.0783e-02  1.7366e-02\n",
       "   -1.0756e-01  9.7775e-03 -3.6370e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "    2.0676e-02 -5.6562e-03  7.4845e-02\n",
       "    2.7554e-03 -5.5328e-02  6.2058e-02\n",
       "   -5.4628e-02 -4.7665e-02  8.6567e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -5.3425e-02 -1.8824e-02 -3.3817e-03\n",
       "   -2.2431e-02 -2.9088e-02 -8.5129e-02\n",
       "   -1.1463e-01 -1.2683e-01  1.8665e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "   -6.0521e-02 -4.8844e-02 -1.1929e-03\n",
       "   -6.8801e-02 -3.4484e-02 -6.6601e-02\n",
       "   -4.3765e-02 -6.2564e-02 -1.4160e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "   -1.6204e-02 -1.9330e-02 -2.9430e-02\n",
       "    2.8263e-02  1.5055e-02  3.2835e-02\n",
       "   -4.4255e-02  8.0358e-03 -6.2661e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    5.1229e-03  1.0315e-01  1.8472e-02\n",
       "   -5.6607e-02 -2.8802e-02 -5.7014e-02\n",
       "    2.2985e-02  1.5350e-02 -8.9121e-03\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "    4.3189e-02  2.4613e-02  3.3070e-02\n",
       "    6.0755e-03  1.1967e-02  4.3919e-02\n",
       "   -5.1546e-02  3.6873e-02 -1.2191e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "   -4.9293e-02 -6.9069e-02 -4.0191e-02\n",
       "   -4.3620e-02 -3.3091e-02 -5.9742e-02\n",
       "    3.3139e-02 -1.4517e-02 -5.8211e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "    2.0858e-02  2.4952e-02  3.8124e-03\n",
       "    6.0791e-02 -1.7908e-02 -7.3853e-02\n",
       "   -4.2198e-02 -6.7115e-02 -6.0098e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "   -5.0321e-02  3.1707e-02 -6.0578e-03\n",
       "   -3.1759e-02 -2.1343e-02 -7.4463e-02\n",
       "    5.1511e-02 -3.0425e-02 -1.2466e-01\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "    2.9322e-02  3.7553e-03  1.9084e-02\n",
       "    1.2839e-02 -1.3700e-02  2.9261e-02\n",
       "   -2.1674e-04 -1.8462e-02  1.4488e-02\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "    2.5601e-02  3.9316e-02  9.0485e-03\n",
       "    1.0250e-02 -3.8732e-04  2.5603e-02\n",
       "    9.2959e-02  2.8393e-02 -5.4359e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "   -6.8265e-03 -6.1786e-03 -2.9882e-02\n",
       "   -1.2116e-02  3.0505e-02 -2.1729e-02\n",
       "   -1.6528e-02 -1.7440e-02  1.5117e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "    4.4729e-02 -1.5319e-02 -3.0410e-02\n",
       "   -2.7783e-02 -6.5032e-02  3.4627e-03\n",
       "   -1.1457e-01  2.8645e-02  6.6604e-02\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "   -8.1296e-02 -7.7778e-02 -3.8113e-02\n",
       "   -5.5831e-02 -1.2894e-01 -8.2788e-02\n",
       "   -7.5695e-02 -1.0194e-01 -7.9912e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    7.0251e-03 -4.7726e-02 -4.5076e-02\n",
       "    4.3951e-03  2.1323e-02  8.7090e-03\n",
       "   -2.8777e-02 -1.4559e-02 -5.1083e-02\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "   -9.9980e-03  2.1732e-02 -9.7543e-04\n",
       "    2.1660e-02 -9.3791e-03  3.8273e-02\n",
       "    5.0253e-02 -1.1436e-02  1.8124e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "    5.9653e-02  6.3778e-02  2.3321e-02\n",
       "   -2.1978e-02 -1.0237e-01 -1.0994e-02\n",
       "    2.5362e-03 -6.1944e-02 -1.8796e-02\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    2.5467e-02 -4.3342e-02 -5.6960e-03\n",
       "    2.9012e-03  3.7636e-02  1.7471e-02\n",
       "    2.1348e-02 -1.4174e-02 -6.7136e-02\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "   -3.1233e-02  1.8262e-02 -1.2918e-02\n",
       "   -7.7727e-02  3.2118e-02 -5.9820e-02\n",
       "   -2.2976e-02 -3.6286e-02  7.6830e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7594\n",
       "   0.6948\n",
       "   0.7604\n",
       "   0.7992\n",
       "   0.7884\n",
       "   0.7590\n",
       "   0.8787\n",
       "   0.7862\n",
       "   0.7419\n",
       "   0.7696\n",
       "   0.6698\n",
       "   0.6901\n",
       "   0.8184\n",
       "   0.6991\n",
       "   0.7697\n",
       "   0.6738\n",
       "   0.7266\n",
       "   0.6836\n",
       "   1.0492\n",
       "   0.7690\n",
       "   0.7450\n",
       "   0.7572\n",
       "   0.7608\n",
       "   0.7836\n",
       "   0.6702\n",
       "   0.7739\n",
       "   0.8057\n",
       "   0.8521\n",
       "   0.7126\n",
       "   0.8093\n",
       "   0.8017\n",
       "   0.6979\n",
       "   0.7983\n",
       "   0.7320\n",
       "   0.6959\n",
       "   0.7861\n",
       "   0.9004\n",
       "   0.8652\n",
       "   0.7447\n",
       "   0.8382\n",
       "   0.8801\n",
       "   0.8238\n",
       "   0.7448\n",
       "   0.8502\n",
       "   0.7262\n",
       "   0.7275\n",
       "   0.7832\n",
       "   0.7685\n",
       "   0.7824\n",
       "   0.7829\n",
       "   0.8863\n",
       "   0.7349\n",
       "   0.7822\n",
       "   0.7903\n",
       "   0.7245\n",
       "   0.8080\n",
       "   0.7389\n",
       "   0.6957\n",
       "   0.7625\n",
       "   0.7993\n",
       "   0.6904\n",
       "   0.7021\n",
       "   0.7029\n",
       "   0.7574\n",
       "   0.7479\n",
       "   0.7924\n",
       "   0.7363\n",
       "   0.7309\n",
       "   0.7449\n",
       "   0.7106\n",
       "   0.8016\n",
       "   0.8148\n",
       "   0.7453\n",
       "   0.7977\n",
       "   0.8644\n",
       "   0.7329\n",
       "   0.6776\n",
       "   0.8141\n",
       "   0.9206\n",
       "   1.0551\n",
       "   0.9356\n",
       "   0.8143\n",
       "   0.7584\n",
       "   0.7701\n",
       "   0.8405\n",
       "   0.7054\n",
       "   0.6926\n",
       "   0.7682\n",
       "   0.7040\n",
       "   0.7660\n",
       "   0.9567\n",
       "   0.8173\n",
       "   0.7878\n",
       "   0.8426\n",
       "   0.8138\n",
       "   0.6756\n",
       "   0.7899\n",
       "   0.7978\n",
       "   0.7885\n",
       "   0.7330\n",
       "   0.7456\n",
       "   0.7768\n",
       "   0.8015\n",
       "   0.7559\n",
       "   0.7763\n",
       "   0.7974\n",
       "   0.6830\n",
       "   0.7060\n",
       "   0.8326\n",
       "   0.8365\n",
       "   0.7577\n",
       "   0.8476\n",
       "   0.7140\n",
       "   1.1627\n",
       "   0.7797\n",
       "   0.6927\n",
       "   0.7351\n",
       "   0.6265\n",
       "   0.6889\n",
       "   0.6868\n",
       "   0.8148\n",
       "   0.6715\n",
       "   0.7380\n",
       "   0.7662\n",
       "   0.7861\n",
       "   0.8129\n",
       "   0.8092\n",
       "   0.7745\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "   0.0199\n",
       "  -0.3090\n",
       "  -0.0263\n",
       "   0.0430\n",
       "   0.0412\n",
       "  -0.4352\n",
       "  -0.0946\n",
       "   0.1948\n",
       "  -0.0672\n",
       "   0.0449\n",
       "  -0.0232\n",
       "  -0.0953\n",
       "   0.0440\n",
       "  -0.3209\n",
       "  -0.1297\n",
       "  -0.1921\n",
       "  -0.2198\n",
       "  -0.1302\n",
       "  -0.2237\n",
       "  -0.1621\n",
       "   0.2353\n",
       "  -0.0517\n",
       "   0.1312\n",
       "   0.0188\n",
       "  -0.2690\n",
       "  -0.2518\n",
       "   0.0077\n",
       "   0.1725\n",
       "   0.0194\n",
       "   0.1619\n",
       "   0.1134\n",
       "  -0.0750\n",
       "   0.0208\n",
       "  -0.0182\n",
       "  -0.0347\n",
       "   0.0059\n",
       "   0.0666\n",
       "   0.1189\n",
       "  -0.0553\n",
       "   0.2770\n",
       "  -0.0349\n",
       "  -0.0196\n",
       "  -0.0077\n",
       "  -0.0391\n",
       "  -0.0587\n",
       "  -0.1278\n",
       "  -0.0162\n",
       "   0.0188\n",
       "  -0.0211\n",
       "   0.0886\n",
       "  -0.1275\n",
       "   0.1777\n",
       "   0.1622\n",
       "   0.0708\n",
       "  -0.2573\n",
       "   0.1729\n",
       "   0.0104\n",
       "  -0.1345\n",
       "   0.0104\n",
       "   0.0483\n",
       "  -0.0947\n",
       "  -0.1844\n",
       "  -0.2957\n",
       "   0.1353\n",
       "  -0.3089\n",
       "   0.0659\n",
       "  -0.0619\n",
       "   0.0417\n",
       "  -0.0155\n",
       "  -0.0436\n",
       "   0.0497\n",
       "   0.0431\n",
       "  -0.0140\n",
       "   0.0646\n",
       "   0.2110\n",
       "   0.0206\n",
       "  -0.1111\n",
       "   0.0701\n",
       "  -0.0632\n",
       "  -0.0606\n",
       "   0.0553\n",
       "   0.2025\n",
       "  -0.3751\n",
       "   0.0406\n",
       "  -0.0383\n",
       "  -0.0850\n",
       "  -0.0921\n",
       "   0.0278\n",
       "  -0.1483\n",
       "   0.0082\n",
       "  -0.0919\n",
       "  -0.0117\n",
       "   0.0593\n",
       "   0.1002\n",
       "  -0.1761\n",
       "  -0.1323\n",
       "   0.0696\n",
       "   0.1152\n",
       "   0.1000\n",
       "   0.1106\n",
       "  -0.0511\n",
       "   0.0393\n",
       "   0.1391\n",
       "   0.0090\n",
       "   0.0098\n",
       "   0.1303\n",
       "  -0.0263\n",
       "  -0.0326\n",
       "   0.0010\n",
       "   0.0543\n",
       "  -0.0542\n",
       "  -0.0475\n",
       "  -0.0685\n",
       "  -0.0911\n",
       "   0.1041\n",
       "  -0.0452\n",
       "   0.0075\n",
       "  -0.1209\n",
       "  -0.1145\n",
       "  -0.0708\n",
       "   0.1279\n",
       "  -0.0683\n",
       "  -0.0615\n",
       "   0.1851\n",
       "  -0.2919\n",
       "   0.0774\n",
       "   0.1161\n",
       "   0.1220\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -5.9697e-02  2.7429e-02 -6.2431e-02\n",
       "   -3.4642e-02 -3.6309e-02 -8.2645e-02\n",
       "    3.1819e-02  6.0575e-02  9.1350e-05\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    3.3156e-02 -1.4352e-02 -5.7099e-02\n",
       "   -4.0840e-03  4.9129e-02 -5.3976e-02\n",
       "   -3.5542e-02  6.5468e-03 -7.1101e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -6.4133e-02 -2.2891e-02 -6.2949e-03\n",
       "   -2.4140e-02 -1.5618e-02 -2.5056e-02\n",
       "   -2.7298e-02  3.1782e-03 -1.9435e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "   -1.5086e-02 -6.8054e-03  4.1059e-02\n",
       "   -7.3348e-03  3.5024e-02 -5.6193e-03\n",
       "    3.1291e-02  4.0239e-03 -2.8502e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "    1.5693e-02 -6.9098e-03 -3.1962e-02\n",
       "    6.4327e-03 -1.9984e-02  4.2356e-02\n",
       "   -5.5172e-03  2.7932e-03  6.2222e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "    3.2255e-02  6.7175e-02 -1.0703e-02\n",
       "   -9.0606e-03  2.9629e-02  3.1786e-02\n",
       "    5.0538e-03 -3.4664e-02  1.1640e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    2.5116e-02 -1.7358e-02 -1.9546e-02\n",
       "   -2.9935e-02  5.0196e-03 -2.0627e-02\n",
       "   -6.1710e-02 -1.6049e-02  2.8921e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    1.7836e-02 -3.5734e-02  3.6591e-02\n",
       "    1.4734e-02  3.3451e-03  2.7801e-02\n",
       "    7.5780e-02  3.7268e-02  7.0315e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.0041e-02  4.8097e-02  3.1126e-02\n",
       "    3.9652e-03 -4.9225e-03  1.4203e-02\n",
       "    8.4797e-03  2.2699e-02 -6.3637e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    3.5176e-02  2.4641e-03  1.0407e-03\n",
       "    1.0959e-02 -6.5399e-02 -3.2581e-02\n",
       "    1.7357e-02 -3.5653e-02 -2.2436e-02\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "   -1.8357e-02  1.8564e-02 -1.1850e-02\n",
       "   -7.6137e-03  1.8144e-02  1.4806e-02\n",
       "    1.0333e-03  3.2536e-02 -1.7952e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "   -1.5584e-02 -1.2037e-02 -4.1973e-02\n",
       "   -3.3116e-02  2.1278e-02 -7.2765e-03\n",
       "   -2.2516e-02  3.2025e-02 -3.3627e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.1916e-01 -2.8570e-02  4.9569e-02\n",
       "   -5.0269e-03  1.0853e-01  3.8187e-02\n",
       "   -4.3420e-02 -2.0074e-02  1.0388e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -7.3912e-04  1.4805e-02 -9.1321e-02\n",
       "    3.2335e-03 -2.2466e-02 -5.0241e-02\n",
       "    2.4436e-03 -4.4043e-02 -6.9327e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -2.0635e-02  6.2146e-02 -4.5510e-03\n",
       "   -2.3122e-02 -5.7474e-02  6.1565e-03\n",
       "   -6.3021e-02 -1.4352e-02 -1.7218e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "   -9.9595e-03 -5.2687e-02 -1.2943e-01\n",
       "    4.3515e-03  7.5884e-03  4.1437e-03\n",
       "   -1.3017e-02 -8.6995e-02  3.2054e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    8.6249e-03 -2.9502e-02 -5.6257e-02\n",
       "    1.0877e-03 -3.9222e-02 -1.1840e-02\n",
       "    1.5945e-02 -1.3944e-02 -1.9232e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -3.7709e-03 -1.1913e-01 -2.7224e-02\n",
       "   -5.2497e-03 -3.3861e-02 -3.3487e-02\n",
       "   -6.7538e-02 -5.0090e-02 -2.4144e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -7.5643e-02 -7.8885e-03  2.5425e-02\n",
       "   -9.2266e-02  1.4765e-02  4.9210e-02\n",
       "   -3.0075e-02 -6.4649e-02 -3.0408e-03\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "    4.2585e-02 -3.4790e-03  1.4633e-02\n",
       "    2.0460e-03 -7.3342e-03 -4.0560e-02\n",
       "    2.0403e-03 -3.6560e-02  5.3272e-04\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "   -3.5207e-02  1.8124e-02  6.0269e-03\n",
       "    3.3875e-02  6.9554e-03  2.9239e-02\n",
       "   -2.4629e-02 -5.4524e-04  1.8729e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    2.2139e-02 -4.6675e-02  2.8686e-03\n",
       "    1.7995e-02  2.5802e-02  5.8297e-02\n",
       "   -8.4707e-03  6.0949e-02  5.7786e-02\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "    4.8869e-03 -5.3927e-03  6.9814e-02\n",
       "    4.7670e-02  5.8659e-02  1.0064e-01\n",
       "    1.8547e-02 -2.0032e-02  1.6069e-01\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "    7.9999e-03  4.1734e-02  1.1208e-01\n",
       "   -1.1912e-04  3.9861e-02  2.3529e-02\n",
       "    4.0893e-02  1.5358e-02  1.7440e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "   -2.1687e-02 -1.2734e-02 -3.5783e-02\n",
       "    3.0168e-02 -5.2521e-02  1.5452e-02\n",
       "    4.9734e-02  6.0399e-02  3.6916e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "    7.2312e-02  1.0054e-01  6.9038e-02\n",
       "    1.0010e-01  1.4234e-01  2.2588e-02\n",
       "    7.8842e-02  9.6466e-02  9.1436e-02\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "   -1.0653e-02  7.5957e-03 -5.5888e-02\n",
       "    5.1284e-02  6.6933e-02 -1.2515e-02\n",
       "    3.4647e-02  1.3445e-02 -5.7001e-03\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "   -2.8154e-02  4.6205e-03  3.3113e-02\n",
       "   -1.9110e-02  1.2758e-02  5.2577e-03\n",
       "   -5.8560e-03 -2.1202e-02  1.2770e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "    1.5925e-02  3.5861e-02  6.6494e-02\n",
       "    6.5338e-02  2.0556e-03  3.5690e-02\n",
       "    4.8303e-02 -1.2433e-02  3.1743e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "    5.4864e-02 -2.6677e-02  1.2051e-02\n",
       "    5.4447e-02  4.2230e-02  3.7447e-02\n",
       "    4.5553e-03 -2.9512e-03  7.8919e-02\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "    1.5531e-02  3.9239e-02 -1.1111e-02\n",
       "   -5.1104e-03  8.0239e-02 -5.5194e-02\n",
       "   -2.1281e-02 -2.9126e-02 -6.2975e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    1.5014e-02  1.6573e-02  3.9631e-02\n",
       "   -4.2919e-02  1.9590e-02  6.6669e-02\n",
       "   -2.1341e-02  2.0014e-02  2.8418e-02\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "    2.9396e-02 -2.2984e-02 -2.2189e-02\n",
       "   -2.5158e-03 -1.0814e-02  8.3591e-03\n",
       "    5.1441e-02  7.5900e-02 -2.6389e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "    4.8406e-02  5.8512e-03 -2.5754e-02\n",
       "   -4.0480e-02  1.6189e-02  4.7720e-02\n",
       "    2.2553e-03 -5.2344e-02  2.9060e-02\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    2.5322e-02  2.3147e-02  3.3912e-03\n",
       "    3.3212e-02  4.7921e-03 -1.6793e-02\n",
       "    3.0316e-02  6.7850e-02  1.7162e-02\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "    4.1128e-02  3.5991e-02 -5.7718e-03\n",
       "    3.9027e-02  2.0619e-02  7.0390e-02\n",
       "    2.0518e-02  2.8131e-02 -1.6437e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7483\n",
       "   0.6413\n",
       "   0.7984\n",
       "   0.6655\n",
       "   0.7140\n",
       "   0.8057\n",
       "   0.7596\n",
       "   0.7846\n",
       "   0.7727\n",
       "   0.7957\n",
       "   0.7291\n",
       "   0.8549\n",
       "   0.6548\n",
       "   0.7925\n",
       "   0.6463\n",
       "   0.7898\n",
       "   0.9556\n",
       "   0.6518\n",
       "   0.6347\n",
       "   0.6957\n",
       "   0.6431\n",
       "   0.7927\n",
       "   0.7852\n",
       "   0.7657\n",
       "   0.7156\n",
       "   0.7733\n",
       "   0.8029\n",
       "   0.7367\n",
       "   0.7503\n",
       "   0.7356\n",
       "   0.7114\n",
       "   0.7562\n",
       "   0.8413\n",
       "   0.8605\n",
       "   0.6681\n",
       "   0.7519\n",
       "   0.7609\n",
       "   0.8937\n",
       "   0.8220\n",
       "   0.7849\n",
       "   0.7404\n",
       "   0.7747\n",
       "   0.8964\n",
       "   0.6341\n",
       "   0.7611\n",
       "   0.7967\n",
       "   0.7174\n",
       "   0.7221\n",
       "   0.8211\n",
       "   0.7176\n",
       "   0.7822\n",
       "   0.7787\n",
       "   0.8251\n",
       "   0.6730\n",
       "   0.6367\n",
       "   0.6257\n",
       "   0.8008\n",
       "   0.8420\n",
       "   0.6261\n",
       "   0.6502\n",
       "   0.6788\n",
       "   0.7496\n",
       "   0.8147\n",
       "   0.7702\n",
       "   0.6717\n",
       "   0.8104\n",
       "   0.8492\n",
       "   0.8538\n",
       "   0.7720\n",
       "   0.7815\n",
       "   0.7977\n",
       "   0.8357\n",
       "   0.8448\n",
       "   0.8564\n",
       "   0.6559\n",
       "   0.7116\n",
       "   0.7630\n",
       "   0.8228\n",
       "   0.6839\n",
       "   0.8108\n",
       "   0.9646\n",
       "   0.7923\n",
       "   0.6126\n",
       "   0.7215\n",
       "   0.6800\n",
       "   0.6419\n",
       "   0.6798\n",
       "   0.7975\n",
       "   0.7566\n",
       "   0.7838\n",
       "   0.6313\n",
       "   0.8126\n",
       "   0.7874\n",
       "   0.7111\n",
       "   0.7724\n",
       "   0.8190\n",
       "   0.6798\n",
       "   0.7571\n",
       "   0.6490\n",
       "   0.8796\n",
       "   0.7713\n",
       "   0.6486\n",
       "   0.6978\n",
       "   0.7111\n",
       "   0.7838\n",
       "   0.7524\n",
       "   0.7621\n",
       "   0.7937\n",
       "   0.6397\n",
       "   0.7969\n",
       "   0.7170\n",
       "   0.6961\n",
       "   0.8162\n",
       "   0.7452\n",
       "   0.7209\n",
       "   0.6626\n",
       "   0.6966\n",
       "   0.8691\n",
       "   0.8160\n",
       "   0.8265\n",
       "   0.5874\n",
       "   0.6859\n",
       "   0.8211\n",
       "   0.7815\n",
       "   0.8173\n",
       "   0.8500\n",
       "   0.6665\n",
       "   0.6120\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.0095\n",
       "  -0.1465\n",
       "  -0.1118\n",
       "  -0.1252\n",
       "  -0.1788\n",
       "  -0.1407\n",
       "  -0.0153\n",
       "  -0.0711\n",
       "  -0.0207\n",
       "   0.0010\n",
       "  -0.1680\n",
       "  -0.1022\n",
       "  -0.1303\n",
       "  -0.0046\n",
       "  -0.1711\n",
       "  -0.0511\n",
       "  -0.0240\n",
       "  -0.1634\n",
       "  -0.1013\n",
       "  -0.0494\n",
       "  -0.2183\n",
       "   0.0507\n",
       "   0.0118\n",
       "   0.0377\n",
       "  -0.0613\n",
       "   0.0330\n",
       "   0.0890\n",
       "   0.0214\n",
       "   0.0596\n",
       "  -0.1237\n",
       "  -0.1018\n",
       "  -0.0282\n",
       "  -0.1486\n",
       "  -0.1589\n",
       "  -0.0408\n",
       "  -0.0207\n",
       "  -0.1037\n",
       "   0.0335\n",
       "   0.0529\n",
       "  -0.0555\n",
       "  -0.0260\n",
       "  -0.0712\n",
       "  -0.0216\n",
       "  -0.1486\n",
       "  -0.0617\n",
       "  -0.0118\n",
       "  -0.0279\n",
       "  -0.0676\n",
       "   0.0233\n",
       "  -0.1219\n",
       "   0.0317\n",
       "   0.0094\n",
       "   0.0007\n",
       "  -0.1259\n",
       "  -0.0238\n",
       "  -0.2594\n",
       "  -0.0131\n",
       "   0.1650\n",
       "  -0.1211\n",
       "   0.0329\n",
       "  -0.0914\n",
       "  -0.0586\n",
       "  -0.0059\n",
       "  -0.0338\n",
       "  -0.2787\n",
       "   0.0753\n",
       "   0.0776\n",
       "   0.0090\n",
       "  -0.0743\n",
       "  -0.0300\n",
       "   0.0071\n",
       "  -0.0642\n",
       "  -0.0503\n",
       "   0.1432\n",
       "  -0.0181\n",
       "  -0.0983\n",
       "   0.0882\n",
       "   0.1040\n",
       "  -0.4452\n",
       "   0.0617\n",
       "  -0.1070\n",
       "   0.0494\n",
       "  -0.1525\n",
       "  -0.1391\n",
       "  -0.1087\n",
       "  -0.1664\n",
       "  -0.0501\n",
       "   0.0588\n",
       "  -0.1764\n",
       "  -0.0185\n",
       "   0.0214\n",
       "   0.0233\n",
       "   0.0483\n",
       "  -0.1164\n",
       "   0.0999\n",
       "  -0.0213\n",
       "  -0.2067\n",
       "  -0.1311\n",
       "  -0.1200\n",
       "   0.0114\n",
       "  -0.1419\n",
       "  -0.2205\n",
       "  -0.0987\n",
       "  -0.0898\n",
       "  -0.0223\n",
       "   0.0045\n",
       "  -0.1936\n",
       "  -0.1455\n",
       "  -0.1683\n",
       "   0.0010\n",
       "  -0.1062\n",
       "  -0.1671\n",
       "   0.0626\n",
       "   0.0181\n",
       "  -0.1060\n",
       "  -0.1268\n",
       "  -0.1560\n",
       "  -0.0101\n",
       "  -0.0577\n",
       "   0.1187\n",
       "  -0.2148\n",
       "  -0.1569\n",
       "   0.1373\n",
       "   0.0538\n",
       "   0.0316\n",
       "  -0.1582\n",
       "  -0.2553\n",
       "  -0.1467\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.1911e-02  2.8736e-02  4.3106e-02\n",
       "    1.4833e-02  4.4119e-02 -1.0557e-02\n",
       "    2.0614e-02  3.5470e-02  6.7792e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    9.8492e-02  4.5135e-02 -9.3493e-03\n",
       "    4.5190e-02  2.6084e-02  5.5327e-02\n",
       "    7.3249e-03 -4.0701e-02  7.2946e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -2.5661e-02  1.9814e-02  5.0393e-02\n",
       "    2.7601e-02 -1.0192e-02  4.0105e-02\n",
       "   -7.9421e-03 -2.3538e-02 -5.4148e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "   -3.7214e-03 -3.0658e-02  6.9967e-04\n",
       "    7.9233e-03 -2.2130e-02  1.0854e-02\n",
       "    1.2246e-04  1.9181e-02  2.5766e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "    2.7783e-02  2.2908e-02  5.4451e-02\n",
       "    1.0127e-03  5.8916e-02  1.6563e-02\n",
       "    3.4272e-03  9.8737e-02  2.6575e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "    9.0844e-02 -1.4165e-02  3.3869e-03\n",
       "    3.1723e-02  2.4203e-03  4.0115e-02\n",
       "   -4.2372e-02 -1.3915e-02 -5.6367e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -5.8210e-03 -6.3770e-02 -6.0655e-02\n",
       "   -5.6819e-02  2.0372e-02 -3.3679e-02\n",
       "   -9.7297e-03  4.2919e-02 -1.7900e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -6.1522e-02 -2.8891e-02 -1.4031e-02\n",
       "   -2.4641e-02 -2.2764e-02 -1.5180e-02\n",
       "   -9.4980e-02 -2.6894e-03 -4.8866e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -3.8865e-02  2.0330e-03  4.8008e-02\n",
       "   -5.1014e-02  1.5707e-02 -7.8846e-02\n",
       "   -2.7461e-02 -7.0854e-03 -1.7926e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "   -2.4046e-02 -1.1529e-01 -9.5214e-03\n",
       "   -1.3569e-02 -1.0660e-01  6.2863e-02\n",
       "    7.8325e-02 -2.5726e-02 -1.9909e-03\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "   -6.9807e-03 -4.6353e-02  2.1706e-03\n",
       "   -2.6303e-02 -3.6706e-03 -3.7914e-02\n",
       "    3.4431e-03 -2.6407e-02  3.1703e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "   -3.3062e-02 -1.1842e-02 -2.9867e-02\n",
       "    4.7772e-03 -1.2939e-02  4.4636e-03\n",
       "    3.2037e-02  4.5077e-02 -1.3008e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    4.1694e-03 -3.7359e-02  3.2364e-03\n",
       "   -4.1728e-02 -2.2668e-02 -4.8457e-02\n",
       "    5.0316e-03  4.4639e-03 -6.5929e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -5.0324e-02  2.5170e-03  2.2081e-02\n",
       "    6.2617e-02  4.4058e-02 -7.0643e-02\n",
       "   -1.0024e-02  3.1509e-02 -2.7283e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.0554e-02  6.0320e-02 -5.1731e-02\n",
       "   -1.4577e-02 -3.7239e-02 -9.8977e-03\n",
       "    9.8224e-03 -6.8562e-03 -2.8840e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    2.0369e-02 -4.6231e-02 -4.5826e-03\n",
       "   -5.7882e-03 -3.3508e-02 -6.3202e-02\n",
       "   -1.2180e-02  9.7401e-03 -2.8059e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    3.2460e-02 -2.3843e-02  7.3470e-02\n",
       "    3.1207e-02 -1.5112e-02  2.9041e-02\n",
       "    5.5722e-02  1.0743e-02 -1.6090e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "    6.0538e-02 -4.0687e-02  1.1848e-02\n",
       "   -3.5796e-02  1.0911e-02  2.1394e-02\n",
       "   -2.2319e-02 -1.1983e-02 -3.8615e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "    5.8782e-04  1.9859e-02 -3.4684e-02\n",
       "    1.0001e-02  3.4214e-02  4.4908e-02\n",
       "   -8.7141e-02  1.5644e-03 -8.7909e-03\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "    5.6730e-03 -4.6960e-02 -2.2590e-02\n",
       "    7.3819e-02 -2.5762e-02 -1.7030e-02\n",
       "    1.5731e-02 -8.1424e-02 -1.8693e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "    3.0711e-02  1.0085e-01  4.4384e-02\n",
       "    6.6026e-02  8.0590e-02  1.3166e-01\n",
       "    1.0433e-02  4.4796e-02  9.3138e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    4.3686e-02  3.5875e-02 -7.1895e-02\n",
       "    3.9865e-02  7.0444e-03 -9.7055e-02\n",
       "    2.7013e-02 -2.5214e-02 -1.4448e-01\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "    2.4546e-02 -5.7868e-03 -1.8082e-02\n",
       "    3.3951e-02  1.5171e-02  5.0113e-02\n",
       "    1.6942e-02  2.4922e-03 -5.7533e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "    2.1166e-02  3.4171e-02  2.8232e-02\n",
       "   -3.5759e-02 -8.9465e-03 -2.3387e-02\n",
       "   -3.4346e-02 -9.8738e-02  2.1780e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "   -1.4096e-03 -1.2698e-02 -6.6539e-02\n",
       "   -3.8630e-02  9.0074e-04 -6.3903e-02\n",
       "   -2.6034e-02 -6.3042e-03  2.6753e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "    5.6149e-03 -8.2794e-03 -4.7430e-02\n",
       "    2.1432e-02 -5.2396e-02 -4.4929e-03\n",
       "    7.7364e-02 -1.2683e-02 -8.4637e-02\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "    1.6839e-02  2.6029e-02  3.0401e-03\n",
       "   -1.3246e-02 -3.5456e-02 -2.7932e-02\n",
       "   -6.0049e-03 -4.6477e-02  4.5339e-02\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "    2.4535e-02 -1.1100e-02 -5.7724e-02\n",
       "   -1.6634e-02  7.8435e-03 -4.1377e-03\n",
       "    3.5305e-02 -1.9649e-02 -1.4256e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "    4.0971e-02 -4.6085e-03 -4.4032e-02\n",
       "    1.7485e-02 -3.7790e-02  5.0491e-02\n",
       "   -4.7133e-05  6.7180e-02 -6.3309e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "    1.1533e-03 -3.8203e-02 -1.4848e-03\n",
       "   -6.4874e-02 -6.1450e-02  8.2118e-03\n",
       "   -2.3144e-02 -5.1638e-02 -2.2526e-03\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "   -6.1448e-02  1.2374e-02 -2.5760e-03\n",
       "    1.1357e-02 -1.5205e-02  1.4141e-02\n",
       "   -8.7209e-02 -2.8246e-02 -3.1426e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "   -3.4390e-02 -5.1132e-02 -1.1096e-02\n",
       "   -2.6518e-02 -3.6957e-02 -9.7190e-03\n",
       "   -5.3023e-02  4.5942e-03 -1.6157e-02\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "    4.7247e-02  2.6569e-02  1.9415e-02\n",
       "   -7.7486e-03  1.0272e-02 -2.9559e-02\n",
       "    4.9304e-02 -1.4619e-02 -4.3198e-04\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "   -2.8896e-02  3.7043e-02  7.5345e-03\n",
       "   -5.6787e-02  2.7463e-02  6.0434e-02\n",
       "   -2.5302e-03  2.7204e-02  1.4448e-02\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "   -2.9466e-02 -3.1078e-02  6.9963e-02\n",
       "   -5.2819e-02  1.1836e-02  4.8387e-03\n",
       "    1.9904e-02 -2.0343e-02  9.8641e-03\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "   -1.4922e-02 -2.2386e-02  2.2870e-02\n",
       "   -4.2378e-02  2.0257e-02 -3.2252e-03\n",
       "   -5.9171e-03  1.1200e-02 -3.2934e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7136\n",
       "   0.7869\n",
       "   0.7784\n",
       "   0.6995\n",
       "   0.8565\n",
       "   0.8227\n",
       "   0.9528\n",
       "   0.7343\n",
       "   0.7380\n",
       "   0.6577\n",
       "   0.8232\n",
       "   0.6880\n",
       "   0.7351\n",
       "   0.6751\n",
       "   0.9103\n",
       "   0.7756\n",
       "   0.7412\n",
       "   1.0486\n",
       "   0.7653\n",
       "   0.8262\n",
       "   0.7794\n",
       "   0.7128\n",
       "   0.8675\n",
       "   0.9184\n",
       "   0.8160\n",
       "   0.8301\n",
       "   0.8232\n",
       "   0.7453\n",
       "   0.7461\n",
       "   0.8328\n",
       "   0.7851\n",
       "   0.8029\n",
       "   0.8493\n",
       "   0.7962\n",
       "   0.8202\n",
       "   0.7916\n",
       "   0.8002\n",
       "   0.7811\n",
       "   0.6451\n",
       "   0.7387\n",
       "   0.7847\n",
       "   0.7474\n",
       "   0.7218\n",
       "   1.1528\n",
       "   0.9757\n",
       "   0.7992\n",
       "   0.7913\n",
       "   0.8079\n",
       "   0.6468\n",
       "   0.6833\n",
       "   0.7758\n",
       "   0.6125\n",
       "   0.8604\n",
       "   0.6925\n",
       "   0.7552\n",
       "   0.8068\n",
       "   0.7023\n",
       "   0.7048\n",
       "   0.7675\n",
       "   0.7165\n",
       "   0.7941\n",
       "   0.7822\n",
       "   0.8261\n",
       "   0.7196\n",
       "   0.6887\n",
       "   0.8189\n",
       "   0.6793\n",
       "   0.7239\n",
       "   0.7851\n",
       "   0.7220\n",
       "   0.8016\n",
       "   0.7743\n",
       "   0.8048\n",
       "   0.6547\n",
       "   0.7879\n",
       "   0.6905\n",
       "   0.8121\n",
       "   0.6419\n",
       "   1.1129\n",
       "   0.6795\n",
       "   0.8106\n",
       "   0.8179\n",
       "   0.7295\n",
       "   0.6738\n",
       "   0.7078\n",
       "   0.7920\n",
       "   0.7806\n",
       "   0.7967\n",
       "   0.8014\n",
       "   0.7725\n",
       "   0.7893\n",
       "   0.6667\n",
       "   0.7827\n",
       "   0.9048\n",
       "   0.7187\n",
       "   0.6940\n",
       "   0.7300\n",
       "   0.6907\n",
       "   0.7224\n",
       "   0.7928\n",
       "   0.6860\n",
       "   0.7945\n",
       "   0.7105\n",
       "   0.6712\n",
       "   0.8887\n",
       "   0.7970\n",
       "   0.8148\n",
       "   0.7313\n",
       "   0.7189\n",
       "   0.7276\n",
       "   0.8216\n",
       "   0.7794\n",
       "   0.7801\n",
       "   0.6988\n",
       "   0.7992\n",
       "   0.7974\n",
       "   0.8119\n",
       "   0.7226\n",
       "   0.7418\n",
       "   0.8046\n",
       "   0.8254\n",
       "   0.7875\n",
       "   0.8009\n",
       "   0.7920\n",
       "   0.7169\n",
       "   0.9144\n",
       "   0.8020\n",
       "   0.7905\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.1121\n",
       "   0.1092\n",
       "  -0.0376\n",
       "  -0.3851\n",
       "  -0.0142\n",
       "  -0.0539\n",
       "  -0.3488\n",
       "  -0.0764\n",
       "  -0.2187\n",
       "  -0.2479\n",
       "   0.1439\n",
       "  -0.2579\n",
       "   0.0218\n",
       "  -0.2225\n",
       "  -0.0096\n",
       "  -0.0120\n",
       "  -0.0512\n",
       "   0.0155\n",
       "   0.0371\n",
       "  -0.0200\n",
       "   0.0452\n",
       "  -0.1511\n",
       "   0.1148\n",
       "   0.0530\n",
       "   0.2277\n",
       "   0.0673\n",
       "   0.0269\n",
       "  -0.1022\n",
       "   0.0271\n",
       "   0.0028\n",
       "   0.0372\n",
       "   0.0796\n",
       "   0.1539\n",
       "   0.0485\n",
       "  -0.0467\n",
       "   0.0704\n",
       "   0.0270\n",
       "  -0.0260\n",
       "  -0.0779\n",
       "  -0.1635\n",
       "   0.0491\n",
       "  -0.1098\n",
       "  -0.1288\n",
       "  -0.1138\n",
       "  -0.0224\n",
       "   0.1283\n",
       "  -0.0004\n",
       "  -0.0514\n",
       "  -0.1006\n",
       "  -0.1012\n",
       "   0.0167\n",
       "  -0.1084\n",
       "   0.0368\n",
       "  -0.3154\n",
       "   0.0665\n",
       "   0.0105\n",
       "  -0.1129\n",
       "  -0.2353\n",
       "  -0.0222\n",
       "  -0.0890\n",
       "   0.2047\n",
       "   0.0194\n",
       "   0.1333\n",
       "  -0.0529\n",
       "  -0.0452\n",
       "  -0.0062\n",
       "  -0.0688\n",
       "   0.0238\n",
       "  -0.1733\n",
       "  -0.0846\n",
       "   0.0961\n",
       "  -0.0986\n",
       "  -0.1541\n",
       "  -0.2061\n",
       "   0.1500\n",
       "  -0.1193\n",
       "   0.0856\n",
       "  -0.4025\n",
       "   0.1708\n",
       "  -0.1095\n",
       "   0.0229\n",
       "  -0.1070\n",
       "  -0.1034\n",
       "  -0.2474\n",
       "  -0.1050\n",
       "   0.0461\n",
       "   0.0091\n",
       "   0.0492\n",
       "   0.1887\n",
       "   0.0748\n",
       "   0.0340\n",
       "  -0.1816\n",
       "   0.0170\n",
       "   0.0008\n",
       "  -0.0732\n",
       "  -0.1042\n",
       "  -0.0527\n",
       "  -0.0493\n",
       "  -0.1009\n",
       "   0.0424\n",
       "  -0.0581\n",
       "   0.0173\n",
       "  -0.1231\n",
       "  -0.1313\n",
       "   0.1330\n",
       "   0.0394\n",
       "   0.0574\n",
       "  -0.0426\n",
       "  -0.1050\n",
       "  -0.2096\n",
       "   0.2280\n",
       "   0.0904\n",
       "   0.0299\n",
       "  -0.0099\n",
       "   0.0385\n",
       "   0.1381\n",
       "   0.0336\n",
       "  -0.0720\n",
       "  -0.0454\n",
       "   0.0464\n",
       "   0.0570\n",
       "   0.0073\n",
       "   0.2021\n",
       "   0.0696\n",
       "  -0.1080\n",
       "  -0.5344\n",
       "   0.2593\n",
       "   0.0355\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -4.5089e-02  2.7750e-02  3.6651e-03\n",
       "   -2.8973e-02 -5.0421e-02 -9.5645e-03\n",
       "   -4.7905e-02 -7.4902e-02 -6.4143e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.8233e-03  1.0227e-02 -1.5526e-02\n",
       "   -4.3889e-03 -9.3281e-03 -1.4236e-02\n",
       "   -1.9218e-02 -1.6864e-02  4.7408e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    5.3272e-02  5.3698e-02  3.1156e-02\n",
       "   -2.0855e-02  3.2823e-02  3.3493e-02\n",
       "    5.1308e-02 -4.9429e-02  5.4683e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "    2.1257e-02 -2.9492e-02 -3.2852e-02\n",
       "    3.5124e-02 -4.9551e-03 -4.0000e-02\n",
       "    2.3616e-03 -1.6445e-02 -5.3557e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "   -5.3534e-02 -5.9348e-02 -2.2269e-03\n",
       "   -4.7920e-02  4.3355e-02 -1.2173e-03\n",
       "    1.8138e-02  2.0302e-02 -4.7234e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "    1.8513e-02  1.0096e-02  8.4290e-03\n",
       "   -2.7199e-02  2.6124e-02 -5.0117e-02\n",
       "   -1.1760e-02  2.0642e-02  1.8442e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    2.6419e-02  8.0644e-02  4.5014e-02\n",
       "   -2.1310e-03 -4.9911e-02 -7.8902e-03\n",
       "   -3.5453e-02  5.3623e-02  1.2367e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    1.8016e-02  1.7764e-02  2.5289e-02\n",
       "    3.2102e-02  3.2164e-02 -6.5187e-03\n",
       "    4.1311e-04 -4.3225e-03  3.7194e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -2.5264e-03  4.4422e-02 -1.5184e-02\n",
       "    4.4003e-03 -7.6670e-02  9.2283e-03\n",
       "   -4.4507e-03  1.7317e-02  3.3962e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    5.8065e-02  4.8492e-03 -3.2104e-02\n",
       "   -3.1829e-02  1.3435e-02  1.5298e-02\n",
       "    6.2861e-02 -6.2295e-02  1.7458e-02\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    3.6267e-02  4.7588e-02  5.9911e-02\n",
       "    5.6889e-02 -1.5609e-02  3.8612e-02\n",
       "    8.3909e-02 -4.5629e-03  3.3783e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "   -4.1699e-02 -1.1729e-02  1.3299e-02\n",
       "    2.5633e-02  7.3563e-04 -1.4277e-03\n",
       "   -1.2655e-02  3.6561e-02 -2.5540e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -4.9348e-03  4.4602e-02  1.6764e-02\n",
       "   -6.5608e-03 -6.7352e-02  4.4086e-03\n",
       "   -4.0901e-02  2.3779e-02 -3.3286e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    4.9980e-02  8.1326e-03 -1.4188e-02\n",
       "    3.9995e-02  2.0674e-02 -1.1916e-01\n",
       "    5.0375e-02 -4.8317e-02 -2.5861e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -9.7774e-04  1.7121e-02 -4.2486e-02\n",
       "    5.2126e-02 -3.7796e-02 -4.6166e-02\n",
       "    6.7009e-02 -2.7279e-02  1.9604e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "   -6.1894e-02 -6.3086e-02 -1.4172e-01\n",
       "    1.7131e-02 -1.6572e-02 -1.5267e-01\n",
       "   -3.7019e-03  1.6610e-02 -4.6569e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    3.1134e-02 -2.9919e-02 -2.5105e-02\n",
       "    8.2828e-02  3.7981e-03  3.9582e-02\n",
       "   -4.6890e-02  1.4551e-02  1.8322e-03\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -1.9715e-02  3.5853e-03  7.7819e-02\n",
       "   -1.1210e-03 -3.7196e-03 -1.3182e-02\n",
       "    1.6725e-02 -3.7874e-03  1.1839e-03\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "    6.2737e-03  1.3695e-03 -1.9437e-02\n",
       "   -2.6188e-02 -5.4284e-02 -5.9784e-02\n",
       "    3.0677e-02 -1.0666e-02 -3.0480e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "    7.7232e-02  2.7719e-02 -3.6905e-02\n",
       "    7.3983e-02  4.5349e-02 -8.4921e-02\n",
       "    3.0812e-02 -1.3416e-02 -7.2654e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "    6.8115e-03 -1.0050e-02 -2.9505e-02\n",
       "   -4.5514e-02 -6.8308e-03  3.8333e-02\n",
       "    3.2125e-02  6.8422e-02  3.1095e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    3.1890e-02  5.7319e-02  5.6016e-02\n",
       "   -3.7558e-02  4.2701e-02 -3.4045e-02\n",
       "   -7.4743e-02  4.6963e-02  9.9188e-02\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "   -1.8388e-03  2.1808e-02 -1.8643e-03\n",
       "    3.0349e-02 -4.2505e-02  3.1518e-02\n",
       "    3.3994e-02  6.8032e-02  4.0681e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "    7.4703e-02  9.8734e-02  1.4667e-02\n",
       "   -2.3031e-02  2.0671e-02  3.3468e-03\n",
       "   -1.5852e-03  4.7415e-02  1.4238e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "    2.0435e-02  5.7507e-03  4.6949e-02\n",
       "    1.9998e-02  1.3664e-02 -5.3215e-02\n",
       "    3.0025e-02 -1.6797e-02  4.0989e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "   -3.4148e-02  1.3103e-02  2.7669e-03\n",
       "   -1.0026e-02  2.6842e-03  6.0883e-02\n",
       "    4.3998e-02 -2.5825e-03 -1.6657e-03\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "    2.0675e-02 -2.5559e-02 -7.9424e-03\n",
       "    2.9902e-02  4.5959e-02  2.8364e-02\n",
       "   -3.0863e-02  4.4660e-02 -2.2448e-02\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "    5.8330e-02  4.2710e-02  3.9657e-02\n",
       "   -1.3717e-02  5.3900e-02 -1.9745e-02\n",
       "    9.5908e-03  8.8946e-03 -1.7288e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "    3.1609e-02  6.6123e-02  2.0384e-02\n",
       "    6.3850e-02 -5.4782e-03  8.8730e-02\n",
       "    1.9142e-02 -3.0148e-02 -1.7325e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "    5.1902e-02 -1.1452e-02  2.2910e-02\n",
       "   -4.7176e-02 -6.8636e-03  2.0064e-02\n",
       "    5.6869e-02  8.2156e-03 -1.6117e-02\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "    1.1270e-03  5.2828e-03 -1.4363e-02\n",
       "   -7.3734e-02  6.0878e-02  4.6034e-03\n",
       "   -2.0494e-02 -1.9046e-02  2.3807e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    6.2515e-02  8.2551e-03 -6.2759e-03\n",
       "    6.3459e-02  8.9818e-02 -1.0349e-02\n",
       "    5.5272e-02  2.1301e-02  3.4507e-03\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "   -2.0267e-02  4.5866e-03  1.7382e-03\n",
       "   -2.2536e-03 -3.3384e-02 -3.1062e-02\n",
       "    1.5690e-02 -6.3517e-02  1.4852e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "    9.4787e-04 -8.4903e-03 -3.9194e-02\n",
       "    4.0472e-02  5.5918e-02 -3.4216e-02\n",
       "    9.3804e-03 -3.8378e-02  1.5911e-02\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    2.2387e-02  9.5343e-02 -3.6300e-03\n",
       "    3.3288e-02  1.9986e-02  2.6729e-02\n",
       "   -8.0432e-03  4.3922e-02  4.7855e-02\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "   -1.4469e-02  3.6507e-03 -2.3834e-02\n",
       "   -3.1329e-02  3.9289e-03 -1.6643e-02\n",
       "    2.3880e-02  4.6522e-02 -3.1082e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7819\n",
       "   0.7591\n",
       "   0.8238\n",
       "   0.7986\n",
       "   0.8816\n",
       "   0.8560\n",
       "   0.7492\n",
       "   0.7545\n",
       "   0.7798\n",
       "   0.6929\n",
       "   0.6936\n",
       "   0.8342\n",
       "   0.7867\n",
       "   0.8074\n",
       "   0.8099\n",
       "   0.7718\n",
       "   0.7458\n",
       "   0.8153\n",
       "   0.7746\n",
       "   0.7227\n",
       "   0.7448\n",
       "   0.7807\n",
       "   0.8021\n",
       "   0.7717\n",
       "   0.8333\n",
       "   0.7783\n",
       "   0.7231\n",
       "   0.7947\n",
       "   0.8335\n",
       "   0.6949\n",
       "   0.7271\n",
       "   0.6882\n",
       "   0.7443\n",
       "   0.7517\n",
       "   0.8005\n",
       "   0.8389\n",
       "   0.8270\n",
       "   0.8378\n",
       "   0.7807\n",
       "   0.7330\n",
       "   0.7387\n",
       "   0.8057\n",
       "   0.8224\n",
       "   0.6875\n",
       "   0.6476\n",
       "   0.7375\n",
       "   0.7657\n",
       "   0.7679\n",
       "   0.8016\n",
       "   0.7555\n",
       "   0.7822\n",
       "   0.9106\n",
       "   0.7509\n",
       "   0.7758\n",
       "   0.7255\n",
       "   0.7092\n",
       "   0.7928\n",
       "   0.8768\n",
       "   0.8307\n",
       "   0.7273\n",
       "   0.7248\n",
       "   0.7408\n",
       "   0.7845\n",
       "   0.7946\n",
       "   0.8649\n",
       "   0.6838\n",
       "   0.7956\n",
       "   0.8355\n",
       "   0.7128\n",
       "   0.7670\n",
       "   0.7762\n",
       "   0.7217\n",
       "   0.8659\n",
       "   0.8206\n",
       "   0.7999\n",
       "   0.7246\n",
       "   0.7522\n",
       "   0.8268\n",
       "   0.9687\n",
       "   0.7412\n",
       "   0.8526\n",
       "   1.0142\n",
       "   0.6934\n",
       "   0.7569\n",
       "   0.8217\n",
       "   0.7834\n",
       "   0.7947\n",
       "   0.8165\n",
       "   0.7991\n",
       "   0.8101\n",
       "   0.7700\n",
       "   0.7121\n",
       "   0.8119\n",
       "   0.7688\n",
       "   0.7848\n",
       "   0.7486\n",
       "   0.8066\n",
       "   0.7946\n",
       "   0.7257\n",
       "   0.8223\n",
       "   0.8894\n",
       "   0.7196\n",
       "   0.7687\n",
       "   0.8835\n",
       "   0.7761\n",
       "   0.7798\n",
       "   0.7772\n",
       "   0.9188\n",
       "   0.7203\n",
       "   0.7760\n",
       "   0.8061\n",
       "   0.8521\n",
       "   0.8029\n",
       "   0.7056\n",
       "   0.8918\n",
       "   0.7449\n",
       "   0.7233\n",
       "   0.7122\n",
       "   0.7329\n",
       "   0.6823\n",
       "   0.6632\n",
       "   0.7377\n",
       "   0.6978\n",
       "   0.7904\n",
       "   0.8054\n",
       "   0.9268\n",
       "   0.7028\n",
       "   0.8243\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.0044\n",
       "  -0.1064\n",
       "  -0.0767\n",
       "  -0.1377\n",
       "  -0.0406\n",
       "  -0.0879\n",
       "  -0.0068\n",
       "  -0.0320\n",
       "   0.0326\n",
       "  -0.0556\n",
       "  -0.1033\n",
       "   0.0046\n",
       "  -0.1113\n",
       "   0.0438\n",
       "  -0.1265\n",
       "  -0.0326\n",
       "  -0.0455\n",
       "  -0.0784\n",
       "  -0.0142\n",
       "  -0.0165\n",
       "  -0.1412\n",
       "   0.0094\n",
       "  -0.0058\n",
       "   0.0082\n",
       "  -0.0263\n",
       "   0.0329\n",
       "   0.0835\n",
       "   0.0703\n",
       "   0.0251\n",
       "  -0.1083\n",
       "  -0.0866\n",
       "  -0.0720\n",
       "  -0.1104\n",
       "  -0.1238\n",
       "   0.0057\n",
       "  -0.0323\n",
       "  -0.1085\n",
       "   0.0491\n",
       "   0.0565\n",
       "  -0.0427\n",
       "  -0.0408\n",
       "  -0.0718\n",
       "   0.0034\n",
       "  -0.1417\n",
       "  -0.0688\n",
       "   0.0140\n",
       "  -0.0048\n",
       "  -0.0594\n",
       "   0.0058\n",
       "  -0.0529\n",
       "   0.0377\n",
       "  -0.0308\n",
       "   0.0504\n",
       "   0.0907\n",
       "  -0.0304\n",
       "  -0.1278\n",
       "  -0.0219\n",
       "   0.1000\n",
       "  -0.0466\n",
       "   0.0463\n",
       "  -0.0569\n",
       "   0.0231\n",
       "  -0.0489\n",
       "   0.0091\n",
       "  -0.2314\n",
       "  -0.0366\n",
       "   0.0861\n",
       "   0.0218\n",
       "  -0.0847\n",
       "  -0.0145\n",
       "   0.0081\n",
       "  -0.0500\n",
       "  -0.0055\n",
       "   0.0988\n",
       "  -0.0178\n",
       "  -0.0716\n",
       "   0.0259\n",
       "   0.0867\n",
       "  -0.2473\n",
       "   0.0428\n",
       "  -0.1328\n",
       "  -0.0943\n",
       "  -0.0552\n",
       "   0.0131\n",
       "   0.0158\n",
       "  -0.1437\n",
       "   0.0366\n",
       "   0.0757\n",
       "  -0.0408\n",
       "   0.0053\n",
       "   0.0654\n",
       "  -0.0147\n",
       "   0.0479\n",
       "  -0.0770\n",
       "   0.0624\n",
       "  -0.0444\n",
       "  -0.1031\n",
       "  -0.0337\n",
       "  -0.0387\n",
       "  -0.0545\n",
       "  -0.1113\n",
       "  -0.1759\n",
       "   0.0152\n",
       "  -0.0049\n",
       "   0.0100\n",
       "   0.0281\n",
       "  -0.0594\n",
       "  -0.0674\n",
       "  -0.1103\n",
       "   0.0237\n",
       "   0.0137\n",
       "  -0.0542\n",
       "   0.0317\n",
       "  -0.0240\n",
       "  -0.0290\n",
       "  -0.0747\n",
       "  -0.1693\n",
       "  -0.0085\n",
       "  -0.0613\n",
       "  -0.0228\n",
       "  -0.1895\n",
       "  -0.0707\n",
       "  -0.0393\n",
       "   0.0285\n",
       "   0.0052\n",
       "  -0.1066\n",
       "  -0.1682\n",
       "  -0.1469\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -8.1617e-02  1.1294e-02  1.1446e-02\n",
       "   -1.6529e-03 -4.8089e-03  7.8908e-04\n",
       "   -1.6281e-02 -5.8649e-03 -3.4671e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    2.1818e-02 -8.0065e-02 -2.6454e-02\n",
       "    3.8173e-02 -2.0853e-02 -4.4410e-03\n",
       "    4.6959e-02 -7.0403e-02 -6.3126e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.8269e-02  9.7540e-03 -8.4988e-03\n",
       "   -1.8798e-02 -1.3095e-02 -6.2251e-02\n",
       "   -4.4790e-02  2.0459e-02  5.0067e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "   -2.1779e-02  2.2854e-02 -1.3288e-02\n",
       "   -1.1183e-02 -9.2737e-03  2.3929e-02\n",
       "   -3.5328e-02 -3.0160e-02 -1.2555e-03\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "    1.9068e-02  3.4100e-03 -1.9311e-04\n",
       "    5.6472e-02  3.5463e-03 -9.9977e-03\n",
       "    3.5485e-02 -1.0636e-01 -3.8903e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "   -2.9848e-02 -2.9716e-02 -3.6521e-02\n",
       "   -3.0234e-02  5.7539e-03 -1.6007e-03\n",
       "   -2.0375e-02 -2.6620e-02  4.3552e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    7.2171e-03 -2.8449e-03  5.9227e-02\n",
       "    1.4515e-02 -4.3850e-02 -2.9704e-02\n",
       "    2.2387e-02 -5.8278e-02 -4.2192e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    9.8058e-02  1.7201e-02  6.0089e-02\n",
       "    2.1270e-02 -1.7372e-04  5.9941e-02\n",
       "    2.2842e-02  5.5293e-02  1.6395e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -6.4582e-02  3.4757e-02 -1.4106e-02\n",
       "    3.2878e-02  8.8498e-03  1.1400e-02\n",
       "    1.3905e-02  2.3890e-02 -3.6087e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    5.4510e-02  3.9674e-02 -7.0243e-03\n",
       "   -4.3709e-02 -1.2544e-02  3.0622e-02\n",
       "    3.2793e-02 -1.8653e-02  1.9433e-02\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "   -1.1168e-02 -1.4707e-02  2.6683e-02\n",
       "    3.5342e-02  2.3943e-02 -4.1802e-03\n",
       "   -1.5418e-02  1.0047e-02 -2.0415e-03\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "   -1.3087e-02 -2.3494e-04 -4.4966e-02\n",
       "    7.2100e-02  2.4915e-03 -9.1293e-03\n",
       "    2.6050e-02  3.7349e-02 -1.0511e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -4.6508e-03  9.1095e-02  6.7323e-02\n",
       "   -3.8499e-02  3.6399e-02 -7.5423e-03\n",
       "   -2.3867e-03 -5.6615e-03 -1.5481e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    6.8823e-02  9.8957e-03  5.0432e-02\n",
       "    6.7275e-02  3.2378e-02  4.0387e-02\n",
       "    4.8168e-02 -2.6480e-02 -4.4707e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -8.3497e-02 -3.8190e-03 -2.1884e-03\n",
       "    1.8974e-02  3.0084e-02 -1.5470e-02\n",
       "    3.1064e-03 -3.5641e-02  1.1534e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    5.8696e-02  6.0675e-02  2.7924e-02\n",
       "   -1.7527e-02 -2.3287e-02 -3.1706e-03\n",
       "    1.4847e-03 -4.5999e-02  2.1165e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    8.2852e-02  5.8667e-03 -5.2591e-02\n",
       "   -4.3127e-02 -1.1051e-02  5.0218e-02\n",
       "   -1.2767e-02 -5.9279e-02  6.5948e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "    1.1949e-01  1.1333e-02  1.7815e-02\n",
       "    4.0702e-02  4.5410e-02 -3.0383e-02\n",
       "   -8.5252e-03  1.9714e-02  1.2694e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -5.0997e-04 -6.2708e-02 -1.4951e-03\n",
       "   -1.8969e-02 -2.1072e-03  2.6742e-02\n",
       "   -2.7869e-02 -9.5052e-03 -2.9727e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "   -3.5195e-02 -5.6662e-02 -5.0495e-02\n",
       "   -1.8975e-02 -5.6546e-03 -1.2826e-02\n",
       "   -1.7324e-03 -4.7203e-02 -4.1435e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "   -7.0426e-02 -1.9696e-02 -5.5495e-02\n",
       "   -2.7489e-02 -9.8028e-03 -4.0772e-02\n",
       "   -1.7212e-02  3.4893e-02 -1.3231e-02\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "    2.5104e-02  7.6068e-03 -5.6774e-02\n",
       "   -1.0144e-02 -1.3347e-02  3.1369e-02\n",
       "    1.1499e-02 -8.1327e-02 -4.0778e-02\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "   -3.1999e-02  3.4151e-02 -6.0163e-02\n",
       "    3.4499e-02 -1.8973e-02 -1.4324e-02\n",
       "   -3.5098e-02  1.5793e-02 -3.0834e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "   -3.6717e-03  7.5802e-02  5.6534e-03\n",
       "   -1.7859e-02 -1.2510e-03  5.4255e-02\n",
       "   -1.3407e-02  4.7682e-02 -1.6883e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "    5.1482e-02 -8.2961e-03 -2.3917e-02\n",
       "    3.5196e-02 -1.1236e-02 -4.4563e-02\n",
       "    3.8362e-03  7.0029e-03 -6.5164e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "    4.1465e-03  1.6738e-02 -1.9328e-02\n",
       "   -3.2968e-02  9.6147e-03 -7.0430e-02\n",
       "   -5.2808e-02 -2.6152e-02 -3.5570e-03\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "   -5.7432e-02 -2.8410e-03  1.5357e-02\n",
       "    2.5498e-02 -4.2946e-02  2.0535e-04\n",
       "   -3.7866e-02  2.1260e-02 -1.3812e-02\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "   -3.7285e-02 -2.3234e-02 -3.3591e-02\n",
       "   -1.0101e-03 -6.2051e-02 -2.1364e-02\n",
       "   -8.3502e-03 -4.9804e-02  1.6380e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "    7.6246e-03  2.0669e-02 -8.7486e-04\n",
       "   -7.1705e-02  9.9717e-03 -3.2277e-02\n",
       "    3.3782e-02  2.6786e-02 -1.8237e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "   -3.6745e-02 -1.4501e-03  2.9669e-02\n",
       "   -2.1613e-02  6.7036e-02  2.6746e-02\n",
       "   -2.4615e-02 -4.7969e-02 -1.1916e-02\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "   -3.7640e-02 -3.7885e-02  9.9874e-03\n",
       "   -5.4643e-02  3.6751e-02  3.2141e-02\n",
       "   -2.0157e-02 -6.5713e-02 -3.0662e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "   -8.5158e-03  5.4912e-02  1.9205e-02\n",
       "    6.8081e-02 -7.5586e-02 -4.0589e-02\n",
       "    1.3202e-03 -1.8537e-02 -9.6033e-03\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "    3.4691e-02  2.6215e-02 -2.5431e-02\n",
       "   -2.9824e-02 -4.2806e-03  2.2649e-02\n",
       "   -1.8447e-02  1.7215e-02 -8.0029e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "    8.6360e-02  2.1524e-02  4.8965e-02\n",
       "    1.0473e-01  2.9054e-02  2.9782e-02\n",
       "    8.9450e-02  6.5669e-02 -7.6672e-03\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    3.2985e-03 -6.6935e-02 -2.1028e-02\n",
       "    6.4460e-02 -2.2508e-02  6.6811e-03\n",
       "   -5.0907e-02 -6.8870e-03 -2.4642e-03\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "    1.7257e-03  1.8548e-02  3.6346e-02\n",
       "   -2.4725e-02 -3.1516e-02  5.3789e-03\n",
       "    2.6801e-02 -1.3372e-02  1.4660e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7658\n",
       "   0.7033\n",
       "   0.7341\n",
       "   0.7771\n",
       "   0.7413\n",
       "   0.7621\n",
       "   0.7730\n",
       "   0.7124\n",
       "   0.7230\n",
       "   0.9397\n",
       "   0.7917\n",
       "   0.7805\n",
       "   0.7834\n",
       "   0.7547\n",
       "   0.7939\n",
       "   0.8030\n",
       "   0.7687\n",
       "   0.8017\n",
       "   0.8008\n",
       "   0.7559\n",
       "   0.7531\n",
       "   0.7383\n",
       "   0.8054\n",
       "   0.6969\n",
       "   0.7500\n",
       "   0.7436\n",
       "   0.7516\n",
       "   0.7403\n",
       "   0.8024\n",
       "   0.6630\n",
       "   0.7580\n",
       "   0.8135\n",
       "   0.7415\n",
       "   0.8380\n",
       "   0.8034\n",
       "   0.8339\n",
       "   0.8182\n",
       "   0.8006\n",
       "   0.8806\n",
       "   0.7817\n",
       "   0.6951\n",
       "   0.7786\n",
       "   0.8360\n",
       "   0.8587\n",
       "   0.7768\n",
       "   0.7712\n",
       "   0.7994\n",
       "   0.6907\n",
       "   0.7594\n",
       "   0.8030\n",
       "   0.7668\n",
       "   0.7759\n",
       "   0.8389\n",
       "   0.7621\n",
       "   0.7585\n",
       "   0.7331\n",
       "   0.7981\n",
       "   0.6616\n",
       "   0.7028\n",
       "   0.7923\n",
       "   0.7458\n",
       "   0.8138\n",
       "   0.8548\n",
       "   0.7352\n",
       "   0.8001\n",
       "   0.8729\n",
       "   0.7460\n",
       "   0.9493\n",
       "   0.7816\n",
       "   0.7866\n",
       "   0.7465\n",
       "   0.7086\n",
       "   0.7327\n",
       "   0.7929\n",
       "   0.7737\n",
       "   0.7362\n",
       "   0.8232\n",
       "   0.7844\n",
       "   0.7856\n",
       "   0.7643\n",
       "   0.7984\n",
       "   0.8047\n",
       "   0.7466\n",
       "   0.8111\n",
       "   0.9355\n",
       "   0.7737\n",
       "   0.7691\n",
       "   0.7185\n",
       "   0.7888\n",
       "   0.8334\n",
       "   0.7670\n",
       "   0.7920\n",
       "   0.7448\n",
       "   0.8232\n",
       "   0.7899\n",
       "   0.7880\n",
       "   0.7128\n",
       "   0.9105\n",
       "   0.7372\n",
       "   0.7171\n",
       "   0.7732\n",
       "   0.7741\n",
       "   0.7642\n",
       "   0.8121\n",
       "   0.7551\n",
       "   0.8036\n",
       "   0.7985\n",
       "   0.9303\n",
       "   0.7825\n",
       "   0.8354\n",
       "   0.7399\n",
       "   0.8731\n",
       "   0.7824\n",
       "   0.7469\n",
       "   0.7236\n",
       "   0.7676\n",
       "   0.7650\n",
       "   0.7819\n",
       "   0.8223\n",
       "   0.7134\n",
       "   0.7787\n",
       "   0.7910\n",
       "   0.7680\n",
       "   0.8064\n",
       "   0.8217\n",
       "   0.7940\n",
       "   0.8144\n",
       "   0.7494\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.0415\n",
       "  -0.0455\n",
       "  -0.1029\n",
       "  -0.0178\n",
       "  -0.0169\n",
       "  -0.0128\n",
       "   0.0277\n",
       "  -0.0824\n",
       "  -0.0902\n",
       "  -0.1064\n",
       "   0.0424\n",
       "  -0.1436\n",
       "   0.0264\n",
       "  -0.0021\n",
       "   0.0005\n",
       "   0.0560\n",
       "   0.0094\n",
       "   0.0162\n",
       "   0.1294\n",
       "  -0.0162\n",
       "  -0.0067\n",
       "  -0.1102\n",
       "   0.0154\n",
       "  -0.0708\n",
       "  -0.0483\n",
       "  -0.0657\n",
       "  -0.1635\n",
       "  -0.1471\n",
       "  -0.0679\n",
       "  -0.1714\n",
       "  -0.1104\n",
       "   0.0507\n",
       "  -0.0412\n",
       "   0.0424\n",
       "   0.0180\n",
       "   0.0363\n",
       "   0.0393\n",
       "   0.0035\n",
       "  -0.0331\n",
       "   0.0093\n",
       "  -0.2401\n",
       "   0.0921\n",
       "  -0.0891\n",
       "   0.0846\n",
       "   0.0740\n",
       "   0.1269\n",
       "  -0.0902\n",
       "  -0.0760\n",
       "   0.0107\n",
       "   0.0424\n",
       "  -0.0305\n",
       "   0.0567\n",
       "   0.0733\n",
       "  -0.1313\n",
       "   0.0523\n",
       "  -0.0403\n",
       "  -0.1940\n",
       "  -0.0813\n",
       "  -0.1340\n",
       "  -0.0748\n",
       "  -0.1462\n",
       "   0.1014\n",
       "  -0.0354\n",
       "  -0.1138\n",
       "  -0.0388\n",
       "  -0.0826\n",
       "  -0.1013\n",
       "   0.0206\n",
       "  -0.0187\n",
       "   0.0462\n",
       "  -0.0485\n",
       "  -0.0681\n",
       "  -0.0923\n",
       "   0.1198\n",
       "   0.0036\n",
       "  -0.0340\n",
       "   0.1064\n",
       "   0.0100\n",
       "  -0.1180\n",
       "  -0.0380\n",
       "   0.0073\n",
       "   0.0403\n",
       "  -0.1020\n",
       "   0.1362\n",
       "   0.0141\n",
       "  -0.0091\n",
       "  -0.0008\n",
       "  -0.0788\n",
       "   0.0471\n",
       "   0.0488\n",
       "  -0.0121\n",
       "   0.0460\n",
       "  -0.0914\n",
       "   0.0617\n",
       "  -0.0325\n",
       "  -0.0053\n",
       "  -0.2260\n",
       "   0.0928\n",
       "  -0.0883\n",
       "  -0.0398\n",
       "  -0.0278\n",
       "  -0.0197\n",
       "  -0.0065\n",
       "  -0.0431\n",
       "  -0.0516\n",
       "   0.0515\n",
       "   0.0280\n",
       "  -0.1301\n",
       "   0.0372\n",
       "   0.0519\n",
       "  -0.0447\n",
       "  -0.1048\n",
       "  -0.0999\n",
       "  -0.2130\n",
       "  -0.0771\n",
       "   0.0129\n",
       "  -0.0812\n",
       "   0.1085\n",
       "   0.1573\n",
       "  -0.1409\n",
       "   0.0604\n",
       "  -0.1979\n",
       "  -0.0016\n",
       "   0.1175\n",
       "  -0.1940\n",
       "  -0.0194\n",
       "   0.0336\n",
       "  -0.0570\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.1113e-02 -3.2681e-02 -7.0723e-02\n",
       "    1.6453e-02  4.6251e-02  4.0834e-02\n",
       "   -1.9985e-02 -2.1618e-02  2.4287e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -2.2152e-02  9.0743e-03 -2.9071e-02\n",
       "    3.2470e-02  7.8884e-03  2.0817e-02\n",
       "    3.0390e-02 -3.2280e-02  5.9950e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    2.6822e-02  2.3050e-02  2.0207e-02\n",
       "    2.4771e-02 -2.4180e-03 -2.8935e-02\n",
       "   -4.8301e-02  1.2764e-02  4.0853e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "    3.2280e-02  2.4753e-02  5.6911e-03\n",
       "   -3.6398e-02  2.0051e-02  3.9996e-02\n",
       "   -5.5868e-02 -3.2387e-02 -3.6243e-03\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "   -3.9845e-02  3.2537e-03 -1.7178e-02\n",
       "   -1.1952e-02  1.2775e-02  7.0364e-03\n",
       "   -2.4189e-02 -2.3397e-02 -9.1919e-03\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "   -3.4366e-02 -5.8067e-03  6.7834e-02\n",
       "    3.9073e-02  3.3256e-02  1.1519e-02\n",
       "   -2.3980e-02  4.1178e-02  4.1508e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -3.7733e-03 -3.1998e-02 -3.3886e-02\n",
       "    5.8249e-03  3.0237e-02  5.4616e-03\n",
       "   -2.5900e-03 -6.9480e-03  2.8122e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    9.0147e-02 -7.1646e-03 -2.2115e-02\n",
       "    8.5090e-02  3.7164e-03 -8.2051e-03\n",
       "    3.0609e-02 -9.2023e-03 -4.1811e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    3.1853e-02  1.9683e-02 -2.7340e-02\n",
       "   -5.6588e-02  1.1108e-02  1.7547e-02\n",
       "   -8.7102e-03 -1.3532e-02 -4.3030e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "   -7.5442e-02 -2.1586e-02  1.0675e-02\n",
       "   -2.2768e-02  3.0038e-02 -2.5174e-02\n",
       "    7.0382e-02  4.4057e-02 -5.2749e-02\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    3.4944e-02 -1.4731e-02  2.3709e-02\n",
       "    5.4278e-02 -9.8396e-03  2.6397e-02\n",
       "    2.9124e-02  6.5486e-02 -5.8250e-04\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "   -1.2135e-02 -2.0637e-02 -1.6768e-02\n",
       "   -7.2308e-03  1.4712e-03 -5.4058e-02\n",
       "   -4.6623e-02  3.8488e-02 -2.0556e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.8779e-02 -3.3449e-02  2.9595e-03\n",
       "   -2.6325e-03  4.5934e-02  6.7467e-02\n",
       "   -6.0867e-03 -4.9739e-02  8.7793e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -6.4330e-03  4.2795e-02 -1.6710e-02\n",
       "   -3.7672e-02 -1.4658e-02  4.2049e-02\n",
       "   -6.6395e-02 -1.4227e-02  1.7319e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.4247e-02 -3.3262e-02 -2.0239e-02\n",
       "   -4.5702e-02 -2.0582e-02 -8.2668e-02\n",
       "    8.7124e-02  3.7177e-02  4.6450e-03\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "   -2.0509e-02  1.0235e-01  1.8216e-03\n",
       "    9.1176e-03  6.5132e-02  8.7653e-02\n",
       "    1.5895e-02  7.6192e-02 -3.5895e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "   -3.0082e-02 -2.5554e-02 -1.5469e-02\n",
       "   -5.6059e-02 -2.4039e-02 -4.1974e-02\n",
       "   -4.7531e-02 -3.6990e-02  4.5700e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -5.9199e-02  6.2698e-03 -1.0440e-02\n",
       "   -2.2408e-03  8.7316e-03 -2.0077e-02\n",
       "   -5.6572e-02 -1.5804e-02 -1.0265e-01\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (125, 0 ,.,.) = \n",
       "   -1.4177e-02 -2.3342e-02  1.8873e-02\n",
       "    1.5908e-02 -3.0307e-02  4.4754e-02\n",
       "   -1.6764e-02 -2.5373e-02 -2.4609e-02\n",
       "  \n",
       "  (125, 1 ,.,.) = \n",
       "   -2.5475e-02  7.9095e-03 -1.1746e-02\n",
       "    2.3410e-02 -2.8696e-02  1.5477e-02\n",
       "   -3.6656e-02 -4.2402e-02  4.4897e-02\n",
       "  \n",
       "  (125, 2 ,.,.) = \n",
       "   -2.9791e-02 -1.0973e-02 -3.6886e-03\n",
       "   -7.4730e-02 -4.6028e-02  3.0017e-02\n",
       "   -1.3925e-04 -3.2271e-02 -6.8069e-03\n",
       "      ... \n",
       "  \n",
       "  (125,125,.,.) = \n",
       "   -7.7267e-03 -1.1042e-02  1.0312e-02\n",
       "    7.0748e-02 -2.0899e-02 -8.0619e-03\n",
       "   -8.9319e-03 -6.5962e-02  4.1376e-02\n",
       "  \n",
       "  (125,126,.,.) = \n",
       "    9.8683e-03 -1.7829e-02  7.3899e-02\n",
       "   -4.8319e-03  4.5815e-02  4.1718e-02\n",
       "    2.7335e-02  3.9504e-03  5.4610e-02\n",
       "  \n",
       "  (125,127,.,.) = \n",
       "    7.2943e-02 -2.1369e-02  4.4180e-03\n",
       "    1.7924e-02 -4.2541e-03 -1.6888e-02\n",
       "   -4.8380e-02 -1.3400e-02 -3.4714e-02\n",
       "          \n",
       "  \n",
       "  (126, 0 ,.,.) = \n",
       "   -4.2533e-02  3.4221e-02  2.9138e-02\n",
       "    1.9207e-02 -6.4486e-02 -2.7850e-02\n",
       "    7.4260e-03 -1.9551e-02  1.0210e-02\n",
       "  \n",
       "  (126, 1 ,.,.) = \n",
       "    1.9419e-03  1.3657e-02  2.4666e-02\n",
       "    1.4419e-02 -2.6367e-02  1.6974e-02\n",
       "    2.8195e-03 -1.0066e-02 -6.1246e-02\n",
       "  \n",
       "  (126, 2 ,.,.) = \n",
       "   -2.6463e-02 -7.7041e-03 -3.2421e-02\n",
       "    4.1947e-02  2.8272e-02  5.1984e-02\n",
       "    1.3344e-02 -4.2278e-02  5.4306e-03\n",
       "      ... \n",
       "  \n",
       "  (126,125,.,.) = \n",
       "    1.7155e-02  3.7758e-02 -2.7249e-02\n",
       "    4.3609e-03  2.3321e-02  1.6627e-02\n",
       "   -5.8102e-04 -7.8478e-02  3.2642e-02\n",
       "  \n",
       "  (126,126,.,.) = \n",
       "   -3.1800e-02  3.1148e-02  1.4117e-02\n",
       "    6.6163e-02  6.3275e-02  1.7791e-02\n",
       "    2.9587e-02  3.4027e-02 -6.1435e-02\n",
       "  \n",
       "  (126,127,.,.) = \n",
       "    2.2420e-02 -1.9451e-02 -3.8958e-02\n",
       "   -3.8800e-03  6.5368e-03  1.9637e-02\n",
       "   -2.6139e-02  1.7861e-02  2.7684e-03\n",
       "          \n",
       "  \n",
       "  (127, 0 ,.,.) = \n",
       "   -1.9648e-02 -5.5260e-02  2.3120e-02\n",
       "    6.7507e-04  2.8917e-02 -3.7729e-02\n",
       "    3.3716e-03  3.4720e-02 -2.9130e-02\n",
       "  \n",
       "  (127, 1 ,.,.) = \n",
       "    1.5345e-02 -2.8550e-02  5.2370e-02\n",
       "    1.6861e-02 -2.3090e-02  6.3326e-04\n",
       "   -3.0349e-02  1.9131e-02 -4.1472e-02\n",
       "  \n",
       "  (127, 2 ,.,.) = \n",
       "    5.5192e-02  3.0057e-02  3.1725e-02\n",
       "    1.3936e-02  4.3195e-03  2.2408e-02\n",
       "    4.7873e-02  2.9788e-02  3.4331e-02\n",
       "      ... \n",
       "  \n",
       "  (127,125,.,.) = \n",
       "   -3.4272e-02 -1.5251e-02 -3.4580e-02\n",
       "    1.0711e-02 -3.3492e-02 -5.0326e-02\n",
       "    2.5159e-02  4.7362e-02 -7.1202e-03\n",
       "  \n",
       "  (127,126,.,.) = \n",
       "    2.1113e-02  3.5049e-02  5.0644e-02\n",
       "    5.4170e-03 -7.1216e-03  1.6092e-02\n",
       "    6.3226e-02 -8.2566e-02 -1.8249e-03\n",
       "  \n",
       "  (127,127,.,.) = \n",
       "   -6.8430e-02 -3.8225e-02  2.9766e-02\n",
       "   -5.4894e-03 -2.5399e-02 -1.7096e-02\n",
       "   -3.6047e-03 -4.7375e-03 -1.4988e-02\n",
       "  [torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7701\n",
       "   0.7624\n",
       "   0.8249\n",
       "   0.8066\n",
       "   0.7490\n",
       "   0.8467\n",
       "   0.7961\n",
       "   0.7651\n",
       "   0.7674\n",
       "   0.7735\n",
       "   0.7447\n",
       "   0.7971\n",
       "   0.8346\n",
       "   0.7941\n",
       "   0.8261\n",
       "   0.7976\n",
       "   0.8369\n",
       "   0.7702\n",
       "   0.7467\n",
       "   0.7532\n",
       "   0.7333\n",
       "   0.7325\n",
       "   0.7268\n",
       "   0.7416\n",
       "   0.7719\n",
       "   0.7459\n",
       "   0.7345\n",
       "   0.8272\n",
       "   0.7708\n",
       "   0.7646\n",
       "   0.7303\n",
       "   0.7650\n",
       "   0.8118\n",
       "   0.7644\n",
       "   0.8118\n",
       "   0.8206\n",
       "   0.7837\n",
       "   0.8370\n",
       "   0.7661\n",
       "   0.7318\n",
       "   0.7644\n",
       "   0.7833\n",
       "   0.8204\n",
       "   0.7954\n",
       "   0.7129\n",
       "   0.7937\n",
       "   0.7229\n",
       "   0.7900\n",
       "   0.7797\n",
       "   0.7660\n",
       "   0.7848\n",
       "   0.8200\n",
       "   0.7480\n",
       "   0.7439\n",
       "   0.8129\n",
       "   0.7476\n",
       "   0.7503\n",
       "   0.7764\n",
       "   0.7182\n",
       "   0.7537\n",
       "   0.7916\n",
       "   0.7589\n",
       "   0.7607\n",
       "   0.7822\n",
       "   0.7972\n",
       "   0.7564\n",
       "   0.8000\n",
       "   0.8198\n",
       "   0.7487\n",
       "   0.7543\n",
       "   0.7346\n",
       "   0.7212\n",
       "   0.7979\n",
       "   0.7712\n",
       "   0.7839\n",
       "   0.7974\n",
       "   0.7718\n",
       "   0.7980\n",
       "   0.7345\n",
       "   0.8571\n",
       "   0.7622\n",
       "   0.8512\n",
       "   0.6864\n",
       "   0.7723\n",
       "   0.7410\n",
       "   0.8632\n",
       "   0.7891\n",
       "   0.8371\n",
       "   0.8184\n",
       "   0.7736\n",
       "   0.8210\n",
       "   0.7160\n",
       "   0.8106\n",
       "   0.8761\n",
       "   0.7609\n",
       "   0.7561\n",
       "   0.8060\n",
       "   0.8065\n",
       "   0.7482\n",
       "   0.7278\n",
       "   0.7492\n",
       "   0.8741\n",
       "   0.7780\n",
       "   0.7778\n",
       "   0.7837\n",
       "   0.7973\n",
       "   0.8574\n",
       "   0.9021\n",
       "   0.7303\n",
       "   0.8040\n",
       "   0.7729\n",
       "   0.7670\n",
       "   0.8374\n",
       "   0.7747\n",
       "   0.7640\n",
       "   0.8261\n",
       "   0.8252\n",
       "   0.7649\n",
       "   0.7517\n",
       "   0.7617\n",
       "   0.7417\n",
       "   0.8180\n",
       "   0.7902\n",
       "   0.7688\n",
       "   0.8188\n",
       "   0.7843\n",
       "   0.7597\n",
       "   0.7941\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  -0.0067\n",
       "  -0.1277\n",
       "  -0.0911\n",
       "  -0.1518\n",
       "  -0.0299\n",
       "  -0.0616\n",
       "   0.0229\n",
       "  -0.0005\n",
       "   0.0396\n",
       "  -0.0212\n",
       "  -0.0788\n",
       "  -0.0122\n",
       "  -0.1003\n",
       "   0.0205\n",
       "  -0.0403\n",
       "   0.0041\n",
       "  -0.0002\n",
       "  -0.0939\n",
       "  -0.0163\n",
       "  -0.0506\n",
       "  -0.0740\n",
       "  -0.0138\n",
       "  -0.0474\n",
       "  -0.0476\n",
       "  -0.0415\n",
       "  -0.0015\n",
       "   0.0645\n",
       "   0.0745\n",
       "   0.0035\n",
       "  -0.1333\n",
       "  -0.0722\n",
       "  -0.1137\n",
       "  -0.0596\n",
       "  -0.0575\n",
       "   0.0187\n",
       "  -0.0579\n",
       "  -0.0125\n",
       "   0.0541\n",
       "   0.0552\n",
       "   0.0092\n",
       "  -0.0586\n",
       "  -0.0533\n",
       "  -0.0111\n",
       "  -0.0971\n",
       "  -0.0465\n",
       "   0.0250\n",
       "  -0.0180\n",
       "  -0.0571\n",
       "   0.0256\n",
       "  -0.0422\n",
       "   0.0290\n",
       "  -0.0577\n",
       "   0.0629\n",
       "   0.0376\n",
       "  -0.0564\n",
       "  -0.1109\n",
       "   0.0253\n",
       "   0.0112\n",
       "  -0.0466\n",
       "   0.0324\n",
       "  -0.0289\n",
       "   0.0304\n",
       "  -0.0068\n",
       "   0.0450\n",
       "  -0.1778\n",
       "  -0.0570\n",
       "   0.0283\n",
       "   0.0471\n",
       "  -0.0440\n",
       "   0.0075\n",
       "  -0.0081\n",
       "  -0.0467\n",
       "   0.0156\n",
       "  -0.0451\n",
       "  -0.0124\n",
       "  -0.0701\n",
       "   0.0182\n",
       "   0.0110\n",
       "  -0.1745\n",
       "   0.0260\n",
       "  -0.1217\n",
       "  -0.1792\n",
       "  -0.0266\n",
       "   0.0245\n",
       "   0.0271\n",
       "  -0.0327\n",
       "   0.0773\n",
       "   0.0655\n",
       "  -0.0349\n",
       "   0.0012\n",
       "  -0.0804\n",
       "  -0.0295\n",
       "   0.0447\n",
       "  -0.0519\n",
       "   0.0362\n",
       "  -0.0543\n",
       "  -0.1159\n",
       "  -0.0443\n",
       "  -0.0677\n",
       "  -0.0639\n",
       "  -0.0807\n",
       "  -0.0796\n",
       "  -0.0250\n",
       "   0.0215\n",
       "   0.0101\n",
       "   0.0355\n",
       "  -0.0370\n",
       "  -0.0153\n",
       "  -0.0627\n",
       "   0.0201\n",
       "  -0.0155\n",
       "  -0.0157\n",
       "   0.0119\n",
       "  -0.0445\n",
       "  -0.0315\n",
       "  -0.0267\n",
       "  -0.1387\n",
       "   0.0064\n",
       "   0.0162\n",
       "  -0.0441\n",
       "  -0.1652\n",
       "  -0.0177\n",
       "  -0.0420\n",
       "   0.0202\n",
       "  -0.0638\n",
       "  -0.0042\n",
       "  -0.1659\n",
       "  -0.0437\n",
       "  [torch.cuda.FloatTensor of size 128 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -3.1171e-03  4.1505e-03  3.3052e-02\n",
       "   -5.3084e-03 -2.3349e-02 -2.6787e-03\n",
       "   -5.3045e-02 -1.5655e-02  4.3833e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -8.6508e-04  2.4902e-02 -9.7786e-04\n",
       "   -1.2750e-02  1.6118e-02 -1.9558e-02\n",
       "    1.8449e-02  5.1845e-03 -2.6630e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.0286e-02 -2.1840e-02 -2.1705e-02\n",
       "    4.4310e-03  9.8549e-03 -2.5416e-02\n",
       "   -2.5464e-02 -2.3262e-02 -1.2500e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "   -2.8029e-02 -1.3579e-02 -1.4123e-02\n",
       "   -1.0643e-02 -6.9137e-02 -3.1180e-03\n",
       "   -1.8731e-03  8.7115e-03 -1.8787e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "   -4.7700e-03  2.8324e-02  7.8325e-03\n",
       "    1.4978e-03 -1.1864e-02 -8.3076e-03\n",
       "   -7.6582e-03 -2.6647e-02 -9.1210e-03\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "    1.7530e-02  1.1745e-02  6.6423e-03\n",
       "    9.8627e-03  1.3804e-02 -2.8197e-02\n",
       "    2.7545e-03 -4.9773e-02  1.0396e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    3.6225e-02  1.6858e-02  2.9972e-02\n",
       "   -7.1554e-03  3.3755e-02 -1.4700e-02\n",
       "    3.5255e-02  1.6134e-02  2.8194e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    4.5319e-03  5.2687e-04  3.3420e-03\n",
       "    2.0277e-03 -3.4396e-02  2.9532e-02\n",
       "   -1.9761e-02  8.7110e-03  4.6442e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    5.1723e-03  6.0854e-03  3.5150e-03\n",
       "    3.8790e-03  3.1999e-02  3.2682e-02\n",
       "   -4.2697e-02  1.0496e-02 -1.0830e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "    4.7750e-02  5.6707e-02 -5.0057e-03\n",
       "    5.2746e-02  9.8454e-03 -3.9227e-02\n",
       "    7.1875e-03  3.9003e-02 -9.8472e-03\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    5.9419e-02  4.1722e-02  9.1693e-03\n",
       "    6.1699e-02  5.8346e-02  1.4756e-02\n",
       "    1.6897e-02  4.7577e-02  1.3653e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "    1.3418e-02 -1.4133e-02  2.6887e-02\n",
       "   -1.1927e-03 -2.2616e-02 -1.2345e-02\n",
       "   -4.0419e-03  1.3023e-02  3.7465e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    5.1637e-03 -7.9549e-04  1.4556e-02\n",
       "    1.8356e-02 -2.7583e-02  1.4918e-02\n",
       "   -4.8665e-02  1.4336e-02  3.0509e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    2.0910e-02  3.2089e-02  9.1297e-03\n",
       "   -4.8344e-02 -1.6253e-03  8.3470e-03\n",
       "   -3.3995e-02 -5.3122e-02 -3.3455e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.0398e-02  8.4618e-03  4.9473e-02\n",
       "    8.6258e-03 -1.2215e-03 -2.9720e-03\n",
       "   -3.7142e-03  2.3501e-02  1.7866e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    8.7726e-03 -4.7110e-02  2.1814e-02\n",
       "    1.5589e-02 -4.6685e-02 -4.6466e-03\n",
       "   -7.4389e-02  1.1675e-02  1.7232e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "    2.0769e-02 -5.5170e-02  1.6033e-02\n",
       "   -8.1459e-03 -5.9552e-03 -1.5518e-02\n",
       "   -6.4703e-02  1.8667e-02  4.8431e-04\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -1.6577e-02 -2.9590e-02  3.7530e-02\n",
       "   -4.7906e-02 -3.1145e-02 -9.1583e-03\n",
       "   -3.0162e-02 -6.3828e-02 -8.5056e-04\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    1.5906e-02 -1.8214e-02 -6.4473e-02\n",
       "   -4.1495e-02  2.8123e-03 -2.7025e-02\n",
       "   -2.2377e-02  1.1828e-02  1.7509e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -3.1572e-02 -3.6342e-02 -3.8493e-02\n",
       "    2.2887e-02  5.1659e-03 -3.3658e-03\n",
       "   -2.0771e-02 -3.6770e-02 -3.0692e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -1.3843e-02  1.9658e-02  1.2315e-02\n",
       "   -1.5210e-02  2.7431e-02 -7.5745e-03\n",
       "   -1.8726e-02 -5.6952e-02  3.2982e-03\n",
       "      ... \n",
       "  \n",
       "  (253,125,.,.) = \n",
       "    4.8344e-03  2.0954e-02 -4.2043e-02\n",
       "   -2.4165e-02 -2.0181e-02 -1.4340e-02\n",
       "   -2.4886e-02 -9.6353e-03 -6.4446e-03\n",
       "  \n",
       "  (253,126,.,.) = \n",
       "   -9.4734e-03 -2.6065e-02 -1.6941e-02\n",
       "   -6.2850e-03 -1.4221e-02 -8.6036e-05\n",
       "   -5.5483e-02 -8.2548e-03 -3.3223e-02\n",
       "  \n",
       "  (253,127,.,.) = \n",
       "    7.6226e-03 -1.2466e-02 -4.8343e-02\n",
       "   -1.7950e-02  2.0294e-02 -2.5909e-02\n",
       "   -3.1518e-02 -1.2569e-02 -2.8884e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -2.0866e-02  4.0688e-02  1.5359e-02\n",
       "    2.7190e-02 -1.4968e-03  3.3745e-03\n",
       "    4.9271e-02  2.6345e-02  1.6739e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "   -2.3665e-02  2.8538e-02 -1.5775e-02\n",
       "   -4.4947e-02 -2.1842e-02 -2.0582e-02\n",
       "    6.4458e-03 -8.0721e-03 -7.5089e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -2.4810e-02  2.6022e-02  8.8196e-03\n",
       "   -1.4653e-02 -6.4891e-03 -2.3043e-02\n",
       "    4.4045e-02  3.2803e-02 -5.1799e-04\n",
       "      ... \n",
       "  \n",
       "  (254,125,.,.) = \n",
       "   -2.9068e-02 -2.8120e-03  3.2466e-02\n",
       "    1.5200e-02  5.9195e-03 -6.0602e-02\n",
       "   -1.7594e-03 -2.4391e-02 -1.4967e-02\n",
       "  \n",
       "  (254,126,.,.) = \n",
       "   -3.2309e-02  4.2169e-02  3.4394e-03\n",
       "    8.2567e-03  1.3827e-02  1.5701e-02\n",
       "   -3.8191e-03 -2.1682e-02 -2.3262e-02\n",
       "  \n",
       "  (254,127,.,.) = \n",
       "   -2.3654e-02 -3.7353e-02 -1.8038e-02\n",
       "   -1.0030e-02 -1.2861e-02  3.2266e-02\n",
       "   -8.2976e-03  1.5981e-02 -4.2702e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -1.3006e-02  2.1567e-02 -3.8379e-02\n",
       "   -4.5016e-02  5.1721e-02 -1.9738e-02\n",
       "    8.8969e-03  1.2118e-02 -1.7186e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    3.4399e-03 -2.7348e-02  7.4288e-03\n",
       "    8.6279e-03  7.0099e-02  4.9767e-02\n",
       "   -2.5971e-03  2.1342e-02  2.4733e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    1.2516e-02  9.3733e-03 -1.4129e-02\n",
       "   -2.0923e-02  3.4456e-02  5.2041e-02\n",
       "    3.1328e-03 -1.6432e-02  3.9588e-02\n",
       "      ... \n",
       "  \n",
       "  (255,125,.,.) = \n",
       "    3.7233e-02  3.4348e-02  8.8507e-02\n",
       "    1.9451e-02  6.0567e-02  3.7245e-02\n",
       "    1.6688e-02  4.3087e-02  2.4972e-02\n",
       "  \n",
       "  (255,126,.,.) = \n",
       "    3.3606e-02  7.2203e-02  4.4879e-02\n",
       "    2.7765e-02  3.7545e-02  6.0608e-02\n",
       "   -5.4988e-03  1.9272e-02  1.9704e-02\n",
       "  \n",
       "  (255,127,.,.) = \n",
       "    8.7896e-03  4.5551e-02  6.2331e-03\n",
       "   -6.4151e-03  3.5549e-02  3.5483e-02\n",
       "    1.6636e-02 -1.1736e-02  1.5896e-02\n",
       "  [torch.cuda.FloatTensor of size 256x128x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7596\n",
       "   0.7665\n",
       "   0.7808\n",
       "   0.7649\n",
       "   0.8080\n",
       "   0.7438\n",
       "   0.7751\n",
       "   0.7939\n",
       "   0.7908\n",
       "   0.7750\n",
       "   0.7401\n",
       "   0.8015\n",
       "   0.7556\n",
       "   0.7728\n",
       "   0.7817\n",
       "   0.7808\n",
       "   0.7674\n",
       "   0.7643\n",
       "   0.7933\n",
       "   0.7791\n",
       "   0.7627\n",
       "   0.7551\n",
       "   0.7572\n",
       "   0.7957\n",
       "   0.7488\n",
       "   0.7785\n",
       "   0.7872\n",
       "   0.7867\n",
       "   0.7517\n",
       "   0.7438\n",
       "   0.7646\n",
       "   0.7633\n",
       "   0.7911\n",
       "   0.7770\n",
       "   0.8080\n",
       "   0.7876\n",
       "   0.7552\n",
       "   0.7937\n",
       "   0.7877\n",
       "   0.7475\n",
       "   0.7237\n",
       "   0.8025\n",
       "   0.7796\n",
       "   0.7930\n",
       "   0.7830\n",
       "   0.7760\n",
       "   0.7776\n",
       "   0.8150\n",
       "   0.7687\n",
       "   0.8096\n",
       "   0.7787\n",
       "   0.7488\n",
       "   0.8122\n",
       "   0.7601\n",
       "   0.7979\n",
       "   0.7808\n",
       "   0.8137\n",
       "   0.8157\n",
       "   0.8377\n",
       "   0.7737\n",
       "   0.7829\n",
       "   0.8208\n",
       "   0.7742\n",
       "   0.8572\n",
       "   0.7655\n",
       "   0.7917\n",
       "   0.7774\n",
       "   0.8269\n",
       "   0.7848\n",
       "   0.7659\n",
       "   0.7358\n",
       "   0.8002\n",
       "   0.7811\n",
       "   0.7781\n",
       "   0.7859\n",
       "   0.7758\n",
       "   0.7840\n",
       "   0.8257\n",
       "   0.7528\n",
       "   0.7919\n",
       "   0.7851\n",
       "   0.7671\n",
       "   0.8253\n",
       "   0.7818\n",
       "   0.7631\n",
       "   0.8116\n",
       "   0.7872\n",
       "   0.7556\n",
       "   0.7678\n",
       "   0.7586\n",
       "   0.7700\n",
       "   0.7597\n",
       "   0.7755\n",
       "   0.7987\n",
       "   0.7693\n",
       "   0.8024\n",
       "   0.7624\n",
       "   0.8072\n",
       "   0.7520\n",
       "   0.7804\n",
       "   0.8225\n",
       "   0.7816\n",
       "   0.8112\n",
       "   0.7859\n",
       "   0.7653\n",
       "   0.7815\n",
       "   0.8497\n",
       "   0.7678\n",
       "   0.7994\n",
       "   0.7828\n",
       "   0.7599\n",
       "   0.7701\n",
       "   0.7879\n",
       "   0.7752\n",
       "   0.7757\n",
       "   0.7895\n",
       "   0.7385\n",
       "   0.7448\n",
       "   0.7692\n",
       "   0.7831\n",
       "   0.7933\n",
       "   0.7673\n",
       "   0.7861\n",
       "   0.7868\n",
       "   0.7989\n",
       "   0.7674\n",
       "   0.7782\n",
       "   0.7815\n",
       "   0.7883\n",
       "   0.7508\n",
       "   0.8202\n",
       "   0.7715\n",
       "   0.8134\n",
       "   0.7969\n",
       "   0.7667\n",
       "   0.7811\n",
       "   0.8169\n",
       "   0.8273\n",
       "   0.8054\n",
       "   0.7780\n",
       "   0.7666\n",
       "   0.7927\n",
       "   0.7864\n",
       "   0.8112\n",
       "   0.7668\n",
       "   0.7747\n",
       "   0.8174\n",
       "   0.7679\n",
       "   0.8505\n",
       "   0.7458\n",
       "   0.7928\n",
       "   0.8441\n",
       "   0.8923\n",
       "   0.7239\n",
       "   0.7923\n",
       "   0.7907\n",
       "   0.7959\n",
       "   0.7611\n",
       "   0.7885\n",
       "   0.7679\n",
       "   0.7775\n",
       "   0.8131\n",
       "   0.7525\n",
       "   0.7506\n",
       "   0.7657\n",
       "   0.7975\n",
       "   0.7880\n",
       "   0.7763\n",
       "   0.7848\n",
       "   0.7803\n",
       "   0.7925\n",
       "   0.7819\n",
       "   0.7800\n",
       "   0.7951\n",
       "   0.7703\n",
       "   0.7472\n",
       "   0.7471\n",
       "   0.7616\n",
       "   0.7749\n",
       "   0.7925\n",
       "   0.7564\n",
       "   0.7541\n",
       "   0.7853\n",
       "   0.7745\n",
       "   0.7548\n",
       "   0.7853\n",
       "   0.7642\n",
       "   0.7817\n",
       "   0.8123\n",
       "   0.8347\n",
       "   0.7749\n",
       "   0.8098\n",
       "   0.8119\n",
       "   0.7119\n",
       "   0.7627\n",
       "   0.7858\n",
       "   0.7811\n",
       "   0.8022\n",
       "   0.7925\n",
       "   0.7760\n",
       "   0.7549\n",
       "   0.7651\n",
       "   0.7609\n",
       "   0.7840\n",
       "   0.7991\n",
       "   0.8048\n",
       "   0.8010\n",
       "   0.8144\n",
       "   0.7532\n",
       "   0.7553\n",
       "   0.7612\n",
       "   0.8178\n",
       "   0.7859\n",
       "   0.7999\n",
       "   0.7858\n",
       "   0.7948\n",
       "   0.7825\n",
       "   0.7907\n",
       "   0.8223\n",
       "   0.8142\n",
       "   0.7934\n",
       "   0.7884\n",
       "   0.7956\n",
       "   0.8306\n",
       "   0.7826\n",
       "   0.7764\n",
       "   0.7498\n",
       "   0.7555\n",
       "   0.7861\n",
       "   0.7591\n",
       "   0.7892\n",
       "   0.7809\n",
       "   0.7583\n",
       "   0.7663\n",
       "   0.7483\n",
       "   0.7963\n",
       "   0.7430\n",
       "   0.7775\n",
       "   0.7709\n",
       "   0.7900\n",
       "   0.7929\n",
       "   0.8025\n",
       "   0.8647\n",
       "   0.7820\n",
       "   0.7776\n",
       "   0.7875\n",
       "   0.7897\n",
       "   0.7402\n",
       "   0.7859\n",
       "   0.7904\n",
       "   0.7818\n",
       "   0.7751\n",
       "   0.8011\n",
       "   0.7864\n",
       "   0.7992\n",
       "   0.7677\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "   0.0022\n",
       "  -0.1293\n",
       "   0.0012\n",
       "  -0.0554\n",
       "  -0.1174\n",
       "  -0.0527\n",
       "  -0.0011\n",
       "  -0.1584\n",
       "   0.0188\n",
       "  -0.0977\n",
       "  -0.0677\n",
       "   0.0432\n",
       "  -0.0327\n",
       "  -0.0194\n",
       "   0.0147\n",
       "  -0.0107\n",
       "  -0.0046\n",
       "  -0.0762\n",
       "  -0.1175\n",
       "  -0.0168\n",
       "  -0.0610\n",
       "  -0.0323\n",
       "  -0.0880\n",
       "   0.0508\n",
       "  -0.0016\n",
       "  -0.1284\n",
       "  -0.0035\n",
       "   0.0349\n",
       "  -0.0887\n",
       "  -0.1082\n",
       "  -0.0266\n",
       "  -0.0081\n",
       "  -0.0706\n",
       "  -0.0746\n",
       "  -0.0659\n",
       "  -0.1129\n",
       "  -0.0892\n",
       "   0.0156\n",
       "   0.0315\n",
       "  -0.0338\n",
       "  -0.1107\n",
       "  -0.0695\n",
       "   0.0189\n",
       "   0.0329\n",
       "   0.0108\n",
       "   0.0061\n",
       "   0.0293\n",
       "   0.0084\n",
       "  -0.0018\n",
       "   0.0768\n",
       "  -0.0220\n",
       "   0.0064\n",
       "   0.0679\n",
       "  -0.1126\n",
       "   0.0122\n",
       "   0.0448\n",
       "   0.0409\n",
       "   0.0748\n",
       "   0.0860\n",
       "  -0.0484\n",
       "   0.0670\n",
       "  -0.0009\n",
       "   0.0121\n",
       "   0.0688\n",
       "  -0.0403\n",
       "  -0.0809\n",
       "   0.0159\n",
       "   0.0323\n",
       "   0.0315\n",
       "  -0.0075\n",
       "  -0.0635\n",
       "   0.0377\n",
       "  -0.0531\n",
       "  -0.0112\n",
       "  -0.0164\n",
       "  -0.0432\n",
       "  -0.0798\n",
       "  -0.0255\n",
       "  -0.0179\n",
       "   0.0110\n",
       "   0.0020\n",
       "  -0.0254\n",
       "   0.0079\n",
       "   0.0494\n",
       "   0.0002\n",
       "  -0.0580\n",
       "  -0.0112\n",
       "  -0.0236\n",
       "   0.0212\n",
       "  -0.0261\n",
       "  -0.0454\n",
       "  -0.1106\n",
       "  -0.0336\n",
       "   0.0789\n",
       "   0.0082\n",
       "   0.0679\n",
       "  -0.0929\n",
       "   0.0127\n",
       "  -0.0819\n",
       "   0.0060\n",
       "  -0.0706\n",
       "  -0.0008\n",
       "  -0.1229\n",
       "   0.0066\n",
       "  -0.0678\n",
       "   0.0004\n",
       "   0.1292\n",
       "  -0.0077\n",
       "   0.0477\n",
       "   0.0404\n",
       "  -0.0225\n",
       "  -0.0475\n",
       "   0.0136\n",
       "   0.0171\n",
       "  -0.0874\n",
       "   0.0278\n",
       "  -0.0850\n",
       "  -0.0187\n",
       "   0.0125\n",
       "   0.0156\n",
       "   0.0375\n",
       "  -0.0342\n",
       "   0.0033\n",
       "  -0.0173\n",
       "   0.0174\n",
       "  -0.0193\n",
       "   0.0106\n",
       "  -0.0741\n",
       "   0.0460\n",
       "  -0.0394\n",
       "  -0.0102\n",
       "  -0.1069\n",
       "   0.0072\n",
       "  -0.1592\n",
       "   0.0376\n",
       "  -0.0174\n",
       "  -0.0527\n",
       "   0.0212\n",
       "  -0.1315\n",
       "  -0.0067\n",
       "  -0.0291\n",
       "   0.0054\n",
       "  -0.0106\n",
       "  -0.0669\n",
       "  -0.0337\n",
       "  -0.1019\n",
       "   0.0276\n",
       "  -0.1732\n",
       "   0.0612\n",
       "  -0.0155\n",
       "   0.0389\n",
       "   0.0538\n",
       "   0.0381\n",
       "  -0.0747\n",
       "   0.0111\n",
       "  -0.0004\n",
       "   0.0344\n",
       "  -0.0202\n",
       "   0.0118\n",
       "  -0.0317\n",
       "   0.0029\n",
       "   0.0907\n",
       "  -0.0218\n",
       "   0.0162\n",
       "  -0.0646\n",
       "  -0.1452\n",
       "   0.0170\n",
       "   0.0724\n",
       "  -0.0035\n",
       "  -0.0256\n",
       "   0.0347\n",
       "   0.0565\n",
       "  -0.0089\n",
       "  -0.0288\n",
       "  -0.0056\n",
       "  -0.0175\n",
       "  -0.0414\n",
       "  -0.0161\n",
       "  -0.1343\n",
       "  -0.0142\n",
       "  -0.0108\n",
       "   0.0144\n",
       "   0.0503\n",
       "   0.0626\n",
       "  -0.0340\n",
       "  -0.0211\n",
       "  -0.0754\n",
       "  -0.0395\n",
       "  -0.0798\n",
       "   0.0584\n",
       "   0.0237\n",
       "   0.0431\n",
       "   0.0307\n",
       "  -0.1201\n",
       "  -0.0149\n",
       "  -0.1136\n",
       "  -0.0214\n",
       "   0.0392\n",
       "   0.0098\n",
       "  -0.0061\n",
       "  -0.0955\n",
       "   0.0105\n",
       "  -0.0313\n",
       "  -0.0332\n",
       "  -0.1445\n",
       "   0.0932\n",
       "   0.0124\n",
       "   0.0609\n",
       "  -0.0503\n",
       "  -0.0266\n",
       "  -0.0783\n",
       "   0.0086\n",
       "  -0.0006\n",
       "   0.0458\n",
       "  -0.0053\n",
       "  -0.0384\n",
       "   0.0114\n",
       "   0.0209\n",
       "   0.0059\n",
       "   0.0273\n",
       "   0.0195\n",
       "  -0.1451\n",
       "   0.0264\n",
       "   0.0652\n",
       "  -0.1216\n",
       "  -0.0883\n",
       "  -0.0636\n",
       "  -0.0727\n",
       "  -0.1127\n",
       "  -0.1187\n",
       "   0.0443\n",
       "  -0.0641\n",
       "  -0.0229\n",
       "  -0.0684\n",
       "  -0.0433\n",
       "  -0.1387\n",
       "  -0.0400\n",
       "  -0.0396\n",
       "  -0.0376\n",
       "  -0.0248\n",
       "   0.0451\n",
       "   0.0345\n",
       "  -0.0805\n",
       "   0.0192\n",
       "  -0.0187\n",
       "  -0.0164\n",
       "   0.0446\n",
       "  -0.0152\n",
       "   0.0113\n",
       "   0.0484\n",
       "  -0.0197\n",
       "  -0.0401\n",
       "   0.0105\n",
       "   0.0292\n",
       "   0.0357\n",
       "   0.0076\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -9.5728e-03 -4.0784e-03 -3.3484e-03\n",
       "    2.0690e-02  1.0036e-02  3.0906e-02\n",
       "   -1.6352e-02  5.1670e-02  4.4857e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    1.2171e-02 -4.7333e-03  1.1937e-02\n",
       "    2.0314e-03  2.3415e-02  2.7949e-02\n",
       "   -1.7612e-02  2.9453e-04  5.9016e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.1803e-02  7.1557e-04 -5.4350e-03\n",
       "   -2.7270e-02 -2.6833e-02 -5.6663e-02\n",
       "   -3.8716e-03 -2.1156e-02  1.2084e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -1.0009e-02  2.3209e-02 -2.8393e-02\n",
       "   -2.8330e-02  8.0911e-03  1.5366e-02\n",
       "    1.4379e-02 -1.1109e-02 -1.4964e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    1.1927e-02 -3.1010e-02 -3.4814e-02\n",
       "   -1.0114e-02  4.8129e-02 -1.7791e-03\n",
       "    1.5150e-02 -1.5212e-02  1.0158e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    3.8734e-03 -2.8554e-02  1.2344e-02\n",
       "    5.2547e-03  2.4749e-02  2.3765e-02\n",
       "   -1.6984e-02 -2.4135e-02  8.5660e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    2.5218e-02  2.7015e-02  2.7618e-02\n",
       "    2.7442e-02 -3.6592e-03  3.2074e-03\n",
       "   -1.8639e-02  1.6689e-02  1.2389e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    1.5412e-02  2.0200e-02  7.1958e-03\n",
       "    2.4592e-02 -1.0266e-02  3.5622e-02\n",
       "   -5.2607e-03 -4.7063e-03  6.2980e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -2.8077e-02  2.9813e-02  1.7425e-02\n",
       "    6.1659e-03 -2.2261e-02 -2.1453e-02\n",
       "   -5.7247e-02  1.1056e-02  4.4238e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "   -7.0587e-03 -1.6028e-03  1.3226e-02\n",
       "   -1.8077e-02 -2.4023e-03 -6.2109e-02\n",
       "   -1.2986e-02  2.3874e-02  1.8569e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -2.5379e-03 -2.7919e-02 -3.5962e-02\n",
       "   -1.9365e-02  7.0866e-03  2.4460e-02\n",
       "   -1.2319e-02 -3.9258e-04  4.0464e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -2.4311e-02  1.7115e-02 -3.2912e-02\n",
       "    6.9689e-02 -9.0088e-03 -4.4040e-03\n",
       "   -5.6468e-03 -1.8420e-02 -1.0955e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -3.2210e-03 -3.7796e-02 -2.2343e-02\n",
       "   -1.4723e-02  3.3476e-03  2.7401e-02\n",
       "   -1.9828e-03 -2.5441e-02 -3.4507e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    7.5065e-03 -2.8042e-03  2.3966e-02\n",
       "    4.7771e-02  2.8358e-02 -1.3806e-02\n",
       "    6.3895e-03 -2.3684e-03 -4.2767e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    1.4851e-02 -1.5829e-02 -8.4924e-04\n",
       "   -6.3006e-03  2.0121e-02 -5.6698e-02\n",
       "   -2.7319e-02  6.1641e-03  2.2998e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    1.1245e-02 -2.7695e-02  3.3381e-02\n",
       "    2.4328e-03 -4.6286e-03 -4.9358e-04\n",
       "    1.3505e-02 -1.5473e-02  1.0739e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    1.1678e-02  5.3372e-04  5.3344e-02\n",
       "    2.5885e-02 -1.6435e-02  2.2154e-02\n",
       "   -1.1504e-02 -4.3020e-02 -8.6151e-03\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -1.4921e-02 -6.6181e-04 -1.8870e-02\n",
       "    2.2367e-03 -1.6113e-02 -9.0813e-03\n",
       "   -7.6912e-03  9.4234e-03  3.5474e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    1.2996e-02  7.9983e-03 -6.8312e-02\n",
       "    1.3014e-02  3.8841e-03 -1.3594e-02\n",
       "   -1.4562e-02  4.3064e-03 -5.1784e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    2.3207e-03  9.3787e-03 -7.3326e-03\n",
       "   -4.2412e-02  1.6235e-02 -2.8079e-02\n",
       "    2.0248e-02  1.1344e-02 -3.9124e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -1.2717e-02 -8.9259e-03 -2.0688e-02\n",
       "    7.6637e-02  1.6335e-02 -5.1282e-02\n",
       "    6.9659e-02 -4.2413e-03  6.1995e-03\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    1.0477e-02  9.3749e-03 -1.3039e-02\n",
       "   -7.7590e-03 -2.4274e-02 -9.8094e-03\n",
       "    3.2097e-02  3.3534e-02  5.6574e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    5.8894e-02 -1.3899e-02  1.1135e-02\n",
       "    1.0696e-02  2.1988e-02 -4.7327e-02\n",
       "    1.7883e-02  8.6387e-03 -1.6326e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -4.5601e-02  2.2027e-02  7.4880e-03\n",
       "   -3.2854e-02 -3.5116e-02 -4.5300e-02\n",
       "    1.4202e-02  3.4559e-02  4.1322e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    2.3446e-02  9.4537e-03  6.3768e-04\n",
       "   -4.5247e-04  6.3706e-03 -2.4385e-02\n",
       "   -3.3035e-02  5.5680e-02 -3.1564e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "   -1.5705e-02  5.2411e-02  3.0456e-02\n",
       "    4.5659e-02 -2.2709e-03  2.3147e-02\n",
       "    1.8839e-02  2.2631e-02  6.1376e-03\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -1.3126e-02  2.5054e-02 -1.5111e-02\n",
       "   -9.4086e-03  2.3672e-02  1.5855e-02\n",
       "   -1.8124e-02 -4.2734e-02  1.5710e-03\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    3.5963e-02 -2.9673e-02 -9.8445e-03\n",
       "   -7.8344e-03  8.0148e-03  3.6429e-03\n",
       "    5.7951e-03 -2.0037e-02  2.1306e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    3.3398e-02 -8.0093e-03  5.4984e-02\n",
       "    2.3645e-02 -8.1929e-03 -1.1301e-02\n",
       "   -1.6048e-02  1.6183e-02  3.7187e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    1.4965e-02 -1.4460e-02 -4.6072e-02\n",
       "   -3.0919e-03 -6.1842e-03 -2.1080e-03\n",
       "    1.1650e-02  5.5449e-03  1.6977e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    1.6360e-02  3.3233e-02  8.2668e-03\n",
       "    2.8103e-02  3.2542e-02  1.5630e-02\n",
       "   -7.5365e-04  1.4080e-02  1.7808e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    1.0628e-03 -6.1617e-03 -8.3581e-04\n",
       "   -4.8414e-03 -1.4233e-02  1.6434e-03\n",
       "   -3.2846e-02  1.0591e-02  3.1949e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -1.0173e-02  1.0143e-02 -2.9038e-03\n",
       "   -1.1357e-02 -5.3137e-03  1.5844e-02\n",
       "    2.9077e-03 -3.9871e-02  2.1098e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "    3.9523e-02  2.6032e-03 -2.0502e-02\n",
       "    2.8784e-02  1.1722e-02  1.3524e-02\n",
       "   -5.0156e-03  8.0203e-03 -2.0815e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    2.1694e-02 -1.9664e-02 -3.2807e-02\n",
       "   -1.4274e-02 -1.3850e-03  3.2168e-05\n",
       "   -1.4035e-02 -2.1543e-02  1.1725e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    3.0009e-02  3.2612e-02  6.2180e-03\n",
       "   -1.8912e-02 -2.5352e-02 -6.7276e-03\n",
       "    2.0936e-02 -1.2503e-02  3.8861e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.8272\n",
       "   0.7385\n",
       "   0.7951\n",
       "   0.7510\n",
       "   0.7294\n",
       "   0.7063\n",
       "   0.7819\n",
       "   0.7750\n",
       "   0.7696\n",
       "   0.7843\n",
       "   0.7551\n",
       "   0.8093\n",
       "   0.8235\n",
       "   0.8055\n",
       "   0.7664\n",
       "   0.7521\n",
       "   0.8012\n",
       "   0.7573\n",
       "   0.7999\n",
       "   0.8616\n",
       "   0.8114\n",
       "   0.7791\n",
       "   0.7652\n",
       "   0.7806\n",
       "   0.7864\n",
       "   0.7422\n",
       "   0.8065\n",
       "   0.7819\n",
       "   0.7977\n",
       "   0.7618\n",
       "   0.7916\n",
       "   0.7490\n",
       "   0.7740\n",
       "   0.8118\n",
       "   0.8009\n",
       "   0.7416\n",
       "   0.7883\n",
       "   0.7723\n",
       "   0.7959\n",
       "   0.7663\n",
       "   0.7723\n",
       "   0.7856\n",
       "   0.7154\n",
       "   0.7879\n",
       "   0.7235\n",
       "   0.7853\n",
       "   0.8017\n",
       "   0.8091\n",
       "   0.7216\n",
       "   0.7542\n",
       "   0.7033\n",
       "   0.7622\n",
       "   0.7951\n",
       "   0.7801\n",
       "   0.6976\n",
       "   0.7648\n",
       "   0.8335\n",
       "   0.7272\n",
       "   0.7871\n",
       "   0.7905\n",
       "   0.7729\n",
       "   0.7575\n",
       "   0.7969\n",
       "   0.8365\n",
       "   0.7491\n",
       "   0.8125\n",
       "   0.7977\n",
       "   0.7802\n",
       "   0.6855\n",
       "   0.7725\n",
       "   0.7082\n",
       "   0.7123\n",
       "   0.7900\n",
       "   0.8009\n",
       "   0.7799\n",
       "   0.7506\n",
       "   0.7844\n",
       "   0.7358\n",
       "   0.7899\n",
       "   0.7868\n",
       "   0.7899\n",
       "   0.7998\n",
       "   0.6859\n",
       "   0.7962\n",
       "   0.8641\n",
       "   0.8002\n",
       "   0.7616\n",
       "   0.7756\n",
       "   0.7719\n",
       "   0.7876\n",
       "   0.7530\n",
       "   0.7999\n",
       "   0.7463\n",
       "   0.7358\n",
       "   0.7182\n",
       "   0.7402\n",
       "   0.7155\n",
       "   0.8704\n",
       "   0.7608\n",
       "   0.8004\n",
       "   0.8026\n",
       "   0.8053\n",
       "   0.8099\n",
       "   0.7982\n",
       "   0.7899\n",
       "   0.7267\n",
       "   0.8272\n",
       "   0.7681\n",
       "   0.8110\n",
       "   0.7876\n",
       "   0.7636\n",
       "   0.7470\n",
       "   0.7947\n",
       "   0.8034\n",
       "   0.7956\n",
       "   0.7795\n",
       "   0.6959\n",
       "   0.7730\n",
       "   0.7614\n",
       "   0.7884\n",
       "   0.7682\n",
       "   0.6208\n",
       "   0.8089\n",
       "   0.7699\n",
       "   0.7785\n",
       "   0.7822\n",
       "   0.7708\n",
       "   0.7888\n",
       "   0.8144\n",
       "   0.7998\n",
       "   0.7795\n",
       "   0.7564\n",
       "   0.7775\n",
       "   0.7677\n",
       "   0.7506\n",
       "   0.7796\n",
       "   0.7454\n",
       "   0.7754\n",
       "   0.7776\n",
       "   0.7640\n",
       "   0.8112\n",
       "   0.7613\n",
       "   0.7684\n",
       "   0.7820\n",
       "   0.7924\n",
       "   0.7836\n",
       "   0.7836\n",
       "   0.8029\n",
       "   0.7832\n",
       "   0.8095\n",
       "   0.7803\n",
       "   0.8088\n",
       "   0.8168\n",
       "   0.7394\n",
       "   0.8091\n",
       "   0.7752\n",
       "   0.7387\n",
       "   0.7488\n",
       "   0.6880\n",
       "   0.7743\n",
       "   0.7382\n",
       "   0.7925\n",
       "   0.7958\n",
       "   0.8431\n",
       "   0.8055\n",
       "   0.8200\n",
       "   0.7108\n",
       "   0.7544\n",
       "   0.7732\n",
       "   0.7691\n",
       "   0.7706\n",
       "   0.7422\n",
       "   0.7836\n",
       "   0.7854\n",
       "   0.7382\n",
       "   0.7332\n",
       "   0.7166\n",
       "   0.7999\n",
       "   0.7609\n",
       "   0.7288\n",
       "   0.7679\n",
       "   0.7477\n",
       "   0.7873\n",
       "   0.7973\n",
       "   0.8277\n",
       "   0.8282\n",
       "   0.8397\n",
       "   0.7852\n",
       "   0.8163\n",
       "   0.7599\n",
       "   0.7867\n",
       "   0.7502\n",
       "   0.6053\n",
       "   0.7137\n",
       "   0.7602\n",
       "   0.8091\n",
       "   0.8073\n",
       "   0.8097\n",
       "   0.7540\n",
       "   0.7631\n",
       "   0.7851\n",
       "   0.7924\n",
       "   0.7737\n",
       "   0.7790\n",
       "   0.7978\n",
       "   0.7398\n",
       "   0.7725\n",
       "   0.7799\n",
       "   0.8015\n",
       "   0.7492\n",
       "   0.8079\n",
       "   0.7974\n",
       "   0.8003\n",
       "   0.7863\n",
       "   0.7850\n",
       "   0.7382\n",
       "   0.7327\n",
       "   0.8085\n",
       "   0.8293\n",
       "   0.7099\n",
       "   0.7685\n",
       "   0.7699\n",
       "   0.7494\n",
       "   0.7875\n",
       "   0.7371\n",
       "   0.7724\n",
       "   0.7818\n",
       "   0.7781\n",
       "   0.7702\n",
       "   0.7839\n",
       "   0.8009\n",
       "   0.7573\n",
       "   0.7731\n",
       "   0.8100\n",
       "   0.8026\n",
       "   0.8529\n",
       "   0.7815\n",
       "   0.6795\n",
       "   0.7866\n",
       "   0.7979\n",
       "   0.7705\n",
       "   0.7481\n",
       "   0.7496\n",
       "   0.7842\n",
       "   0.7880\n",
       "   0.7658\n",
       "   0.8624\n",
       "   0.7550\n",
       "   0.7853\n",
       "   0.7498\n",
       "   0.7790\n",
       "   0.8058\n",
       "   0.7591\n",
       "   0.8069\n",
       "   0.7648\n",
       "   0.7715\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0450\n",
       "  -0.1347\n",
       "  -0.0316\n",
       "  -0.0460\n",
       "   0.0917\n",
       "  -0.1769\n",
       "   0.0336\n",
       "   0.0085\n",
       "  -0.0076\n",
       "  -0.0548\n",
       "  -0.0931\n",
       "   0.0384\n",
       "  -0.1863\n",
       "  -0.1591\n",
       "  -0.1511\n",
       "  -0.1326\n",
       "   0.0275\n",
       "  -0.1293\n",
       "   0.0482\n",
       "  -0.0904\n",
       "  -0.0423\n",
       "   0.0400\n",
       "  -0.0187\n",
       "  -0.0014\n",
       "  -0.0036\n",
       "  -0.0932\n",
       "   0.0335\n",
       "  -0.0318\n",
       "  -0.0199\n",
       "  -0.0246\n",
       "  -0.0088\n",
       "  -0.1064\n",
       "   0.0339\n",
       "  -0.0390\n",
       "  -0.0270\n",
       "  -0.0362\n",
       "  -0.0157\n",
       "  -0.0114\n",
       "   0.0525\n",
       "  -0.0505\n",
       "  -0.0112\n",
       "  -0.0146\n",
       "  -0.0830\n",
       "  -0.0892\n",
       "  -0.1075\n",
       "  -0.0217\n",
       "  -0.0268\n",
       "   0.0335\n",
       "  -0.0980\n",
       "  -0.0479\n",
       "  -0.1233\n",
       "  -0.0373\n",
       "   0.0563\n",
       "   0.0042\n",
       "  -0.0860\n",
       "  -0.0203\n",
       "   0.0835\n",
       "  -0.0824\n",
       "   0.0040\n",
       "   0.0391\n",
       "  -0.0605\n",
       "  -0.0440\n",
       "   0.0400\n",
       "  -0.0492\n",
       "  -0.1092\n",
       "  -0.1244\n",
       "   0.0209\n",
       "  -0.1065\n",
       "  -0.0474\n",
       "   0.0260\n",
       "  -0.0309\n",
       "  -0.0706\n",
       "  -0.0014\n",
       "  -0.0078\n",
       "   0.0140\n",
       "  -0.0755\n",
       "  -0.0386\n",
       "  -0.0338\n",
       "   0.0112\n",
       "  -0.0149\n",
       "  -0.0039\n",
       "  -0.0307\n",
       "  -0.1600\n",
       "   0.1490\n",
       "  -0.0811\n",
       "  -0.0109\n",
       "  -0.0506\n",
       "  -0.0630\n",
       "  -0.0238\n",
       "  -0.0920\n",
       "  -0.0111\n",
       "  -0.0359\n",
       "  -0.0524\n",
       "  -0.0177\n",
       "  -0.0614\n",
       "  -0.1279\n",
       "  -0.0647\n",
       "   0.1192\n",
       "  -0.0568\n",
       "   0.0201\n",
       "   0.0058\n",
       "   0.1091\n",
       "   0.0528\n",
       "  -0.0435\n",
       "  -0.0445\n",
       "  -0.1782\n",
       "   0.0781\n",
       "  -0.0344\n",
       "   0.0730\n",
       "   0.0293\n",
       "  -0.0297\n",
       "  -0.0425\n",
       "  -0.0553\n",
       "  -0.1180\n",
       "   0.0385\n",
       "   0.0066\n",
       "  -0.1658\n",
       "   0.0037\n",
       "  -0.0264\n",
       "  -0.0550\n",
       "  -0.0617\n",
       "  -0.0528\n",
       "  -0.0235\n",
       "  -0.0157\n",
       "  -0.0211\n",
       "  -0.0244\n",
       "  -0.0796\n",
       "  -0.0299\n",
       "   0.0454\n",
       "  -0.0311\n",
       "  -0.0339\n",
       "  -0.0611\n",
       "  -0.0362\n",
       "  -0.0222\n",
       "  -0.0608\n",
       "   0.0675\n",
       "  -0.0799\n",
       "  -0.0603\n",
       "  -0.0161\n",
       "  -0.0452\n",
       "  -0.0733\n",
       "  -0.0486\n",
       "  -0.0274\n",
       "  -0.1199\n",
       "  -0.0128\n",
       "  -0.0515\n",
       "   0.0662\n",
       "  -0.0628\n",
       "  -0.0080\n",
       "  -0.0362\n",
       "  -0.0063\n",
       "  -0.1163\n",
       "   0.0085\n",
       "  -0.0444\n",
       "   0.0195\n",
       "   0.0067\n",
       "  -0.1157\n",
       "  -0.0199\n",
       "  -0.0351\n",
       "  -0.0092\n",
       "  -0.0002\n",
       "  -0.0706\n",
       "  -0.0304\n",
       "  -0.0209\n",
       "   0.0768\n",
       "  -0.0924\n",
       "  -0.0284\n",
       "  -0.0663\n",
       "  -0.0258\n",
       "  -0.0665\n",
       "  -0.0096\n",
       "  -0.1815\n",
       "  -0.0376\n",
       "  -0.0156\n",
       "  -0.1146\n",
       "  -0.0894\n",
       "  -0.0824\n",
       "  -0.0415\n",
       "  -0.0885\n",
       "  -0.0899\n",
       "  -0.0380\n",
       "  -0.0971\n",
       "  -0.0462\n",
       "  -0.0535\n",
       "  -0.0928\n",
       "  -0.0692\n",
       "   0.0478\n",
       "  -0.0814\n",
       "  -0.0911\n",
       "  -0.0276\n",
       "  -0.2041\n",
       "  -0.1098\n",
       "  -0.2376\n",
       "  -0.0445\n",
       "  -0.0160\n",
       "  -0.0646\n",
       "  -0.0055\n",
       "   0.1048\n",
       "  -0.1336\n",
       "  -0.0978\n",
       "   0.0509\n",
       "   0.0399\n",
       "  -0.0315\n",
       "  -0.0694\n",
       "  -0.0388\n",
       "  -0.0827\n",
       "   0.0115\n",
       "   0.0204\n",
       "  -0.1726\n",
       "  -0.0178\n",
       "   0.0061\n",
       "  -0.1624\n",
       "  -0.0723\n",
       "  -0.0073\n",
       "   0.0462\n",
       "  -0.0266\n",
       "  -0.0850\n",
       "  -0.0808\n",
       "  -0.2502\n",
       "  -0.0862\n",
       "  -0.0637\n",
       "  -0.0746\n",
       "  -0.0551\n",
       "   0.0121\n",
       "  -0.0641\n",
       "   0.0126\n",
       "  -0.0962\n",
       "  -0.0202\n",
       "  -0.0490\n",
       "   0.0172\n",
       "  -0.1176\n",
       "  -0.1540\n",
       "  -0.0551\n",
       "   0.0422\n",
       "   0.0466\n",
       "  -0.0486\n",
       "  -0.0493\n",
       "  -0.0507\n",
       "  -0.0461\n",
       "  -0.0255\n",
       "   0.0098\n",
       "   0.0030\n",
       "  -0.0649\n",
       "  -0.0290\n",
       "  -0.0199\n",
       "  -0.1267\n",
       "  -0.0174\n",
       "  -0.0967\n",
       "   0.0017\n",
       "  -0.1682\n",
       "  -0.0031\n",
       "  -0.0429\n",
       "  -0.0363\n",
       "  -0.0832\n",
       "  -0.0686\n",
       "  -0.0479\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.4964e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.3060e-01\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -9.1985e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,125,.,.) = \n",
       "   -2.2717e-02\n",
       "  \n",
       "  ( 0 ,126,.,.) = \n",
       "   -5.9633e-02\n",
       "  \n",
       "  ( 0 ,127,.,.) = \n",
       "   -1.1618e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -5.0247e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    4.1303e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    3.5611e-01\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,125,.,.) = \n",
       "   -1.2329e-01\n",
       "  \n",
       "  ( 1 ,126,.,.) = \n",
       "    2.6516e-02\n",
       "  \n",
       "  ( 1 ,127,.,.) = \n",
       "    1.0828e-01\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.4812e-01\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -1.7942e-01\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    4.0972e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,125,.,.) = \n",
       "    2.4269e-02\n",
       "  \n",
       "  ( 2 ,126,.,.) = \n",
       "   -1.7680e-02\n",
       "  \n",
       "  ( 2 ,127,.,.) = \n",
       "   -1.2617e-01\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "   -5.0987e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    1.0820e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    1.8252e-02\n",
       "      ... \n",
       "  \n",
       "  (253,125,.,.) = \n",
       "    2.4245e-01\n",
       "  \n",
       "  (253,126,.,.) = \n",
       "    4.0370e-02\n",
       "  \n",
       "  (253,127,.,.) = \n",
       "    5.1487e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -7.2365e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "   -7.0828e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    8.6412e-02\n",
       "      ... \n",
       "  \n",
       "  (254,125,.,.) = \n",
       "    9.1402e-02\n",
       "  \n",
       "  (254,126,.,.) = \n",
       "   -4.1929e-02\n",
       "  \n",
       "  (254,127,.,.) = \n",
       "   -2.9515e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -8.8863e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -6.0863e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -3.6431e-02\n",
       "      ... \n",
       "  \n",
       "  (255,125,.,.) = \n",
       "    3.8621e-02\n",
       "  \n",
       "  (255,126,.,.) = \n",
       "    5.2105e-02\n",
       "  \n",
       "  (255,127,.,.) = \n",
       "   -2.2272e-02\n",
       "  [torch.cuda.FloatTensor of size 256x128x1x1 (GPU 0)], Parameter containing:\n",
       "   0.7354\n",
       "   1.2472\n",
       "   0.7673\n",
       "   0.7901\n",
       "   0.8721\n",
       "   0.6037\n",
       "   0.8014\n",
       "   0.8049\n",
       "   0.7725\n",
       "   0.7468\n",
       "   0.7183\n",
       "   0.8147\n",
       "   1.1852\n",
       "   1.0230\n",
       "   0.7507\n",
       "   0.8002\n",
       "   0.7937\n",
       "   1.1776\n",
       "   0.7875\n",
       "   0.6833\n",
       "   0.6997\n",
       "   0.7785\n",
       "   0.7689\n",
       "   0.7761\n",
       "   0.7663\n",
       "   0.6997\n",
       "   0.8755\n",
       "   0.7609\n",
       "   0.7699\n",
       "   0.8858\n",
       "   0.7591\n",
       "   1.1828\n",
       "   0.7753\n",
       "   0.8072\n",
       "   0.7702\n",
       "   0.7853\n",
       "   0.7633\n",
       "   0.7701\n",
       "   0.7707\n",
       "   0.7292\n",
       "   0.7833\n",
       "   0.7401\n",
       "   0.7034\n",
       "   0.7976\n",
       "   0.6768\n",
       "   0.7638\n",
       "   0.7892\n",
       "   0.7672\n",
       "   0.6995\n",
       "   0.7436\n",
       "   1.5772\n",
       "   0.8087\n",
       "   0.7781\n",
       "   0.7760\n",
       "   0.6514\n",
       "   0.7679\n",
       "   0.7583\n",
       "   0.7082\n",
       "   0.7677\n",
       "   0.7712\n",
       "   0.7916\n",
       "   0.6846\n",
       "   0.9251\n",
       "   0.8861\n",
       "   0.6575\n",
       "   0.7685\n",
       "   0.7864\n",
       "   0.7082\n",
       "   0.6717\n",
       "   0.7932\n",
       "   0.7080\n",
       "   0.7058\n",
       "   0.7861\n",
       "   0.7288\n",
       "   0.7992\n",
       "   0.7414\n",
       "   0.7606\n",
       "   0.7887\n",
       "   0.8833\n",
       "   0.7746\n",
       "   0.7706\n",
       "   0.7228\n",
       "   0.6281\n",
       "   0.7650\n",
       "   0.7237\n",
       "   0.7775\n",
       "   0.7024\n",
       "   0.7187\n",
       "   0.7498\n",
       "   0.7813\n",
       "   0.7729\n",
       "   0.7454\n",
       "   0.7452\n",
       "   0.7748\n",
       "   0.6945\n",
       "   0.7133\n",
       "   0.9773\n",
       "   0.8337\n",
       "   0.7715\n",
       "   0.8048\n",
       "   0.8832\n",
       "   0.7957\n",
       "   0.8033\n",
       "   0.7331\n",
       "   0.7668\n",
       "   1.0990\n",
       "   0.7980\n",
       "   0.7712\n",
       "   0.7651\n",
       "   0.7827\n",
       "   0.7985\n",
       "   0.7818\n",
       "   0.7387\n",
       "   0.9130\n",
       "   0.7698\n",
       "   0.8394\n",
       "   0.6436\n",
       "   0.7495\n",
       "   0.7677\n",
       "   0.7128\n",
       "   0.7823\n",
       "   0.7476\n",
       "   0.7593\n",
       "   0.8063\n",
       "   0.7577\n",
       "   0.8026\n",
       "   0.7294\n",
       "   0.7450\n",
       "   0.7486\n",
       "   0.7679\n",
       "   0.7997\n",
       "   0.7411\n",
       "   0.7966\n",
       "   0.7709\n",
       "   0.6937\n",
       "   0.9210\n",
       "   0.7490\n",
       "   0.7649\n",
       "   0.7717\n",
       "   0.7889\n",
       "   0.7353\n",
       "   0.7707\n",
       "   0.7718\n",
       "   0.8116\n",
       "   0.7661\n",
       "   0.9373\n",
       "   0.7911\n",
       "   0.7443\n",
       "   0.7667\n",
       "   0.7332\n",
       "   0.8134\n",
       "   0.7821\n",
       "   0.7290\n",
       "   0.7955\n",
       "   0.7842\n",
       "   0.7943\n",
       "   0.6562\n",
       "   0.7736\n",
       "   0.7346\n",
       "   0.8209\n",
       "   0.7967\n",
       "   0.7765\n",
       "   0.8259\n",
       "   0.9009\n",
       "   0.8323\n",
       "   0.7464\n",
       "   0.7294\n",
       "   0.7888\n",
       "   0.7695\n",
       "   0.7491\n",
       "   0.7892\n",
       "   0.6170\n",
       "   0.7407\n",
       "   0.7602\n",
       "   0.6670\n",
       "   0.6703\n",
       "   0.6862\n",
       "   0.7722\n",
       "   0.8782\n",
       "   0.6467\n",
       "   0.7797\n",
       "   1.0327\n",
       "   0.7591\n",
       "   0.7439\n",
       "   0.7886\n",
       "   0.7681\n",
       "   0.8419\n",
       "   0.7391\n",
       "   0.7965\n",
       "   0.7165\n",
       "   1.1448\n",
       "   0.9235\n",
       "   0.5868\n",
       "   0.7098\n",
       "   0.7895\n",
       "   0.8344\n",
       "   0.8084\n",
       "   0.7653\n",
       "   0.6669\n",
       "   0.7043\n",
       "   0.8089\n",
       "   0.7661\n",
       "   0.7430\n",
       "   0.7829\n",
       "   0.7337\n",
       "   0.7103\n",
       "   0.7852\n",
       "   0.7785\n",
       "   0.7155\n",
       "   0.7881\n",
       "   0.8615\n",
       "   1.1603\n",
       "   0.7460\n",
       "   0.7683\n",
       "   0.7731\n",
       "   0.7717\n",
       "   0.7140\n",
       "   0.7836\n",
       "   1.1691\n",
       "   0.6333\n",
       "   0.7222\n",
       "   0.7444\n",
       "   0.8590\n",
       "   0.7446\n",
       "   0.7424\n",
       "   0.7762\n",
       "   0.7518\n",
       "   0.7926\n",
       "   0.7799\n",
       "   0.7864\n",
       "   0.7452\n",
       "   0.6788\n",
       "   0.9767\n",
       "   0.7597\n",
       "   0.9710\n",
       "   0.6559\n",
       "   0.7587\n",
       "   0.7015\n",
       "   1.1429\n",
       "   0.7508\n",
       "   0.8011\n",
       "   0.7543\n",
       "   0.7184\n",
       "   0.7638\n",
       "   0.7928\n",
       "   0.7129\n",
       "   0.7761\n",
       "   0.7085\n",
       "   0.7799\n",
       "   0.7035\n",
       "   0.7575\n",
       "   0.7115\n",
       "   0.7924\n",
       "   0.8388\n",
       "   0.8519\n",
       "   0.7593\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0450\n",
       "  -0.1347\n",
       "  -0.0316\n",
       "  -0.0460\n",
       "   0.0917\n",
       "  -0.1769\n",
       "   0.0336\n",
       "   0.0085\n",
       "  -0.0076\n",
       "  -0.0548\n",
       "  -0.0931\n",
       "   0.0384\n",
       "  -0.1863\n",
       "  -0.1591\n",
       "  -0.1511\n",
       "  -0.1326\n",
       "   0.0275\n",
       "  -0.1293\n",
       "   0.0482\n",
       "  -0.0904\n",
       "  -0.0423\n",
       "   0.0400\n",
       "  -0.0187\n",
       "  -0.0014\n",
       "  -0.0036\n",
       "  -0.0932\n",
       "   0.0335\n",
       "  -0.0318\n",
       "  -0.0199\n",
       "  -0.0246\n",
       "  -0.0088\n",
       "  -0.1064\n",
       "   0.0339\n",
       "  -0.0390\n",
       "  -0.0270\n",
       "  -0.0362\n",
       "  -0.0157\n",
       "  -0.0114\n",
       "   0.0525\n",
       "  -0.0505\n",
       "  -0.0112\n",
       "  -0.0146\n",
       "  -0.0830\n",
       "  -0.0892\n",
       "  -0.1075\n",
       "  -0.0217\n",
       "  -0.0268\n",
       "   0.0335\n",
       "  -0.0980\n",
       "  -0.0479\n",
       "  -0.1233\n",
       "  -0.0373\n",
       "   0.0563\n",
       "   0.0042\n",
       "  -0.0860\n",
       "  -0.0203\n",
       "   0.0835\n",
       "  -0.0824\n",
       "   0.0040\n",
       "   0.0391\n",
       "  -0.0605\n",
       "  -0.0440\n",
       "   0.0400\n",
       "  -0.0492\n",
       "  -0.1092\n",
       "  -0.1244\n",
       "   0.0209\n",
       "  -0.1065\n",
       "  -0.0474\n",
       "   0.0260\n",
       "  -0.0309\n",
       "  -0.0706\n",
       "  -0.0014\n",
       "  -0.0078\n",
       "   0.0140\n",
       "  -0.0755\n",
       "  -0.0386\n",
       "  -0.0338\n",
       "   0.0112\n",
       "  -0.0149\n",
       "  -0.0039\n",
       "  -0.0307\n",
       "  -0.1600\n",
       "   0.1490\n",
       "  -0.0811\n",
       "  -0.0109\n",
       "  -0.0506\n",
       "  -0.0630\n",
       "  -0.0238\n",
       "  -0.0920\n",
       "  -0.0111\n",
       "  -0.0359\n",
       "  -0.0524\n",
       "  -0.0177\n",
       "  -0.0614\n",
       "  -0.1279\n",
       "  -0.0647\n",
       "   0.1192\n",
       "  -0.0568\n",
       "   0.0201\n",
       "   0.0058\n",
       "   0.1091\n",
       "   0.0528\n",
       "  -0.0435\n",
       "  -0.0445\n",
       "  -0.1782\n",
       "   0.0781\n",
       "  -0.0344\n",
       "   0.0730\n",
       "   0.0293\n",
       "  -0.0297\n",
       "  -0.0425\n",
       "  -0.0553\n",
       "  -0.1180\n",
       "   0.0385\n",
       "   0.0066\n",
       "  -0.1658\n",
       "   0.0037\n",
       "  -0.0264\n",
       "  -0.0550\n",
       "  -0.0617\n",
       "  -0.0528\n",
       "  -0.0235\n",
       "  -0.0157\n",
       "  -0.0211\n",
       "  -0.0244\n",
       "  -0.0796\n",
       "  -0.0299\n",
       "   0.0454\n",
       "  -0.0311\n",
       "  -0.0339\n",
       "  -0.0611\n",
       "  -0.0362\n",
       "  -0.0222\n",
       "  -0.0608\n",
       "   0.0675\n",
       "  -0.0799\n",
       "  -0.0603\n",
       "  -0.0161\n",
       "  -0.0452\n",
       "  -0.0733\n",
       "  -0.0486\n",
       "  -0.0274\n",
       "  -0.1199\n",
       "  -0.0128\n",
       "  -0.0515\n",
       "   0.0662\n",
       "  -0.0628\n",
       "  -0.0080\n",
       "  -0.0362\n",
       "  -0.0063\n",
       "  -0.1163\n",
       "   0.0085\n",
       "  -0.0444\n",
       "   0.0195\n",
       "   0.0067\n",
       "  -0.1157\n",
       "  -0.0199\n",
       "  -0.0351\n",
       "  -0.0092\n",
       "  -0.0002\n",
       "  -0.0706\n",
       "  -0.0304\n",
       "  -0.0209\n",
       "   0.0768\n",
       "  -0.0924\n",
       "  -0.0284\n",
       "  -0.0663\n",
       "  -0.0258\n",
       "  -0.0665\n",
       "  -0.0096\n",
       "  -0.1815\n",
       "  -0.0376\n",
       "  -0.0156\n",
       "  -0.1146\n",
       "  -0.0894\n",
       "  -0.0824\n",
       "  -0.0415\n",
       "  -0.0885\n",
       "  -0.0899\n",
       "  -0.0380\n",
       "  -0.0971\n",
       "  -0.0462\n",
       "  -0.0535\n",
       "  -0.0928\n",
       "  -0.0692\n",
       "   0.0478\n",
       "  -0.0814\n",
       "  -0.0911\n",
       "  -0.0276\n",
       "  -0.2041\n",
       "  -0.1098\n",
       "  -0.2376\n",
       "  -0.0445\n",
       "  -0.0160\n",
       "  -0.0646\n",
       "  -0.0055\n",
       "   0.1048\n",
       "  -0.1336\n",
       "  -0.0978\n",
       "   0.0509\n",
       "   0.0399\n",
       "  -0.0315\n",
       "  -0.0694\n",
       "  -0.0388\n",
       "  -0.0827\n",
       "   0.0115\n",
       "   0.0204\n",
       "  -0.1726\n",
       "  -0.0178\n",
       "   0.0061\n",
       "  -0.1624\n",
       "  -0.0723\n",
       "  -0.0073\n",
       "   0.0462\n",
       "  -0.0266\n",
       "  -0.0850\n",
       "  -0.0808\n",
       "  -0.2502\n",
       "  -0.0862\n",
       "  -0.0637\n",
       "  -0.0746\n",
       "  -0.0551\n",
       "   0.0121\n",
       "  -0.0641\n",
       "   0.0126\n",
       "  -0.0962\n",
       "  -0.0202\n",
       "  -0.0490\n",
       "   0.0172\n",
       "  -0.1176\n",
       "  -0.1540\n",
       "  -0.0551\n",
       "   0.0422\n",
       "   0.0466\n",
       "  -0.0486\n",
       "  -0.0493\n",
       "  -0.0507\n",
       "  -0.0461\n",
       "  -0.0255\n",
       "   0.0098\n",
       "   0.0030\n",
       "  -0.0649\n",
       "  -0.0290\n",
       "  -0.0199\n",
       "  -0.1267\n",
       "  -0.0174\n",
       "  -0.0967\n",
       "   0.0017\n",
       "  -0.1682\n",
       "  -0.0031\n",
       "  -0.0429\n",
       "  -0.0363\n",
       "  -0.0832\n",
       "  -0.0686\n",
       "  -0.0479\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -4.2075e-04 -2.9681e-02  4.9690e-03\n",
       "   -8.9731e-03  1.1183e-02 -3.6962e-02\n",
       "    2.6986e-02  2.8613e-02 -1.3298e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    4.2342e-02 -9.9133e-04 -3.1798e-02\n",
       "    2.6702e-02  2.4265e-02  1.6747e-02\n",
       "    5.8440e-02 -2.3942e-02 -1.4175e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    3.6658e-03 -2.2236e-02  2.1514e-02\n",
       "   -6.5340e-04 -1.1758e-02  8.2042e-03\n",
       "    9.8941e-03 -1.8469e-02 -1.4069e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -1.5530e-02  1.3499e-03  1.2656e-02\n",
       "    4.6344e-03  5.1396e-02 -5.9481e-03\n",
       "    2.4878e-02  8.6276e-03 -8.5261e-03\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    5.9172e-03 -3.6301e-02  3.5797e-02\n",
       "   -1.1270e-02  1.7263e-02  5.9253e-03\n",
       "   -2.3922e-02 -8.7650e-03  6.1132e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    4.0612e-02  2.8720e-02 -3.0914e-03\n",
       "   -2.7055e-03  4.0303e-02 -1.2727e-02\n",
       "   -2.1509e-03 -3.3647e-02  7.0832e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -2.8165e-02  4.3886e-03 -1.4377e-02\n",
       "    2.6466e-02  2.0453e-02  1.6297e-03\n",
       "    1.2905e-02  9.7926e-05  8.5417e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    6.4742e-03 -1.2659e-02  1.7974e-02\n",
       "   -8.6614e-03  1.9307e-02 -6.7117e-03\n",
       "    2.4806e-02  3.1717e-02 -4.5778e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.9358e-02  5.1748e-03  1.0239e-03\n",
       "   -3.8956e-02  1.6197e-03 -1.0283e-02\n",
       "   -1.8124e-02 -1.1890e-02 -7.8454e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    2.5311e-02  3.9334e-02  4.4387e-02\n",
       "    1.6109e-02  2.6092e-03  2.4656e-02\n",
       "   -1.0641e-02  2.0964e-02 -1.3048e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    2.3850e-02 -2.1293e-02 -5.0923e-03\n",
       "    1.2343e-02 -9.6484e-03 -4.7498e-02\n",
       "    1.7060e-02  1.7964e-02 -2.3982e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    2.6430e-02 -3.5991e-02 -2.4822e-02\n",
       "    2.6285e-02 -1.0185e-03 -8.8958e-03\n",
       "    6.2592e-02 -1.2670e-02  3.2172e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -2.3096e-02  3.0471e-02 -1.2464e-02\n",
       "   -2.0942e-02 -2.4878e-02 -1.8535e-02\n",
       "    1.5741e-02 -3.1875e-03  2.7924e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    1.1937e-02  2.8299e-02 -6.0251e-02\n",
       "   -2.4173e-02  6.5956e-03 -2.2135e-03\n",
       "    5.2940e-03  7.0765e-03 -2.4122e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    2.9170e-03  1.0595e-03  3.5147e-02\n",
       "    1.1583e-02  4.9214e-02  3.2353e-02\n",
       "   -1.4968e-02  1.5557e-02  2.3050e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    4.4641e-03 -1.4263e-02  6.7644e-04\n",
       "    4.8503e-03 -1.1669e-02  4.2998e-02\n",
       "    5.1256e-03 -1.1183e-03 -3.6096e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    2.3831e-02  4.1387e-02  1.2457e-02\n",
       "   -4.8021e-03 -3.0278e-02  1.4036e-03\n",
       "   -2.4541e-03  1.0394e-02 -2.1597e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    3.1145e-03 -1.0683e-02  9.7647e-03\n",
       "    4.9328e-02 -1.2996e-02 -2.6038e-02\n",
       "   -1.5209e-02 -4.8225e-03  1.8120e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    2.7157e-02 -6.2172e-03 -2.5852e-02\n",
       "    4.0977e-02  4.7232e-02 -2.6971e-03\n",
       "    7.8456e-03  2.9727e-02 -1.0221e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    1.6065e-02 -5.2195e-02  7.2059e-03\n",
       "    1.8261e-03  1.0904e-02 -7.5785e-03\n",
       "    3.3630e-02  1.5688e-02 -2.4749e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    3.1321e-02  1.4729e-02  9.2829e-03\n",
       "   -3.3937e-02 -1.7671e-02  3.1420e-02\n",
       "   -7.6162e-02 -2.8765e-02  3.6141e-03\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    3.3841e-02  1.4632e-02  7.4417e-03\n",
       "    2.3487e-02 -1.4272e-02 -1.3724e-02\n",
       "   -1.3161e-02  4.6283e-02 -3.1826e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    1.4583e-03 -2.8682e-03 -1.0351e-02\n",
       "    3.2701e-02  4.2912e-03 -1.5656e-02\n",
       "    2.2353e-02  2.7666e-02 -1.0490e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "    4.6451e-02  7.9036e-03 -2.0131e-02\n",
       "    1.5162e-02  6.3975e-02 -7.8260e-03\n",
       "    7.6741e-03 -1.3216e-02 -5.0927e-03\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    1.6060e-03 -2.0901e-02 -1.0953e-02\n",
       "   -5.7509e-02 -1.9999e-02  2.4776e-02\n",
       "   -1.4434e-02 -9.1794e-03 -1.8876e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    7.1102e-03  1.2421e-02 -2.7594e-03\n",
       "    3.6221e-02  2.4804e-02  9.2625e-03\n",
       "   -3.2467e-03  1.9736e-02  4.9865e-04\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -5.8136e-02 -8.5862e-03 -1.2618e-02\n",
       "   -1.0925e-02  4.7244e-02 -1.6091e-02\n",
       "   -1.5490e-02  2.6763e-02  1.7456e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    3.9316e-03 -8.0117e-03 -5.6536e-03\n",
       "   -3.2339e-02  7.3562e-03 -1.7393e-02\n",
       "    1.4440e-03 -3.0952e-03 -1.2926e-03\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "   -1.7202e-02  1.2084e-02 -7.9281e-03\n",
       "   -7.4537e-03  1.1761e-02 -1.0129e-02\n",
       "    4.3969e-02  1.9561e-02 -1.1336e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    2.6553e-02 -3.4447e-03  2.5244e-02\n",
       "    1.7199e-02 -4.0516e-03 -7.5878e-03\n",
       "   -1.6872e-03 -2.2875e-02  9.3754e-03\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    4.1214e-02  3.0056e-02 -4.7282e-03\n",
       "    2.2264e-02  1.7914e-02  3.0133e-02\n",
       "   -2.0791e-02  1.0826e-04  8.6414e-03\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -3.5780e-02 -1.8185e-03 -2.7754e-02\n",
       "   -7.9262e-03 -1.3500e-02  1.4361e-02\n",
       "   -6.9181e-03 -2.1344e-02 -1.6140e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    1.6379e-02  7.7216e-03  1.0829e-02\n",
       "   -2.6310e-02  2.7058e-02  2.0010e-03\n",
       "   -2.4491e-02 -8.3371e-03 -8.6772e-03\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -1.4463e-02 -2.3440e-02  1.3987e-02\n",
       "   -1.3850e-02  4.1766e-02 -4.4991e-02\n",
       "    4.4904e-02  1.2316e-02 -1.9610e-03\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "   -5.1622e-02 -2.8332e-02 -3.0689e-02\n",
       "   -3.6424e-03  3.0655e-02 -3.4329e-02\n",
       "   -1.9834e-02  1.0980e-02 -6.6216e-04\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    5.3597e-03 -2.8269e-02  5.4355e-02\n",
       "    2.0573e-02  1.0608e-02 -1.5748e-03\n",
       "    3.0945e-02  1.3182e-02  2.3061e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7826\n",
       "   0.7898\n",
       "   0.7542\n",
       "   0.7532\n",
       "   0.7642\n",
       "   0.7607\n",
       "   0.7687\n",
       "   0.7749\n",
       "   0.7574\n",
       "   0.7839\n",
       "   0.7904\n",
       "   0.7882\n",
       "   0.7862\n",
       "   0.7766\n",
       "   0.7813\n",
       "   0.7795\n",
       "   0.7441\n",
       "   0.7894\n",
       "   0.8103\n",
       "   0.7786\n",
       "   0.7861\n",
       "   0.7755\n",
       "   0.7939\n",
       "   0.7571\n",
       "   0.7745\n",
       "   0.7793\n",
       "   0.7759\n",
       "   0.7862\n",
       "   0.7796\n",
       "   0.7921\n",
       "   0.7799\n",
       "   0.7820\n",
       "   0.7278\n",
       "   0.8089\n",
       "   0.7937\n",
       "   0.7754\n",
       "   0.7680\n",
       "   0.8060\n",
       "   0.7849\n",
       "   0.7862\n",
       "   0.7845\n",
       "   0.8011\n",
       "   0.7638\n",
       "   0.7859\n",
       "   0.7980\n",
       "   0.7711\n",
       "   0.8004\n",
       "   0.7786\n",
       "   0.7707\n",
       "   0.7680\n",
       "   0.7782\n",
       "   0.8041\n",
       "   0.8010\n",
       "   0.7837\n",
       "   0.7984\n",
       "   0.7714\n",
       "   0.7746\n",
       "   0.8003\n",
       "   0.7717\n",
       "   0.7850\n",
       "   0.7953\n",
       "   0.7644\n",
       "   0.7770\n",
       "   0.7793\n",
       "   0.7866\n",
       "   0.7996\n",
       "   0.7880\n",
       "   0.7830\n",
       "   0.7639\n",
       "   0.7592\n",
       "   0.7836\n",
       "   0.7748\n",
       "   0.8126\n",
       "   0.8040\n",
       "   0.7867\n",
       "   0.7934\n",
       "   0.8142\n",
       "   0.7903\n",
       "   0.7577\n",
       "   0.7791\n",
       "   0.7514\n",
       "   0.8028\n",
       "   0.7326\n",
       "   0.7980\n",
       "   0.7700\n",
       "   0.7720\n",
       "   0.7808\n",
       "   0.7820\n",
       "   0.7743\n",
       "   0.7817\n",
       "   0.7838\n",
       "   0.8378\n",
       "   0.7770\n",
       "   0.7569\n",
       "   0.7949\n",
       "   0.7910\n",
       "   0.8116\n",
       "   0.7890\n",
       "   0.7558\n",
       "   0.7764\n",
       "   0.7926\n",
       "   0.7966\n",
       "   0.7852\n",
       "   0.7428\n",
       "   0.7959\n",
       "   0.8353\n",
       "   0.7656\n",
       "   0.7892\n",
       "   0.7725\n",
       "   0.7882\n",
       "   0.7490\n",
       "   0.7814\n",
       "   0.8164\n",
       "   0.7761\n",
       "   0.7802\n",
       "   0.7844\n",
       "   0.7575\n",
       "   0.7807\n",
       "   0.8047\n",
       "   0.7367\n",
       "   0.7755\n",
       "   0.7698\n",
       "   0.7615\n",
       "   0.8027\n",
       "   0.7716\n",
       "   0.7786\n",
       "   0.7894\n",
       "   0.7984\n",
       "   0.7795\n",
       "   0.7840\n",
       "   0.7690\n",
       "   0.7804\n",
       "   0.7754\n",
       "   0.8234\n",
       "   0.7615\n",
       "   0.7757\n",
       "   0.7812\n",
       "   0.7363\n",
       "   0.7901\n",
       "   0.7717\n",
       "   0.7783\n",
       "   0.7575\n",
       "   0.7721\n",
       "   0.7867\n",
       "   0.7827\n",
       "   0.8424\n",
       "   0.7655\n",
       "   0.7777\n",
       "   0.7941\n",
       "   0.7739\n",
       "   0.7847\n",
       "   0.7753\n",
       "   0.7755\n",
       "   0.7945\n",
       "   0.8075\n",
       "   0.7791\n",
       "   0.7765\n",
       "   0.7996\n",
       "   0.7795\n",
       "   0.7764\n",
       "   0.7827\n",
       "   0.7956\n",
       "   0.7667\n",
       "   0.7630\n",
       "   0.7832\n",
       "   0.7620\n",
       "   0.8168\n",
       "   0.7890\n",
       "   0.7916\n",
       "   0.7671\n",
       "   0.8134\n",
       "   0.7551\n",
       "   0.7775\n",
       "   0.7741\n",
       "   0.7916\n",
       "   0.7787\n",
       "   0.8201\n",
       "   0.7518\n",
       "   0.7800\n",
       "   0.7882\n",
       "   0.7650\n",
       "   0.8342\n",
       "   0.7791\n",
       "   0.7884\n",
       "   0.7715\n",
       "   0.7459\n",
       "   0.8010\n",
       "   0.7869\n",
       "   0.7729\n",
       "   0.8455\n",
       "   0.7899\n",
       "   0.7825\n",
       "   0.7517\n",
       "   0.7759\n",
       "   0.7602\n",
       "   0.8603\n",
       "   0.7885\n",
       "   0.7721\n",
       "   0.7629\n",
       "   0.7419\n",
       "   0.7799\n",
       "   0.7888\n",
       "   0.7791\n",
       "   0.7813\n",
       "   0.7804\n",
       "   0.7790\n",
       "   0.7916\n",
       "   0.7668\n",
       "   0.7906\n",
       "   0.7827\n",
       "   0.7868\n",
       "   0.7882\n",
       "   0.7780\n",
       "   0.7755\n",
       "   0.8037\n",
       "   0.8000\n",
       "   0.7590\n",
       "   0.7812\n",
       "   0.7367\n",
       "   0.7626\n",
       "   0.8348\n",
       "   0.7785\n",
       "   0.8063\n",
       "   0.7872\n",
       "   0.7963\n",
       "   0.7631\n",
       "   0.8089\n",
       "   0.7862\n",
       "   0.8340\n",
       "   0.7719\n",
       "   0.7595\n",
       "   0.7462\n",
       "   0.8108\n",
       "   0.7919\n",
       "   0.7762\n",
       "   0.7987\n",
       "   0.7998\n",
       "   0.7601\n",
       "   0.8006\n",
       "   0.8954\n",
       "   0.7727\n",
       "   0.7552\n",
       "   0.7785\n",
       "   0.7887\n",
       "   0.7766\n",
       "   0.7414\n",
       "   0.7788\n",
       "   0.7896\n",
       "   0.8149\n",
       "   0.7913\n",
       "   0.8081\n",
       "   0.8035\n",
       "   0.7541\n",
       "   0.7820\n",
       "   0.7682\n",
       "   0.7872\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0425\n",
       "  -0.0289\n",
       "  -0.0835\n",
       "  -0.0730\n",
       "  -0.0105\n",
       "  -0.0254\n",
       "   0.0304\n",
       "  -0.0115\n",
       "  -0.0225\n",
       "  -0.0764\n",
       "  -0.0459\n",
       "   0.0069\n",
       "   0.0031\n",
       "   0.0223\n",
       "  -0.0229\n",
       "  -0.0461\n",
       "  -0.1111\n",
       "   0.0221\n",
       "  -0.1162\n",
       "   0.0148\n",
       "  -0.1115\n",
       "   0.0005\n",
       "   0.0543\n",
       "  -0.0578\n",
       "  -0.0361\n",
       "  -0.0211\n",
       "  -0.0261\n",
       "   0.0387\n",
       "  -0.0044\n",
       "   0.0184\n",
       "  -0.1338\n",
       "  -0.0730\n",
       "  -0.1041\n",
       "  -0.0949\n",
       "  -0.0457\n",
       "  -0.0109\n",
       "  -0.0208\n",
       "   0.0550\n",
       "   0.0116\n",
       "  -0.0095\n",
       "   0.0256\n",
       "   0.0360\n",
       "  -0.0610\n",
       "  -0.0016\n",
       "   0.0407\n",
       "  -0.0434\n",
       "   0.1008\n",
       "   0.0165\n",
       "  -0.0733\n",
       "  -0.0256\n",
       "  -0.0063\n",
       "   0.0667\n",
       "   0.0872\n",
       "  -0.0027\n",
       "   0.0819\n",
       "  -0.0231\n",
       "  -0.0712\n",
       "   0.0644\n",
       "  -0.0739\n",
       "   0.0141\n",
       "  -0.1148\n",
       "  -0.0168\n",
       "  -0.0153\n",
       "   0.0069\n",
       "   0.0211\n",
       "  -0.0069\n",
       "  -0.0912\n",
       "   0.0323\n",
       "  -0.1469\n",
       "  -0.0228\n",
       "  -0.1020\n",
       "   0.0178\n",
       "   0.0443\n",
       "  -0.0120\n",
       "  -0.1128\n",
       "   0.0314\n",
       "   0.0295\n",
       "  -0.0233\n",
       "  -0.0013\n",
       "   0.0174\n",
       "  -0.1179\n",
       "   0.0230\n",
       "  -0.0785\n",
       "   0.0584\n",
       "  -0.0153\n",
       "   0.0114\n",
       "  -0.0101\n",
       "  -0.0986\n",
       "  -0.0403\n",
       "  -0.0401\n",
       "   0.0225\n",
       "   0.0006\n",
       "  -0.0809\n",
       "  -0.0179\n",
       "   0.0404\n",
       "   0.0797\n",
       "  -0.1347\n",
       "   0.0126\n",
       "  -0.0420\n",
       "  -0.0804\n",
       "  -0.0126\n",
       "  -0.0493\n",
       "   0.0453\n",
       "  -0.0401\n",
       "   0.0265\n",
       "  -0.0003\n",
       "  -0.0639\n",
       "  -0.0580\n",
       "  -0.0314\n",
       "  -0.0457\n",
       "  -0.0417\n",
       "  -0.0249\n",
       "  -0.1108\n",
       "   0.0154\n",
       "  -0.0317\n",
       "   0.0105\n",
       "  -0.0735\n",
       "   0.0197\n",
       "   0.0155\n",
       "  -0.0857\n",
       "   0.0517\n",
       "  -0.0086\n",
       "  -0.0747\n",
       "   0.0353\n",
       "  -0.0263\n",
       "  -0.0176\n",
       "  -0.0717\n",
       "   0.0010\n",
       "   0.0188\n",
       "   0.0295\n",
       "  -0.0268\n",
       "  -0.0056\n",
       "   0.0036\n",
       "   0.0694\n",
       "  -0.0634\n",
       "  -0.0320\n",
       "  -0.0765\n",
       "  -0.0056\n",
       "   0.0406\n",
       "  -0.0210\n",
       "  -0.0047\n",
       "  -0.0900\n",
       "  -0.0502\n",
       "   0.0139\n",
       "  -0.0070\n",
       "   0.0858\n",
       "  -0.0835\n",
       "   0.0037\n",
       "   0.0620\n",
       "  -0.0323\n",
       "  -0.1339\n",
       "  -0.0391\n",
       "  -0.0348\n",
       "   0.0465\n",
       "   0.0950\n",
       "  -0.1196\n",
       "  -0.0183\n",
       "  -0.1085\n",
       "  -0.1159\n",
       "  -0.0229\n",
       "   0.0310\n",
       "   0.0243\n",
       "  -0.0320\n",
       "  -0.0226\n",
       "  -0.0384\n",
       "  -0.0215\n",
       "   0.0893\n",
       "   0.0326\n",
       "   0.0450\n",
       "  -0.0355\n",
       "   0.1164\n",
       "  -0.0466\n",
       "  -0.0809\n",
       "   0.0251\n",
       "   0.0505\n",
       "  -0.0551\n",
       "   0.0928\n",
       "  -0.0513\n",
       "   0.0420\n",
       "   0.0040\n",
       "  -0.1063\n",
       "   0.0033\n",
       "   0.0156\n",
       "   0.0305\n",
       "  -0.0163\n",
       "  -0.0624\n",
       "   0.0380\n",
       "   0.0339\n",
       "  -0.1135\n",
       "   0.0617\n",
       "  -0.1157\n",
       "   0.0068\n",
       "  -0.0105\n",
       "   0.0007\n",
       "  -0.0650\n",
       "   0.0868\n",
       "   0.0082\n",
       "  -0.0431\n",
       "  -0.0824\n",
       "  -0.0552\n",
       "  -0.0099\n",
       "   0.0214\n",
       "  -0.0997\n",
       "  -0.0127\n",
       "   0.0052\n",
       "  -0.0961\n",
       "   0.0131\n",
       "  -0.0587\n",
       "   0.0520\n",
       "   0.0049\n",
       "  -0.0882\n",
       "   0.0093\n",
       "  -0.1241\n",
       "  -0.0635\n",
       "   0.0588\n",
       "   0.0273\n",
       "  -0.0935\n",
       "   0.0505\n",
       "  -0.0644\n",
       "   0.0222\n",
       "   0.0475\n",
       "  -0.0113\n",
       "   0.0593\n",
       "   0.0027\n",
       "   0.0153\n",
       "  -0.0943\n",
       "   0.0901\n",
       "   0.0387\n",
       "  -0.0764\n",
       "  -0.0855\n",
       "  -0.0303\n",
       "  -0.1687\n",
       "   0.0308\n",
       "   0.0589\n",
       "  -0.1357\n",
       "   0.0211\n",
       "   0.0894\n",
       "  -0.0679\n",
       "   0.0726\n",
       "   0.1621\n",
       "   0.0107\n",
       "  -0.0361\n",
       "   0.0099\n",
       "  -0.0303\n",
       "   0.0246\n",
       "  -0.0644\n",
       "   0.0354\n",
       "   0.0649\n",
       "   0.1482\n",
       "   0.0596\n",
       "   0.0283\n",
       "   0.0341\n",
       "  -0.0697\n",
       "  -0.0854\n",
       "  -0.0623\n",
       "   0.0143\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.1227e-02  1.1251e-03  5.3715e-03\n",
       "    7.2061e-03 -2.3212e-02 -4.4657e-02\n",
       "    2.4771e-02 -3.3812e-02  1.5352e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.1526e-02  3.0781e-02  1.8523e-02\n",
       "    3.1693e-02  1.3977e-02 -1.9475e-02\n",
       "    4.5869e-02  7.6924e-03 -5.5116e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    2.1634e-02  1.8069e-02 -1.6119e-02\n",
       "    1.2620e-02 -2.6055e-02  2.8162e-02\n",
       "    1.9797e-02  4.9341e-04  2.1494e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -2.6250e-02  1.9072e-02  1.0549e-02\n",
       "    5.3590e-03  3.8530e-02  1.2635e-02\n",
       "    6.1757e-02  1.8545e-02  5.5556e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -4.0122e-03  2.0295e-02 -3.5904e-02\n",
       "    1.8630e-02 -1.6225e-02 -1.4709e-02\n",
       "   -3.1853e-02 -6.8810e-03 -2.5286e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    6.3437e-03  9.9395e-03 -3.1608e-02\n",
       "    2.6782e-02  1.2840e-02  7.1241e-03\n",
       "   -2.8672e-03 -3.7966e-03  3.9652e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -1.8049e-03  4.0697e-03 -1.2972e-02\n",
       "   -1.4345e-02  1.3745e-02 -5.0176e-03\n",
       "   -5.0874e-03 -3.0926e-02 -2.8489e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    2.4229e-02  4.5387e-03  6.0367e-03\n",
       "    4.7546e-03 -3.3654e-02  3.9980e-02\n",
       "    9.4553e-04  2.3550e-02  4.4123e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.5453e-02  2.0907e-02 -2.6016e-02\n",
       "    2.1828e-02  3.7406e-04  9.0401e-03\n",
       "   -1.7602e-02 -1.3433e-02  4.1070e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    2.1340e-02 -2.8760e-03 -3.4083e-03\n",
       "   -2.1753e-02 -3.4083e-02 -3.3968e-02\n",
       "    4.3061e-04 -2.0343e-02 -1.6777e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -8.3807e-03  3.0170e-02 -9.4347e-03\n",
       "    6.0261e-03  4.7567e-03  2.9485e-04\n",
       "    7.0784e-03 -2.5571e-02 -3.4863e-03\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -4.5420e-02 -4.4160e-02 -1.2788e-03\n",
       "    8.7338e-03  3.8800e-03  2.3632e-02\n",
       "    4.8007e-02  4.0454e-03 -2.8500e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    6.0039e-03 -8.4745e-03  2.8527e-02\n",
       "   -1.4388e-02  6.6000e-03  4.3232e-02\n",
       "    1.3106e-03 -3.9228e-02 -2.0032e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    6.9668e-03 -3.0612e-02  1.4456e-02\n",
       "   -1.0731e-02  4.3607e-02 -9.4929e-03\n",
       "    1.3743e-02  3.6698e-03 -1.7360e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    2.0098e-02  3.6266e-02 -6.0889e-03\n",
       "    5.9905e-03  1.8056e-02 -1.4406e-02\n",
       "   -2.5594e-02  3.2713e-02 -1.8862e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    3.2924e-02 -1.8282e-02  7.8643e-03\n",
       "    9.9800e-03 -1.2656e-02 -2.9405e-02\n",
       "    5.8472e-03  2.1591e-02 -3.6565e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "   -1.6126e-03  9.9296e-03 -5.7364e-02\n",
       "   -4.7845e-02 -6.0800e-02  2.5848e-02\n",
       "   -1.6025e-02 -6.3781e-02  5.9668e-03\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -1.2946e-02  9.3039e-03 -6.1278e-03\n",
       "    3.2613e-03 -6.0994e-02 -6.0371e-03\n",
       "   -1.2439e-02  2.2836e-02  3.4242e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    5.1035e-03  6.6974e-03 -2.1013e-02\n",
       "    4.6364e-02  7.2383e-03  8.4347e-03\n",
       "    7.3056e-03 -1.4403e-02 -2.6754e-03\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -1.0228e-02  4.5322e-02  7.4250e-03\n",
       "   -8.7059e-03  9.8179e-03  2.8625e-02\n",
       "   -1.1734e-02  1.4900e-02 -3.7734e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -1.0290e-02  2.2980e-03 -5.5576e-03\n",
       "    1.8677e-02  1.9621e-02 -3.7188e-02\n",
       "    3.2757e-03 -3.8464e-02  6.7917e-03\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    3.0286e-02  2.5268e-02 -2.9760e-02\n",
       "   -3.5083e-03  2.2422e-02 -2.1851e-03\n",
       "    1.6298e-03 -1.0067e-02 -3.7431e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    2.0363e-02 -1.2798e-02  1.1274e-02\n",
       "   -1.6993e-02  2.9360e-02  6.7480e-03\n",
       "    2.5119e-02 -2.7228e-02 -3.4086e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "    2.7870e-02 -2.2822e-02 -1.3455e-02\n",
       "    1.1201e-03 -4.9389e-02  1.0887e-02\n",
       "   -2.6846e-02 -3.3159e-02  1.4305e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    1.5398e-02 -3.1867e-02 -3.3534e-02\n",
       "    2.4134e-02 -2.2146e-03  1.5183e-02\n",
       "    3.0435e-02  1.0752e-02 -2.2522e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    1.0994e-02  4.6644e-03  3.5057e-02\n",
       "   -4.3657e-03  2.1080e-02  7.8742e-03\n",
       "    8.9004e-03 -3.3574e-03  4.3822e-03\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    1.5868e-02  4.1077e-02 -2.4366e-02\n",
       "    5.5264e-02 -1.9352e-02  1.3826e-02\n",
       "   -9.6744e-03 -5.6795e-03  3.9872e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    1.9847e-02  1.8890e-02  1.9774e-02\n",
       "    2.0102e-02 -7.3087e-03  7.7971e-03\n",
       "   -2.7727e-02  2.1073e-02 -1.3416e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    2.9148e-02  5.3298e-02 -1.3621e-02\n",
       "    5.4690e-04  7.1300e-03  7.6809e-03\n",
       "    5.6859e-02  1.9254e-02  1.4090e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    5.5414e-03 -3.5340e-02  3.6143e-03\n",
       "    3.1626e-02  3.8099e-02  2.4634e-03\n",
       "   -3.8494e-03 -2.2753e-03  1.1923e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    2.4012e-02 -6.9359e-03 -1.5232e-02\n",
       "    2.8845e-03  1.9601e-02  8.0023e-03\n",
       "    1.3051e-02  1.4276e-02  3.7918e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    4.5606e-03  4.5644e-03  4.9780e-02\n",
       "   -2.2412e-02 -5.5407e-03  1.1400e-02\n",
       "    1.2036e-02  8.2516e-03 -7.6759e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    1.1958e-02  2.2803e-02 -5.7673e-03\n",
       "    1.6734e-02 -3.9089e-03 -5.6682e-03\n",
       "   -4.0049e-02 -1.0654e-02 -1.1455e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "    6.2254e-02 -3.4792e-03  4.3637e-02\n",
       "   -4.4585e-02  5.0826e-03  3.1877e-02\n",
       "    8.2576e-03  6.3556e-03  2.8723e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    1.2240e-03 -6.0421e-03 -1.1893e-02\n",
       "   -2.1647e-02 -8.9427e-03  1.8164e-02\n",
       "   -3.7739e-02  9.5270e-03  1.0473e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    7.2933e-03  3.1262e-02 -1.2949e-02\n",
       "   -4.4145e-02 -1.4004e-04  3.5008e-02\n",
       "   -7.7712e-03  1.2110e-02  3.6201e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.8079\n",
       "   0.8246\n",
       "   0.7909\n",
       "   0.7972\n",
       "   0.7853\n",
       "   0.7958\n",
       "   0.7621\n",
       "   0.7534\n",
       "   0.7660\n",
       "   0.7878\n",
       "   0.8084\n",
       "   0.7917\n",
       "   0.8267\n",
       "   0.8231\n",
       "   0.8145\n",
       "   0.7946\n",
       "   0.7852\n",
       "   0.7985\n",
       "   0.7849\n",
       "   0.7280\n",
       "   0.7679\n",
       "   0.7803\n",
       "   0.7809\n",
       "   0.7603\n",
       "   0.7678\n",
       "   0.7878\n",
       "   0.7562\n",
       "   0.7814\n",
       "   0.7776\n",
       "   0.8043\n",
       "   0.7696\n",
       "   0.7890\n",
       "   0.7799\n",
       "   0.8520\n",
       "   0.7532\n",
       "   0.7648\n",
       "   0.7816\n",
       "   0.7432\n",
       "   0.7762\n",
       "   0.8094\n",
       "   0.7578\n",
       "   0.7786\n",
       "   0.8157\n",
       "   0.7984\n",
       "   0.7866\n",
       "   0.7757\n",
       "   0.7639\n",
       "   0.7860\n",
       "   0.7906\n",
       "   0.7771\n",
       "   0.8173\n",
       "   0.7831\n",
       "   0.7872\n",
       "   0.7777\n",
       "   0.7722\n",
       "   0.7816\n",
       "   0.7608\n",
       "   0.7698\n",
       "   0.7338\n",
       "   0.7807\n",
       "   0.7516\n",
       "   0.7672\n",
       "   0.7983\n",
       "   0.8683\n",
       "   0.7619\n",
       "   0.8063\n",
       "   0.7373\n",
       "   0.7827\n",
       "   0.7763\n",
       "   0.7982\n",
       "   0.8040\n",
       "   0.7808\n",
       "   0.7608\n",
       "   0.7786\n",
       "   0.8002\n",
       "   0.7444\n",
       "   0.8068\n",
       "   0.7729\n",
       "   0.8027\n",
       "   0.7772\n",
       "   0.7779\n",
       "   0.7851\n",
       "   0.7562\n",
       "   0.8060\n",
       "   0.7544\n",
       "   0.7712\n",
       "   0.7609\n",
       "   0.8153\n",
       "   0.8040\n",
       "   0.8008\n",
       "   0.7938\n",
       "   0.7683\n",
       "   0.7730\n",
       "   0.7826\n",
       "   0.7950\n",
       "   0.7631\n",
       "   0.7501\n",
       "   0.9392\n",
       "   0.7617\n",
       "   0.7693\n",
       "   0.7900\n",
       "   0.8253\n",
       "   0.7527\n",
       "   0.7556\n",
       "   0.7544\n",
       "   0.7711\n",
       "   0.7788\n",
       "   0.7602\n",
       "   0.7736\n",
       "   0.7703\n",
       "   0.7853\n",
       "   0.7602\n",
       "   0.7939\n",
       "   0.7932\n",
       "   0.8015\n",
       "   0.7992\n",
       "   0.7789\n",
       "   0.7786\n",
       "   0.7852\n",
       "   0.7930\n",
       "   0.7779\n",
       "   0.7604\n",
       "   0.7853\n",
       "   0.7713\n",
       "   0.7477\n",
       "   0.8167\n",
       "   0.7565\n",
       "   0.7529\n",
       "   0.7736\n",
       "   0.7830\n",
       "   0.7740\n",
       "   0.8112\n",
       "   0.7498\n",
       "   0.7637\n",
       "   0.7909\n",
       "   0.7771\n",
       "   0.7604\n",
       "   0.7695\n",
       "   0.7754\n",
       "   0.7644\n",
       "   0.7763\n",
       "   0.7826\n",
       "   0.7754\n",
       "   0.8056\n",
       "   0.7822\n",
       "   0.7699\n",
       "   0.7943\n",
       "   0.7575\n",
       "   0.7656\n",
       "   0.7596\n",
       "   0.7603\n",
       "   0.7796\n",
       "   0.7860\n",
       "   0.7363\n",
       "   0.7948\n",
       "   0.7774\n",
       "   0.7392\n",
       "   0.7547\n",
       "   0.7678\n",
       "   0.8094\n",
       "   0.7784\n",
       "   0.7833\n",
       "   0.7854\n",
       "   0.7785\n",
       "   0.7531\n",
       "   0.7676\n",
       "   0.7612\n",
       "   0.7756\n",
       "   0.7910\n",
       "   0.7621\n",
       "   0.7897\n",
       "   0.8318\n",
       "   0.7956\n",
       "   0.7841\n",
       "   0.7542\n",
       "   0.7611\n",
       "   0.7415\n",
       "   0.7899\n",
       "   0.7673\n",
       "   0.7507\n",
       "   0.7757\n",
       "   0.7958\n",
       "   0.7511\n",
       "   0.7861\n",
       "   0.7982\n",
       "   0.7798\n",
       "   0.8171\n",
       "   0.7843\n",
       "   0.8013\n",
       "   0.8329\n",
       "   0.7924\n",
       "   0.7660\n",
       "   0.7753\n",
       "   0.7512\n",
       "   0.7558\n",
       "   0.7859\n",
       "   0.7797\n",
       "   0.7935\n",
       "   0.7857\n",
       "   0.8138\n",
       "   0.7890\n",
       "   0.7933\n",
       "   0.7499\n",
       "   0.7857\n",
       "   0.7522\n",
       "   0.7791\n",
       "   0.7734\n",
       "   0.7688\n",
       "   0.7633\n",
       "   0.7848\n",
       "   0.7587\n",
       "   0.7925\n",
       "   0.7697\n",
       "   0.7960\n",
       "   0.8035\n",
       "   0.7803\n",
       "   0.8229\n",
       "   0.7681\n",
       "   0.7693\n",
       "   0.7827\n",
       "   0.7785\n",
       "   0.7799\n",
       "   0.7805\n",
       "   0.8006\n",
       "   0.7458\n",
       "   0.7890\n",
       "   0.7916\n",
       "   0.7697\n",
       "   0.7663\n",
       "   0.7761\n",
       "   0.7990\n",
       "   0.8184\n",
       "   0.7654\n",
       "   0.7873\n",
       "   0.8487\n",
       "   0.7836\n",
       "   0.7766\n",
       "   0.7730\n",
       "   0.8307\n",
       "   0.7625\n",
       "   0.7688\n",
       "   0.8109\n",
       "   0.7565\n",
       "   0.7851\n",
       "   0.7722\n",
       "   0.7693\n",
       "   0.8113\n",
       "   0.7665\n",
       "   0.7899\n",
       "   0.7850\n",
       "   0.7758\n",
       "   0.7924\n",
       "   0.7457\n",
       "   0.7829\n",
       "   0.7710\n",
       "   0.7745\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0435\n",
       "   0.0972\n",
       "  -0.0970\n",
       "  -0.0330\n",
       "   0.0659\n",
       "  -0.1428\n",
       "  -0.0265\n",
       "  -0.0310\n",
       "  -0.0073\n",
       "  -0.0560\n",
       "  -0.0364\n",
       "  -0.0101\n",
       "   0.0677\n",
       "   0.0173\n",
       "  -0.1356\n",
       "  -0.0827\n",
       "   0.0208\n",
       "  -0.0585\n",
       "   0.0601\n",
       "  -0.0972\n",
       "  -0.0721\n",
       "   0.0354\n",
       "  -0.0206\n",
       "  -0.0620\n",
       "  -0.0399\n",
       "  -0.0724\n",
       "  -0.0543\n",
       "  -0.0131\n",
       "  -0.0381\n",
       "  -0.0760\n",
       "  -0.0244\n",
       "  -0.0676\n",
       "   0.0147\n",
       "   0.1981\n",
       "  -0.0658\n",
       "  -0.0260\n",
       "  -0.0195\n",
       "  -0.0651\n",
       "  -0.0199\n",
       "  -0.0542\n",
       "  -0.0539\n",
       "  -0.0109\n",
       "  -0.0806\n",
       "  -0.0639\n",
       "  -0.0730\n",
       "  -0.0683\n",
       "  -0.0313\n",
       "   0.0237\n",
       "  -0.0831\n",
       "  -0.0255\n",
       "  -0.1457\n",
       "   0.0666\n",
       "  -0.0156\n",
       "  -0.0007\n",
       "  -0.1055\n",
       "  -0.0199\n",
       "  -0.0128\n",
       "  -0.0680\n",
       "  -0.1187\n",
       "   0.0238\n",
       "  -0.0507\n",
       "  -0.0443\n",
       "   0.0449\n",
       "   0.1072\n",
       "  -0.0807\n",
       "  -0.1067\n",
       "  -0.0529\n",
       "  -0.0449\n",
       "  -0.0829\n",
       "   0.0503\n",
       "  -0.0657\n",
       "  -0.0498\n",
       "  -0.0359\n",
       "  -0.0604\n",
       "  -0.0108\n",
       "  -0.0367\n",
       "  -0.0636\n",
       "  -0.0292\n",
       "   0.0578\n",
       "  -0.0618\n",
       "  -0.0313\n",
       "  -0.0242\n",
       "  -0.1230\n",
       "   0.0037\n",
       "  -0.0646\n",
       "  -0.0268\n",
       "  -0.0567\n",
       "  -0.0461\n",
       "  -0.0234\n",
       "  -0.0288\n",
       "  -0.0069\n",
       "  -0.0268\n",
       "  -0.0475\n",
       "  -0.0366\n",
       "  -0.0588\n",
       "  -0.0922\n",
       "  -0.0669\n",
       "   0.0396\n",
       "  -0.0608\n",
       "  -0.0145\n",
       "  -0.0228\n",
       "   0.0813\n",
       "   0.0227\n",
       "  -0.0561\n",
       "  -0.0654\n",
       "  -0.0983\n",
       "   0.0294\n",
       "  -0.0264\n",
       "  -0.0003\n",
       "  -0.0174\n",
       "  -0.0401\n",
       "  -0.0061\n",
       "  -0.1102\n",
       "   0.0597\n",
       "   0.0566\n",
       "   0.0035\n",
       "  -0.1143\n",
       "  -0.0226\n",
       "  -0.0435\n",
       "  -0.0223\n",
       "  -0.0500\n",
       "  -0.0908\n",
       "  -0.0274\n",
       "  -0.0428\n",
       "  -0.0623\n",
       "  -0.0249\n",
       "  -0.0343\n",
       "  -0.0342\n",
       "  -0.0341\n",
       "  -0.0184\n",
       "  -0.0169\n",
       "  -0.0239\n",
       "  -0.0369\n",
       "  -0.0769\n",
       "  -0.0321\n",
       "   0.0059\n",
       "  -0.0312\n",
       "  -0.0086\n",
       "  -0.0417\n",
       "  -0.0422\n",
       "  -0.0263\n",
       "  -0.0374\n",
       "  -0.0123\n",
       "  -0.0700\n",
       "  -0.0354\n",
       "  -0.0979\n",
       "   0.0405\n",
       "  -0.0370\n",
       "  -0.0335\n",
       "  -0.0949\n",
       "  -0.0260\n",
       "  -0.0464\n",
       "  -0.0390\n",
       "  -0.0169\n",
       "  -0.0253\n",
       "  -0.0395\n",
       "  -0.0935\n",
       "  -0.0062\n",
       "  -0.0577\n",
       "   0.0537\n",
       "  -0.0321\n",
       "  -0.0408\n",
       "  -0.0657\n",
       "   0.0106\n",
       "   0.0666\n",
       "   0.0063\n",
       "  -0.0206\n",
       "   0.0023\n",
       "  -0.0490\n",
       "  -0.0803\n",
       "  -0.0005\n",
       "  -0.0630\n",
       "   0.0582\n",
       "  -0.0063\n",
       "  -0.0629\n",
       "  -0.0537\n",
       "  -0.0388\n",
       "  -0.0311\n",
       "  -0.0667\n",
       "  -0.0605\n",
       "  -0.0366\n",
       "  -0.1317\n",
       "  -0.0317\n",
       "  -0.1035\n",
       "  -0.0943\n",
       "  -0.0845\n",
       "   0.0812\n",
       "  -0.0491\n",
       "  -0.0607\n",
       "   0.0020\n",
       "   0.0599\n",
       "  -0.0776\n",
       "  -0.1950\n",
       "  -0.0332\n",
       "  -0.0400\n",
       "  -0.0471\n",
       "   0.0031\n",
       "   0.0740\n",
       "  -0.1005\n",
       "   0.0134\n",
       "   0.0027\n",
       "   0.0244\n",
       "  -0.0711\n",
       "  -0.0582\n",
       "  -0.0561\n",
       "  -0.0594\n",
       "  -0.0477\n",
       "  -0.0989\n",
       "  -0.0944\n",
       "  -0.0288\n",
       "  -0.0493\n",
       "  -0.1550\n",
       "  -0.0391\n",
       "   0.0277\n",
       "   0.0079\n",
       "  -0.0859\n",
       "  -0.0506\n",
       "  -0.0205\n",
       "   0.0367\n",
       "  -0.0827\n",
       "  -0.0231\n",
       "  -0.0344\n",
       "  -0.0571\n",
       "   0.0113\n",
       "  -0.0624\n",
       "  -0.0506\n",
       "  -0.0073\n",
       "  -0.0288\n",
       "  -0.0679\n",
       "  -0.0698\n",
       "  -0.0252\n",
       "   0.0340\n",
       "  -0.0595\n",
       "   0.0138\n",
       "  -0.0043\n",
       "  -0.0433\n",
       "   0.0006\n",
       "  -0.0559\n",
       "  -0.0840\n",
       "  -0.0533\n",
       "  -0.0188\n",
       "   0.0206\n",
       "  -0.0491\n",
       "   0.0196\n",
       "  -0.0090\n",
       "  -0.0622\n",
       "   0.0441\n",
       "  -0.0216\n",
       "  -0.0177\n",
       "  -0.1257\n",
       "  -0.0158\n",
       "  -0.0582\n",
       "  -0.0643\n",
       "  -0.0256\n",
       "  -0.0710\n",
       "  -0.0296\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.4668e-02 -4.1399e-03 -1.0397e-02\n",
       "    9.0343e-03  2.9162e-02  2.0996e-02\n",
       "    1.8523e-02  1.5654e-02  4.8811e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    1.5605e-02 -4.3750e-02  4.1747e-02\n",
       "   -1.7516e-02  5.8231e-03 -2.2956e-02\n",
       "   -3.2322e-03 -8.9939e-03 -2.2608e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    4.3335e-03 -3.6811e-03  4.1959e-03\n",
       "    1.1863e-02  1.3406e-02  6.4124e-03\n",
       "   -1.5157e-03  4.3986e-02 -2.2076e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    9.0389e-03 -3.7477e-02 -3.0720e-02\n",
       "    8.9551e-03  2.1905e-02 -2.9049e-02\n",
       "    9.5290e-03  7.9022e-03 -1.3960e-03\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    4.5265e-02  1.1065e-02  7.5116e-03\n",
       "   -1.0424e-02  3.3607e-03 -1.3872e-02\n",
       "   -4.3293e-03 -4.7829e-03  9.1682e-03\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    3.0773e-02  4.5837e-03  1.3834e-02\n",
       "   -5.9348e-02  9.4360e-04  1.2501e-02\n",
       "    3.1739e-02 -2.7520e-02  2.2490e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    4.1042e-02 -2.3328e-02  2.5579e-02\n",
       "    1.0688e-02 -2.4484e-02  1.1247e-03\n",
       "   -7.9411e-03  2.7624e-02  1.7300e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -3.9753e-02  9.9546e-03 -8.5764e-03\n",
       "    3.6870e-02 -1.0773e-03 -7.6383e-03\n",
       "   -9.0393e-03  8.5899e-03  6.7154e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    6.4407e-03 -3.0397e-02 -8.8189e-03\n",
       "   -2.0137e-02 -4.1718e-04  3.2042e-03\n",
       "   -7.6660e-03 -1.4762e-02 -8.2096e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "   -2.9285e-02 -1.5048e-02  5.9486e-02\n",
       "    1.3174e-02 -2.4807e-02  3.7977e-02\n",
       "    1.2389e-03  3.0323e-02  1.6206e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    1.3910e-02 -4.9836e-02 -2.5527e-02\n",
       "   -4.2137e-02 -2.1826e-02  1.4292e-02\n",
       "   -1.4300e-02  1.0606e-02 -6.1280e-03\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    1.1651e-02 -9.3131e-03  2.3282e-02\n",
       "   -1.0349e-03 -7.1914e-03 -1.4027e-04\n",
       "    2.6475e-02  1.0814e-02 -1.1227e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    4.3829e-02 -1.0220e-02 -1.1109e-02\n",
       "    5.0373e-02  2.2902e-02 -5.5933e-02\n",
       "    2.6755e-02  7.9390e-03  3.9333e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    1.8983e-02  1.8764e-02 -2.2932e-03\n",
       "    6.5302e-02  6.1329e-02  6.9343e-03\n",
       "    5.1868e-02 -9.1650e-03  7.6991e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    4.7128e-02 -5.2469e-03 -1.2937e-02\n",
       "   -1.1368e-02  5.1021e-02 -1.3128e-02\n",
       "    1.3970e-02  4.7932e-03 -1.5536e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "   -3.7428e-03  1.6110e-02 -1.7998e-02\n",
       "    1.0136e-02  1.5767e-02 -3.8010e-02\n",
       "    1.5210e-02 -3.4451e-02 -6.0009e-03\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    2.0685e-03  2.0980e-03  6.1585e-02\n",
       "   -8.7313e-03  2.5525e-02 -2.3347e-02\n",
       "    1.3838e-02 -4.7080e-02 -4.0827e-04\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    5.1953e-03 -1.5842e-02 -5.1672e-02\n",
       "    1.4469e-02 -1.3091e-02 -2.9896e-02\n",
       "    4.5770e-02  1.0303e-04  2.5101e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    2.6756e-02 -3.5036e-02  4.3903e-02\n",
       "   -3.0176e-02 -1.7625e-03 -6.7407e-04\n",
       "   -1.5219e-02  1.6027e-02 -1.5076e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    2.2853e-02 -3.0828e-03  6.4885e-03\n",
       "   -1.8858e-02 -4.2303e-03  5.1865e-03\n",
       "    1.9894e-02  2.9288e-02  6.9348e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -3.1113e-02 -4.0027e-02  1.6645e-02\n",
       "   -3.4930e-02 -3.5418e-02  7.2164e-03\n",
       "   -3.5361e-02 -5.1704e-02  1.7856e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "   -1.3754e-02 -8.9552e-03  7.8442e-03\n",
       "    2.8791e-02 -2.8147e-02  7.6840e-03\n",
       "    2.0197e-02  2.3479e-02  9.7022e-03\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    3.0621e-02 -5.0098e-03 -5.4397e-03\n",
       "    1.5859e-02  1.8326e-02  2.0924e-02\n",
       "   -4.3845e-03  2.5101e-02  2.6197e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -7.3956e-03 -1.4043e-02  8.6685e-03\n",
       "   -5.0414e-03  1.6785e-02  2.4693e-02\n",
       "    6.1726e-03 -1.0826e-02 -1.0074e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -3.0020e-03 -4.7743e-02 -1.6731e-02\n",
       "   -1.1604e-02 -3.6640e-02 -3.8261e-02\n",
       "    3.5630e-02  1.9535e-02 -1.4390e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    1.8665e-02 -4.8067e-02  3.8646e-02\n",
       "    2.0076e-02  1.2128e-02 -2.8841e-02\n",
       "   -1.5288e-02 -1.7239e-02 -9.2288e-03\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    1.9325e-02 -7.7447e-02  5.9182e-03\n",
       "    2.6870e-02  3.3546e-02 -2.4275e-03\n",
       "    3.0590e-02  6.1534e-03  2.8289e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    3.4763e-02 -5.8032e-02  2.4303e-03\n",
       "   -2.5954e-03 -1.5480e-02 -5.3503e-03\n",
       "    1.1004e-02  1.7194e-02 -1.6793e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    3.1142e-02  3.9295e-02  2.5239e-02\n",
       "   -2.6694e-03 -6.5686e-03  1.8174e-02\n",
       "    8.6083e-03  1.9330e-02  2.0258e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    2.2961e-02 -3.9636e-03  1.1309e-03\n",
       "    2.1406e-02  1.0409e-02 -1.6444e-02\n",
       "    2.0676e-02  2.1344e-02  2.9120e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -1.1097e-02 -1.5451e-02 -3.8529e-02\n",
       "   -3.4672e-02 -2.7788e-02 -4.5949e-02\n",
       "   -5.5201e-02 -5.1865e-03 -2.6928e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -6.5977e-03 -3.0149e-02 -7.9226e-03\n",
       "   -1.7384e-02  8.9357e-03 -2.0559e-02\n",
       "   -4.8564e-02 -4.3257e-02 -2.6124e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    1.2849e-02  2.7893e-02 -6.1354e-03\n",
       "   -1.6254e-02 -1.9512e-03  3.2102e-02\n",
       "   -5.0174e-02 -1.9272e-03 -3.0328e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -5.8531e-03  2.4180e-03 -5.4398e-02\n",
       "   -1.1991e-02  3.0492e-02 -2.8974e-02\n",
       "    4.1675e-02  3.6449e-02  2.7488e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "   -2.0525e-02 -8.6351e-03 -1.6096e-02\n",
       "   -9.5908e-03  4.4899e-02  2.8347e-02\n",
       "    2.8046e-02  1.6512e-02  2.6196e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    5.3014e-02 -2.2524e-02 -1.8360e-02\n",
       "   -5.0609e-04 -2.2197e-02 -2.0141e-02\n",
       "    5.5831e-02 -3.5545e-02  1.0788e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7923\n",
       "   0.7795\n",
       "   0.7637\n",
       "   0.7761\n",
       "   0.7781\n",
       "   0.7746\n",
       "   0.7856\n",
       "   0.7791\n",
       "   0.7931\n",
       "   0.8021\n",
       "   0.7759\n",
       "   0.7801\n",
       "   0.7800\n",
       "   0.8062\n",
       "   0.7890\n",
       "   0.7982\n",
       "   0.8036\n",
       "   0.7785\n",
       "   0.7772\n",
       "   0.7722\n",
       "   0.7990\n",
       "   0.7707\n",
       "   0.7701\n",
       "   0.7812\n",
       "   0.7917\n",
       "   0.7814\n",
       "   0.7878\n",
       "   0.7867\n",
       "   0.7963\n",
       "   0.8041\n",
       "   0.7784\n",
       "   0.7633\n",
       "   0.7886\n",
       "   0.7836\n",
       "   0.7836\n",
       "   0.7828\n",
       "   0.7550\n",
       "   0.7911\n",
       "   0.7946\n",
       "   0.7810\n",
       "   0.7786\n",
       "   0.7946\n",
       "   0.7637\n",
       "   0.8036\n",
       "   0.7882\n",
       "   0.7878\n",
       "   0.7767\n",
       "   0.7599\n",
       "   0.7825\n",
       "   0.7771\n",
       "   0.7851\n",
       "   0.7746\n",
       "   0.7908\n",
       "   0.7856\n",
       "   0.7943\n",
       "   0.7935\n",
       "   0.7774\n",
       "   0.7720\n",
       "   0.7919\n",
       "   0.7969\n",
       "   0.7818\n",
       "   0.7807\n",
       "   0.7909\n",
       "   0.7793\n",
       "   0.7790\n",
       "   0.7843\n",
       "   0.7801\n",
       "   0.7806\n",
       "   0.7811\n",
       "   0.7828\n",
       "   0.7729\n",
       "   0.7790\n",
       "   0.7800\n",
       "   0.8059\n",
       "   0.7737\n",
       "   0.7492\n",
       "   0.8011\n",
       "   0.7832\n",
       "   0.7786\n",
       "   0.7843\n",
       "   0.7555\n",
       "   0.7935\n",
       "   0.8096\n",
       "   0.7809\n",
       "   0.7804\n",
       "   0.7927\n",
       "   0.7875\n",
       "   0.7703\n",
       "   0.7743\n",
       "   0.7826\n",
       "   0.7883\n",
       "   0.7830\n",
       "   0.7910\n",
       "   0.7836\n",
       "   0.7706\n",
       "   0.7884\n",
       "   0.7904\n",
       "   0.7891\n",
       "   0.7795\n",
       "   0.7860\n",
       "   0.7947\n",
       "   0.7778\n",
       "   0.7760\n",
       "   0.7850\n",
       "   0.7706\n",
       "   0.7669\n",
       "   0.7792\n",
       "   0.7918\n",
       "   0.7823\n",
       "   0.7841\n",
       "   0.7742\n",
       "   0.7890\n",
       "   0.7818\n",
       "   0.7828\n",
       "   0.7786\n",
       "   0.7953\n",
       "   0.7927\n",
       "   0.7838\n",
       "   0.7681\n",
       "   0.7853\n",
       "   0.7901\n",
       "   0.7848\n",
       "   0.7761\n",
       "   0.7811\n",
       "   0.7830\n",
       "   0.8003\n",
       "   0.7754\n",
       "   0.7947\n",
       "   0.7770\n",
       "   0.8031\n",
       "   0.7778\n",
       "   0.7938\n",
       "   0.7756\n",
       "   0.7810\n",
       "   0.7687\n",
       "   0.7876\n",
       "   0.7835\n",
       "   0.7832\n",
       "   0.7761\n",
       "   0.7708\n",
       "   0.7955\n",
       "   0.7822\n",
       "   0.7976\n",
       "   0.7960\n",
       "   0.7600\n",
       "   0.7681\n",
       "   0.7733\n",
       "   0.7833\n",
       "   0.7985\n",
       "   0.7946\n",
       "   0.7782\n",
       "   0.7756\n",
       "   0.7755\n",
       "   0.7698\n",
       "   0.7789\n",
       "   0.7754\n",
       "   0.7807\n",
       "   0.7865\n",
       "   0.7829\n",
       "   0.7772\n",
       "   0.7773\n",
       "   0.7747\n",
       "   0.7657\n",
       "   0.7720\n",
       "   0.7766\n",
       "   0.7793\n",
       "   0.7708\n",
       "   0.7807\n",
       "   0.7797\n",
       "   0.7648\n",
       "   0.7581\n",
       "   0.7800\n",
       "   0.7780\n",
       "   0.7778\n",
       "   0.7859\n",
       "   0.7933\n",
       "   0.7975\n",
       "   0.7945\n",
       "   0.7740\n",
       "   0.7784\n",
       "   0.7816\n",
       "   0.7720\n",
       "   0.7823\n",
       "   0.7830\n",
       "   0.7806\n",
       "   0.7817\n",
       "   0.7834\n",
       "   0.7803\n",
       "   0.7887\n",
       "   0.7829\n",
       "   0.7906\n",
       "   0.8008\n",
       "   0.7814\n",
       "   0.7650\n",
       "   0.7818\n",
       "   0.7875\n",
       "   0.7796\n",
       "   0.7783\n",
       "   0.7682\n",
       "   0.7763\n",
       "   0.7868\n",
       "   0.8150\n",
       "   0.7884\n",
       "   0.7877\n",
       "   0.7962\n",
       "   0.7773\n",
       "   0.7759\n",
       "   0.7713\n",
       "   0.7933\n",
       "   0.7845\n",
       "   0.7739\n",
       "   0.7844\n",
       "   0.8086\n",
       "   0.7922\n",
       "   0.8000\n",
       "   0.7834\n",
       "   0.7794\n",
       "   0.7911\n",
       "   0.7812\n",
       "   0.7979\n",
       "   0.7852\n",
       "   0.7730\n",
       "   0.8092\n",
       "   0.7837\n",
       "   0.7768\n",
       "   0.7886\n",
       "   0.7754\n",
       "   0.7925\n",
       "   0.7933\n",
       "   0.7854\n",
       "   0.7913\n",
       "   0.7791\n",
       "   0.7800\n",
       "   0.8039\n",
       "   0.7792\n",
       "   0.7897\n",
       "   0.7852\n",
       "   0.7688\n",
       "   0.8049\n",
       "   0.7792\n",
       "   0.8036\n",
       "   0.7792\n",
       "   0.7911\n",
       "   0.7918\n",
       "   0.7851\n",
       "   0.7981\n",
       "   0.7919\n",
       "   0.7732\n",
       "   0.7935\n",
       "   0.7786\n",
       "   0.7793\n",
       "   0.7716\n",
       "   0.7786\n",
       "   0.7904\n",
       "   0.7789\n",
       "   0.7918\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "   0.0161\n",
       "  -0.0270\n",
       "  -0.0264\n",
       "  -0.0650\n",
       "  -0.0197\n",
       "   0.0035\n",
       "   0.0209\n",
       "  -0.0117\n",
       "  -0.0279\n",
       "   0.0319\n",
       "  -0.0030\n",
       "  -0.0001\n",
       "   0.0050\n",
       "   0.0402\n",
       "   0.0258\n",
       "   0.0507\n",
       "  -0.0401\n",
       "  -0.0046\n",
       "  -0.0598\n",
       "  -0.0250\n",
       "  -0.0260\n",
       "  -0.0079\n",
       "  -0.0076\n",
       "   0.0126\n",
       "   0.0127\n",
       "   0.0058\n",
       "   0.0234\n",
       "  -0.0094\n",
       "   0.0230\n",
       "   0.0213\n",
       "  -0.0160\n",
       "  -0.0529\n",
       "   0.0150\n",
       "  -0.0459\n",
       "  -0.0219\n",
       "   0.0320\n",
       "  -0.0450\n",
       "   0.0207\n",
       "   0.0291\n",
       "  -0.0099\n",
       "  -0.0064\n",
       "  -0.1032\n",
       "  -0.0226\n",
       "   0.0077\n",
       "   0.0065\n",
       "  -0.0358\n",
       "  -0.0966\n",
       "  -0.0448\n",
       "   0.0545\n",
       "  -0.0050\n",
       "   0.0052\n",
       "  -0.0084\n",
       "  -0.0654\n",
       "  -0.0082\n",
       "   0.0406\n",
       "   0.0361\n",
       "  -0.0384\n",
       "  -0.0191\n",
       "  -0.0951\n",
       "   0.0356\n",
       "   0.0072\n",
       "  -0.0017\n",
       "  -0.0516\n",
       "  -0.0039\n",
       "  -0.0450\n",
       "   0.0145\n",
       "   0.0082\n",
       "  -0.0664\n",
       "   0.0245\n",
       "   0.0117\n",
       "  -0.0708\n",
       "  -0.0079\n",
       "   0.0075\n",
       "  -0.0727\n",
       "  -0.0194\n",
       "  -0.0852\n",
       "   0.0562\n",
       "  -0.0085\n",
       "  -0.0220\n",
       "   0.0169\n",
       "  -0.0141\n",
       "   0.0274\n",
       "  -0.0946\n",
       "  -0.0097\n",
       "   0.0041\n",
       "   0.0154\n",
       "   0.0118\n",
       "  -0.0250\n",
       "   0.0123\n",
       "   0.0027\n",
       "  -0.0583\n",
       "  -0.0673\n",
       "   0.0205\n",
       "   0.0227\n",
       "  -0.0219\n",
       "  -0.0815\n",
       "   0.0389\n",
       "   0.0173\n",
       "   0.0169\n",
       "   0.0162\n",
       "  -0.0220\n",
       "  -0.0315\n",
       "   0.0112\n",
       "   0.0035\n",
       "  -0.0454\n",
       "  -0.0395\n",
       "  -0.0012\n",
       "   0.0331\n",
       "   0.0085\n",
       "  -0.0041\n",
       "   0.0081\n",
       "   0.0199\n",
       "  -0.0351\n",
       "  -0.0091\n",
       "  -0.0128\n",
       "   0.0160\n",
       "   0.0774\n",
       "   0.0099\n",
       "  -0.0190\n",
       "   0.0181\n",
       "   0.0300\n",
       "  -0.0164\n",
       "  -0.0327\n",
       "  -0.0158\n",
       "  -0.0757\n",
       "  -0.0738\n",
       "  -0.0511\n",
       "  -0.0929\n",
       "  -0.0703\n",
       "   0.0625\n",
       "  -0.0067\n",
       "  -0.0361\n",
       "  -0.1405\n",
       "  -0.0099\n",
       "  -0.0173\n",
       "   0.0084\n",
       "  -0.0389\n",
       "   0.0135\n",
       "  -0.1100\n",
       "   0.0058\n",
       "   0.0151\n",
       "  -0.1148\n",
       "   0.0375\n",
       "  -0.0807\n",
       "  -0.1025\n",
       "  -0.0561\n",
       "  -0.1043\n",
       "  -0.0373\n",
       "   0.0414\n",
       "   0.0422\n",
       "  -0.0251\n",
       "  -0.0065\n",
       "   0.0089\n",
       "  -0.0443\n",
       "  -0.0429\n",
       "  -0.0132\n",
       "   0.0115\n",
       "  -0.0785\n",
       "   0.0752\n",
       "  -0.0350\n",
       "  -0.0460\n",
       "  -0.0196\n",
       "  -0.0959\n",
       "  -0.0922\n",
       "  -0.0641\n",
       "  -0.0411\n",
       "  -0.0744\n",
       "  -0.0217\n",
       "  -0.0048\n",
       "  -0.0288\n",
       "  -0.0616\n",
       "  -0.0425\n",
       "  -0.0112\n",
       "   0.0212\n",
       "   0.0052\n",
       "  -0.0161\n",
       "  -0.0201\n",
       "  -0.0085\n",
       "  -0.0231\n",
       "  -0.0021\n",
       "  -0.0001\n",
       "  -0.1025\n",
       "  -0.0592\n",
       "   0.0286\n",
       "   0.0208\n",
       "  -0.0764\n",
       "  -0.0226\n",
       "  -0.0336\n",
       "   0.0234\n",
       "   0.0322\n",
       "   0.0045\n",
       "   0.0690\n",
       "   0.0369\n",
       "  -0.0234\n",
       "  -0.0443\n",
       "   0.0276\n",
       "  -0.0069\n",
       "  -0.0170\n",
       "   0.0030\n",
       "  -0.0567\n",
       "   0.0277\n",
       "  -0.1009\n",
       "   0.0235\n",
       "   0.0602\n",
       "   0.0415\n",
       "  -0.0931\n",
       "  -0.0868\n",
       "  -0.0179\n",
       "   0.0055\n",
       "   0.0475\n",
       "  -0.0277\n",
       "   0.0123\n",
       "   0.0698\n",
       "  -0.0151\n",
       "  -0.0584\n",
       "  -0.1046\n",
       "  -0.0092\n",
       "   0.0187\n",
       "   0.0509\n",
       "   0.0792\n",
       "   0.0016\n",
       "  -0.0113\n",
       "   0.0009\n",
       "  -0.0619\n",
       "  -0.0338\n",
       "  -0.0648\n",
       "  -0.0073\n",
       "   0.0299\n",
       "  -0.0724\n",
       "  -0.0229\n",
       "  -0.0282\n",
       "  -0.0400\n",
       "   0.0113\n",
       "  -0.0865\n",
       "  -0.0439\n",
       "  -0.0548\n",
       "  -0.0098\n",
       "  -0.0205\n",
       "   0.0164\n",
       "  -0.0909\n",
       "   0.0404\n",
       "  -0.0361\n",
       "   0.0107\n",
       "   0.0324\n",
       "   0.0481\n",
       "  -0.0227\n",
       "  -0.0278\n",
       "  -0.0338\n",
       "  -0.0376\n",
       "   0.0017\n",
       "  -0.0893\n",
       "  -0.0426\n",
       "   0.0106\n",
       "   0.0516\n",
       "  -0.0533\n",
       "   0.0236\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -8.7616e-03  1.1042e-02  3.9612e-02\n",
       "    9.2329e-03  1.1642e-02  1.3619e-02\n",
       "    1.2317e-02  7.0382e-03 -1.7411e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    1.4871e-03 -1.0810e-02 -1.0362e-02\n",
       "   -2.5897e-02 -2.4948e-02 -3.1483e-02\n",
       "   -5.2335e-02 -4.4776e-02 -1.9739e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -8.7745e-03 -1.0627e-02  1.9893e-04\n",
       "    8.4156e-03  2.5510e-02 -5.6246e-02\n",
       "    1.0646e-02  1.3780e-02 -9.6965e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    2.7395e-02  2.9251e-02 -2.2714e-02\n",
       "   -1.1874e-02  3.4320e-03  2.0177e-02\n",
       "    2.7067e-03 -9.1457e-04  9.5010e-04\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -2.5665e-02  1.8727e-02  1.7692e-02\n",
       "   -1.6729e-02 -4.5780e-02 -5.5994e-03\n",
       "   -6.8149e-03  7.2233e-03 -5.9806e-03\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    3.3971e-02  2.2974e-03  3.8748e-02\n",
       "   -5.7584e-03 -2.4871e-02 -2.2251e-02\n",
       "   -8.4235e-03  6.0754e-03 -2.4574e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -2.1618e-02  2.6050e-02  2.8668e-02\n",
       "    5.1068e-02 -2.0509e-02  9.9334e-03\n",
       "    1.2648e-02 -2.5516e-02 -1.4264e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    1.1152e-02  2.5848e-02  3.6390e-02\n",
       "    2.9093e-02 -1.5584e-02 -9.2891e-03\n",
       "   -1.2070e-02  3.9081e-02 -5.8467e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.9762e-02  4.4111e-02  4.2697e-02\n",
       "   -1.1872e-02  2.3853e-02  1.9455e-02\n",
       "   -1.8029e-03  4.6948e-02 -1.1616e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    1.3646e-02  2.2915e-02  1.6486e-03\n",
       "    1.8259e-03  3.1221e-02 -1.4911e-03\n",
       "    2.8693e-02  1.4879e-02  4.2430e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -2.6793e-02  3.4780e-02 -4.9184e-03\n",
       "   -9.1798e-04 -2.3429e-02  3.1419e-02\n",
       "   -2.1890e-03  2.4922e-03 -7.4160e-03\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    7.1532e-03 -2.7855e-03  1.3535e-02\n",
       "   -4.4059e-02 -6.2492e-04 -5.6798e-03\n",
       "   -2.1642e-02 -4.9304e-03 -1.2524e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -9.6086e-03  1.1697e-02 -2.6906e-02\n",
       "    3.6083e-04 -1.3725e-02 -4.3109e-03\n",
       "    6.2652e-03  3.5794e-02  2.0931e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    9.2825e-05  1.5653e-02 -9.8008e-03\n",
       "    2.1266e-03  3.2866e-02  2.2064e-02\n",
       "   -6.5564e-03 -4.2729e-02 -2.0847e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    2.7538e-03  7.8001e-03 -2.3185e-02\n",
       "    3.5028e-02 -1.0271e-03  2.9869e-02\n",
       "   -8.5045e-03 -1.1371e-02 -2.4157e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    3.3816e-02  2.0130e-02  1.8075e-02\n",
       "    3.6779e-02  1.7251e-02  5.6778e-02\n",
       "    3.2038e-02  3.5872e-02  2.5252e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    2.2611e-02  1.7421e-02 -1.4529e-03\n",
       "   -2.4023e-02 -2.6629e-02 -3.3049e-02\n",
       "    2.8027e-02 -1.3716e-02  1.1676e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -3.3916e-02  4.2931e-03 -2.7553e-02\n",
       "    2.2916e-02  3.7462e-02  7.1689e-04\n",
       "   -3.9501e-02  1.7817e-03 -3.1410e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    9.7965e-03 -3.6010e-03 -2.0877e-03\n",
       "    1.5812e-02 -2.6027e-02  2.3468e-03\n",
       "    7.3577e-03  7.8222e-03  2.6455e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -1.0529e-02  1.5320e-02 -2.3092e-02\n",
       "    3.2928e-02 -3.5985e-02  7.9349e-03\n",
       "    1.7003e-02 -5.3383e-03  6.8159e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    3.2552e-02  4.5296e-04 -9.8813e-03\n",
       "    5.4463e-03  5.0274e-02  6.0290e-03\n",
       "   -2.8935e-02  1.2171e-02  1.7867e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    2.5995e-03  1.9542e-02 -9.8674e-03\n",
       "    3.2285e-02 -3.0639e-02  1.1968e-02\n",
       "    2.1829e-06 -2.3227e-02 -1.9498e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    1.2298e-02  2.1877e-02 -2.2703e-02\n",
       "   -6.8508e-03 -1.0898e-03  5.1382e-02\n",
       "    1.0769e-02  5.7598e-02 -1.1950e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -2.6252e-02 -7.4802e-03  5.4069e-03\n",
       "   -2.6725e-02 -3.3091e-02 -1.9844e-02\n",
       "   -2.2716e-02 -2.8442e-02  5.6506e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    4.1325e-02 -1.1564e-02 -2.1088e-04\n",
       "    7.1216e-03 -7.8997e-03 -8.1346e-03\n",
       "   -3.6832e-02 -2.5297e-02  2.2230e-03\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    1.1521e-02  3.7894e-02 -4.0746e-03\n",
       "   -6.8851e-04 -3.8586e-02  2.5904e-02\n",
       "    4.3684e-03  1.3112e-02  8.7302e-03\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -3.4966e-02 -9.7824e-03 -1.5605e-02\n",
       "    4.6598e-03 -1.4751e-02 -4.0453e-05\n",
       "    1.0991e-02  1.5466e-02 -2.6985e-03\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "   -5.9251e-03 -5.7684e-03  1.3394e-02\n",
       "    2.3733e-02  2.5384e-02  3.0899e-02\n",
       "   -7.7936e-03  2.2835e-02 -7.8784e-03\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    5.8065e-03  2.8554e-02  6.1232e-03\n",
       "    3.5189e-02  3.0784e-02  1.4143e-02\n",
       "    2.0076e-02  2.2275e-02 -1.6646e-03\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    7.9357e-03  2.6347e-02  1.0482e-02\n",
       "    3.1723e-02 -6.0899e-03  1.1373e-02\n",
       "    2.9045e-02  2.5903e-02 -3.2700e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    2.4456e-02  1.4707e-02  1.6952e-02\n",
       "    6.3916e-04 -2.7358e-02  1.9069e-02\n",
       "   -3.6642e-02  5.3570e-03 -1.4501e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -2.8901e-02 -4.1804e-02 -4.0574e-02\n",
       "    2.1404e-04  1.9886e-02  3.5828e-02\n",
       "   -1.4961e-02  2.1568e-02  3.1712e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    2.5262e-02  2.9755e-02 -3.5164e-02\n",
       "    2.6217e-02  1.9603e-02  6.0358e-03\n",
       "    1.2210e-02 -3.4820e-02 -3.4868e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -2.3321e-02  2.3834e-02 -6.1355e-03\n",
       "    1.6966e-02 -1.4296e-02 -7.6092e-03\n",
       "   -3.5934e-03 -1.2350e-02 -2.5168e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "   -1.3449e-02  1.4041e-02 -4.0859e-03\n",
       "   -1.7450e-02 -1.7283e-03 -2.3385e-02\n",
       "    2.4016e-02 -1.0583e-02  3.8793e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    5.1626e-03 -3.2584e-02 -7.5056e-03\n",
       "    5.7952e-03 -9.0895e-03  1.2654e-02\n",
       "    3.0957e-02  1.1274e-02  1.2412e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7757\n",
       "   0.7544\n",
       "   0.7944\n",
       "   0.7803\n",
       "   0.7701\n",
       "   0.7743\n",
       "   0.7782\n",
       "   0.7853\n",
       "   0.7804\n",
       "   0.7861\n",
       "   0.7886\n",
       "   0.7888\n",
       "   0.7850\n",
       "   0.8290\n",
       "   0.8003\n",
       "   0.7773\n",
       "   0.7648\n",
       "   0.8122\n",
       "   0.7784\n",
       "   0.7873\n",
       "   0.7784\n",
       "   0.7776\n",
       "   0.7884\n",
       "   0.7945\n",
       "   0.7675\n",
       "   0.8017\n",
       "   0.7622\n",
       "   0.7535\n",
       "   0.7635\n",
       "   0.7492\n",
       "   0.7972\n",
       "   0.7781\n",
       "   0.7866\n",
       "   0.8189\n",
       "   0.7706\n",
       "   0.7798\n",
       "   0.7849\n",
       "   0.7708\n",
       "   0.7757\n",
       "   0.8000\n",
       "   0.7629\n",
       "   0.7856\n",
       "   0.7893\n",
       "   0.7836\n",
       "   0.7668\n",
       "   0.7838\n",
       "   0.7873\n",
       "   0.7900\n",
       "   0.7936\n",
       "   0.7679\n",
       "   0.7755\n",
       "   0.7706\n",
       "   0.8005\n",
       "   0.7690\n",
       "   0.7869\n",
       "   0.7791\n",
       "   0.7904\n",
       "   0.7668\n",
       "   0.8020\n",
       "   0.7946\n",
       "   0.8091\n",
       "   0.7892\n",
       "   0.7908\n",
       "   0.7824\n",
       "   0.7857\n",
       "   0.7984\n",
       "   0.7575\n",
       "   0.7931\n",
       "   0.7902\n",
       "   0.7919\n",
       "   0.7934\n",
       "   0.7944\n",
       "   0.7743\n",
       "   0.7924\n",
       "   0.7834\n",
       "   0.7905\n",
       "   0.7612\n",
       "   0.7786\n",
       "   0.8082\n",
       "   0.7907\n",
       "   0.7603\n",
       "   0.7776\n",
       "   0.7787\n",
       "   0.7829\n",
       "   0.7995\n",
       "   0.7737\n",
       "   0.7622\n",
       "   0.7883\n",
       "   0.7927\n",
       "   0.7664\n",
       "   0.7670\n",
       "   0.7818\n",
       "   0.7589\n",
       "   0.7804\n",
       "   0.8239\n",
       "   0.7815\n",
       "   0.7576\n",
       "   0.7962\n",
       "   0.7940\n",
       "   0.7827\n",
       "   0.7665\n",
       "   0.7936\n",
       "   0.7576\n",
       "   0.7630\n",
       "   0.7892\n",
       "   0.7854\n",
       "   0.8055\n",
       "   0.7848\n",
       "   0.7818\n",
       "   0.7875\n",
       "   0.7721\n",
       "   0.7987\n",
       "   0.7725\n",
       "   0.7801\n",
       "   0.7930\n",
       "   0.7837\n",
       "   0.8160\n",
       "   0.7803\n",
       "   0.7865\n",
       "   0.7883\n",
       "   0.7688\n",
       "   0.7825\n",
       "   0.7759\n",
       "   0.7833\n",
       "   0.7816\n",
       "   0.7668\n",
       "   0.7733\n",
       "   0.7890\n",
       "   0.7876\n",
       "   0.8083\n",
       "   0.7889\n",
       "   0.7813\n",
       "   0.7501\n",
       "   0.7728\n",
       "   0.7797\n",
       "   0.8038\n",
       "   0.7880\n",
       "   0.7743\n",
       "   0.7835\n",
       "   0.7564\n",
       "   0.7690\n",
       "   0.7892\n",
       "   0.7968\n",
       "   0.8045\n",
       "   0.7932\n",
       "   0.7573\n",
       "   0.7604\n",
       "   0.7732\n",
       "   0.7949\n",
       "   0.7657\n",
       "   0.7587\n",
       "   0.8031\n",
       "   0.7756\n",
       "   0.7642\n",
       "   0.7755\n",
       "   0.7840\n",
       "   0.7843\n",
       "   0.7801\n",
       "   0.7689\n",
       "   0.7845\n",
       "   0.7733\n",
       "   0.7736\n",
       "   0.8101\n",
       "   0.7795\n",
       "   0.7534\n",
       "   0.7773\n",
       "   0.7862\n",
       "   0.7777\n",
       "   0.7844\n",
       "   0.7981\n",
       "   0.7722\n",
       "   0.8214\n",
       "   0.7898\n",
       "   0.7793\n",
       "   0.8246\n",
       "   0.7704\n",
       "   0.7813\n",
       "   0.7691\n",
       "   0.7608\n",
       "   0.7650\n",
       "   0.7994\n",
       "   0.8026\n",
       "   0.7653\n",
       "   0.7511\n",
       "   0.7965\n",
       "   0.7942\n",
       "   0.8056\n",
       "   0.7771\n",
       "   0.8009\n",
       "   0.7958\n",
       "   0.8104\n",
       "   0.7813\n",
       "   0.7967\n",
       "   0.7533\n",
       "   0.7753\n",
       "   0.7538\n",
       "   0.7750\n",
       "   0.7737\n",
       "   0.7935\n",
       "   0.8076\n",
       "   0.8045\n",
       "   0.7672\n",
       "   0.7945\n",
       "   0.7875\n",
       "   0.7793\n",
       "   0.7942\n",
       "   0.8061\n",
       "   0.7878\n",
       "   0.7713\n",
       "   0.7756\n",
       "   0.7780\n",
       "   0.7521\n",
       "   0.7865\n",
       "   0.7889\n",
       "   0.7881\n",
       "   0.7683\n",
       "   0.7745\n",
       "   0.7902\n",
       "   0.7804\n",
       "   0.7692\n",
       "   0.7917\n",
       "   0.7807\n",
       "   0.7624\n",
       "   0.7724\n",
       "   0.7770\n",
       "   0.7961\n",
       "   0.7920\n",
       "   0.7787\n",
       "   0.7722\n",
       "   0.7981\n",
       "   0.7905\n",
       "   0.7785\n",
       "   0.7740\n",
       "   0.7860\n",
       "   0.7860\n",
       "   0.7870\n",
       "   0.7844\n",
       "   0.7861\n",
       "   0.8004\n",
       "   0.7669\n",
       "   0.7833\n",
       "   0.7690\n",
       "   0.7531\n",
       "   0.7855\n",
       "   0.7861\n",
       "   0.7894\n",
       "   0.7927\n",
       "   0.7941\n",
       "   0.7877\n",
       "   0.8140\n",
       "   0.7945\n",
       "   0.7710\n",
       "   0.7730\n",
       "   0.7839\n",
       "   0.7569\n",
       "   0.7741\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0267\n",
       "   0.1285\n",
       "  -0.0685\n",
       "  -0.0461\n",
       "   0.0338\n",
       "  -0.1042\n",
       "  -0.0189\n",
       "  -0.0230\n",
       "  -0.0069\n",
       "  -0.0186\n",
       "  -0.0421\n",
       "  -0.0218\n",
       "   0.0155\n",
       "  -0.0067\n",
       "  -0.0898\n",
       "  -0.0739\n",
       "   0.0321\n",
       "  -0.1398\n",
       "   0.0438\n",
       "  -0.0681\n",
       "  -0.0707\n",
       "   0.0331\n",
       "  -0.0217\n",
       "  -0.0803\n",
       "  -0.0490\n",
       "  -0.0588\n",
       "  -0.0607\n",
       "  -0.0002\n",
       "  -0.0300\n",
       "  -0.0452\n",
       "  -0.0285\n",
       "  -0.0662\n",
       "   0.0116\n",
       "   0.0524\n",
       "  -0.0750\n",
       "  -0.0250\n",
       "  -0.0370\n",
       "  -0.0572\n",
       "  -0.0268\n",
       "  -0.0490\n",
       "  -0.0457\n",
       "  -0.0108\n",
       "  -0.0644\n",
       "  -0.0225\n",
       "  -0.0458\n",
       "  -0.0595\n",
       "  -0.0258\n",
       "   0.0276\n",
       "  -0.0610\n",
       "  -0.0355\n",
       "  -0.0586\n",
       "   0.0645\n",
       "  -0.0125\n",
       "  -0.0107\n",
       "  -0.0655\n",
       "  -0.0217\n",
       "  -0.0024\n",
       "  -0.0516\n",
       "  -0.1070\n",
       "   0.0066\n",
       "  -0.0435\n",
       "  -0.0457\n",
       "  -0.0118\n",
       "   0.1141\n",
       "  -0.0546\n",
       "  -0.0594\n",
       "  -0.0487\n",
       "  -0.0156\n",
       "  -0.0824\n",
       "   0.0500\n",
       "  -0.0534\n",
       "  -0.0356\n",
       "  -0.0392\n",
       "  -0.0556\n",
       "   0.0299\n",
       "  -0.0133\n",
       "  -0.0423\n",
       "  -0.0209\n",
       "   0.0230\n",
       "  -0.0570\n",
       "  -0.0343\n",
       "  -0.0456\n",
       "  -0.0922\n",
       "   0.0090\n",
       "  -0.0624\n",
       "  -0.0213\n",
       "  -0.0393\n",
       "  -0.0280\n",
       "  -0.0308\n",
       "  -0.0281\n",
       "  -0.0112\n",
       "  -0.0233\n",
       "  -0.0193\n",
       "  -0.0452\n",
       "  -0.0477\n",
       "  -0.0694\n",
       "  -0.0530\n",
       "   0.0092\n",
       "  -0.0531\n",
       "  -0.0233\n",
       "  -0.0365\n",
       "   0.0590\n",
       "   0.0293\n",
       "  -0.0624\n",
       "  -0.0410\n",
       "   0.0534\n",
       "   0.0295\n",
       "  -0.0348\n",
       "  -0.0069\n",
       "   0.0195\n",
       "  -0.0328\n",
       "  -0.0105\n",
       "  -0.0913\n",
       "   0.0386\n",
       "   0.0437\n",
       "   0.0220\n",
       "  -0.0706\n",
       "  -0.0015\n",
       "   0.0275\n",
       "  -0.0039\n",
       "  -0.0542\n",
       "  -0.0635\n",
       "  -0.0160\n",
       "   0.0221\n",
       "  -0.0871\n",
       "  -0.0450\n",
       "  -0.0344\n",
       "  -0.0330\n",
       "  -0.0411\n",
       "   0.0077\n",
       "  -0.0134\n",
       "  -0.0210\n",
       "  -0.0190\n",
       "  -0.0761\n",
       "  -0.0362\n",
       "   0.0345\n",
       "  -0.0333\n",
       "  -0.0126\n",
       "  -0.0404\n",
       "  -0.0279\n",
       "  -0.0181\n",
       "  -0.0333\n",
       "  -0.0273\n",
       "  -0.0546\n",
       "  -0.0379\n",
       "  -0.0848\n",
       "  -0.0134\n",
       "  -0.0348\n",
       "  -0.0253\n",
       "  -0.0643\n",
       "  -0.0129\n",
       "  -0.0369\n",
       "  -0.0259\n",
       "  -0.0201\n",
       "   0.0231\n",
       "  -0.0356\n",
       "  -0.0794\n",
       "  -0.0122\n",
       "  -0.0543\n",
       "   0.0485\n",
       "  -0.0345\n",
       "  -0.0476\n",
       "  -0.0534\n",
       "   0.0118\n",
       "   0.0701\n",
       "   0.0098\n",
       "  -0.0077\n",
       "   0.0047\n",
       "  -0.0281\n",
       "  -0.0629\n",
       "  -0.0316\n",
       "  -0.0672\n",
       "   0.0483\n",
       "   0.0056\n",
       "   0.0035\n",
       "  -0.0388\n",
       "  -0.0366\n",
       "  -0.0221\n",
       "  -0.0354\n",
       "  -0.0351\n",
       "  -0.0182\n",
       "  -0.1108\n",
       "  -0.0465\n",
       "  -0.0789\n",
       "  -0.0562\n",
       "  -0.0626\n",
       "   0.0846\n",
       "   0.0079\n",
       "  -0.0382\n",
       "   0.0072\n",
       "   0.0564\n",
       "  -0.0536\n",
       "  -0.1537\n",
       "  -0.0227\n",
       "  -0.0489\n",
       "  -0.0361\n",
       "   0.0094\n",
       "   0.0288\n",
       "  -0.0657\n",
       "  -0.0010\n",
       "   0.0354\n",
       "  -0.0031\n",
       "  -0.0625\n",
       "   0.0190\n",
       "  -0.0554\n",
       "  -0.0462\n",
       "  -0.0456\n",
       "  -0.0927\n",
       "  -0.0694\n",
       "  -0.0141\n",
       "  -0.0363\n",
       "  -0.1355\n",
       "  -0.0114\n",
       "   0.0140\n",
       "  -0.0159\n",
       "  -0.0616\n",
       "  -0.0394\n",
       "  -0.0237\n",
       "   0.0276\n",
       "  -0.0697\n",
       "  -0.0198\n",
       "  -0.0362\n",
       "  -0.0503\n",
       "  -0.0119\n",
       "  -0.0490\n",
       "  -0.0501\n",
       "   0.0301\n",
       "  -0.0256\n",
       "  -0.0523\n",
       "  -0.0678\n",
       "  -0.0246\n",
       "   0.0230\n",
       "  -0.0434\n",
       "   0.0202\n",
       "   0.0435\n",
       "  -0.0024\n",
       "   0.0064\n",
       "  -0.0555\n",
       "   0.1287\n",
       "  -0.0508\n",
       "  -0.0254\n",
       "   0.0245\n",
       "  -0.0404\n",
       "   0.0190\n",
       "  -0.0134\n",
       "  -0.0393\n",
       "   0.0254\n",
       "  -0.0280\n",
       "   0.0043\n",
       "  -0.1056\n",
       "  -0.0194\n",
       "  -0.0350\n",
       "  -0.0504\n",
       "  -0.0229\n",
       "  -0.0524\n",
       "  -0.0219\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    2.1206e-02  7.0638e-03 -8.7593e-03\n",
       "   -1.8432e-02 -2.6908e-03 -2.1580e-02\n",
       "    3.4584e-02  2.5157e-02  6.0487e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -3.5066e-02 -2.9542e-03  2.5927e-02\n",
       "   -1.5427e-02  7.1922e-03 -4.0593e-02\n",
       "    3.5580e-02  8.3564e-03 -8.4324e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -5.3016e-03  1.3245e-02  4.3326e-02\n",
       "   -4.0219e-03  4.6315e-02  2.0219e-02\n",
       "    3.9773e-02  4.3047e-03  4.4940e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -9.5145e-03  3.0985e-02  1.9147e-02\n",
       "    1.4511e-02 -9.6528e-03 -1.5042e-02\n",
       "   -1.5995e-02  2.2667e-02 -1.5598e-04\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    4.5362e-02  2.9388e-02 -1.5090e-02\n",
       "   -6.7139e-03  6.0681e-04  9.2027e-03\n",
       "   -3.2256e-02 -4.5678e-02 -2.5726e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    2.4024e-02 -2.1572e-02  3.3691e-04\n",
       "   -5.5158e-03  2.5858e-02 -4.6258e-02\n",
       "   -3.2358e-02 -3.4077e-02 -1.3252e-04\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    3.2210e-02  1.7508e-02 -2.7725e-02\n",
       "   -1.1022e-03  3.4839e-02  4.6152e-02\n",
       "   -1.2179e-02  5.3090e-02 -1.7881e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    8.4922e-03  1.9339e-03 -1.2378e-02\n",
       "   -1.4165e-02 -1.0798e-03  5.2876e-03\n",
       "   -1.5232e-02 -3.9725e-02 -9.5523e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.5579e-02  1.8147e-02  2.8029e-02\n",
       "    3.5576e-02  2.5632e-02  6.8966e-02\n",
       "   -2.4666e-02 -3.2207e-02 -2.5254e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    2.8342e-03 -2.8426e-02  1.2937e-02\n",
       "   -2.0973e-03  1.0022e-02 -1.7786e-02\n",
       "   -6.4477e-02 -2.8722e-02 -1.0937e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -4.0095e-03  4.1303e-02  2.6629e-03\n",
       "    3.3118e-03 -2.6468e-02  2.1814e-02\n",
       "    3.0414e-02  3.3257e-02  2.0552e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -8.9821e-03 -2.8254e-02 -2.0973e-02\n",
       "   -3.6610e-02  1.3070e-02 -9.7434e-03\n",
       "    6.5180e-03 -1.5626e-02 -1.8452e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.5368e-02 -2.7943e-02 -4.4511e-04\n",
       "    3.0331e-03 -1.4962e-02  1.6053e-02\n",
       "   -1.5067e-02 -9.6642e-04 -1.8323e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -1.2411e-02 -1.3428e-02  3.7308e-03\n",
       "   -1.9072e-02  1.3753e-02  2.3154e-02\n",
       "    1.9280e-02  1.1937e-02 -3.4058e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.5363e-02  6.7379e-03  4.6432e-03\n",
       "    5.4651e-02 -2.1234e-02 -1.3235e-03\n",
       "   -3.9630e-02  6.4825e-03 -2.7101e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    4.3172e-02  5.8543e-02  4.0217e-02\n",
       "    5.5206e-03 -9.2215e-03 -8.7624e-03\n",
       "    3.6070e-02 -1.6537e-02 -3.4483e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "   -1.0950e-02  3.5376e-03  5.2607e-03\n",
       "    4.8688e-03 -4.4840e-02 -3.2133e-02\n",
       "   -3.5632e-03  4.3504e-03 -8.7115e-03\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    2.7444e-02 -7.4137e-03  1.0736e-02\n",
       "    1.8419e-02 -9.2123e-03 -1.1938e-03\n",
       "   -1.6193e-02  4.8596e-04 -4.5278e-03\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    1.2238e-02  4.0082e-02 -1.6834e-02\n",
       "    2.9795e-03 -2.3114e-02  1.0198e-02\n",
       "    1.1907e-02  2.5075e-02  1.0568e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    1.0961e-02  1.2187e-02  1.9666e-02\n",
       "   -5.3667e-02  1.1345e-02  2.1039e-03\n",
       "    3.2530e-03  1.9313e-02 -6.8653e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    4.3871e-02 -2.2869e-02  9.4801e-03\n",
       "   -5.5763e-03  1.7817e-02  1.2838e-02\n",
       "   -8.2090e-03 -1.0007e-02 -5.7731e-04\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    2.6386e-03  8.7226e-03  5.6277e-03\n",
       "   -5.9135e-03  3.8468e-03 -1.0529e-02\n",
       "    1.7996e-02  3.2775e-02  1.8560e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    2.0005e-02  1.4684e-02 -1.6932e-02\n",
       "    1.3503e-02  1.1484e-02  7.9084e-03\n",
       "   -2.8317e-03 -6.3319e-03  2.6584e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -1.6029e-02  2.9768e-02  1.8774e-02\n",
       "   -1.3314e-02  4.3846e-02  4.3833e-02\n",
       "   -1.1851e-04  4.8177e-02  1.3980e-03\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    4.4882e-02  5.4134e-03  1.2446e-02\n",
       "   -1.6362e-02 -1.5897e-02 -5.2157e-02\n",
       "    6.1567e-03 -1.1368e-03 -3.8051e-03\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "   -1.3868e-03 -5.2523e-03 -4.0972e-02\n",
       "   -8.6530e-03  2.5097e-02  7.3517e-03\n",
       "   -4.0763e-02 -8.8666e-03 -3.9590e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -1.8247e-03 -3.4023e-02  4.0149e-03\n",
       "   -2.0825e-02 -1.4675e-02  2.0242e-03\n",
       "    2.3898e-03 -1.3845e-02 -2.3684e-03\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    4.4522e-02 -1.0170e-02  2.8711e-02\n",
       "    4.9921e-02 -3.2162e-03  1.4094e-02\n",
       "   -2.0908e-02 -3.2532e-02 -1.9761e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "   -1.8820e-02  2.6102e-02 -3.8517e-02\n",
       "    3.7180e-02 -1.6513e-02  3.8094e-02\n",
       "   -9.7758e-03  2.0648e-02 -4.2769e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "   -8.6522e-03  7.5377e-03 -3.5507e-02\n",
       "    1.4565e-02  4.7272e-02 -1.3152e-02\n",
       "   -4.7584e-02 -1.3762e-03 -8.1962e-03\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -1.8111e-02  4.7458e-03 -1.9933e-02\n",
       "   -2.1555e-02 -5.0829e-03 -6.1625e-03\n",
       "    1.2003e-02 -8.9700e-03  1.4174e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    3.3210e-02 -3.6969e-03 -4.4138e-03\n",
       "    3.6027e-02 -2.6858e-02 -3.2475e-03\n",
       "   -2.5013e-02  1.3712e-02  2.6506e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -2.0208e-03 -2.1021e-03 -2.2415e-03\n",
       "    2.5397e-02  5.9766e-03 -1.0336e-02\n",
       "   -9.4096e-04  3.6511e-02 -2.0826e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "    1.6106e-02  1.8123e-02  2.1929e-03\n",
       "   -6.4143e-03  1.2512e-02  2.3742e-02\n",
       "    3.1537e-02 -2.9639e-02 -1.2119e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    6.3998e-03 -9.3553e-03  8.4890e-03\n",
       "    2.5155e-02  9.7785e-03  5.4708e-03\n",
       "    7.9608e-03  1.6629e-02 -4.5028e-03\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "   -2.9727e-02  7.6017e-03  8.1029e-03\n",
       "    5.8956e-03  2.8093e-02 -2.4300e-02\n",
       "    9.8072e-03 -2.0396e-02 -1.8775e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7537\n",
       "   0.7854\n",
       "   0.7847\n",
       "   0.8058\n",
       "   0.7829\n",
       "   0.7917\n",
       "   0.7881\n",
       "   0.7475\n",
       "   0.7957\n",
       "   0.7684\n",
       "   0.8106\n",
       "   0.7733\n",
       "   0.7863\n",
       "   0.7725\n",
       "   0.7825\n",
       "   0.7775\n",
       "   0.7819\n",
       "   0.7868\n",
       "   0.7987\n",
       "   0.7792\n",
       "   0.7980\n",
       "   0.8390\n",
       "   0.7653\n",
       "   0.7824\n",
       "   0.7777\n",
       "   0.7764\n",
       "   0.8051\n",
       "   0.7741\n",
       "   0.7825\n",
       "   0.7762\n",
       "   0.7945\n",
       "   0.7844\n",
       "   0.7828\n",
       "   0.7992\n",
       "   0.7810\n",
       "   0.7788\n",
       "   0.7738\n",
       "   0.7854\n",
       "   0.7835\n",
       "   0.7861\n",
       "   0.7621\n",
       "   0.7885\n",
       "   0.7833\n",
       "   0.7740\n",
       "   0.7835\n",
       "   0.7877\n",
       "   0.7959\n",
       "   0.7815\n",
       "   0.7777\n",
       "   0.8003\n",
       "   0.7801\n",
       "   0.7837\n",
       "   0.7936\n",
       "   0.7837\n",
       "   0.8087\n",
       "   0.7723\n",
       "   0.7919\n",
       "   0.7707\n",
       "   0.7848\n",
       "   0.7902\n",
       "   0.7873\n",
       "   0.7950\n",
       "   0.7820\n",
       "   0.7790\n",
       "   0.7624\n",
       "   0.7739\n",
       "   0.7656\n",
       "   0.7781\n",
       "   0.7628\n",
       "   0.7645\n",
       "   0.7820\n",
       "   0.7854\n",
       "   0.7942\n",
       "   0.7721\n",
       "   0.7962\n",
       "   0.7759\n",
       "   0.7804\n",
       "   0.7745\n",
       "   0.7835\n",
       "   0.7655\n",
       "   0.7924\n",
       "   0.7866\n",
       "   0.7901\n",
       "   0.7681\n",
       "   0.7878\n",
       "   0.7847\n",
       "   0.7940\n",
       "   0.7791\n",
       "   0.7849\n",
       "   0.7874\n",
       "   0.7681\n",
       "   0.7816\n",
       "   0.7749\n",
       "   0.7801\n",
       "   0.8032\n",
       "   0.7927\n",
       "   0.7816\n",
       "   0.8008\n",
       "   0.7846\n",
       "   0.7956\n",
       "   0.7719\n",
       "   0.7824\n",
       "   0.7893\n",
       "   0.7827\n",
       "   0.7835\n",
       "   0.7757\n",
       "   0.7754\n",
       "   0.7565\n",
       "   0.7774\n",
       "   0.7897\n",
       "   0.7956\n",
       "   0.7745\n",
       "   0.7812\n",
       "   0.7867\n",
       "   0.7880\n",
       "   0.7796\n",
       "   0.7908\n",
       "   0.7874\n",
       "   0.7822\n",
       "   0.7852\n",
       "   0.7908\n",
       "   0.7698\n",
       "   0.7952\n",
       "   0.7986\n",
       "   0.7704\n",
       "   0.7858\n",
       "   0.7856\n",
       "   0.7870\n",
       "   0.7851\n",
       "   0.7764\n",
       "   0.7855\n",
       "   0.7856\n",
       "   0.8187\n",
       "   0.7749\n",
       "   0.7741\n",
       "   0.7896\n",
       "   0.7756\n",
       "   0.7832\n",
       "   0.7806\n",
       "   0.7690\n",
       "   0.7973\n",
       "   0.7800\n",
       "   0.7716\n",
       "   0.7847\n",
       "   0.7719\n",
       "   0.7973\n",
       "   0.7921\n",
       "   0.7875\n",
       "   0.7798\n",
       "   0.7941\n",
       "   0.7963\n",
       "   0.7847\n",
       "   0.7860\n",
       "   0.7760\n",
       "   0.7878\n",
       "   0.7839\n",
       "   0.7681\n",
       "   0.7728\n",
       "   0.7762\n",
       "   0.7604\n",
       "   0.7826\n",
       "   0.7810\n",
       "   0.7776\n",
       "   0.7947\n",
       "   0.7805\n",
       "   0.7866\n",
       "   0.7788\n",
       "   0.7819\n",
       "   0.8013\n",
       "   0.8047\n",
       "   0.7897\n",
       "   0.7851\n",
       "   0.7814\n",
       "   0.7796\n",
       "   0.7720\n",
       "   0.7842\n",
       "   0.7890\n",
       "   0.7933\n",
       "   0.7970\n",
       "   0.7885\n",
       "   0.7760\n",
       "   0.7830\n",
       "   0.7859\n",
       "   0.7694\n",
       "   0.7793\n",
       "   0.7799\n",
       "   0.7701\n",
       "   0.7627\n",
       "   0.7865\n",
       "   0.7880\n",
       "   0.7932\n",
       "   0.7935\n",
       "   0.7808\n",
       "   0.7912\n",
       "   0.7751\n",
       "   0.8031\n",
       "   0.7717\n",
       "   0.7940\n",
       "   0.7829\n",
       "   0.7929\n",
       "   0.7805\n",
       "   0.7664\n",
       "   0.7733\n",
       "   0.7937\n",
       "   0.7857\n",
       "   0.7854\n",
       "   0.7881\n",
       "   0.8025\n",
       "   0.7847\n",
       "   0.7760\n",
       "   0.7761\n",
       "   0.7845\n",
       "   0.7951\n",
       "   0.7871\n",
       "   0.8054\n",
       "   0.7854\n",
       "   0.7752\n",
       "   0.7791\n",
       "   0.7726\n",
       "   0.7851\n",
       "   0.7858\n",
       "   0.7765\n",
       "   0.7716\n",
       "   0.7781\n",
       "   0.7768\n",
       "   0.8039\n",
       "   0.7764\n",
       "   0.7925\n",
       "   0.8051\n",
       "   0.8185\n",
       "   0.7720\n",
       "   0.7778\n",
       "   0.7906\n",
       "   0.7826\n",
       "   0.7780\n",
       "   0.7896\n",
       "   0.7743\n",
       "   0.7761\n",
       "   0.7884\n",
       "   0.7643\n",
       "   0.7816\n",
       "   0.7876\n",
       "   0.7814\n",
       "   0.7773\n",
       "   0.7740\n",
       "   0.7700\n",
       "   0.7741\n",
       "   0.7817\n",
       "   0.7816\n",
       "   0.7725\n",
       "   0.7933\n",
       "   0.7890\n",
       "   0.7786\n",
       "   0.7738\n",
       "   0.7872\n",
       "   0.7842\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  -0.0689\n",
       "  -0.0428\n",
       "   0.0047\n",
       "  -0.0175\n",
       "  -0.0348\n",
       "   0.0149\n",
       "   0.0180\n",
       "  -0.0493\n",
       "   0.0675\n",
       "  -0.0045\n",
       "   0.0625\n",
       "  -0.0253\n",
       "   0.0086\n",
       "  -0.0555\n",
       "   0.0032\n",
       "   0.0115\n",
       "  -0.0084\n",
       "  -0.0891\n",
       "   0.0078\n",
       "  -0.0314\n",
       "   0.0545\n",
       "   0.0033\n",
       "  -0.0450\n",
       "  -0.0070\n",
       "  -0.0411\n",
       "   0.0126\n",
       "  -0.0412\n",
       "  -0.0223\n",
       "   0.0043\n",
       "  -0.0001\n",
       "  -0.0512\n",
       "   0.0003\n",
       "  -0.0003\n",
       "   0.0203\n",
       "  -0.0228\n",
       "   0.0031\n",
       "  -0.0395\n",
       "   0.0108\n",
       "  -0.0037\n",
       "  -0.0049\n",
       "  -0.0658\n",
       "   0.0456\n",
       "  -0.0198\n",
       "  -0.0485\n",
       "  -0.0296\n",
       "  -0.0401\n",
       "  -0.0733\n",
       "   0.0403\n",
       "  -0.0197\n",
       "   0.0218\n",
       "  -0.0285\n",
       "  -0.0473\n",
       "  -0.0133\n",
       "   0.0286\n",
       "   0.0589\n",
       "  -0.0645\n",
       "  -0.0015\n",
       "  -0.0144\n",
       "   0.0057\n",
       "   0.0222\n",
       "   0.0126\n",
       "  -0.0476\n",
       "   0.0114\n",
       "  -0.0200\n",
       "  -0.0501\n",
       "   0.0362\n",
       "  -0.0587\n",
       "   0.0176\n",
       "  -0.0645\n",
       "  -0.0875\n",
       "  -0.0194\n",
       "   0.0143\n",
       "  -0.0727\n",
       "   0.0137\n",
       "   0.0578\n",
       "  -0.0420\n",
       "  -0.0227\n",
       "  -0.0340\n",
       "   0.0019\n",
       "  -0.0794\n",
       "   0.0259\n",
       "   0.0321\n",
       "  -0.0935\n",
       "   0.0123\n",
       "  -0.0766\n",
       "  -0.0042\n",
       "   0.0345\n",
       "  -0.0522\n",
       "   0.0054\n",
       "   0.0111\n",
       "   0.0231\n",
       "  -0.0747\n",
       "  -0.0183\n",
       "   0.0077\n",
       "  -0.0047\n",
       "  -0.0061\n",
       "  -0.0486\n",
       "   0.0737\n",
       "   0.0132\n",
       "   0.0691\n",
       "  -0.0086\n",
       "  -0.0185\n",
       "   0.0355\n",
       "  -0.0858\n",
       "   0.0018\n",
       "  -0.0471\n",
       "  -0.0762\n",
       "  -0.0538\n",
       "   0.0039\n",
       "   0.0932\n",
       "  -0.0323\n",
       "  -0.0445\n",
       "  -0.0238\n",
       "   0.0657\n",
       "  -0.0521\n",
       "  -0.0173\n",
       "  -0.0802\n",
       "   0.0043\n",
       "  -0.0605\n",
       "   0.0085\n",
       "   0.0350\n",
       "  -0.0304\n",
       "   0.0133\n",
       "   0.0414\n",
       "  -0.0561\n",
       "   0.0260\n",
       "  -0.0144\n",
       "  -0.0093\n",
       "   0.0093\n",
       "   0.0106\n",
       "  -0.0178\n",
       "  -0.0174\n",
       "   0.0238\n",
       "  -0.0236\n",
       "  -0.1025\n",
       "   0.0371\n",
       "  -0.0145\n",
       "   0.0151\n",
       "  -0.0159\n",
       "   0.0033\n",
       "   0.0709\n",
       "   0.0056\n",
       "  -0.0315\n",
       "   0.0254\n",
       "  -0.0073\n",
       "  -0.0101\n",
       "   0.0364\n",
       "   0.0288\n",
       "  -0.0054\n",
       "   0.0710\n",
       "   0.0501\n",
       "  -0.0439\n",
       "  -0.0142\n",
       "  -0.0847\n",
       "  -0.0502\n",
       "   0.0045\n",
       "  -0.0590\n",
       "  -0.0457\n",
       "  -0.0182\n",
       "   0.0156\n",
       "  -0.0195\n",
       "  -0.0074\n",
       "  -0.0041\n",
       "   0.0035\n",
       "   0.0014\n",
       "   0.0357\n",
       "  -0.0017\n",
       "  -0.0371\n",
       "   0.0102\n",
       "   0.0540\n",
       "   0.1282\n",
       "   0.0482\n",
       "  -0.0635\n",
       "   0.0164\n",
       "   0.0029\n",
       "   0.0091\n",
       "   0.0404\n",
       "   0.0577\n",
       "   0.0588\n",
       "  -0.0879\n",
       "  -0.0231\n",
       "  -0.0443\n",
       "  -0.0704\n",
       "  -0.0483\n",
       "  -0.0007\n",
       "  -0.0131\n",
       "  -0.0110\n",
       "  -0.0345\n",
       "   0.0154\n",
       "   0.0040\n",
       "   0.0386\n",
       "  -0.0467\n",
       "   0.0043\n",
       "   0.0016\n",
       "  -0.0447\n",
       "  -0.0794\n",
       "  -0.0531\n",
       "   0.0169\n",
       "   0.0012\n",
       "   0.0285\n",
       "  -0.0017\n",
       "  -0.0245\n",
       "  -0.0298\n",
       "   0.0352\n",
       "   0.0213\n",
       "  -0.0151\n",
       "  -0.0426\n",
       "   0.0743\n",
       "   0.0047\n",
       "  -0.0647\n",
       "  -0.0112\n",
       "  -0.0558\n",
       "   0.0352\n",
       "   0.0217\n",
       "   0.0501\n",
       "  -0.0016\n",
       "  -0.0460\n",
       "  -0.0342\n",
       "   0.0093\n",
       "   0.0047\n",
       "  -0.0598\n",
       "  -0.0191\n",
       "  -0.0426\n",
       "  -0.0314\n",
       "  -0.0493\n",
       "   0.0740\n",
       "  -0.0098\n",
       "   0.0063\n",
       "  -0.0652\n",
       "   0.0883\n",
       "   0.0015\n",
       "  -0.0813\n",
       "  -0.0722\n",
       "  -0.0143\n",
       "  -0.0773\n",
       "   0.0230\n",
       "  -0.0375\n",
       "  -0.0564\n",
       "   0.0247\n",
       "  -0.0416\n",
       "   0.0089\n",
       "  -0.0023\n",
       "   0.0308\n",
       "  -0.0065\n",
       "  -0.0290\n",
       "  -0.0625\n",
       "  -0.0233\n",
       "  -0.0947\n",
       "  -0.0342\n",
       "   0.0069\n",
       "   0.0198\n",
       "   0.0419\n",
       "  -0.0121\n",
       "  -0.0092\n",
       "   0.0132\n",
       "   0.0108\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    2.6265e-04  1.0567e-03 -5.3264e-03\n",
       "   -1.9206e-03 -1.4774e-02  1.9112e-02\n",
       "   -2.1489e-02 -1.5855e-02  3.3066e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    4.1168e-03  2.6844e-02 -3.6059e-02\n",
       "   -1.5589e-02  7.4392e-03 -2.9765e-02\n",
       "   -9.0247e-03 -4.9777e-04 -3.9905e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -5.4019e-03  2.5879e-02 -2.0110e-02\n",
       "    2.6320e-02  4.4046e-03 -1.3099e-02\n",
       "    1.8450e-02 -2.0833e-02  4.5970e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    1.4116e-02  1.0635e-02  2.3686e-02\n",
       "   -5.5788e-03 -4.7868e-03 -4.0658e-02\n",
       "   -1.9140e-02 -3.5244e-03  2.1575e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -2.8480e-02  2.2210e-02  2.6819e-02\n",
       "    1.6379e-03 -3.9443e-02  1.9771e-02\n",
       "   -1.1666e-02  2.5867e-02 -4.5324e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    1.6216e-02  1.4473e-02  1.0476e-04\n",
       "    1.9663e-02  9.9440e-03  2.6505e-02\n",
       "   -2.4246e-02  1.7466e-02 -1.0138e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    3.1542e-04  1.8737e-03 -4.2646e-02\n",
       "    3.4205e-02 -7.0246e-03 -2.2679e-02\n",
       "   -2.4574e-02  2.4549e-02  1.4640e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -5.9461e-03 -1.9576e-03 -6.9289e-03\n",
       "   -7.8348e-03  2.1920e-02  3.1300e-02\n",
       "    6.9212e-03  2.9678e-02  4.8164e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    4.4427e-03  1.9771e-02 -1.2305e-02\n",
       "   -1.4255e-03  3.5985e-02 -7.4051e-03\n",
       "   -3.6528e-02 -9.1356e-03  6.3382e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "   -1.4347e-02 -1.0141e-02 -3.8648e-03\n",
       "    8.9154e-03  3.2400e-02 -1.0488e-02\n",
       "    8.2785e-03 -2.3892e-03  4.3111e-03\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    3.5861e-02 -4.5427e-03 -9.7656e-03\n",
       "    3.4132e-02 -7.2451e-03 -7.4710e-04\n",
       "    1.5966e-03 -2.9951e-02  4.0267e-03\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -1.0350e-03  1.5257e-02  1.4392e-02\n",
       "    2.7745e-02 -1.3458e-02  2.7072e-02\n",
       "    7.4971e-03 -9.4701e-03 -1.2475e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -1.1593e-03  1.9195e-02 -3.6909e-03\n",
       "    3.1089e-02 -4.0659e-02 -7.5934e-04\n",
       "   -8.7134e-03  4.4932e-02  2.3430e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    2.1934e-02 -1.3052e-02  2.0882e-02\n",
       "    1.5866e-03 -2.3881e-02 -1.4000e-02\n",
       "    2.4876e-02  1.6339e-03  2.5144e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -2.5991e-02 -6.9620e-03 -9.4322e-03\n",
       "    3.3111e-02 -1.6534e-02 -2.4259e-02\n",
       "    6.4369e-03  6.9523e-04 -2.5770e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "   -5.7725e-02 -2.6290e-02 -2.0703e-03\n",
       "    1.0749e-02 -4.3674e-03 -3.1027e-02\n",
       "    5.6487e-02  4.2682e-02  1.6557e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    2.6011e-02  1.6798e-02 -1.4949e-02\n",
       "   -1.4469e-02 -2.2053e-02  2.8678e-02\n",
       "    1.7281e-02 -4.1919e-02  1.3005e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    1.1540e-02  1.6850e-02  3.7036e-02\n",
       "    1.1967e-02 -1.4658e-02 -4.9360e-03\n",
       "    5.1584e-02  1.7831e-02  3.4567e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "   -4.5305e-04 -3.0041e-02  2.4921e-02\n",
       "    2.2510e-02  1.5306e-02  1.7537e-02\n",
       "   -8.2150e-03  4.5687e-03  1.0340e-03\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    5.1745e-02  3.4451e-02  8.1205e-03\n",
       "   -8.9530e-04  4.7977e-02  2.5715e-03\n",
       "    4.3721e-03  2.6769e-02  5.0403e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    5.7927e-03 -1.7930e-02 -1.6991e-02\n",
       "    1.1927e-02  1.5370e-02  4.3222e-02\n",
       "    2.1217e-04 -1.7062e-02  4.1376e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "   -1.2610e-02  2.0042e-02 -4.0774e-02\n",
       "   -1.1433e-02 -1.5947e-02 -4.0492e-03\n",
       "    5.0167e-03 -1.8695e-02  4.3778e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    2.9128e-02  2.1587e-02  3.8997e-02\n",
       "   -3.5573e-03  3.6565e-02  1.3139e-02\n",
       "    2.6851e-02 -1.3666e-02 -2.6193e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -2.0303e-02 -1.8588e-03  1.3411e-02\n",
       "   -1.9192e-03  1.5660e-02  3.0117e-02\n",
       "    1.5210e-02 -1.7442e-02 -1.1793e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    3.5000e-02 -2.0166e-02 -2.3658e-02\n",
       "   -2.1880e-03 -5.0371e-02  7.4636e-03\n",
       "    1.0606e-02 -3.0587e-02 -3.7180e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    2.9838e-03 -1.1053e-02 -8.5351e-03\n",
       "    2.8522e-02 -5.9973e-02  1.7967e-02\n",
       "    1.6372e-03 -1.3652e-02  1.1521e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -5.4925e-02 -2.4844e-02  2.0592e-02\n",
       "    2.8410e-02 -4.4332e-02  3.4821e-03\n",
       "    6.1823e-03  3.3478e-02 -2.4652e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    1.3983e-02 -1.9177e-02 -1.1621e-02\n",
       "    2.4409e-02  3.8031e-02  4.1781e-02\n",
       "   -2.2119e-02 -3.3728e-02  2.3989e-03\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    2.7891e-02 -1.6812e-03  2.6020e-02\n",
       "    2.5189e-02  1.1545e-02 -9.8725e-04\n",
       "   -1.6324e-02 -2.2113e-02 -4.7646e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "   -3.2866e-02 -3.9186e-02 -1.5406e-02\n",
       "   -1.4892e-02 -2.3239e-02  7.7942e-02\n",
       "    2.1044e-02  9.0184e-03  1.3782e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -2.6312e-02  7.7279e-03  1.2238e-02\n",
       "   -6.9889e-03  2.2296e-02 -4.2776e-03\n",
       "    2.1609e-02 -6.7006e-03 -2.3045e-03\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    1.0858e-02  3.1139e-03  8.6968e-03\n",
       "    1.6947e-02 -3.9424e-02 -4.7135e-03\n",
       "    7.6690e-03  3.4305e-02 -4.7877e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -9.9930e-03 -6.6969e-02  1.5592e-02\n",
       "    2.3930e-02  1.9210e-02 -4.8647e-02\n",
       "    1.0570e-02 -9.8224e-03 -2.6493e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -5.8426e-03 -2.8645e-03 -3.2451e-02\n",
       "    7.8692e-03  7.3684e-03 -3.7604e-02\n",
       "   -2.6275e-02  8.5036e-03 -1.5618e-04\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "   -1.3240e-02  4.6209e-02  1.6314e-02\n",
       "   -1.7091e-02  3.3070e-02 -6.9285e-02\n",
       "    4.7231e-03  1.8841e-02 -2.5308e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "    3.9509e-02  2.8192e-02  1.5912e-02\n",
       "   -8.3089e-03  2.6583e-02  3.4695e-02\n",
       "    1.5932e-02 -2.4237e-02  4.5800e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7879\n",
       "   0.7696\n",
       "   0.7839\n",
       "   0.7932\n",
       "   0.8052\n",
       "   0.7981\n",
       "   0.7879\n",
       "   0.7764\n",
       "   0.7753\n",
       "   0.7833\n",
       "   0.7993\n",
       "   0.7804\n",
       "   0.7957\n",
       "   0.7933\n",
       "   0.8132\n",
       "   0.7940\n",
       "   0.7940\n",
       "   0.8189\n",
       "   0.7838\n",
       "   0.7764\n",
       "   0.7725\n",
       "   0.7842\n",
       "   0.7707\n",
       "   0.8111\n",
       "   0.7980\n",
       "   0.7901\n",
       "   0.7767\n",
       "   0.7908\n",
       "   0.7980\n",
       "   0.7919\n",
       "   0.7956\n",
       "   0.7722\n",
       "   0.7807\n",
       "   0.7875\n",
       "   0.7712\n",
       "   0.7573\n",
       "   0.7820\n",
       "   0.7736\n",
       "   0.7926\n",
       "   0.7973\n",
       "   0.7550\n",
       "   0.7813\n",
       "   0.7965\n",
       "   0.8087\n",
       "   0.7937\n",
       "   0.7794\n",
       "   0.7764\n",
       "   0.7857\n",
       "   0.7853\n",
       "   0.7551\n",
       "   0.7745\n",
       "   0.7859\n",
       "   0.7955\n",
       "   0.7767\n",
       "   0.7893\n",
       "   0.7829\n",
       "   0.7857\n",
       "   0.7701\n",
       "   0.7972\n",
       "   0.7817\n",
       "   0.7984\n",
       "   0.8025\n",
       "   0.7787\n",
       "   0.7804\n",
       "   0.7902\n",
       "   0.8008\n",
       "   0.7655\n",
       "   0.7709\n",
       "   0.8559\n",
       "   0.7794\n",
       "   0.8038\n",
       "   0.7950\n",
       "   0.7754\n",
       "   0.7785\n",
       "   0.7809\n",
       "   0.7857\n",
       "   0.8220\n",
       "   0.7987\n",
       "   0.8152\n",
       "   0.7799\n",
       "   0.7897\n",
       "   0.7787\n",
       "   0.8053\n",
       "   0.7860\n",
       "   0.7692\n",
       "   0.7849\n",
       "   0.7762\n",
       "   0.8085\n",
       "   0.7822\n",
       "   0.7819\n",
       "   0.7697\n",
       "   0.7769\n",
       "   0.7792\n",
       "   0.7810\n",
       "   0.8013\n",
       "   0.7833\n",
       "   0.7851\n",
       "   0.7955\n",
       "   0.7881\n",
       "   0.7862\n",
       "   0.7876\n",
       "   0.7825\n",
       "   0.8071\n",
       "   0.7529\n",
       "   0.7737\n",
       "   0.7456\n",
       "   0.7756\n",
       "   0.7888\n",
       "   0.8005\n",
       "   0.7718\n",
       "   0.7877\n",
       "   0.7727\n",
       "   0.7844\n",
       "   0.7639\n",
       "   0.7489\n",
       "   0.7869\n",
       "   0.7743\n",
       "   0.7715\n",
       "   0.7961\n",
       "   0.7915\n",
       "   0.7750\n",
       "   0.8018\n",
       "   0.7887\n",
       "   0.7781\n",
       "   0.7965\n",
       "   0.7926\n",
       "   0.7833\n",
       "   0.7679\n",
       "   0.7859\n",
       "   0.8056\n",
       "   0.7953\n",
       "   0.7828\n",
       "   0.7547\n",
       "   0.7915\n",
       "   0.7704\n",
       "   0.7961\n",
       "   0.7922\n",
       "   0.7776\n",
       "   0.7716\n",
       "   0.7665\n",
       "   0.7511\n",
       "   0.7802\n",
       "   0.8204\n",
       "   0.7763\n",
       "   0.7743\n",
       "   0.7665\n",
       "   0.8118\n",
       "   0.7885\n",
       "   0.7868\n",
       "   0.7716\n",
       "   0.7782\n",
       "   0.7759\n",
       "   0.7884\n",
       "   0.7885\n",
       "   0.7847\n",
       "   0.7802\n",
       "   0.7761\n",
       "   0.7823\n",
       "   0.7883\n",
       "   0.7896\n",
       "   0.7960\n",
       "   0.7762\n",
       "   0.8041\n",
       "   0.7761\n",
       "   0.7958\n",
       "   0.7800\n",
       "   0.7958\n",
       "   0.7804\n",
       "   0.7929\n",
       "   0.7970\n",
       "   0.7770\n",
       "   0.7780\n",
       "   0.7963\n",
       "   0.7849\n",
       "   0.8503\n",
       "   0.7795\n",
       "   0.7896\n",
       "   0.7789\n",
       "   0.7720\n",
       "   0.7965\n",
       "   0.7839\n",
       "   0.7880\n",
       "   0.7731\n",
       "   0.7737\n",
       "   0.7962\n",
       "   0.7809\n",
       "   0.7775\n",
       "   0.7821\n",
       "   0.7904\n",
       "   0.7963\n",
       "   0.7657\n",
       "   0.7750\n",
       "   0.8243\n",
       "   0.7603\n",
       "   0.7845\n",
       "   0.7898\n",
       "   0.7876\n",
       "   0.7839\n",
       "   0.7943\n",
       "   0.7873\n",
       "   0.7861\n",
       "   0.7631\n",
       "   0.7904\n",
       "   0.7820\n",
       "   0.7782\n",
       "   0.7754\n",
       "   0.7934\n",
       "   0.7844\n",
       "   0.8334\n",
       "   0.7771\n",
       "   0.8134\n",
       "   0.7812\n",
       "   0.7664\n",
       "   0.7829\n",
       "   0.7781\n",
       "   0.7874\n",
       "   0.7751\n",
       "   0.7670\n",
       "   0.7862\n",
       "   0.7886\n",
       "   0.7680\n",
       "   0.7677\n",
       "   0.7665\n",
       "   0.7883\n",
       "   0.7892\n",
       "   0.7692\n",
       "   0.7988\n",
       "   0.7931\n",
       "   0.7829\n",
       "   0.7696\n",
       "   0.7718\n",
       "   0.8264\n",
       "   0.7770\n",
       "   0.7744\n",
       "   0.7888\n",
       "   0.7763\n",
       "   0.7769\n",
       "   0.7861\n",
       "   0.8120\n",
       "   0.7900\n",
       "   0.7749\n",
       "   0.7887\n",
       "   0.8035\n",
       "   0.7876\n",
       "   0.7750\n",
       "   0.7713\n",
       "   0.7699\n",
       "   0.7993\n",
       "   0.7802\n",
       "   0.8828\n",
       "   0.8001\n",
       "   0.7878\n",
       "   0.7775\n",
       "   0.7878\n",
       "   0.8367\n",
       "   0.7894\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "   0.0056\n",
       "   0.0220\n",
       "  -0.0569\n",
       "  -0.0497\n",
       "   0.0024\n",
       "  -0.0928\n",
       "  -0.0202\n",
       "  -0.0294\n",
       "  -0.0023\n",
       "  -0.0241\n",
       "  -0.0310\n",
       "   0.0079\n",
       "   0.0462\n",
       "  -0.0426\n",
       "  -0.0163\n",
       "  -0.0559\n",
       "  -0.0023\n",
       "  -0.1173\n",
       "   0.0233\n",
       "  -0.0449\n",
       "  -0.0578\n",
       "   0.0108\n",
       "  -0.0133\n",
       "  -0.0662\n",
       "   0.0095\n",
       "  -0.0616\n",
       "  -0.0484\n",
       "   0.0076\n",
       "  -0.0086\n",
       "  -0.0619\n",
       "  -0.0308\n",
       "  -0.0545\n",
       "   0.0118\n",
       "   0.0338\n",
       "  -0.0656\n",
       "  -0.0288\n",
       "  -0.0319\n",
       "  -0.0507\n",
       "  -0.0307\n",
       "  -0.0355\n",
       "  -0.0375\n",
       "   0.0008\n",
       "  -0.0525\n",
       "   0.0105\n",
       "  -0.0425\n",
       "  -0.0338\n",
       "  -0.0156\n",
       "   0.0209\n",
       "  -0.0503\n",
       "  -0.0324\n",
       "  -0.0621\n",
       "   0.0406\n",
       "  -0.0136\n",
       "  -0.0152\n",
       "  -0.0576\n",
       "  -0.0188\n",
       "  -0.0157\n",
       "  -0.0398\n",
       "  -0.0978\n",
       "   0.0016\n",
       "  -0.0062\n",
       "  -0.0235\n",
       "  -0.0131\n",
       "   0.0233\n",
       "  -0.0425\n",
       "  -0.0518\n",
       "  -0.0471\n",
       "  -0.0127\n",
       "  -0.0474\n",
       "  -0.0054\n",
       "  -0.0377\n",
       "  -0.0309\n",
       "  -0.0371\n",
       "  -0.0514\n",
       "   0.0204\n",
       "  -0.0177\n",
       "  -0.0529\n",
       "  -0.0170\n",
       "   0.0445\n",
       "  -0.0124\n",
       "  -0.0301\n",
       "  -0.0371\n",
       "  -0.0579\n",
       "   0.0062\n",
       "  -0.0445\n",
       "  -0.0239\n",
       "  -0.0246\n",
       "  -0.0234\n",
       "  -0.0280\n",
       "  -0.0333\n",
       "  -0.0118\n",
       "  -0.0225\n",
       "  -0.0082\n",
       "  -0.0741\n",
       "  -0.0381\n",
       "  -0.0477\n",
       "  -0.0409\n",
       "   0.0216\n",
       "  -0.0366\n",
       "  -0.0410\n",
       "  -0.0205\n",
       "   0.0534\n",
       "  -0.0364\n",
       "  -0.0565\n",
       "  -0.0279\n",
       "   0.0532\n",
       "   0.0352\n",
       "  -0.0257\n",
       "   0.0032\n",
       "   0.0186\n",
       "  -0.0275\n",
       "  -0.0013\n",
       "  -0.0786\n",
       "  -0.0002\n",
       "  -0.0006\n",
       "   0.0280\n",
       "  -0.0655\n",
       "  -0.0122\n",
       "   0.0260\n",
       "   0.0046\n",
       "  -0.0572\n",
       "  -0.0425\n",
       "  -0.0079\n",
       "   0.0285\n",
       "  -0.0858\n",
       "  -0.0544\n",
       "  -0.0330\n",
       "  -0.0402\n",
       "  -0.0489\n",
       "   0.0052\n",
       "  -0.0218\n",
       "  -0.0143\n",
       "  -0.0195\n",
       "  -0.0611\n",
       "  -0.0232\n",
       "   0.0429\n",
       "  -0.0334\n",
       "  -0.0083\n",
       "  -0.0411\n",
       "  -0.0300\n",
       "  -0.0154\n",
       "  -0.0299\n",
       "   0.0208\n",
       "  -0.0483\n",
       "  -0.0324\n",
       "  -0.0685\n",
       "  -0.0109\n",
       "  -0.0517\n",
       "  -0.0258\n",
       "  -0.0489\n",
       "  -0.0123\n",
       "  -0.0273\n",
       "  -0.0174\n",
       "  -0.0153\n",
       "   0.0236\n",
       "  -0.0360\n",
       "  -0.0700\n",
       "  -0.0090\n",
       "  -0.0448\n",
       "   0.0324\n",
       "  -0.0307\n",
       "  -0.0486\n",
       "  -0.0334\n",
       "   0.0106\n",
       "   0.0450\n",
       "   0.0123\n",
       "  -0.0139\n",
       "   0.0007\n",
       "  -0.0141\n",
       "  -0.0417\n",
       "  -0.0162\n",
       "  -0.0442\n",
       "   0.0520\n",
       "   0.0141\n",
       "   0.0167\n",
       "  -0.0320\n",
       "  -0.0404\n",
       "  -0.0211\n",
       "  -0.0158\n",
       "  -0.0374\n",
       "  -0.0140\n",
       "  -0.0172\n",
       "  -0.0376\n",
       "  -0.0643\n",
       "  -0.0353\n",
       "  -0.0501\n",
       "   0.0768\n",
       "   0.0081\n",
       "  -0.0208\n",
       "   0.0080\n",
       "   0.0415\n",
       "  -0.0319\n",
       "  -0.1336\n",
       "  -0.0179\n",
       "  -0.0415\n",
       "  -0.0376\n",
       "   0.0213\n",
       "   0.0198\n",
       "  -0.0547\n",
       "  -0.0045\n",
       "   0.0248\n",
       "  -0.0041\n",
       "  -0.0547\n",
       "   0.0158\n",
       "  -0.0488\n",
       "  -0.0063\n",
       "  -0.0377\n",
       "  -0.0900\n",
       "  -0.0494\n",
       "  -0.0154\n",
       "  -0.0445\n",
       "  -0.0725\n",
       "  -0.0076\n",
       "   0.0123\n",
       "  -0.0241\n",
       "  -0.0607\n",
       "  -0.0313\n",
       "  -0.0157\n",
       "   0.0375\n",
       "  -0.0483\n",
       "  -0.0180\n",
       "  -0.0419\n",
       "  -0.0254\n",
       "  -0.0113\n",
       "  -0.0410\n",
       "  -0.0390\n",
       "   0.0324\n",
       "  -0.0150\n",
       "  -0.0509\n",
       "  -0.0685\n",
       "  -0.0052\n",
       "  -0.0117\n",
       "  -0.0138\n",
       "   0.0081\n",
       "   0.0416\n",
       "  -0.0020\n",
       "   0.0036\n",
       "  -0.0356\n",
       "   0.1242\n",
       "  -0.0497\n",
       "  -0.0250\n",
       "  -0.0262\n",
       "  -0.0004\n",
       "   0.0219\n",
       "  -0.0109\n",
       "  -0.0467\n",
       "   0.0145\n",
       "   0.0010\n",
       "   0.0064\n",
       "  -0.0679\n",
       "  -0.0214\n",
       "  -0.0223\n",
       "  -0.0480\n",
       "  -0.0062\n",
       "  -0.0319\n",
       "  -0.0124\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.9379e-03 -3.3492e-03 -8.1111e-03\n",
       "   -3.1563e-02  2.1265e-02 -2.4123e-03\n",
       "    1.7990e-03 -1.0281e-02  3.0316e-04\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -3.8422e-02  1.6326e-02  1.1391e-03\n",
       "   -9.0290e-03  2.1605e-02  4.6563e-03\n",
       "    4.4145e-02 -9.4238e-03 -1.4311e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    4.9618e-02 -1.9301e-02  3.8929e-02\n",
       "   -1.5790e-02  2.6154e-02  1.8471e-02\n",
       "   -2.0243e-02 -1.5973e-02 -2.0326e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    5.5500e-03  7.1731e-03 -1.6242e-03\n",
       "   -9.7920e-03 -3.2865e-02 -1.0484e-02\n",
       "   -1.1358e-02 -1.5456e-02 -1.0606e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -1.0677e-02  3.1135e-02  6.5313e-02\n",
       "    1.0370e-02  4.2001e-03 -2.9980e-02\n",
       "   -5.0648e-02  2.5226e-02  2.9226e-04\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "   -3.6856e-02  2.6361e-03  3.1076e-04\n",
       "   -4.1208e-02  8.7569e-03  4.5078e-03\n",
       "    5.7476e-03 -1.8936e-02 -5.0725e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    4.7289e-02  1.0301e-03  7.9832e-03\n",
       "    7.4202e-03  2.8193e-03 -4.1185e-03\n",
       "    1.8958e-02 -5.8888e-03 -1.4020e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    3.8520e-02  2.9850e-02  3.3026e-03\n",
       "    3.2746e-02  1.4197e-02  4.8224e-03\n",
       "    6.4595e-03 -1.1990e-02 -2.2560e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    3.2392e-02  4.1890e-02  3.5180e-02\n",
       "   -1.0933e-02  1.0936e-03  5.0729e-03\n",
       "   -9.8054e-03 -9.3999e-03  1.1815e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    3.9622e-02  1.3318e-02 -6.2290e-02\n",
       "   -6.7133e-03 -1.6542e-02  4.9112e-03\n",
       "   -1.5212e-02  1.3082e-02 -1.0055e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    1.2304e-02  1.9092e-02  9.6020e-04\n",
       "    5.9545e-03  5.9790e-03  1.5906e-02\n",
       "   -2.8816e-03  2.3185e-03  1.0312e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -1.0771e-02 -1.2216e-03 -2.5125e-02\n",
       "    3.4055e-02 -1.9956e-02  4.7795e-03\n",
       "    3.1780e-02 -3.2763e-02  9.0701e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.5620e-02  7.0589e-03  4.4249e-02\n",
       "   -1.0177e-02 -2.2325e-02 -4.7250e-02\n",
       "    2.6444e-02 -1.7120e-02  3.5680e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -3.2000e-02 -4.4163e-02 -1.8513e-03\n",
       "    2.0593e-02  4.0445e-02  1.0356e-02\n",
       "    1.2176e-02 -6.8674e-03 -7.7652e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    2.6561e-02  7.4700e-03  2.2141e-02\n",
       "   -2.8610e-02  2.7777e-02 -2.3376e-02\n",
       "   -2.0447e-04  5.4750e-03 -2.8970e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    2.3506e-02 -7.7418e-03 -3.0338e-02\n",
       "    9.7026e-03 -2.6188e-02  2.0834e-02\n",
       "   -2.2918e-02 -1.1565e-02  2.2602e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "   -1.6726e-02  3.7035e-03  9.9444e-03\n",
       "   -1.1628e-02 -1.9828e-02 -4.3236e-02\n",
       "    3.1282e-02 -2.1769e-03 -1.3937e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -7.3527e-03 -9.4612e-03 -2.0220e-02\n",
       "   -1.9897e-02 -7.2036e-04 -6.7318e-03\n",
       "    6.9938e-03 -2.4127e-02 -7.6924e-04\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "   -1.2015e-02 -2.1315e-02 -1.0711e-02\n",
       "    9.2006e-03  2.0802e-02  5.5906e-03\n",
       "   -2.2574e-02 -2.1861e-02  1.6920e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -2.5325e-02  5.7973e-03 -3.4454e-02\n",
       "    2.4251e-02  3.7397e-02 -2.4322e-02\n",
       "    5.2154e-03 -2.8114e-02 -5.2274e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -1.6611e-02 -6.1928e-03  4.7702e-02\n",
       "   -1.5303e-02 -2.4241e-02 -4.2945e-02\n",
       "    6.5540e-03  1.6614e-02  1.7843e-03\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "   -2.1917e-02  2.5946e-02 -5.3050e-02\n",
       "   -1.6047e-02 -1.4256e-02 -1.2597e-02\n",
       "   -2.7902e-02  2.9535e-03 -4.8386e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "   -5.3257e-03 -3.2903e-02 -2.9234e-02\n",
       "    2.9946e-03 -6.4362e-03 -1.0759e-02\n",
       "   -4.3906e-02 -8.3035e-03 -2.2942e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "    2.6789e-02  3.2927e-02  9.6602e-03\n",
       "   -3.4283e-03 -3.8231e-02  1.1167e-02\n",
       "   -6.6183e-03 -2.0919e-02  1.9179e-02\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -2.8508e-02  2.1353e-03 -2.4232e-02\n",
       "   -3.1903e-03  6.5344e-03 -9.1668e-03\n",
       "   -1.0975e-02 -9.3841e-03 -8.4860e-03\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    3.8603e-02 -5.7145e-03  1.4782e-02\n",
       "    9.4961e-03  2.4297e-02  1.0892e-02\n",
       "   -7.6099e-03 -3.6790e-02  1.2488e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "   -2.0826e-02 -2.5341e-02 -4.0281e-02\n",
       "    8.1661e-03 -1.1679e-02 -4.7067e-02\n",
       "   -1.3532e-02  3.7683e-02 -1.5166e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "   -1.6778e-02 -1.3210e-02 -3.2026e-02\n",
       "    2.5143e-03  1.5160e-02 -3.1501e-02\n",
       "   -2.4097e-02 -2.6780e-02 -1.0387e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    3.5150e-02 -2.4476e-02 -1.7411e-02\n",
       "   -2.1396e-02 -2.3435e-02  1.6126e-02\n",
       "   -5.0408e-04  1.5628e-03 -1.6366e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "   -6.9447e-03  6.9314e-03  2.5287e-02\n",
       "    2.2637e-02  4.1536e-02  3.1788e-02\n",
       "   -1.2695e-02 -2.5437e-02 -1.1208e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    2.5629e-02  1.1540e-02  2.0942e-02\n",
       "   -3.8888e-02  2.0445e-02 -4.8887e-03\n",
       "   -1.6105e-02  3.0668e-02  3.2753e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -3.9653e-03  1.5769e-02  2.6829e-03\n",
       "    2.6945e-02  1.9643e-02  1.8325e-02\n",
       "    3.1940e-03 -3.1948e-03 -5.0718e-03\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -2.2283e-02  1.4863e-02 -2.8502e-02\n",
       "   -7.5721e-03 -3.6262e-02 -6.4214e-03\n",
       "    3.6901e-03 -1.3971e-02 -5.2844e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "    1.1889e-02 -1.7912e-03 -4.9595e-02\n",
       "   -4.7395e-02  1.7755e-02 -2.8956e-02\n",
       "   -1.4719e-02 -9.7089e-03 -1.3443e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    3.3888e-03 -2.8778e-02 -2.4209e-02\n",
       "   -4.5194e-03  2.5437e-02 -2.3005e-02\n",
       "   -2.0055e-02 -2.7273e-02  3.4065e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "   -1.6726e-02 -2.2089e-02 -1.5099e-02\n",
       "    2.7797e-02 -2.3942e-02  9.5439e-03\n",
       "    4.6076e-02  7.0318e-03  8.8429e-03\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7858\n",
       "   0.7919\n",
       "   0.7797\n",
       "   0.7843\n",
       "   0.7890\n",
       "   0.7886\n",
       "   0.7931\n",
       "   0.7935\n",
       "   0.7831\n",
       "   0.7981\n",
       "   0.7885\n",
       "   0.7674\n",
       "   0.7939\n",
       "   0.7831\n",
       "   0.7798\n",
       "   0.7692\n",
       "   0.7789\n",
       "   0.7886\n",
       "   0.7719\n",
       "   0.7803\n",
       "   0.7938\n",
       "   0.7831\n",
       "   0.7808\n",
       "   0.7818\n",
       "   0.7865\n",
       "   0.7718\n",
       "   0.7841\n",
       "   0.7846\n",
       "   0.7766\n",
       "   0.7834\n",
       "   0.7818\n",
       "   0.7868\n",
       "   0.7708\n",
       "   0.7722\n",
       "   0.7733\n",
       "   0.7850\n",
       "   0.7863\n",
       "   0.7821\n",
       "   0.7776\n",
       "   0.7829\n",
       "   0.8026\n",
       "   0.7813\n",
       "   0.7791\n",
       "   0.7896\n",
       "   0.7752\n",
       "   0.7659\n",
       "   0.7899\n",
       "   0.7866\n",
       "   0.7727\n",
       "   0.7641\n",
       "   0.7761\n",
       "   0.7799\n",
       "   0.7965\n",
       "   0.7748\n",
       "   0.7814\n",
       "   0.7738\n",
       "   0.7881\n",
       "   0.7769\n",
       "   0.7857\n",
       "   0.7915\n",
       "   0.7899\n",
       "   0.7799\n",
       "   0.7773\n",
       "   0.8046\n",
       "   0.7887\n",
       "   0.7840\n",
       "   0.7949\n",
       "   0.7900\n",
       "   0.7832\n",
       "   0.8094\n",
       "   0.8038\n",
       "   0.7628\n",
       "   0.7941\n",
       "   0.7870\n",
       "   0.7855\n",
       "   0.7888\n",
       "   0.7767\n",
       "   0.7896\n",
       "   0.7782\n",
       "   0.7737\n",
       "   0.7816\n",
       "   0.7713\n",
       "   0.7916\n",
       "   0.7972\n",
       "   0.7845\n",
       "   0.7813\n",
       "   0.7855\n",
       "   0.8005\n",
       "   0.7807\n",
       "   0.7868\n",
       "   0.7797\n",
       "   0.7846\n",
       "   0.7837\n",
       "   0.7738\n",
       "   0.7751\n",
       "   0.7768\n",
       "   0.7917\n",
       "   0.7799\n",
       "   0.7807\n",
       "   0.7881\n",
       "   0.7961\n",
       "   0.7932\n",
       "   0.7799\n",
       "   0.7801\n",
       "   0.7733\n",
       "   0.7879\n",
       "   0.7746\n",
       "   0.7939\n",
       "   0.7817\n",
       "   0.7677\n",
       "   0.7941\n",
       "   0.7880\n",
       "   0.7976\n",
       "   0.7843\n",
       "   0.7904\n",
       "   0.7913\n",
       "   0.7933\n",
       "   0.8001\n",
       "   0.7809\n",
       "   0.7765\n",
       "   0.7832\n",
       "   0.7949\n",
       "   0.7852\n",
       "   0.7771\n",
       "   0.7864\n",
       "   0.7835\n",
       "   0.7904\n",
       "   0.7888\n",
       "   0.7809\n",
       "   0.7909\n",
       "   0.7812\n",
       "   0.7886\n",
       "   0.7958\n",
       "   0.7880\n",
       "   0.7979\n",
       "   0.8083\n",
       "   0.7939\n",
       "   0.8151\n",
       "   0.7829\n",
       "   0.7874\n",
       "   0.7834\n",
       "   0.7740\n",
       "   0.7976\n",
       "   0.7770\n",
       "   0.7820\n",
       "   0.7798\n",
       "   0.7887\n",
       "   0.7994\n",
       "   0.7866\n",
       "   0.7777\n",
       "   0.8003\n",
       "   0.7858\n",
       "   0.7946\n",
       "   0.7965\n",
       "   0.7746\n",
       "   0.7876\n",
       "   0.7862\n",
       "   0.7703\n",
       "   0.7775\n",
       "   0.7855\n",
       "   0.7767\n",
       "   0.7675\n",
       "   0.7704\n",
       "   0.7679\n",
       "   0.7833\n",
       "   0.7871\n",
       "   0.7802\n",
       "   0.7859\n",
       "   0.7815\n",
       "   0.7916\n",
       "   0.7863\n",
       "   0.7821\n",
       "   0.7842\n",
       "   0.7757\n",
       "   0.7899\n",
       "   0.7834\n",
       "   0.7833\n",
       "   0.7858\n",
       "   0.7873\n",
       "   0.7784\n",
       "   0.7702\n",
       "   0.7785\n",
       "   0.7773\n",
       "   0.7536\n",
       "   0.7814\n",
       "   0.7844\n",
       "   0.7793\n",
       "   0.7793\n",
       "   0.7909\n",
       "   0.7810\n",
       "   0.7926\n",
       "   0.7771\n",
       "   0.7862\n",
       "   0.7614\n",
       "   0.7938\n",
       "   0.7827\n",
       "   0.7800\n",
       "   0.7761\n",
       "   0.7719\n",
       "   0.7647\n",
       "   0.7881\n",
       "   0.7941\n",
       "   0.7847\n",
       "   0.7813\n",
       "   0.8009\n",
       "   0.7905\n",
       "   0.7854\n",
       "   0.7876\n",
       "   0.7871\n",
       "   0.7838\n",
       "   0.7908\n",
       "   0.7800\n",
       "   0.7789\n",
       "   0.7733\n",
       "   0.7812\n",
       "   0.7859\n",
       "   0.7771\n",
       "   0.7943\n",
       "   0.7837\n",
       "   0.7763\n",
       "   0.7829\n",
       "   0.7846\n",
       "   0.7698\n",
       "   0.7804\n",
       "   0.7707\n",
       "   0.7899\n",
       "   0.7752\n",
       "   0.7872\n",
       "   0.7802\n",
       "   0.7930\n",
       "   0.7734\n",
       "   0.7891\n",
       "   0.7961\n",
       "   0.7781\n",
       "   0.7864\n",
       "   0.7753\n",
       "   0.7588\n",
       "   0.7768\n",
       "   0.7928\n",
       "   0.7854\n",
       "   0.7677\n",
       "   0.7903\n",
       "   0.7826\n",
       "   0.7798\n",
       "   0.7964\n",
       "   0.7776\n",
       "   0.7771\n",
       "   0.7802\n",
       "   0.7993\n",
       "   0.7423\n",
       "   0.7600\n",
       "   0.8062\n",
       "   0.8021\n",
       "   0.7765\n",
       "   0.7794\n",
       "   0.7868\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  1.00000e-02 *\n",
       "    6.3663\n",
       "   -0.7282\n",
       "    0.7810\n",
       "    0.6159\n",
       "   -3.8967\n",
       "    6.1538\n",
       "    2.3649\n",
       "   -3.5651\n",
       "    1.9142\n",
       "   -4.3930\n",
       "    0.4710\n",
       "   -6.7878\n",
       "   -3.9477\n",
       "    0.8344\n",
       "    2.5604\n",
       "   -1.5990\n",
       "    1.7945\n",
       "    0.1209\n",
       "   -2.6536\n",
       "    2.1417\n",
       "    2.2214\n",
       "    0.2551\n",
       "    1.2669\n",
       "   -3.9996\n",
       "   -0.6272\n",
       "   -0.7472\n",
       "   -0.5049\n",
       "   -0.4885\n",
       "   -1.7850\n",
       "   -4.2861\n",
       "   -1.1424\n",
       "    3.5058\n",
       "    1.8297\n",
       "   -2.2796\n",
       "   -3.7199\n",
       "   -0.5054\n",
       "   -0.1250\n",
       "    0.5080\n",
       "    0.4586\n",
       "    4.7028\n",
       "    6.0089\n",
       "   -3.6056\n",
       "   -1.4373\n",
       "    2.4167\n",
       "    0.9303\n",
       "   -2.8354\n",
       "    6.0622\n",
       "   -1.0623\n",
       "   -0.5900\n",
       "   -4.7354\n",
       "    0.2776\n",
       "   -0.0562\n",
       "    0.9890\n",
       "   -1.9589\n",
       "   -2.3016\n",
       "   -1.1752\n",
       "   -1.5469\n",
       "   -1.6057\n",
       "   -6.0460\n",
       "    1.9928\n",
       "   -0.7333\n",
       "   -3.9330\n",
       "   -1.0450\n",
       "    5.4675\n",
       "   -7.5358\n",
       "   -1.6125\n",
       "    4.7325\n",
       "   -1.0740\n",
       "    1.6333\n",
       "    6.8034\n",
       "    5.3906\n",
       "   -4.6620\n",
       "    1.1932\n",
       "   -3.8817\n",
       "    2.6137\n",
       "    6.8993\n",
       "   -4.1287\n",
       "   -2.7343\n",
       "   -0.5373\n",
       "   -5.2841\n",
       "   -0.7915\n",
       "   -2.4428\n",
       "    2.9896\n",
       "    5.1932\n",
       "   -0.5795\n",
       "   -0.2266\n",
       "    0.2893\n",
       "   -3.5802\n",
       "    2.1901\n",
       "   -5.7941\n",
       "    0.0955\n",
       "   -0.5595\n",
       "   -1.8863\n",
       "   -0.9556\n",
       "   -2.2983\n",
       "   -1.2517\n",
       "   -8.1370\n",
       "    1.9086\n",
       "    1.0744\n",
       "    3.2069\n",
       "    5.8633\n",
       "   -3.4364\n",
       "   -6.1158\n",
       "    1.2526\n",
       "    0.6143\n",
       "   -4.2955\n",
       "   -5.1015\n",
       "    2.3382\n",
       "   -0.6506\n",
       "   -5.1015\n",
       "    4.3382\n",
       "   -1.5573\n",
       "   -6.5416\n",
       "    1.2845\n",
       "    2.3287\n",
       "    5.2764\n",
       "    4.2336\n",
       "   -6.5946\n",
       "   -2.1917\n",
       "   -1.9257\n",
       "   -5.5169\n",
       "    3.9218\n",
       "   -1.9171\n",
       "    0.0692\n",
       "    4.4695\n",
       "   -1.4558\n",
       "    6.0344\n",
       "    2.5413\n",
       "   -4.7177\n",
       "   -3.1281\n",
       "   -2.1762\n",
       "   -7.1872\n",
       "    0.2069\n",
       "    1.5666\n",
       "    5.8471\n",
       "   -2.5774\n",
       "   -5.0030\n",
       "    6.1854\n",
       "   -5.6884\n",
       "   -4.8855\n",
       "    1.3815\n",
       "   -3.9017\n",
       "    2.7246\n",
       "   -0.4940\n",
       "    3.0081\n",
       "   -1.8510\n",
       "   -2.9695\n",
       "    0.8600\n",
       "    0.1585\n",
       "   -4.1781\n",
       "    4.6510\n",
       "   -0.6458\n",
       "    4.2295\n",
       "    2.2963\n",
       "   -2.4622\n",
       "    3.3190\n",
       "    1.1040\n",
       "    1.5178\n",
       "   -6.3969\n",
       "    1.4276\n",
       "   -0.5448\n",
       "   -5.4065\n",
       "    1.7403\n",
       "   -2.5956\n",
       "    3.2797\n",
       "   -1.7021\n",
       "   -2.2713\n",
       "    0.0864\n",
       "   -2.5129\n",
       "   -4.7301\n",
       "    3.6454\n",
       "   -0.1461\n",
       "    0.6412\n",
       "   -0.9385\n",
       "    4.6928\n",
       "   -1.3190\n",
       "   -0.2125\n",
       "   -5.4420\n",
       "   -0.3032\n",
       "    3.0684\n",
       "   -0.2154\n",
       "    0.3921\n",
       "    1.4389\n",
       "   -5.2464\n",
       "   -0.5530\n",
       "   -7.1409\n",
       "    0.4417\n",
       "   -0.5353\n",
       "   -0.4875\n",
       "    0.2428\n",
       "   -0.0797\n",
       "   -1.0689\n",
       "    0.8295\n",
       "   -1.5419\n",
       "    2.7569\n",
       "    1.7345\n",
       "   -0.3621\n",
       "   -0.8771\n",
       "   -1.7933\n",
       "   -3.7382\n",
       "   -1.6388\n",
       "    0.4468\n",
       "    1.6728\n",
       "    1.0112\n",
       "   -8.7346\n",
       "    2.1826\n",
       "   -3.5278\n",
       "    3.4813\n",
       "   -3.5737\n",
       "   -1.5804\n",
       "    1.0132\n",
       "    0.7403\n",
       "   -2.9694\n",
       "   -2.4226\n",
       "   -2.6992\n",
       "   -3.5130\n",
       "   -0.9389\n",
       "    5.2359\n",
       "   -5.4437\n",
       "   -0.2048\n",
       "    2.5268\n",
       "    1.6795\n",
       "   -0.5305\n",
       "   -2.2859\n",
       "   -4.7240\n",
       "    2.0313\n",
       "    0.7892\n",
       "   -1.4214\n",
       "   -0.9742\n",
       "   -6.2329\n",
       "   -2.4722\n",
       "   -3.2425\n",
       "   -7.1001\n",
       "   -5.3731\n",
       "    0.1408\n",
       "   -2.1768\n",
       "   -7.3886\n",
       "   -3.6065\n",
       "   -0.6650\n",
       "    0.6635\n",
       "   -4.6833\n",
       "   -8.7072\n",
       "    5.3578\n",
       "    3.4803\n",
       "    4.8922\n",
       "   -3.3596\n",
       "    0.2284\n",
       "   -0.9528\n",
       "    4.7258\n",
       "   -5.5474\n",
       "   -1.3847\n",
       "   -8.0903\n",
       "   -4.5993\n",
       "    4.2845\n",
       "    2.1511\n",
       "    1.7043\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -3.8135e-04 -1.9963e-04  9.5190e-03\n",
       "   -1.5390e-03 -1.7772e-02 -6.2204e-03\n",
       "   -7.1299e-03  4.4976e-03  2.2282e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -3.7543e-02 -2.2312e-02 -3.5141e-02\n",
       "    1.8130e-02  1.2860e-02  9.9955e-03\n",
       "    7.4434e-03 -3.1567e-02 -2.3473e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -2.1055e-02  6.4796e-02  2.2882e-02\n",
       "    4.2565e-03  2.3074e-02  3.8688e-02\n",
       "    3.3185e-02  3.7795e-03 -1.4150e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -1.1853e-03  3.6117e-02 -2.1324e-02\n",
       "   -2.7444e-03 -1.8688e-02  7.1433e-03\n",
       "   -1.9305e-02 -1.2377e-02 -1.0538e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -1.7499e-03 -3.3789e-02 -2.6940e-02\n",
       "   -1.6907e-02 -8.3136e-03 -1.3612e-02\n",
       "    3.1333e-02  9.6108e-03  5.2725e-03\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "   -5.5856e-03 -9.1150e-03 -1.1702e-02\n",
       "    1.9737e-02  8.0122e-03 -6.9530e-02\n",
       "    3.6895e-02 -1.1822e-02  3.1552e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    1.2734e-02  7.6277e-03  3.1194e-02\n",
       "   -9.5050e-03 -3.9570e-03  2.2690e-03\n",
       "   -3.6182e-03 -4.7215e-03  6.1565e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    3.7235e-03 -3.2706e-02 -3.0002e-02\n",
       "    7.6063e-03  2.9566e-02  7.8593e-03\n",
       "   -1.4543e-02 -8.6004e-03 -2.6566e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    8.3708e-03  5.8166e-03 -3.9088e-02\n",
       "    2.1920e-02  2.3055e-02 -8.8319e-03\n",
       "   -3.0820e-02  1.8541e-02  1.6151e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    2.4242e-02 -1.3737e-02 -2.9540e-03\n",
       "   -8.1190e-04  5.7933e-03  6.6388e-02\n",
       "   -6.3433e-03  2.3281e-02 -1.0977e-03\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -6.0271e-04  2.6786e-02 -3.7611e-02\n",
       "   -3.9286e-03  2.1252e-02  4.2224e-02\n",
       "   -1.5586e-02  3.7703e-02 -5.4368e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    4.1376e-02  2.3207e-02  2.8978e-02\n",
       "   -1.1043e-02 -3.1518e-02  8.3915e-04\n",
       "   -3.0914e-02  2.0362e-02  4.1273e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.2833e-02 -8.0890e-03  1.5043e-02\n",
       "    2.4131e-02  4.2064e-02  3.7077e-02\n",
       "    4.1761e-02  2.4932e-02  5.6529e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    2.3277e-02  9.6311e-03 -3.1594e-02\n",
       "   -1.4926e-02  5.6717e-02  7.3019e-03\n",
       "   -3.6821e-02  3.7978e-02  1.1504e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -8.4299e-03 -2.5094e-02 -1.9125e-03\n",
       "   -2.0650e-02 -1.4758e-02  1.8314e-03\n",
       "   -2.7521e-02  3.7172e-03  5.6280e-03\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    6.1952e-03  9.8280e-03 -2.3264e-03\n",
       "   -3.7525e-02 -2.7438e-02  7.2677e-04\n",
       "   -3.6215e-03  2.7195e-02 -2.3301e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    5.9164e-02 -3.8665e-03  3.6578e-02\n",
       "    4.5468e-02  8.8933e-03 -3.0903e-03\n",
       "   -6.8785e-03  1.0120e-02  1.9351e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -1.4597e-02  9.3406e-03 -2.7613e-03\n",
       "    4.3065e-02  9.6958e-03  3.5986e-03\n",
       "    1.9586e-02 -4.2761e-02  4.7084e-03\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "   -1.2895e-02 -2.3951e-02  8.1509e-03\n",
       "    1.2235e-03 -6.0286e-03 -5.6227e-03\n",
       "    9.6986e-03 -6.8061e-03 -7.2264e-03\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -6.0377e-03  5.4588e-03 -3.8862e-03\n",
       "   -3.4137e-02 -1.8577e-02  2.0323e-02\n",
       "    4.8673e-02 -1.7845e-02 -3.2139e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    1.9381e-02 -4.1570e-03  2.3002e-02\n",
       "   -2.2651e-02  2.8291e-02  8.8929e-03\n",
       "    1.9141e-03  3.9296e-02 -3.4090e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    1.0155e-02  2.2769e-02  2.3479e-03\n",
       "   -7.0396e-02 -3.4506e-02  8.5608e-05\n",
       "    7.2509e-03  1.5118e-02  1.6332e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    1.3899e-02  4.9229e-02  4.6084e-02\n",
       "   -2.3039e-02 -2.2691e-03  7.9114e-03\n",
       "    1.5974e-02 -1.4388e-02 -4.9968e-03\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "    1.9368e-02 -1.3612e-02  1.2566e-02\n",
       "   -1.2674e-02  1.3880e-02 -2.1131e-02\n",
       "    1.5113e-02  1.1718e-02  5.6799e-03\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -2.5575e-02 -5.8447e-03  1.5312e-02\n",
       "    1.3579e-02  4.0101e-02 -1.1873e-02\n",
       "   -1.1242e-02 -1.8431e-03 -2.7424e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    9.8782e-04  2.1801e-02 -1.4453e-02\n",
       "    6.8350e-03  8.8514e-03 -5.5526e-03\n",
       "    3.2284e-03 -2.4277e-02 -3.6346e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    1.0625e-03  8.7627e-03  2.7333e-02\n",
       "    1.7459e-02  3.0104e-02 -7.0545e-03\n",
       "    4.4100e-03  1.1781e-02 -1.2001e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    2.3965e-02  2.3655e-02  2.9373e-02\n",
       "   -1.0243e-02  2.3590e-02  9.9025e-03\n",
       "    5.0798e-02 -5.5449e-03  2.2697e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "   -3.1861e-02 -3.3978e-02 -1.2110e-03\n",
       "    1.7685e-02  2.4439e-02 -3.3397e-02\n",
       "    2.4423e-02 -4.2810e-03  2.0918e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "   -6.9705e-03  1.8583e-02  4.0561e-02\n",
       "    2.6981e-02  2.4597e-03 -6.4040e-02\n",
       "    2.4589e-02  1.5794e-02 -1.6730e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "    3.0889e-02 -3.8265e-02  2.7803e-02\n",
       "    7.9833e-03 -2.8256e-02 -4.8679e-04\n",
       "   -1.1961e-02 -2.8030e-02  1.5754e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -5.3433e-02 -5.4308e-02  1.2777e-02\n",
       "    3.8279e-02  5.6457e-03  3.8233e-03\n",
       "   -1.0843e-02 -5.6358e-02  1.2432e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -3.2157e-02 -1.0917e-02  6.4001e-03\n",
       "    4.3967e-02  6.4915e-03 -5.6756e-03\n",
       "    2.5433e-02 -1.4605e-03 -5.8737e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -1.7775e-02  1.6651e-02  6.0378e-03\n",
       "   -5.5650e-03 -3.0404e-02 -1.1798e-02\n",
       "    1.4146e-02 -2.2396e-02 -4.2732e-02\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    1.3420e-02 -6.9626e-03 -1.0580e-03\n",
       "   -3.1764e-02  4.9205e-02  6.3812e-02\n",
       "    4.1584e-02 -3.0907e-03 -4.2204e-03\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "   -3.9171e-02 -2.3408e-02 -8.9381e-03\n",
       "    9.5805e-03  9.5982e-03  1.9640e-02\n",
       "   -4.4979e-03 -8.4082e-03 -1.1445e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7914\n",
       "   0.7793\n",
       "   0.7824\n",
       "   0.7790\n",
       "   0.7850\n",
       "   0.7962\n",
       "   0.7787\n",
       "   0.7756\n",
       "   0.7631\n",
       "   0.7930\n",
       "   0.7817\n",
       "   0.7840\n",
       "   0.7773\n",
       "   0.7625\n",
       "   0.7980\n",
       "   0.7920\n",
       "   0.7894\n",
       "   0.7980\n",
       "   0.7661\n",
       "   0.7956\n",
       "   0.7825\n",
       "   0.7874\n",
       "   0.7753\n",
       "   0.7913\n",
       "   0.7973\n",
       "   0.8023\n",
       "   0.7974\n",
       "   0.7918\n",
       "   0.7816\n",
       "   0.7904\n",
       "   0.7842\n",
       "   0.7814\n",
       "   0.7677\n",
       "   0.8120\n",
       "   0.7803\n",
       "   0.7964\n",
       "   0.7839\n",
       "   0.7595\n",
       "   0.7823\n",
       "   0.7950\n",
       "   0.7676\n",
       "   0.7762\n",
       "   0.7739\n",
       "   0.8095\n",
       "   0.7854\n",
       "   0.7854\n",
       "   0.7777\n",
       "   0.7733\n",
       "   0.7751\n",
       "   0.7635\n",
       "   0.7906\n",
       "   0.7624\n",
       "   0.7927\n",
       "   0.7713\n",
       "   0.7868\n",
       "   0.7927\n",
       "   0.7920\n",
       "   0.7780\n",
       "   0.7951\n",
       "   0.7754\n",
       "   0.7862\n",
       "   0.7926\n",
       "   0.7836\n",
       "   0.8001\n",
       "   0.7916\n",
       "   0.8340\n",
       "   0.7534\n",
       "   0.7773\n",
       "   0.8421\n",
       "   0.7774\n",
       "   0.7981\n",
       "   0.7931\n",
       "   0.8079\n",
       "   0.7492\n",
       "   0.7792\n",
       "   0.7802\n",
       "   0.7990\n",
       "   0.7933\n",
       "   0.7895\n",
       "   0.7787\n",
       "   0.7862\n",
       "   0.7950\n",
       "   0.7840\n",
       "   0.7863\n",
       "   0.7824\n",
       "   0.7818\n",
       "   0.7740\n",
       "   0.7694\n",
       "   0.7882\n",
       "   0.7662\n",
       "   0.7606\n",
       "   0.7834\n",
       "   0.7769\n",
       "   0.7905\n",
       "   0.8117\n",
       "   0.7863\n",
       "   0.7951\n",
       "   0.7946\n",
       "   0.7853\n",
       "   0.7832\n",
       "   0.7901\n",
       "   0.7751\n",
       "   0.7823\n",
       "   0.7827\n",
       "   0.7906\n",
       "   0.7892\n",
       "   0.7857\n",
       "   0.7854\n",
       "   0.7777\n",
       "   0.7845\n",
       "   0.7851\n",
       "   0.7895\n",
       "   0.7942\n",
       "   0.7829\n",
       "   0.7636\n",
       "   0.7831\n",
       "   0.7769\n",
       "   0.7815\n",
       "   0.7729\n",
       "   0.7878\n",
       "   0.7845\n",
       "   0.8138\n",
       "   0.7882\n",
       "   0.7932\n",
       "   0.7929\n",
       "   0.7824\n",
       "   0.7810\n",
       "   0.7819\n",
       "   0.7906\n",
       "   0.8252\n",
       "   0.7929\n",
       "   0.7903\n",
       "   0.7858\n",
       "   0.7973\n",
       "   0.7682\n",
       "   0.7705\n",
       "   0.7805\n",
       "   0.7780\n",
       "   0.7922\n",
       "   0.8116\n",
       "   0.7822\n",
       "   0.7959\n",
       "   0.7902\n",
       "   0.8011\n",
       "   0.7935\n",
       "   0.7675\n",
       "   0.7699\n",
       "   0.7725\n",
       "   0.7942\n",
       "   0.7698\n",
       "   0.7851\n",
       "   0.7930\n",
       "   0.7829\n",
       "   0.8147\n",
       "   0.7847\n",
       "   0.7988\n",
       "   0.8010\n",
       "   0.7622\n",
       "   0.7749\n",
       "   0.7711\n",
       "   0.7829\n",
       "   0.7666\n",
       "   0.7929\n",
       "   0.7814\n",
       "   0.8125\n",
       "   0.7859\n",
       "   0.8020\n",
       "   0.7876\n",
       "   0.7700\n",
       "   0.8070\n",
       "   0.7820\n",
       "   0.7610\n",
       "   0.7849\n",
       "   0.7696\n",
       "   0.7901\n",
       "   0.7841\n",
       "   0.7628\n",
       "   0.7803\n",
       "   0.7866\n",
       "   0.7889\n",
       "   0.7835\n",
       "   0.7850\n",
       "   0.7827\n",
       "   0.7578\n",
       "   0.7907\n",
       "   0.7908\n",
       "   0.7745\n",
       "   0.7876\n",
       "   0.7691\n",
       "   0.7942\n",
       "   0.7691\n",
       "   0.7834\n",
       "   0.8097\n",
       "   0.7667\n",
       "   0.7959\n",
       "   0.7812\n",
       "   0.7797\n",
       "   0.7762\n",
       "   0.7919\n",
       "   0.7944\n",
       "   0.7739\n",
       "   0.7912\n",
       "   0.7899\n",
       "   0.7868\n",
       "   0.7901\n",
       "   0.7869\n",
       "   0.7893\n",
       "   0.7890\n",
       "   0.7865\n",
       "   0.7819\n",
       "   0.8083\n",
       "   0.7869\n",
       "   0.7841\n",
       "   0.7654\n",
       "   0.7589\n",
       "   0.8029\n",
       "   0.7758\n",
       "   0.7906\n",
       "   0.7722\n",
       "   0.7757\n",
       "   0.7796\n",
       "   0.7965\n",
       "   0.7990\n",
       "   0.7771\n",
       "   0.7661\n",
       "   0.7925\n",
       "   0.8062\n",
       "   0.7719\n",
       "   0.8080\n",
       "   0.7887\n",
       "   0.7859\n",
       "   0.7800\n",
       "   0.7741\n",
       "   0.7806\n",
       "   0.8006\n",
       "   0.7847\n",
       "   0.7757\n",
       "   0.7839\n",
       "   0.7947\n",
       "   0.8167\n",
       "   0.7847\n",
       "   0.7658\n",
       "   0.7760\n",
       "   0.7867\n",
       "   0.7786\n",
       "   0.7763\n",
       "   0.7794\n",
       "   0.7863\n",
       "   0.7658\n",
       "   0.8018\n",
       "   0.7594\n",
       "   0.7780\n",
       "   0.7837\n",
       "   0.7954\n",
       "   0.7971\n",
       "   0.7816\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "   0.0058\n",
       "   0.0253\n",
       "  -0.0509\n",
       "  -0.0484\n",
       "  -0.0137\n",
       "  -0.0749\n",
       "  -0.0228\n",
       "  -0.0263\n",
       "  -0.0070\n",
       "  -0.0182\n",
       "  -0.0166\n",
       "   0.0132\n",
       "   0.0563\n",
       "  -0.0541\n",
       "  -0.0002\n",
       "  -0.0534\n",
       "  -0.0009\n",
       "   0.0398\n",
       "   0.0232\n",
       "  -0.0625\n",
       "  -0.0530\n",
       "   0.0116\n",
       "  -0.0142\n",
       "  -0.0572\n",
       "   0.0078\n",
       "  -0.0535\n",
       "  -0.0365\n",
       "   0.0081\n",
       "  -0.0075\n",
       "  -0.0529\n",
       "  -0.0247\n",
       "  -0.0023\n",
       "  -0.0034\n",
       "   0.0357\n",
       "  -0.0484\n",
       "  -0.0184\n",
       "  -0.0224\n",
       "  -0.0376\n",
       "  -0.0188\n",
       "  -0.0353\n",
       "  -0.0346\n",
       "   0.0057\n",
       "  -0.0496\n",
       "   0.0131\n",
       "  -0.0346\n",
       "  -0.0312\n",
       "  -0.0163\n",
       "  -0.0013\n",
       "  -0.0530\n",
       "  -0.0268\n",
       "  -0.0682\n",
       "   0.0440\n",
       "   0.0042\n",
       "  -0.0096\n",
       "  -0.0219\n",
       "  -0.0144\n",
       "  -0.0099\n",
       "  -0.0280\n",
       "  -0.0841\n",
       "  -0.0141\n",
       "  -0.0092\n",
       "  -0.0209\n",
       "  -0.0097\n",
       "   0.0210\n",
       "  -0.0408\n",
       "  -0.0092\n",
       "  -0.0347\n",
       "   0.0004\n",
       "  -0.0375\n",
       "  -0.0080\n",
       "  -0.0398\n",
       "  -0.0279\n",
       "  -0.0065\n",
       "  -0.0403\n",
       "   0.0138\n",
       "  -0.0181\n",
       "  -0.0532\n",
       "   0.0000\n",
       "   0.0414\n",
       "  -0.0124\n",
       "  -0.0301\n",
       "   0.0065\n",
       "  -0.0535\n",
       "   0.0089\n",
       "  -0.0214\n",
       "  -0.0226\n",
       "  -0.0186\n",
       "  -0.0170\n",
       "  -0.0300\n",
       "  -0.0057\n",
       "  -0.0090\n",
       "  -0.0131\n",
       "  -0.0095\n",
       "  -0.0656\n",
       "  -0.0216\n",
       "  -0.0360\n",
       "  -0.0305\n",
       "   0.0232\n",
       "  -0.0260\n",
       "  -0.0541\n",
       "  -0.0235\n",
       "   0.0375\n",
       "  -0.0196\n",
       "  -0.0489\n",
       "  -0.0704\n",
       "   0.0301\n",
       "   0.0438\n",
       "  -0.0229\n",
       "   0.0026\n",
       "   0.0278\n",
       "  -0.0277\n",
       "   0.0007\n",
       "  -0.0704\n",
       "   0.0148\n",
       "  -0.0025\n",
       "   0.0270\n",
       "  -0.0529\n",
       "  -0.0128\n",
       "   0.0274\n",
       "   0.0033\n",
       "  -0.0565\n",
       "  -0.0137\n",
       "  -0.0064\n",
       "   0.0140\n",
       "  -0.0721\n",
       "  -0.0547\n",
       "  -0.0057\n",
       "  -0.0314\n",
       "  -0.0568\n",
       "  -0.0004\n",
       "  -0.0190\n",
       "  -0.0165\n",
       "  -0.0178\n",
       "  -0.0624\n",
       "  -0.0129\n",
       "   0.0354\n",
       "  -0.0287\n",
       "  -0.0026\n",
       "  -0.0333\n",
       "   0.0171\n",
       "  -0.0156\n",
       "  -0.0298\n",
       "   0.0299\n",
       "  -0.0554\n",
       "  -0.0122\n",
       "  -0.0531\n",
       "  -0.0136\n",
       "  -0.0491\n",
       "  -0.0235\n",
       "  -0.0411\n",
       "  -0.0088\n",
       "  -0.0163\n",
       "   0.0007\n",
       "  -0.0080\n",
       "   0.0266\n",
       "  -0.0404\n",
       "  -0.0578\n",
       "  -0.0035\n",
       "  -0.0472\n",
       "   0.0020\n",
       "  -0.0313\n",
       "  -0.0387\n",
       "  -0.0267\n",
       "   0.0115\n",
       "   0.0486\n",
       "   0.0136\n",
       "  -0.0156\n",
       "   0.0017\n",
       "  -0.0129\n",
       "  -0.0154\n",
       "   0.0043\n",
       "  -0.0356\n",
       "   0.0410\n",
       "  -0.0074\n",
       "   0.0170\n",
       "  -0.0257\n",
       "  -0.0355\n",
       "  -0.0298\n",
       "   0.0096\n",
       "  -0.0340\n",
       "  -0.0151\n",
       "   0.0004\n",
       "  -0.0055\n",
       "  -0.0498\n",
       "  -0.0266\n",
       "  -0.0437\n",
       "   0.0754\n",
       "   0.0022\n",
       "   0.0010\n",
       "   0.0008\n",
       "   0.0481\n",
       "  -0.0131\n",
       "  -0.1103\n",
       "  -0.0148\n",
       "  -0.0454\n",
       "  -0.0393\n",
       "   0.0180\n",
       "   0.0257\n",
       "  -0.0420\n",
       "  -0.0006\n",
       "   0.0141\n",
       "   0.0074\n",
       "  -0.0352\n",
       "   0.0196\n",
       "  -0.0444\n",
       "  -0.0060\n",
       "  -0.0252\n",
       "  -0.0750\n",
       "  -0.0463\n",
       "  -0.0123\n",
       "  -0.0345\n",
       "  -0.0439\n",
       "  -0.0088\n",
       "  -0.0032\n",
       "  -0.0347\n",
       "  -0.0337\n",
       "  -0.0252\n",
       "  -0.0171\n",
       "   0.0354\n",
       "  -0.0284\n",
       "  -0.0137\n",
       "  -0.0303\n",
       "  -0.0049\n",
       "  -0.0075\n",
       "  -0.0358\n",
       "   0.0101\n",
       "   0.0365\n",
       "  -0.0206\n",
       "  -0.0335\n",
       "  -0.0575\n",
       "  -0.0008\n",
       "   0.0025\n",
       "  -0.0061\n",
       "   0.0138\n",
       "   0.0323\n",
       "   0.0041\n",
       "  -0.0015\n",
       "  -0.0249\n",
       "   0.0682\n",
       "   0.0448\n",
       "  -0.0219\n",
       "  -0.0194\n",
       "  -0.0020\n",
       "   0.0203\n",
       "  -0.0088\n",
       "  -0.0462\n",
       "  -0.0246\n",
       "  -0.0011\n",
       "  -0.0025\n",
       "  -0.0642\n",
       "  -0.0133\n",
       "  -0.0222\n",
       "  -0.0077\n",
       "  -0.0030\n",
       "  -0.0270\n",
       "  -0.0062\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    4.0386e-05 -3.1115e-02 -5.0413e-03\n",
       "   -1.4904e-02 -4.3789e-02  3.9858e-02\n",
       "   -2.3772e-02 -1.1730e-02  4.9444e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    1.8039e-02  1.6821e-03  3.8102e-02\n",
       "    1.9276e-03  2.0505e-02  6.3048e-02\n",
       "    1.2871e-02  1.9002e-02  2.1223e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -2.8393e-02  8.9459e-03  5.2515e-03\n",
       "   -9.1550e-03  3.5060e-02 -1.9803e-02\n",
       "    1.3488e-02  3.0241e-02  9.9878e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    6.6086e-03  3.7575e-02  1.8446e-02\n",
       "   -2.4178e-02 -4.4888e-02 -1.1232e-02\n",
       "   -1.6676e-02 -5.9549e-03 -1.0995e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    1.9369e-02  1.3414e-02  1.5087e-02\n",
       "    2.1634e-02 -4.2645e-03 -1.3481e-02\n",
       "    7.4917e-02  3.6410e-02  2.8321e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    4.1965e-03  1.3405e-02  6.2595e-02\n",
       "   -1.5151e-02 -1.3237e-02  2.8057e-04\n",
       "    9.9048e-03 -5.0698e-02  1.0859e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -2.0573e-02 -3.1784e-02 -9.3797e-03\n",
       "    1.1694e-02  1.2403e-02 -1.9029e-02\n",
       "    1.4032e-02  2.0660e-02 -2.3921e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    2.8354e-02 -8.7066e-03 -5.4072e-03\n",
       "   -1.6729e-02 -3.9608e-02  1.9119e-02\n",
       "    1.7795e-03 -1.1543e-02  1.0183e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -2.5211e-03 -8.6524e-04 -9.4046e-03\n",
       "    9.9806e-04 -1.2034e-02 -7.1988e-02\n",
       "   -1.8572e-02 -6.8700e-03  1.4830e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    1.7198e-02  1.5722e-02 -2.8600e-02\n",
       "    4.5062e-02  1.7772e-02  9.3934e-03\n",
       "   -2.5271e-02  1.2521e-02  1.6849e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -1.0483e-02  9.7539e-03  3.2015e-02\n",
       "    4.8809e-02  3.6435e-02  1.1002e-02\n",
       "    1.6115e-03  3.0206e-02  8.2795e-04\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    4.7491e-03  3.3580e-03  1.8239e-02\n",
       "   -7.9597e-04  5.1179e-03  4.0249e-02\n",
       "    1.3874e-02 -1.9823e-02 -1.4905e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    3.3072e-03 -9.4838e-03 -3.5337e-02\n",
       "    1.0988e-02 -1.4597e-02 -1.3065e-02\n",
       "    1.2244e-02 -9.2653e-03  1.0064e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    2.6069e-02  2.5037e-02  4.9600e-02\n",
       "    2.1729e-02 -7.5255e-05  2.1491e-02\n",
       "   -6.0459e-03  5.3896e-03 -6.4811e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -4.0272e-02  2.4408e-02 -8.7503e-03\n",
       "   -1.1522e-02 -4.4379e-02 -3.4473e-02\n",
       "   -4.3791e-02 -5.0547e-02 -5.2937e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    2.6593e-03  2.5198e-02 -1.3514e-02\n",
       "    1.2276e-02 -5.8179e-02  7.0904e-03\n",
       "   -3.0617e-02  8.1959e-03  4.0033e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "   -2.7928e-02  3.2626e-02 -7.4612e-03\n",
       "   -9.9562e-03  8.4358e-03 -2.1591e-04\n",
       "    1.0183e-02 -5.6281e-02  5.9491e-03\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    3.0356e-02 -1.8178e-02 -3.0113e-02\n",
       "    8.2556e-03  2.5495e-02  3.7646e-02\n",
       "    7.4738e-03  6.8373e-03 -3.9464e-03\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "    1.5012e-02  2.1008e-02 -1.1741e-02\n",
       "   -7.5344e-03  1.0976e-02 -1.1661e-02\n",
       "    1.1297e-02  4.2404e-02  7.8521e-03\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "   -2.8167e-03 -1.7753e-02  2.1790e-02\n",
       "    1.8312e-02  1.9646e-02 -9.8455e-03\n",
       "   -6.2642e-02  1.4942e-02 -8.2615e-03\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "   -8.0833e-03 -7.0933e-03 -3.0201e-02\n",
       "    3.7106e-02  2.3009e-02 -2.9575e-02\n",
       "    1.1860e-02 -1.2426e-02 -3.8813e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    4.0871e-02 -4.8668e-03  5.2529e-02\n",
       "   -3.3235e-02 -1.4227e-02 -2.4771e-02\n",
       "   -1.1747e-02 -6.9599e-02  1.0872e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "   -3.7159e-02  2.9292e-02  1.1753e-02\n",
       "   -1.3636e-02 -3.4435e-02 -2.7233e-02\n",
       "    3.3372e-02 -2.7067e-02 -2.5381e-02\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "    1.8932e-02 -2.9867e-02 -4.8674e-02\n",
       "   -3.8218e-03 -2.1744e-02 -3.8521e-02\n",
       "    5.0060e-03 -4.3021e-02 -9.8883e-03\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "   -4.0117e-02 -1.1513e-02 -3.7402e-02\n",
       "    7.9964e-03 -2.1562e-02  2.8226e-03\n",
       "    1.7082e-02 -2.0193e-03  1.1839e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    1.0656e-02 -1.7448e-03  1.4968e-02\n",
       "   -7.5574e-02 -3.3870e-03 -6.5517e-02\n",
       "   -1.2121e-02 -1.0082e-02 -4.1162e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    4.0784e-02  6.3232e-04 -2.7496e-02\n",
       "    5.1801e-04  2.8891e-03 -3.1841e-02\n",
       "   -1.6984e-02 -9.2507e-03  2.7470e-03\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    8.6155e-03 -3.0525e-03 -8.6495e-03\n",
       "   -4.0238e-02  4.6217e-03  1.4255e-02\n",
       "   -5.9370e-03  3.1860e-03  4.1358e-02\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "    1.1810e-02 -1.3203e-02  1.2500e-02\n",
       "    7.8222e-03  2.0615e-02  1.2035e-02\n",
       "   -3.1093e-02  3.2336e-02  2.4002e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "    7.7001e-02  6.4695e-03 -3.0654e-02\n",
       "   -2.0174e-02  2.7605e-02 -1.5041e-02\n",
       "    8.7595e-03 -6.4203e-03 -1.8406e-03\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -2.4962e-02 -6.0357e-02 -5.1684e-02\n",
       "   -1.5166e-02 -8.7768e-03 -3.8635e-02\n",
       "    7.0912e-03 -1.2639e-02  1.9164e-02\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "    2.0738e-02  1.0700e-02  3.1576e-02\n",
       "   -1.6428e-02  2.9883e-02  6.0950e-03\n",
       "    1.2185e-02  4.1270e-03 -4.1913e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "   -1.6879e-02  1.9035e-02 -2.1223e-02\n",
       "   -1.3932e-03  3.6484e-02 -1.4590e-02\n",
       "   -3.8018e-02 -3.4397e-02 -8.5724e-03\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -4.6202e-03 -5.3077e-02 -2.4127e-02\n",
       "   -3.9993e-02 -3.9727e-02  2.5820e-02\n",
       "   -1.3865e-03 -3.0558e-02 -1.4237e-03\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "    2.0996e-02 -1.6290e-02  1.5218e-02\n",
       "   -3.1922e-02 -5.5419e-03  1.7178e-02\n",
       "   -7.9243e-03  1.1027e-02  4.2634e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "   -2.3705e-02  1.0095e-02 -2.3380e-03\n",
       "   -8.7622e-03 -1.0700e-02 -4.4513e-02\n",
       "    4.4211e-02 -3.4391e-02 -1.8947e-02\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7849\n",
       "   0.7735\n",
       "   0.8102\n",
       "   0.7815\n",
       "   0.7801\n",
       "   0.7793\n",
       "   0.7897\n",
       "   0.7798\n",
       "   0.7791\n",
       "   0.7899\n",
       "   0.7722\n",
       "   0.7800\n",
       "   0.7900\n",
       "   0.7730\n",
       "   0.7824\n",
       "   0.7841\n",
       "   0.7709\n",
       "   0.7919\n",
       "   0.8029\n",
       "   0.7842\n",
       "   0.7977\n",
       "   0.8050\n",
       "   0.7929\n",
       "   0.7750\n",
       "   0.7731\n",
       "   0.7932\n",
       "   0.7808\n",
       "   0.7767\n",
       "   0.7817\n",
       "   0.7839\n",
       "   0.7944\n",
       "   0.7838\n",
       "   0.7805\n",
       "   0.8101\n",
       "   0.7701\n",
       "   0.8019\n",
       "   0.7956\n",
       "   0.7947\n",
       "   0.7854\n",
       "   0.7871\n",
       "   0.7883\n",
       "   0.7787\n",
       "   0.7786\n",
       "   0.7563\n",
       "   0.7857\n",
       "   0.7957\n",
       "   0.7971\n",
       "   0.7780\n",
       "   0.7826\n",
       "   0.7801\n",
       "   0.7894\n",
       "   0.7732\n",
       "   0.7728\n",
       "   0.7814\n",
       "   0.7979\n",
       "   0.7902\n",
       "   0.7748\n",
       "   0.7787\n",
       "   0.7798\n",
       "   0.7964\n",
       "   0.7765\n",
       "   0.7854\n",
       "   0.7947\n",
       "   0.7820\n",
       "   0.7756\n",
       "   0.7783\n",
       "   0.7748\n",
       "   0.7920\n",
       "   0.7801\n",
       "   0.7600\n",
       "   0.7833\n",
       "   0.7791\n",
       "   0.8060\n",
       "   0.7920\n",
       "   0.7868\n",
       "   0.7803\n",
       "   0.7947\n",
       "   0.7777\n",
       "   0.7880\n",
       "   0.7831\n",
       "   0.8001\n",
       "   0.8029\n",
       "   0.7880\n",
       "   0.7731\n",
       "   0.7780\n",
       "   0.7866\n",
       "   0.7815\n",
       "   0.7865\n",
       "   0.7658\n",
       "   0.7882\n",
       "   0.7752\n",
       "   0.7646\n",
       "   0.8028\n",
       "   0.7850\n",
       "   0.7952\n",
       "   0.7725\n",
       "   0.7901\n",
       "   0.7852\n",
       "   0.7822\n",
       "   0.7601\n",
       "   0.7845\n",
       "   0.7795\n",
       "   0.7732\n",
       "   0.7850\n",
       "   0.7902\n",
       "   0.7750\n",
       "   0.7747\n",
       "   0.7636\n",
       "   0.7945\n",
       "   0.7863\n",
       "   0.7793\n",
       "   0.7920\n",
       "   0.7725\n",
       "   0.7682\n",
       "   0.7902\n",
       "   0.7920\n",
       "   0.8065\n",
       "   0.7764\n",
       "   0.7869\n",
       "   0.7817\n",
       "   0.7769\n",
       "   0.7716\n",
       "   0.7760\n",
       "   0.7772\n",
       "   0.7761\n",
       "   0.8017\n",
       "   0.7833\n",
       "   0.7769\n",
       "   0.7823\n",
       "   0.7761\n",
       "   0.7964\n",
       "   0.7817\n",
       "   0.7772\n",
       "   0.7870\n",
       "   0.7838\n",
       "   0.7928\n",
       "   0.7836\n",
       "   0.7959\n",
       "   0.7506\n",
       "   0.7725\n",
       "   0.7922\n",
       "   0.7774\n",
       "   0.7971\n",
       "   0.7919\n",
       "   0.7809\n",
       "   0.7759\n",
       "   0.7812\n",
       "   0.7798\n",
       "   0.7682\n",
       "   0.7917\n",
       "   0.7841\n",
       "   0.7905\n",
       "   0.7939\n",
       "   0.7858\n",
       "   0.7879\n",
       "   0.7793\n",
       "   0.7822\n",
       "   0.7782\n",
       "   0.7748\n",
       "   0.7721\n",
       "   0.7811\n",
       "   0.7868\n",
       "   0.7770\n",
       "   0.7883\n",
       "   0.7884\n",
       "   0.7824\n",
       "   0.7802\n",
       "   0.7858\n",
       "   0.7815\n",
       "   0.7906\n",
       "   0.7949\n",
       "   0.7701\n",
       "   0.7825\n",
       "   0.7876\n",
       "   0.7839\n",
       "   0.7820\n",
       "   0.7927\n",
       "   0.7692\n",
       "   0.7849\n",
       "   0.7809\n",
       "   0.7782\n",
       "   0.7804\n",
       "   0.7786\n",
       "   0.7765\n",
       "   0.7872\n",
       "   0.7848\n",
       "   0.7852\n",
       "   0.7915\n",
       "   0.7831\n",
       "   0.7929\n",
       "   0.7829\n",
       "   0.7933\n",
       "   0.7874\n",
       "   0.7863\n",
       "   0.7746\n",
       "   0.7854\n",
       "   0.7662\n",
       "   0.7746\n",
       "   0.7823\n",
       "   0.7630\n",
       "   0.7811\n",
       "   0.7911\n",
       "   0.7946\n",
       "   0.7835\n",
       "   0.7747\n",
       "   0.7846\n",
       "   0.7812\n",
       "   0.7954\n",
       "   0.7808\n",
       "   0.7779\n",
       "   0.7925\n",
       "   0.7912\n",
       "   0.7822\n",
       "   0.7919\n",
       "   0.7908\n",
       "   0.7715\n",
       "   0.7805\n",
       "   0.7916\n",
       "   0.7881\n",
       "   0.7867\n",
       "   0.7788\n",
       "   0.7900\n",
       "   0.7826\n",
       "   0.7763\n",
       "   0.7751\n",
       "   0.8237\n",
       "   0.7840\n",
       "   0.7878\n",
       "   0.7678\n",
       "   0.7833\n",
       "   0.7827\n",
       "   0.7925\n",
       "   0.7817\n",
       "   0.7997\n",
       "   0.7694\n",
       "   0.7840\n",
       "   0.7689\n",
       "   0.7838\n",
       "   0.7801\n",
       "   0.7916\n",
       "   0.7844\n",
       "   0.7802\n",
       "   0.7925\n",
       "   0.7914\n",
       "   0.7833\n",
       "   0.7932\n",
       "   0.7736\n",
       "   0.7985\n",
       "   0.7850\n",
       "   0.7880\n",
       "   0.7844\n",
       "   0.7881\n",
       "   0.7868\n",
       "   0.7825\n",
       "   0.7931\n",
       "   0.7763\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  1.00000e-02 *\n",
       "    0.7101\n",
       "   -0.6295\n",
       "    2.5484\n",
       "    0.7127\n",
       "   -0.2634\n",
       "    0.1054\n",
       "    0.7387\n",
       "   -1.0718\n",
       "   -6.1825\n",
       "    1.5262\n",
       "   -1.3589\n",
       "    0.3075\n",
       "    1.8332\n",
       "   -2.5353\n",
       "   -0.2598\n",
       "   -1.4289\n",
       "   -5.6150\n",
       "    2.9640\n",
       "    8.7786\n",
       "    0.2768\n",
       "    0.9477\n",
       "   -5.1437\n",
       "    3.1297\n",
       "   -2.4592\n",
       "   -8.0071\n",
       "    0.9500\n",
       "   -4.4814\n",
       "   -5.5092\n",
       "   -2.9644\n",
       "    0.1988\n",
       "    1.5644\n",
       "   -3.1678\n",
       "   -2.6698\n",
       "    2.7358\n",
       "   -1.2367\n",
       "   -4.8363\n",
       "   -1.4685\n",
       "   -2.9819\n",
       "    1.7137\n",
       "   -0.8578\n",
       "   -2.9990\n",
       "    0.9386\n",
       "   -0.6579\n",
       "   -4.8439\n",
       "    3.9966\n",
       "    2.3071\n",
       "   -1.3923\n",
       "    2.0597\n",
       "   -2.5721\n",
       "   -0.6261\n",
       "    0.8673\n",
       "   -6.0319\n",
       "   -3.5637\n",
       "    0.3593\n",
       "   -0.6178\n",
       "    2.9028\n",
       "   -4.0637\n",
       "   -1.1084\n",
       "    2.0521\n",
       "   -0.6178\n",
       "    5.3659\n",
       "    0.8653\n",
       "    6.1667\n",
       "    0.2454\n",
       "   -1.7900\n",
       "   -0.3446\n",
       "   -1.7745\n",
       "    4.4543\n",
       "   -4.0127\n",
       "   -5.0820\n",
       "    0.0429\n",
       "    0.6199\n",
       "    5.0925\n",
       "    2.1909\n",
       "    0.0854\n",
       "    0.5679\n",
       "   -8.1909\n",
       "    0.5842\n",
       "    3.0318\n",
       "    0.5410\n",
       "   -4.3833\n",
       "    2.6882\n",
       "    1.0420\n",
       "   -0.9616\n",
       "   -1.0285\n",
       "   -2.2948\n",
       "    1.7918\n",
       "   -1.3613\n",
       "   -1.8501\n",
       "   -0.1222\n",
       "   -0.7349\n",
       "   -4.3175\n",
       "    9.7274\n",
       "    1.4836\n",
       "    1.9255\n",
       "    2.7584\n",
       "    1.9634\n",
       "    0.1571\n",
       "   -3.2508\n",
       "   -3.6827\n",
       "   -0.0230\n",
       "   -0.9826\n",
       "    0.2569\n",
       "    3.1442\n",
       "    0.3260\n",
       "   -4.7170\n",
       "   -5.1980\n",
       "   -5.1666\n",
       "    1.5775\n",
       "    1.9034\n",
       "   -1.9110\n",
       "    1.8784\n",
       "    1.0662\n",
       "   -0.8635\n",
       "    2.7843\n",
       "   -0.6427\n",
       "    4.2570\n",
       "   -6.7106\n",
       "    1.7036\n",
       "    0.8728\n",
       "   -0.5225\n",
       "   -4.7954\n",
       "   -5.8527\n",
       "   -3.8042\n",
       "   -5.0940\n",
       "   -0.0015\n",
       "   -0.3450\n",
       "   -4.2640\n",
       "   -5.3869\n",
       "   -2.2999\n",
       "    0.0469\n",
       "   -5.7897\n",
       "   -4.8215\n",
       "   -3.1095\n",
       "    4.1136\n",
       "    4.3889\n",
       "   -0.3124\n",
       "   -1.3548\n",
       "   -6.3481\n",
       "   -0.2028\n",
       "   -2.0501\n",
       "    0.3515\n",
       "   -1.5259\n",
       "    3.1748\n",
       "    0.6085\n",
       "    0.5919\n",
       "    0.5497\n",
       "    2.2207\n",
       "   -5.8447\n",
       "    5.2321\n",
       "    2.9125\n",
       "   -0.6940\n",
       "    4.2720\n",
       "    4.5137\n",
       "    2.3725\n",
       "   -0.6927\n",
       "    2.8860\n",
       "   -2.2997\n",
       "   -3.2234\n",
       "   -2.5294\n",
       "    0.2025\n",
       "    2.2185\n",
       "    2.2002\n",
       "   -0.1068\n",
       "    1.3996\n",
       "    2.4275\n",
       "   -1.1912\n",
       "    4.7699\n",
       "    2.0356\n",
       "    0.8806\n",
       "   -0.9514\n",
       "    0.7295\n",
       "   -0.8615\n",
       "    2.1517\n",
       "    0.0039\n",
       "    1.7299\n",
       "    2.4140\n",
       "   -5.4157\n",
       "    0.5932\n",
       "   -1.5786\n",
       "   -0.1864\n",
       "   -4.8443\n",
       "   -0.4985\n",
       "   -1.1207\n",
       "    2.9091\n",
       "    1.0870\n",
       "    0.2173\n",
       "    2.2793\n",
       "    0.7147\n",
       "    0.6852\n",
       "    0.5667\n",
       "   -2.0454\n",
       "    4.3164\n",
       "    2.0559\n",
       "   -1.1245\n",
       "    0.5979\n",
       "   -2.4404\n",
       "   -0.1934\n",
       "    0.4932\n",
       "   -4.0618\n",
       "   -3.4973\n",
       "   -1.2723\n",
       "    4.3773\n",
       "    1.0236\n",
       "   -4.1699\n",
       "   -0.8570\n",
       "    0.2898\n",
       "    1.2953\n",
       "   -0.2577\n",
       "   -3.6064\n",
       "    2.8237\n",
       "   -8.0202\n",
       "    4.1237\n",
       "   -4.1495\n",
       "   -1.6631\n",
       "   -5.5875\n",
       "    0.7894\n",
       "   -1.0595\n",
       "    0.4171\n",
       "    2.5645\n",
       "   -3.5593\n",
       "    3.9433\n",
       "   -1.7721\n",
       "   -3.2409\n",
       "   -0.1224\n",
       "    2.8906\n",
       "    1.4572\n",
       "    2.8657\n",
       "   -3.6290\n",
       "   -0.3963\n",
       "   -0.1159\n",
       "    8.7162\n",
       "   -2.5611\n",
       "    4.8908\n",
       "   -3.0745\n",
       "   -0.1291\n",
       "   -3.1644\n",
       "    0.3471\n",
       "    0.1393\n",
       "    4.4509\n",
       "   -0.1463\n",
       "   -0.9844\n",
       "   -0.5852\n",
       "    4.1518\n",
       "   -1.4195\n",
       "    2.1051\n",
       "   -1.2049\n",
       "    1.9386\n",
       "   -2.2445\n",
       "   -3.0725\n",
       "    2.1076\n",
       "    3.2543\n",
       "    1.7479\n",
       "   -0.1210\n",
       "    2.5228\n",
       "    2.5235\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.2208e-04  1.5886e-03  1.0032e-02\n",
       "   -1.6654e-04 -3.0987e-03 -2.8660e-02\n",
       "    2.0988e-02 -1.0799e-03  3.8990e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.2567e-02 -2.1991e-02 -4.6474e-03\n",
       "   -1.2671e-02  1.4062e-03 -1.1220e-02\n",
       "   -9.0112e-03 -3.1088e-02 -3.8172e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -3.1212e-02  1.1340e-02 -2.6662e-02\n",
       "   -3.5898e-02 -8.4164e-03  4.0005e-03\n",
       "   -1.3771e-03 -3.7341e-02  2.9260e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -5.8246e-03  1.5498e-04  1.9072e-02\n",
       "    1.4479e-02 -1.5221e-02 -2.0061e-02\n",
       "    3.0607e-02  2.6430e-02  8.5745e-03\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -3.6156e-02 -2.8592e-02  2.0680e-02\n",
       "    3.4509e-02  2.2169e-02 -4.4295e-02\n",
       "   -2.1539e-02 -2.4759e-03 -1.4194e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    1.0786e-02 -6.7231e-02 -4.5915e-02\n",
       "   -3.4302e-02  1.8691e-02 -2.7696e-02\n",
       "   -1.2587e-02  9.8200e-03  5.8576e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "   -1.6552e-03 -3.9157e-02 -3.7208e-02\n",
       "   -2.2518e-02  1.1935e-02  2.5365e-02\n",
       "   -1.2572e-02 -1.7831e-02  1.0051e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    1.3420e-02  3.1869e-04 -1.9131e-02\n",
       "   -2.0345e-03  2.8499e-03  1.9340e-02\n",
       "    8.4192e-02  4.4180e-02 -3.3548e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -5.7243e-03 -8.9284e-03 -2.8930e-02\n",
       "    5.0158e-02  1.2463e-02 -4.2445e-02\n",
       "   -4.6864e-03  2.1543e-02  1.7523e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "   -1.4809e-02 -3.4234e-02  4.3589e-02\n",
       "    8.0230e-03  5.0075e-03 -3.8791e-02\n",
       "    2.0585e-02  4.0818e-03  8.2286e-03\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "   -1.1801e-03 -2.8226e-02  1.1277e-02\n",
       "   -4.3566e-03 -6.1726e-02 -1.8969e-02\n",
       "    6.9440e-03 -9.5643e-02 -2.7992e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "    6.3588e-03 -2.1698e-02 -1.1030e-02\n",
       "   -2.7897e-02  1.5167e-02  1.3138e-02\n",
       "    7.1728e-03  3.8570e-03  2.8376e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "   -1.4961e-03 -3.1486e-02 -3.1128e-02\n",
       "   -8.9517e-03 -2.9714e-02  1.8087e-02\n",
       "   -2.4727e-02 -2.9426e-03  1.0666e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -2.3111e-03  3.5233e-02 -1.8688e-02\n",
       "   -1.8522e-02  2.2086e-02  8.4581e-03\n",
       "    3.8385e-02 -7.5280e-03 -2.8858e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    1.2041e-02 -1.3460e-02 -3.7960e-02\n",
       "   -3.5905e-03 -3.4693e-02  1.5739e-02\n",
       "   -1.9426e-02  1.0677e-02 -4.5798e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "   -1.7923e-03  1.9277e-02  5.3299e-03\n",
       "    3.8934e-02  9.7237e-03 -2.2205e-03\n",
       "    1.5567e-02  1.2755e-02 -3.7805e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    1.5321e-02 -4.8586e-03  3.2778e-02\n",
       "    1.0265e-02  1.1176e-03 -3.4931e-02\n",
       "    1.0364e-02 -1.6643e-02 -2.1203e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    2.6834e-02  2.1496e-03 -1.5135e-02\n",
       "    2.3618e-02 -1.0914e-02 -2.2241e-03\n",
       "    8.0769e-03  1.3453e-02  1.7372e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (253, 0 ,.,.) = \n",
       "   -2.1763e-02 -8.6056e-03 -2.9296e-02\n",
       "    2.9248e-02  1.6082e-02 -6.1164e-03\n",
       "   -5.9889e-03 -1.7700e-02  1.3798e-02\n",
       "  \n",
       "  (253, 1 ,.,.) = \n",
       "    1.7525e-02  5.4157e-02 -3.7218e-02\n",
       "    1.6918e-02  7.8519e-04  1.2178e-02\n",
       "    8.5243e-03 -2.4137e-02 -2.0377e-02\n",
       "  \n",
       "  (253, 2 ,.,.) = \n",
       "    5.7297e-04  2.4222e-02  3.7573e-03\n",
       "   -9.2391e-03 -1.5032e-02  2.3079e-02\n",
       "   -1.3205e-02  9.7195e-04  1.5809e-02\n",
       "      ... \n",
       "  \n",
       "  (253,253,.,.) = \n",
       "    2.4213e-02  2.8298e-03 -1.4247e-03\n",
       "   -1.0175e-02  2.3372e-02  3.7208e-03\n",
       "    1.0337e-02 -6.6943e-03  2.0077e-02\n",
       "  \n",
       "  (253,254,.,.) = \n",
       "    4.4666e-02 -4.6991e-03 -2.2038e-03\n",
       "    9.7743e-03  1.8359e-02 -2.2629e-02\n",
       "    4.6992e-03  2.9245e-02  5.9238e-03\n",
       "  \n",
       "  (253,255,.,.) = \n",
       "   -2.8195e-02  5.4856e-03 -1.0911e-03\n",
       "   -6.4534e-02 -2.3749e-02 -9.5105e-03\n",
       "    6.8149e-03  6.0197e-02  6.3897e-03\n",
       "          \n",
       "  \n",
       "  (254, 0 ,.,.) = \n",
       "    1.2075e-02 -4.1740e-03  5.6795e-02\n",
       "   -1.8953e-02  3.6059e-02 -2.7102e-02\n",
       "    2.9474e-02 -5.4550e-03 -3.0737e-02\n",
       "  \n",
       "  (254, 1 ,.,.) = \n",
       "    1.7544e-02 -8.6858e-03 -2.2277e-02\n",
       "   -2.0418e-02 -1.3241e-02  3.1916e-02\n",
       "   -3.0195e-03 -4.0487e-02 -2.6544e-02\n",
       "  \n",
       "  (254, 2 ,.,.) = \n",
       "    5.5904e-03 -2.8727e-02 -3.3790e-02\n",
       "    1.6353e-02 -2.7116e-02 -2.6627e-02\n",
       "   -2.0306e-02 -1.6825e-02 -4.1290e-02\n",
       "      ... \n",
       "  \n",
       "  (254,253,.,.) = \n",
       "    6.0106e-02  1.4134e-02 -2.7341e-02\n",
       "    2.4749e-02 -4.7128e-02  1.9242e-02\n",
       "   -2.2815e-03  2.8546e-02  5.8604e-03\n",
       "  \n",
       "  (254,254,.,.) = \n",
       "   -8.9010e-03  1.5137e-02 -1.2723e-02\n",
       "   -3.7857e-02  1.1338e-02 -3.5654e-02\n",
       "   -6.5642e-03  8.4012e-03 -1.8218e-02\n",
       "  \n",
       "  (254,255,.,.) = \n",
       "   -3.7687e-02  7.2920e-02  2.4854e-02\n",
       "    1.0421e-02  4.3048e-02  5.2641e-02\n",
       "    1.6890e-02  2.4714e-02 -1.5973e-02\n",
       "          \n",
       "  \n",
       "  (255, 0 ,.,.) = \n",
       "   -1.2177e-02  3.0029e-02  9.3152e-03\n",
       "    2.2203e-02  2.6678e-03  1.5274e-02\n",
       "   -5.9624e-03  1.0287e-02  7.3665e-03\n",
       "  \n",
       "  (255, 1 ,.,.) = \n",
       "   -4.9912e-03 -3.4928e-03 -2.8445e-02\n",
       "    1.9178e-02  3.5032e-02  8.9347e-03\n",
       "   -5.4947e-03  4.3202e-02 -4.6988e-02\n",
       "  \n",
       "  (255, 2 ,.,.) = \n",
       "    2.3701e-02 -3.9197e-02 -4.2049e-03\n",
       "   -1.3236e-02 -1.5733e-02 -1.5409e-03\n",
       "   -1.2671e-02  3.0944e-03 -4.2066e-02\n",
       "      ... \n",
       "  \n",
       "  (255,253,.,.) = \n",
       "   -2.6062e-02  6.4907e-03  5.7716e-02\n",
       "   -1.7553e-02 -2.3470e-02 -1.2583e-02\n",
       "    1.8220e-02  2.0650e-02  2.7386e-03\n",
       "  \n",
       "  (255,254,.,.) = \n",
       "   -2.7118e-02  1.2317e-03 -2.3828e-02\n",
       "    4.3404e-02  1.6738e-02 -1.1951e-02\n",
       "    5.7418e-03 -1.6145e-03  1.3926e-02\n",
       "  \n",
       "  (255,255,.,.) = \n",
       "   -8.1074e-03 -2.1996e-02  3.4233e-02\n",
       "   -2.5549e-02  3.8570e-03  8.8371e-03\n",
       "   -2.4186e-04 -3.4626e-02 -2.2666e-03\n",
       "  [torch.cuda.FloatTensor of size 256x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7907\n",
       "   0.8023\n",
       "   0.7821\n",
       "   0.7894\n",
       "   0.7983\n",
       "   0.8136\n",
       "   0.7849\n",
       "   0.8033\n",
       "   0.7690\n",
       "   0.7739\n",
       "   0.7886\n",
       "   0.7804\n",
       "   0.7965\n",
       "   0.7779\n",
       "   0.8235\n",
       "   0.7823\n",
       "   0.7806\n",
       "   0.7935\n",
       "   0.7623\n",
       "   0.7957\n",
       "   0.8064\n",
       "   0.7886\n",
       "   0.7866\n",
       "   0.7955\n",
       "   0.7726\n",
       "   0.8039\n",
       "   0.7786\n",
       "   0.7891\n",
       "   0.7692\n",
       "   0.7927\n",
       "   0.7945\n",
       "   0.7740\n",
       "   0.7650\n",
       "   0.7777\n",
       "   0.7815\n",
       "   0.7653\n",
       "   0.7784\n",
       "   0.7606\n",
       "   0.7840\n",
       "   0.7914\n",
       "   0.7741\n",
       "   0.7850\n",
       "   0.7865\n",
       "   0.7922\n",
       "   0.7835\n",
       "   0.7838\n",
       "   0.7788\n",
       "   0.7727\n",
       "   0.7832\n",
       "   0.7990\n",
       "   0.7837\n",
       "   0.7812\n",
       "   0.7860\n",
       "   0.7579\n",
       "   0.8210\n",
       "   0.7970\n",
       "   0.7943\n",
       "   0.7957\n",
       "   0.8398\n",
       "   0.7737\n",
       "   0.7719\n",
       "   0.7968\n",
       "   0.7835\n",
       "   0.7789\n",
       "   0.7900\n",
       "   0.7848\n",
       "   0.7477\n",
       "   0.7919\n",
       "   0.7939\n",
       "   0.7845\n",
       "   0.8104\n",
       "   0.8041\n",
       "   0.7965\n",
       "   0.7756\n",
       "   0.7845\n",
       "   0.7829\n",
       "   0.8049\n",
       "   0.7912\n",
       "   0.7761\n",
       "   0.7868\n",
       "   0.7817\n",
       "   0.7822\n",
       "   0.7920\n",
       "   0.7643\n",
       "   0.7998\n",
       "   0.7620\n",
       "   0.7733\n",
       "   0.7701\n",
       "   0.7843\n",
       "   0.7818\n",
       "   0.7591\n",
       "   0.7921\n",
       "   0.7810\n",
       "   0.7856\n",
       "   0.7945\n",
       "   0.7825\n",
       "   0.7790\n",
       "   0.7947\n",
       "   0.7803\n",
       "   0.8117\n",
       "   0.7921\n",
       "   0.7908\n",
       "   0.7973\n",
       "   0.7637\n",
       "   0.7762\n",
       "   0.7645\n",
       "   0.7789\n",
       "   0.7818\n",
       "   0.7916\n",
       "   0.7862\n",
       "   0.8086\n",
       "   0.7916\n",
       "   0.8075\n",
       "   0.7572\n",
       "   0.7690\n",
       "   0.8022\n",
       "   0.8090\n",
       "   0.7743\n",
       "   0.7870\n",
       "   0.7869\n",
       "   0.7767\n",
       "   0.8104\n",
       "   0.7894\n",
       "   0.7720\n",
       "   0.7946\n",
       "   0.7871\n",
       "   0.7846\n",
       "   0.7864\n",
       "   0.7851\n",
       "   0.8006\n",
       "   0.7768\n",
       "   0.7843\n",
       "   0.7895\n",
       "   0.8423\n",
       "   0.7749\n",
       "   0.7905\n",
       "   0.7821\n",
       "   0.7805\n",
       "   0.7914\n",
       "   0.7820\n",
       "   0.7750\n",
       "   0.7982\n",
       "   0.7671\n",
       "   0.7922\n",
       "   0.7836\n",
       "   0.8038\n",
       "   0.7762\n",
       "   0.7907\n",
       "   0.7910\n",
       "   0.7728\n",
       "   0.7869\n",
       "   0.7808\n",
       "   0.7807\n",
       "   0.7808\n",
       "   0.7724\n",
       "   0.7875\n",
       "   0.8374\n",
       "   0.7734\n",
       "   0.7792\n",
       "   0.7799\n",
       "   0.7704\n",
       "   0.7910\n",
       "   0.7937\n",
       "   0.7691\n",
       "   0.8119\n",
       "   0.7826\n",
       "   0.7914\n",
       "   0.7829\n",
       "   0.7720\n",
       "   0.7872\n",
       "   0.7884\n",
       "   0.7797\n",
       "   0.7712\n",
       "   0.7685\n",
       "   0.7809\n",
       "   0.8051\n",
       "   0.7813\n",
       "   0.7892\n",
       "   0.7602\n",
       "   0.8120\n",
       "   0.7977\n",
       "   0.7825\n",
       "   0.7931\n",
       "   0.7804\n",
       "   0.7873\n",
       "   0.7895\n",
       "   0.7849\n",
       "   0.7958\n",
       "   0.7753\n",
       "   0.7876\n",
       "   0.7719\n",
       "   0.7950\n",
       "   0.8957\n",
       "   0.7680\n",
       "   0.7905\n",
       "   0.7805\n",
       "   0.7815\n",
       "   0.7815\n",
       "   0.7993\n",
       "   0.7734\n",
       "   0.7855\n",
       "   0.8080\n",
       "   0.7778\n",
       "   0.7763\n",
       "   0.7888\n",
       "   0.7844\n",
       "   0.7942\n",
       "   0.7990\n",
       "   0.8026\n",
       "   0.7777\n",
       "   0.7926\n",
       "   0.7899\n",
       "   0.8042\n",
       "   0.7765\n",
       "   0.7642\n",
       "   0.8139\n",
       "   0.7941\n",
       "   0.8058\n",
       "   0.7814\n",
       "   0.7955\n",
       "   0.7823\n",
       "   0.7673\n",
       "   0.7756\n",
       "   0.7811\n",
       "   0.8094\n",
       "   0.7968\n",
       "   0.7820\n",
       "   0.7889\n",
       "   0.7702\n",
       "   0.7814\n",
       "   0.7965\n",
       "   0.7992\n",
       "   0.7879\n",
       "   0.7866\n",
       "   0.7895\n",
       "   0.7756\n",
       "   0.7834\n",
       "   0.7982\n",
       "   0.7785\n",
       "   0.7782\n",
       "   0.7917\n",
       "   0.7678\n",
       "   0.8120\n",
       "   0.7791\n",
       "   0.7808\n",
       "   0.7806\n",
       "   0.7987\n",
       "   0.7893\n",
       "   0.7955\n",
       "   0.8128\n",
       "   0.7945\n",
       "   0.7905\n",
       "   0.7928\n",
       "   0.7788\n",
       "   0.7807\n",
       "   0.7763\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  1.00000e-02 *\n",
       "    0.9242\n",
       "    3.0353\n",
       "   -3.9506\n",
       "    0.1444\n",
       "   -2.7425\n",
       "   -6.4738\n",
       "   -5.4696\n",
       "   -1.0357\n",
       "   -0.7326\n",
       "   -0.8364\n",
       "   -0.6555\n",
       "    1.1360\n",
       "    1.5661\n",
       "   -3.5617\n",
       "   -3.4375\n",
       "   -4.1125\n",
       "   -0.1967\n",
       "   -0.0597\n",
       "    2.4903\n",
       "   -6.0931\n",
       "   -1.8374\n",
       "    1.0925\n",
       "   -0.5330\n",
       "   -3.3451\n",
       "    1.0155\n",
       "   -4.8124\n",
       "   -2.5128\n",
       "    0.7819\n",
       "   -0.7820\n",
       "    2.4555\n",
       "   -2.5361\n",
       "   -0.3070\n",
       "   -0.6827\n",
       "    3.4637\n",
       "   -3.4217\n",
       "   -1.7343\n",
       "   -2.2124\n",
       "   -2.6285\n",
       "   -0.0894\n",
       "   -2.0547\n",
       "   -3.0324\n",
       "   -0.0623\n",
       "   -2.9943\n",
       "    2.0170\n",
       "   -2.6509\n",
       "   -2.4010\n",
       "   -1.3939\n",
       "   -0.2357\n",
       "   -5.5669\n",
       "   -2.1459\n",
       "   -3.6202\n",
       "   -0.5369\n",
       "    0.8352\n",
       "   -0.9804\n",
       "   -1.9282\n",
       "   -1.5389\n",
       "   -0.7293\n",
       "   -0.7921\n",
       "   -3.4982\n",
       "   -1.0603\n",
       "   -0.7447\n",
       "   -1.6016\n",
       "   -0.9619\n",
       "    2.3404\n",
       "   -2.5941\n",
       "   -1.2588\n",
       "   -2.8327\n",
       "    1.0539\n",
       "   -2.8118\n",
       "   -0.8966\n",
       "   -4.7797\n",
       "   -1.8656\n",
       "   -0.7216\n",
       "   -2.2793\n",
       "    1.5483\n",
       "   -2.5306\n",
       "   -4.5431\n",
       "   -0.8757\n",
       "    5.6360\n",
       "   -1.9161\n",
       "   -3.0421\n",
       "    0.3848\n",
       "   -3.3227\n",
       "   -0.7053\n",
       "   -0.4149\n",
       "   -1.4722\n",
       "   -1.4374\n",
       "   -0.5099\n",
       "   -2.8856\n",
       "   -0.6172\n",
       "   -1.1659\n",
       "   -1.4644\n",
       "   -1.4334\n",
       "   -5.8986\n",
       "   -2.0527\n",
       "   -2.7907\n",
       "   -3.9548\n",
       "    1.4631\n",
       "   -2.3715\n",
       "   -2.6561\n",
       "   -2.4928\n",
       "   -0.3602\n",
       "   -1.8407\n",
       "   -3.5198\n",
       "   -6.5213\n",
       "    3.1052\n",
       "    4.8859\n",
       "   -0.1405\n",
       "    1.2218\n",
       "   -0.1908\n",
       "   -1.8533\n",
       "    0.3680\n",
       "   -6.7114\n",
       "    0.3435\n",
       "   -0.1398\n",
       "    2.4797\n",
       "   -5.0550\n",
       "   -0.9702\n",
       "    2.3429\n",
       "    0.6557\n",
       "   -1.7176\n",
       "   -1.0579\n",
       "   -0.7538\n",
       "    1.1139\n",
       "   -6.4535\n",
       "   -4.7387\n",
       "   -0.5766\n",
       "   -3.2733\n",
       "   -4.3919\n",
       "   -0.1306\n",
       "   -0.3778\n",
       "   -1.0329\n",
       "   -1.6367\n",
       "   -3.4522\n",
       "   -1.5075\n",
       "   -0.3293\n",
       "   -2.3610\n",
       "    0.2470\n",
       "   -2.8686\n",
       "    1.7638\n",
       "   -0.9492\n",
       "   -2.1548\n",
       "    0.4241\n",
       "   -4.8096\n",
       "   -0.7866\n",
       "   -3.1694\n",
       "   -3.4371\n",
       "   -0.0378\n",
       "   -1.5038\n",
       "   -3.4051\n",
       "   -0.5155\n",
       "   -0.7416\n",
       "   -0.1301\n",
       "   -0.6369\n",
       "    2.2901\n",
       "   -3.8231\n",
       "   -3.5349\n",
       "    0.3124\n",
       "   -2.5217\n",
       "    0.5041\n",
       "   -2.3565\n",
       "   -3.9801\n",
       "   -1.6420\n",
       "    0.3808\n",
       "   -2.3952\n",
       "    0.7603\n",
       "   -1.1339\n",
       "    0.1162\n",
       "   -1.5869\n",
       "    0.3793\n",
       "    0.6882\n",
       "   -3.1929\n",
       "    1.5219\n",
       "   -0.3517\n",
       "    1.9386\n",
       "   -1.4032\n",
       "   -3.8347\n",
       "   -0.8184\n",
       "    0.8778\n",
       "   -1.3839\n",
       "   -1.5023\n",
       "    1.8335\n",
       "   -0.4572\n",
       "   -4.7069\n",
       "    0.4820\n",
       "   -3.8896\n",
       "   -1.6889\n",
       "    3.4979\n",
       "    0.9355\n",
       "   -0.3350\n",
       "    5.3012\n",
       "   -0.3890\n",
       "   -3.0204\n",
       "   -1.0834\n",
       "   -3.8783\n",
       "   -2.9844\n",
       "    1.4065\n",
       "    2.0955\n",
       "   -0.4720\n",
       "   -0.3715\n",
       "    1.4549\n",
       "    1.2992\n",
       "   -2.9484\n",
       "    1.3483\n",
       "   -4.4433\n",
       "   -0.7682\n",
       "    0.3199\n",
       "   -3.4804\n",
       "   -3.8484\n",
       "   -0.4438\n",
       "   -2.7331\n",
       "    4.3014\n",
       "   -1.1908\n",
       "    0.0727\n",
       "   -2.5600\n",
       "   -1.0500\n",
       "   -0.1957\n",
       "   -2.6936\n",
       "    2.7686\n",
       "   -0.0505\n",
       "   -1.5931\n",
       "   -2.4373\n",
       "   -0.4702\n",
       "   -1.1974\n",
       "   -1.8526\n",
       "    1.8817\n",
       "    3.6278\n",
       "   -1.3942\n",
       "   -3.4665\n",
       "   -4.8325\n",
       "   -0.9650\n",
       "   -1.2956\n",
       "    0.5542\n",
       "    1.9036\n",
       "    3.9459\n",
       "   -0.4243\n",
       "   -0.1371\n",
       "   -1.6061\n",
       "    6.0387\n",
       "    5.1947\n",
       "   -2.7139\n",
       "   -1.9195\n",
       "   -0.2123\n",
       "    1.3103\n",
       "   -0.6612\n",
       "   -4.0540\n",
       "   -3.5224\n",
       "    0.0317\n",
       "    0.4271\n",
       "   -5.7088\n",
       "   -1.5140\n",
       "   -3.0445\n",
       "   -0.7672\n",
       "   -0.4649\n",
       "   -2.9391\n",
       "   -0.5295\n",
       "  [torch.cuda.FloatTensor of size 256 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    8.4379e-04 -8.7682e-03  3.6554e-03\n",
       "   -9.2768e-03  7.5912e-03  3.2966e-02\n",
       "    2.2222e-02 -6.1979e-03  1.2623e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.0370e-02  1.5494e-03  5.0402e-03\n",
       "   -4.2642e-03 -9.9846e-03 -3.2053e-02\n",
       "   -1.0378e-02  2.5461e-02  1.1547e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -4.5710e-02  7.1500e-03  4.5952e-03\n",
       "    1.0924e-02 -2.7109e-03  1.1821e-02\n",
       "    1.4066e-02 -5.5328e-04 -1.8481e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "    2.9492e-02  1.1440e-02 -6.2302e-03\n",
       "    1.9275e-02  7.8866e-03 -3.0124e-02\n",
       "   -4.5105e-02  7.4453e-03 -2.3201e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "    4.2897e-02  1.8484e-02 -3.3362e-02\n",
       "    2.6879e-02  1.7792e-02  5.5265e-03\n",
       "    2.8549e-03  1.1602e-02  1.8330e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "    6.8266e-03  2.6075e-02 -8.1665e-04\n",
       "   -3.2539e-02 -1.9676e-02 -1.8563e-02\n",
       "    1.6925e-02 -2.2808e-02 -1.0560e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    1.7844e-02 -6.1931e-03  6.7292e-03\n",
       "   -1.0358e-02  3.9263e-02 -3.6029e-02\n",
       "   -1.1996e-02  3.2317e-03 -7.0932e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -1.5314e-03  4.9859e-03 -4.1705e-03\n",
       "   -1.6162e-02 -3.7406e-03 -4.6221e-02\n",
       "   -2.5671e-02  2.1601e-03  7.5613e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    8.4756e-03  1.6299e-02 -2.2964e-02\n",
       "   -1.2520e-02 -1.8029e-02  1.2262e-02\n",
       "   -9.6244e-03  6.1456e-03 -9.0597e-04\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    2.1801e-02  2.6028e-02  1.8834e-02\n",
       "    6.7297e-03 -1.6240e-02  1.3173e-02\n",
       "    1.1023e-02 -4.6940e-03 -3.9036e-03\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    2.4080e-02 -2.4799e-02 -2.7192e-03\n",
       "   -2.2602e-02  2.9527e-04  1.0312e-02\n",
       "   -1.5377e-02  1.9445e-03  4.3950e-04\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -6.9452e-03 -2.1005e-02 -2.4527e-02\n",
       "    5.0356e-03  2.8193e-02 -3.0606e-03\n",
       "    2.0076e-02 -1.6861e-03  2.9266e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.2038e-02 -6.3613e-03 -1.8145e-02\n",
       "   -1.1853e-02 -2.4614e-02 -1.8860e-03\n",
       "    1.2357e-02 -1.3833e-02 -1.5111e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    1.4472e-02  1.9061e-03 -7.0826e-03\n",
       "    6.3681e-03 -1.0020e-02 -4.9493e-03\n",
       "   -1.1512e-02 -1.7133e-02 -8.2813e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    9.8507e-03  4.2894e-03  1.0856e-02\n",
       "    2.8278e-03  1.0201e-03 -1.3270e-02\n",
       "   -8.1316e-03  5.0453e-04  2.7898e-03\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "   -6.3665e-03  1.4591e-03  8.7325e-03\n",
       "   -1.6096e-02  3.7047e-02  1.6827e-02\n",
       "    1.5634e-03 -2.3051e-02  3.0832e-03\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    3.0150e-03 -2.4428e-02  1.6952e-02\n",
       "   -6.5583e-03  1.4458e-02  2.4760e-02\n",
       "    9.5337e-03 -1.1842e-02  4.0490e-03\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "    7.5873e-04  7.9592e-03 -4.0903e-03\n",
       "    2.0389e-03  5.9340e-04 -8.4480e-03\n",
       "    7.0588e-03 -1.4360e-02  4.2305e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "    8.4874e-03  3.2951e-02 -1.0698e-02\n",
       "    1.3895e-02  1.1246e-02  3.1981e-02\n",
       "   -1.2709e-02 -1.2882e-02 -8.7751e-03\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "    5.3330e-03  1.2042e-03 -1.0518e-03\n",
       "    3.0134e-02 -8.3900e-04 -6.4136e-03\n",
       "   -1.5670e-02 -3.2456e-02  7.2968e-04\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "    3.5668e-02  1.1175e-02  1.7269e-02\n",
       "    1.2861e-04  7.8051e-03  1.7186e-02\n",
       "    5.5906e-03  7.4772e-03 -1.0401e-02\n",
       "      ... \n",
       "  \n",
       "  (509,253,.,.) = \n",
       "   -3.2157e-02  8.8447e-03  3.1045e-03\n",
       "   -1.6364e-02  1.2588e-02  1.8243e-02\n",
       "   -9.6635e-03 -5.8744e-03  1.4286e-02\n",
       "  \n",
       "  (509,254,.,.) = \n",
       "    3.9345e-02  3.3215e-02  3.0887e-02\n",
       "   -1.3769e-02  2.6777e-02  7.4466e-03\n",
       "   -2.4790e-02 -1.9126e-02  3.3580e-02\n",
       "  \n",
       "  (509,255,.,.) = \n",
       "   -6.4483e-03 -1.5768e-02 -2.2145e-03\n",
       "    5.6605e-03  3.2489e-03 -1.3330e-02\n",
       "   -1.5847e-02  3.6636e-02 -1.6904e-02\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "   -8.3932e-03  8.7417e-03  2.1741e-02\n",
       "    2.3609e-02 -1.2792e-02  9.6566e-03\n",
       "   -1.9738e-02  2.0675e-02  2.5311e-02\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "    1.1246e-03 -8.8059e-04 -3.4390e-02\n",
       "    1.4459e-02  2.7330e-02  4.9666e-03\n",
       "    7.6993e-03  1.3743e-02 -8.9185e-03\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "   -8.9731e-03  1.8390e-02  7.2245e-03\n",
       "   -3.0191e-03 -1.0296e-02 -5.2375e-05\n",
       "   -1.2439e-02  1.8830e-03  5.5628e-03\n",
       "      ... \n",
       "  \n",
       "  (510,253,.,.) = \n",
       "   -6.8938e-03 -1.6415e-02  1.6974e-03\n",
       "    1.9074e-02 -1.7125e-02  1.2657e-02\n",
       "   -3.3320e-02  1.9343e-02 -9.0125e-03\n",
       "  \n",
       "  (510,254,.,.) = \n",
       "   -2.2270e-02  1.9849e-02  3.9470e-03\n",
       "    3.7537e-02  1.5811e-02 -1.2650e-02\n",
       "    2.4178e-02  1.1642e-03  3.8396e-02\n",
       "  \n",
       "  (510,255,.,.) = \n",
       "    1.1756e-02 -1.1775e-02 -9.9673e-03\n",
       "   -8.3079e-03 -7.7619e-03 -4.5103e-03\n",
       "    1.0695e-02 -3.7739e-04  7.2699e-03\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "    2.5247e-02  1.3825e-02 -1.5675e-02\n",
       "   -7.5175e-03  4.7969e-02 -4.7200e-03\n",
       "    1.9154e-02 -4.0242e-03 -9.2731e-04\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "   -1.3682e-02 -3.6213e-02 -4.3720e-02\n",
       "   -8.0832e-03 -1.4016e-02 -1.9973e-02\n",
       "   -1.3888e-02 -2.1704e-02 -4.9539e-03\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "    5.1913e-03  1.2999e-02 -2.7152e-02\n",
       "    6.9087e-03  2.3388e-03 -6.4451e-03\n",
       "   -2.7536e-02  1.5216e-02 -1.0125e-02\n",
       "      ... \n",
       "  \n",
       "  (511,253,.,.) = \n",
       "    2.6160e-02 -1.0932e-02 -1.6310e-02\n",
       "   -9.6863e-03  2.2450e-02 -2.3562e-02\n",
       "    2.1532e-02 -1.1239e-02  2.0118e-02\n",
       "  \n",
       "  (511,254,.,.) = \n",
       "    1.1989e-03 -1.0115e-02  9.5221e-03\n",
       "    8.7300e-03 -2.2280e-03  1.3534e-03\n",
       "    6.4022e-04 -1.3701e-03  1.5633e-02\n",
       "  \n",
       "  (511,255,.,.) = \n",
       "    1.1094e-02 -7.0289e-03  7.6598e-03\n",
       "    1.1131e-02 -1.4106e-02 -4.7326e-03\n",
       "    3.0818e-02 -5.2154e-03 -2.1297e-02\n",
       "  [torch.cuda.FloatTensor of size 512x256x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7832\n",
       "   0.7931\n",
       "   0.7964\n",
       "   0.7822\n",
       "   0.7943\n",
       "   0.7867\n",
       "   0.7746\n",
       "   0.7829\n",
       "   0.8069\n",
       "   0.7815\n",
       "   0.7653\n",
       "   0.7825\n",
       "   0.7582\n",
       "   0.7941\n",
       "   0.7720\n",
       "   0.7656\n",
       "   0.7837\n",
       "   0.7778\n",
       "   0.7859\n",
       "   0.7743\n",
       "   0.7753\n",
       "   0.7895\n",
       "   0.7819\n",
       "   0.7987\n",
       "   0.7858\n",
       "   0.7937\n",
       "   0.7976\n",
       "   0.7628\n",
       "   0.7717\n",
       "   0.7816\n",
       "   0.8259\n",
       "   0.8028\n",
       "   0.7571\n",
       "   0.8011\n",
       "   0.7820\n",
       "   0.7809\n",
       "   0.7799\n",
       "   0.7812\n",
       "   0.7910\n",
       "   0.7733\n",
       "   0.7932\n",
       "   0.7811\n",
       "   0.7922\n",
       "   0.7824\n",
       "   0.8071\n",
       "   0.7686\n",
       "   0.7793\n",
       "   0.7833\n",
       "   0.7682\n",
       "   0.7849\n",
       "   0.7795\n",
       "   0.7589\n",
       "   0.7837\n",
       "   0.7715\n",
       "   0.7860\n",
       "   0.7857\n",
       "   0.7829\n",
       "   0.8275\n",
       "   0.8239\n",
       "   0.7743\n",
       "   0.7751\n",
       "   0.7770\n",
       "   0.7784\n",
       "   0.7791\n",
       "   0.7816\n",
       "   0.8135\n",
       "   0.7888\n",
       "   0.7669\n",
       "   0.7730\n",
       "   0.7743\n",
       "   0.8258\n",
       "   0.7670\n",
       "   0.7879\n",
       "   0.7610\n",
       "   0.7792\n",
       "   0.7703\n",
       "   0.7638\n",
       "   0.7870\n",
       "   0.7786\n",
       "   0.8072\n",
       "   0.7803\n",
       "   0.7888\n",
       "   0.7784\n",
       "   0.7911\n",
       "   0.7790\n",
       "   0.7767\n",
       "   0.7946\n",
       "   0.7875\n",
       "   0.7681\n",
       "   0.7744\n",
       "   0.7863\n",
       "   0.8004\n",
       "   0.7773\n",
       "   0.7753\n",
       "   0.7808\n",
       "   0.7820\n",
       "   0.7847\n",
       "   0.7927\n",
       "   0.7719\n",
       "   0.7961\n",
       "   0.7869\n",
       "   0.8063\n",
       "   0.7387\n",
       "   0.7709\n",
       "   0.7801\n",
       "   0.7902\n",
       "   0.7764\n",
       "   0.7879\n",
       "   0.7944\n",
       "   0.7612\n",
       "   0.7739\n",
       "   0.8067\n",
       "   0.7650\n",
       "   0.7487\n",
       "   0.7733\n",
       "   0.7886\n",
       "   0.7984\n",
       "   0.7983\n",
       "   0.7876\n",
       "   0.7823\n",
       "   0.8090\n",
       "   0.7923\n",
       "   0.7797\n",
       "   0.7993\n",
       "   0.7849\n",
       "   0.7807\n",
       "   0.7773\n",
       "   0.8077\n",
       "   0.7825\n",
       "   0.7852\n",
       "   0.7846\n",
       "   0.7722\n",
       "   0.7924\n",
       "   0.7907\n",
       "   0.7772\n",
       "   0.8163\n",
       "   0.7855\n",
       "   0.7786\n",
       "   0.7767\n",
       "   0.7728\n",
       "   0.7909\n",
       "   0.7984\n",
       "   0.7895\n",
       "   0.7601\n",
       "   0.7835\n",
       "   0.8093\n",
       "   0.7798\n",
       "   0.7900\n",
       "   0.7937\n",
       "   0.8055\n",
       "   0.7852\n",
       "   0.8202\n",
       "   0.7620\n",
       "   0.7837\n",
       "   0.7959\n",
       "   0.7602\n",
       "   0.7782\n",
       "   0.7860\n",
       "   0.7903\n",
       "   0.7775\n",
       "   0.7960\n",
       "   0.7911\n",
       "   0.8031\n",
       "   0.7939\n",
       "   0.7829\n",
       "   0.7876\n",
       "   0.7791\n",
       "   0.7734\n",
       "   0.8227\n",
       "   0.7946\n",
       "   0.7741\n",
       "   0.8109\n",
       "   0.7773\n",
       "   0.7845\n",
       "   0.8111\n",
       "   0.7993\n",
       "   0.7814\n",
       "   0.7874\n",
       "   0.7696\n",
       "   0.7893\n",
       "   0.8059\n",
       "   0.7810\n",
       "   0.7862\n",
       "   0.8050\n",
       "   0.7867\n",
       "   0.7807\n",
       "   0.7955\n",
       "   0.7701\n",
       "   0.7927\n",
       "   0.7737\n",
       "   0.7351\n",
       "   0.7938\n",
       "   0.7700\n",
       "   0.7907\n",
       "   0.8028\n",
       "   0.7798\n",
       "   0.7838\n",
       "   0.7958\n",
       "   0.8039\n",
       "   0.8068\n",
       "   0.7671\n",
       "   0.7879\n",
       "   0.7999\n",
       "   0.7642\n",
       "   0.7897\n",
       "   0.7877\n",
       "   0.7621\n",
       "   0.7485\n",
       "   0.7745\n",
       "   0.7969\n",
       "   0.7582\n",
       "   0.8100\n",
       "   0.7863\n",
       "   0.7822\n",
       "   0.7761\n",
       "   0.7847\n",
       "   0.7938\n",
       "   0.7548\n",
       "   0.7557\n",
       "   0.7789\n",
       "   0.7856\n",
       "   0.8055\n",
       "   0.8231\n",
       "   0.7784\n",
       "   0.7811\n",
       "   0.7928\n",
       "   0.7825\n",
       "   0.7731\n",
       "   0.7796\n",
       "   0.7783\n",
       "   0.7750\n",
       "   0.7904\n",
       "   0.7998\n",
       "   0.7811\n",
       "   0.7920\n",
       "   0.7866\n",
       "   0.7783\n",
       "   0.7740\n",
       "   0.7831\n",
       "   0.7935\n",
       "   0.7684\n",
       "   0.8048\n",
       "   0.8003\n",
       "   0.7998\n",
       "   0.7958\n",
       "   0.7680\n",
       "   0.7707\n",
       "   0.7608\n",
       "   0.7805\n",
       "   0.7720\n",
       "   0.7959\n",
       "   0.7855\n",
       "   0.7816\n",
       "   0.7843\n",
       "   0.7773\n",
       "   0.7777\n",
       "   0.7657\n",
       "   0.7773\n",
       "   0.7820\n",
       "   0.7665\n",
       "   0.7589\n",
       "   0.7730\n",
       "   0.7771\n",
       "   0.7799\n",
       "   0.7938\n",
       "   0.7794\n",
       "   0.8013\n",
       "   0.7838\n",
       "   0.7717\n",
       "   0.7591\n",
       "   0.7857\n",
       "   0.7786\n",
       "   0.7956\n",
       "   0.7706\n",
       "   0.7881\n",
       "   0.7908\n",
       "   0.7793\n",
       "   0.8070\n",
       "   0.7758\n",
       "   0.7924\n",
       "   0.7834\n",
       "   0.7788\n",
       "   0.7858\n",
       "   0.7806\n",
       "   0.7831\n",
       "   0.7743\n",
       "   0.8039\n",
       "   0.7823\n",
       "   0.7844\n",
       "   0.7818\n",
       "   0.7761\n",
       "   0.7764\n",
       "   0.7891\n",
       "   0.7744\n",
       "   0.7784\n",
       "   0.7762\n",
       "   0.7564\n",
       "   0.7741\n",
       "   0.7779\n",
       "   0.7882\n",
       "   0.7929\n",
       "   0.7815\n",
       "   0.7911\n",
       "   0.7807\n",
       "   0.7789\n",
       "   0.7839\n",
       "   0.7857\n",
       "   0.7892\n",
       "   0.7746\n",
       "   0.7888\n",
       "   0.7996\n",
       "   0.7784\n",
       "   0.7787\n",
       "   0.7856\n",
       "   0.7865\n",
       "   0.7993\n",
       "   0.7923\n",
       "   0.7874\n",
       "   0.7824\n",
       "   0.7809\n",
       "   0.7906\n",
       "   0.7726\n",
       "   0.7926\n",
       "   0.7965\n",
       "   0.7802\n",
       "   0.7764\n",
       "   0.7815\n",
       "   0.7991\n",
       "   0.7570\n",
       "   0.8179\n",
       "   0.7557\n",
       "   0.7910\n",
       "   0.7843\n",
       "   0.7605\n",
       "   0.7639\n",
       "   0.8042\n",
       "   0.7804\n",
       "   0.8083\n",
       "   0.7916\n",
       "   0.7915\n",
       "   0.7476\n",
       "   0.7659\n",
       "   0.7830\n",
       "   0.7830\n",
       "   0.7838\n",
       "   0.7890\n",
       "   0.8055\n",
       "   0.7997\n",
       "   0.7808\n",
       "   0.7922\n",
       "   0.7504\n",
       "   0.7938\n",
       "   0.8113\n",
       "   0.7782\n",
       "   0.7591\n",
       "   0.7808\n",
       "   0.7825\n",
       "   0.7737\n",
       "   0.8131\n",
       "   0.7487\n",
       "   0.7646\n",
       "   0.7923\n",
       "   0.7744\n",
       "   0.7287\n",
       "   0.7482\n",
       "   0.7588\n",
       "   0.7938\n",
       "   0.7763\n",
       "   0.8052\n",
       "   0.7804\n",
       "   0.7809\n",
       "   0.7912\n",
       "   0.7696\n",
       "   0.7824\n",
       "   0.7767\n",
       "   0.7817\n",
       "   0.7764\n",
       "   0.8092\n",
       "   0.7757\n",
       "   0.7623\n",
       "   0.7838\n",
       "   0.7841\n",
       "   0.7800\n",
       "   0.7891\n",
       "   0.7697\n",
       "   0.7940\n",
       "   0.7794\n",
       "   0.7889\n",
       "   0.7882\n",
       "   0.7859\n",
       "   0.7832\n",
       "   0.7916\n",
       "   0.7884\n",
       "   0.7772\n",
       "   0.7953\n",
       "   0.7843\n",
       "   0.7802\n",
       "   0.7865\n",
       "   0.7599\n",
       "   0.7833\n",
       "   0.7710\n",
       "   0.7643\n",
       "   0.7813\n",
       "   0.7980\n",
       "   0.7814\n",
       "   0.7709\n",
       "   0.8033\n",
       "   0.7977\n",
       "   0.7855\n",
       "   0.7843\n",
       "   0.7565\n",
       "   0.7884\n",
       "   0.7825\n",
       "   0.7783\n",
       "   0.7471\n",
       "   0.7908\n",
       "   0.7702\n",
       "   0.7781\n",
       "   0.7774\n",
       "   0.7787\n",
       "   0.7614\n",
       "   0.7701\n",
       "   0.7627\n",
       "   0.7784\n",
       "   0.7590\n",
       "   0.7733\n",
       "   0.7844\n",
       "   0.7891\n",
       "   0.7812\n",
       "   0.7877\n",
       "   0.7901\n",
       "   0.7515\n",
       "   0.8034\n",
       "   0.8062\n",
       "   0.8086\n",
       "   0.7854\n",
       "   0.7780\n",
       "   0.7808\n",
       "   0.8009\n",
       "   0.7790\n",
       "   0.7803\n",
       "   0.7918\n",
       "   0.7874\n",
       "   0.7829\n",
       "   0.8028\n",
       "   0.7692\n",
       "   0.7933\n",
       "   0.7689\n",
       "   0.7866\n",
       "   0.7844\n",
       "   0.7880\n",
       "   0.7671\n",
       "   0.7760\n",
       "   0.7813\n",
       "   0.7804\n",
       "   0.7848\n",
       "   0.8290\n",
       "   0.7806\n",
       "   0.7820\n",
       "   0.7798\n",
       "   0.7784\n",
       "   0.7828\n",
       "   0.7543\n",
       "   0.7930\n",
       "   0.7719\n",
       "   0.7787\n",
       "   0.7873\n",
       "   0.7833\n",
       "   0.7757\n",
       "   0.7856\n",
       "   0.8053\n",
       "   0.8166\n",
       "   0.8247\n",
       "   0.7818\n",
       "   0.7741\n",
       "   0.7450\n",
       "   0.7836\n",
       "   0.7688\n",
       "   0.7508\n",
       "   0.7981\n",
       "   0.7950\n",
       "   0.7808\n",
       "   0.7709\n",
       "   0.8125\n",
       "   0.7817\n",
       "   0.7949\n",
       "   0.7918\n",
       "   0.7794\n",
       "   0.8024\n",
       "   0.7864\n",
       "   0.7905\n",
       "   0.7963\n",
       "   0.8158\n",
       "   0.7794\n",
       "   0.7952\n",
       "   0.7830\n",
       "   0.7862\n",
       "   0.7824\n",
       "   0.7905\n",
       "   0.7942\n",
       "   0.7932\n",
       "   0.7798\n",
       "   0.7833\n",
       "   0.7797\n",
       "   0.7932\n",
       "   0.8017\n",
       "   0.7814\n",
       "   0.7895\n",
       "   0.7782\n",
       "   0.7623\n",
       "   0.8073\n",
       "   0.7895\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.0452\n",
       "   0.0083\n",
       "  -0.0205\n",
       "   0.0070\n",
       "   0.0050\n",
       "  -0.0163\n",
       "  -0.0221\n",
       "   0.0244\n",
       "  -0.0118\n",
       "  -0.0641\n",
       "  -0.0577\n",
       "   0.0057\n",
       "  -0.0496\n",
       "  -0.0020\n",
       "  -0.0550\n",
       "  -0.0719\n",
       "  -0.0216\n",
       "  -0.0201\n",
       "  -0.0184\n",
       "  -0.0305\n",
       "   0.0068\n",
       "  -0.0099\n",
       "  -0.0478\n",
       "  -0.0065\n",
       "   0.0169\n",
       "  -0.0143\n",
       "  -0.0386\n",
       "  -0.0624\n",
       "   0.0029\n",
       "   0.0151\n",
       "   0.0053\n",
       "  -0.0190\n",
       "  -0.0143\n",
       "   0.0053\n",
       "   0.0140\n",
       "   0.0148\n",
       "   0.0023\n",
       "   0.0109\n",
       "   0.0335\n",
       "  -0.0676\n",
       "  -0.0166\n",
       "  -0.0005\n",
       "  -0.0094\n",
       "  -0.0620\n",
       "  -0.0095\n",
       "  -0.0373\n",
       "  -0.0355\n",
       "   0.0063\n",
       "  -0.0476\n",
       "  -0.0102\n",
       "  -0.0229\n",
       "  -0.0358\n",
       "  -0.0079\n",
       "  -0.0506\n",
       "  -0.0759\n",
       "  -0.0121\n",
       "   0.0293\n",
       "   0.0757\n",
       "   0.0033\n",
       "  -0.0427\n",
       "  -0.0611\n",
       "  -0.0117\n",
       "   0.0243\n",
       "  -0.0124\n",
       "  -0.0517\n",
       "  -0.0039\n",
       "  -0.0105\n",
       "  -0.0506\n",
       "  -0.0621\n",
       "  -0.0050\n",
       "   0.0562\n",
       "  -0.0785\n",
       "   0.0285\n",
       "  -0.0171\n",
       "  -0.0142\n",
       "  -0.0578\n",
       "  -0.0138\n",
       "   0.0203\n",
       "  -0.0666\n",
       "   0.0011\n",
       "   0.0055\n",
       "  -0.0110\n",
       "   0.0061\n",
       "  -0.0394\n",
       "  -0.0138\n",
       "  -0.0097\n",
       "   0.0432\n",
       "  -0.0155\n",
       "  -0.0551\n",
       "  -0.0374\n",
       "  -0.0504\n",
       "   0.0018\n",
       "   0.0077\n",
       "  -0.0015\n",
       "  -0.0049\n",
       "  -0.0278\n",
       "  -0.0016\n",
       "  -0.0094\n",
       "  -0.0290\n",
       "   0.0079\n",
       "  -0.0339\n",
       "   0.0588\n",
       "  -0.0865\n",
       "  -0.0162\n",
       "  -0.0142\n",
       "  -0.0300\n",
       "  -0.0166\n",
       "  -0.0295\n",
       "  -0.0416\n",
       "  -0.0496\n",
       "  -0.0251\n",
       "  -0.0345\n",
       "  -0.0212\n",
       "  -0.0847\n",
       "  -0.0117\n",
       "  -0.0285\n",
       "   0.0527\n",
       "  -0.0339\n",
       "  -0.0454\n",
       "   0.0152\n",
       "   0.0512\n",
       "  -0.0252\n",
       "  -0.0387\n",
       "   0.0361\n",
       "   0.0080\n",
       "  -0.0291\n",
       "  -0.0133\n",
       "  -0.0078\n",
       "   0.0071\n",
       "   0.0026\n",
       "   0.0108\n",
       "  -0.0412\n",
       "   0.0471\n",
       "   0.0119\n",
       "  -0.0339\n",
       "   0.0635\n",
       "  -0.0302\n",
       "  -0.0197\n",
       "  -0.0171\n",
       "  -0.0356\n",
       "   0.0600\n",
       "  -0.0056\n",
       "   0.0201\n",
       "  -0.0619\n",
       "  -0.0400\n",
       "  -0.0172\n",
       "   0.0012\n",
       "   0.0344\n",
       "   0.0579\n",
       "   0.0029\n",
       "  -0.0115\n",
       "  -0.0213\n",
       "  -0.0736\n",
       "   0.0180\n",
       "   0.1222\n",
       "  -0.0585\n",
       "  -0.0031\n",
       "  -0.0163\n",
       "   0.0360\n",
       "  -0.0387\n",
       "  -0.0154\n",
       "   0.0282\n",
       "  -0.0090\n",
       "   0.0006\n",
       "  -0.0147\n",
       "  -0.0263\n",
       "  -0.0256\n",
       "  -0.0506\n",
       "   0.0917\n",
       "  -0.0026\n",
       "  -0.0008\n",
       "   0.0063\n",
       "  -0.0402\n",
       "  -0.0622\n",
       "   0.0106\n",
       "  -0.0149\n",
       "  -0.0184\n",
       "   0.0187\n",
       "  -0.0747\n",
       "  -0.0348\n",
       "   0.0072\n",
       "   0.0097\n",
       "  -0.0238\n",
       "  -0.0248\n",
       "   0.0313\n",
       "  -0.0205\n",
       "  -0.0001\n",
       "  -0.0279\n",
       "  -0.0149\n",
       "  -0.0188\n",
       "  -0.0662\n",
       "   0.0182\n",
       "  -0.0133\n",
       "  -0.0313\n",
       "   0.0682\n",
       "   0.0081\n",
       "  -0.0188\n",
       "  -0.0163\n",
       "   0.0026\n",
       "  -0.0066\n",
       "  -0.0776\n",
       "  -0.0654\n",
       "   0.0379\n",
       "  -0.0745\n",
       "   0.0208\n",
       "   0.0281\n",
       "  -0.0566\n",
       "  -0.0832\n",
       "  -0.0405\n",
       "   0.0033\n",
       "  -0.0308\n",
       "  -0.0070\n",
       "  -0.0388\n",
       "   0.0162\n",
       "   0.0045\n",
       "   0.0242\n",
       "  -0.0182\n",
       "  -0.0511\n",
       "  -0.0382\n",
       "   0.0054\n",
       "   0.0003\n",
       "  -0.0213\n",
       "   0.0182\n",
       "  -0.0174\n",
       "  -0.0001\n",
       "   0.0272\n",
       "  -0.0352\n",
       "  -0.0493\n",
       "  -0.0522\n",
       "  -0.0458\n",
       "  -0.0274\n",
       "  -0.0098\n",
       "   0.0077\n",
       "   0.0060\n",
       "  -0.0237\n",
       "   0.0313\n",
       "  -0.0364\n",
       "  -0.0507\n",
       "   0.0065\n",
       "  -0.0252\n",
       "  -0.0486\n",
       "   0.0044\n",
       "   0.0613\n",
       "   0.0035\n",
       "  -0.0261\n",
       "  -0.0241\n",
       "  -0.0516\n",
       "  -0.0707\n",
       "  -0.0346\n",
       "  -0.0186\n",
       "  -0.0258\n",
       "   0.0256\n",
       "   0.0147\n",
       "   0.0131\n",
       "  -0.0044\n",
       "  -0.0061\n",
       "  -0.0518\n",
       "  -0.0160\n",
       "   0.0084\n",
       "  -0.0421\n",
       "  -0.0701\n",
       "  -0.0316\n",
       "  -0.0035\n",
       "  -0.0364\n",
       "  -0.0266\n",
       "   0.0021\n",
       "  -0.0059\n",
       "  -0.0400\n",
       "  -0.0634\n",
       "  -0.0275\n",
       "   0.0200\n",
       "  -0.0753\n",
       "   0.0007\n",
       "  -0.0480\n",
       "  -0.0347\n",
       "   0.0005\n",
       "   0.0011\n",
       "   0.0096\n",
       "  -0.0089\n",
       "  -0.0022\n",
       "  -0.0356\n",
       "  -0.0101\n",
       "   0.0078\n",
       "  -0.0016\n",
       "  -0.0053\n",
       "   0.0016\n",
       "  -0.0280\n",
       "  -0.0269\n",
       "   0.0149\n",
       "  -0.0438\n",
       "  -0.0290\n",
       "  -0.0423\n",
       "  -0.0451\n",
       "  -0.0297\n",
       "  -0.0094\n",
       "  -0.0108\n",
       "  -0.0667\n",
       "  -0.0073\n",
       "   0.0139\n",
       "  -0.0512\n",
       "  -0.0430\n",
       "  -0.0372\n",
       "   0.0182\n",
       "  -0.0167\n",
       "  -0.0601\n",
       "  -0.0139\n",
       "   0.0247\n",
       "  -0.0048\n",
       "  -0.0378\n",
       "  -0.0157\n",
       "  -0.0274\n",
       "  -0.0037\n",
       "  -0.0122\n",
       "   0.0229\n",
       "  -0.0011\n",
       "   0.0385\n",
       "  -0.0792\n",
       "  -0.0175\n",
       "  -0.0071\n",
       "  -0.0526\n",
       "  -0.0157\n",
       "  -0.0300\n",
       "   0.0286\n",
       "   0.0379\n",
       "  -0.0033\n",
       "   0.0071\n",
       "  -0.0012\n",
       "   0.0524\n",
       "  -0.0694\n",
       "   0.0464\n",
       "  -0.0524\n",
       "   0.0318\n",
       "   0.0029\n",
       "  -0.0648\n",
       "  -0.0431\n",
       "  -0.0071\n",
       "   0.0031\n",
       "  -0.0063\n",
       "   0.0518\n",
       "  -0.0011\n",
       "  -0.0609\n",
       "  -0.0391\n",
       "  -0.0054\n",
       "  -0.0163\n",
       "   0.0096\n",
       "  -0.0371\n",
       "   0.0165\n",
       "   0.0685\n",
       "  -0.0162\n",
       "  -0.0023\n",
       "  -0.0585\n",
       "   0.0031\n",
       "   0.0545\n",
       "  -0.0479\n",
       "  -0.0638\n",
       "   0.0098\n",
       "   0.0107\n",
       "  -0.0367\n",
       "   0.0067\n",
       "  -0.0808\n",
       "  -0.0848\n",
       "   0.0385\n",
       "  -0.0611\n",
       "  -0.0825\n",
       "  -0.0653\n",
       "  -0.0927\n",
       "  -0.0393\n",
       "  -0.0262\n",
       "   0.0545\n",
       "   0.0040\n",
       "   0.0071\n",
       "  -0.0395\n",
       "  -0.0466\n",
       "   0.0017\n",
       "  -0.0608\n",
       "   0.0071\n",
       "  -0.0595\n",
       "  -0.0104\n",
       "  -0.0441\n",
       "  -0.0529\n",
       "  -0.0444\n",
       "  -0.0318\n",
       "   0.0110\n",
       "   0.0361\n",
       "   0.0098\n",
       "   0.0156\n",
       "  -0.0309\n",
       "  -0.0053\n",
       "  -0.0180\n",
       "   0.0431\n",
       "   0.0114\n",
       "  -0.0052\n",
       "   0.0424\n",
       "  -0.0022\n",
       "   0.0605\n",
       "  -0.0179\n",
       "  -0.0189\n",
       "   0.0162\n",
       "  -0.0315\n",
       "  -0.0089\n",
       "  -0.0714\n",
       "  -0.0448\n",
       "   0.0282\n",
       "  -0.0110\n",
       "   0.0206\n",
       "  -0.0558\n",
       "  -0.0081\n",
       "   0.0461\n",
       "  -0.0077\n",
       "  -0.0571\n",
       "  -0.0604\n",
       "   0.0308\n",
       "   0.0024\n",
       "  -0.0199\n",
       "  -0.0491\n",
       "  -0.0190\n",
       "  -0.0510\n",
       "  -0.0298\n",
       "  -0.0128\n",
       "  -0.0490\n",
       "  -0.0562\n",
       "  -0.0113\n",
       "  -0.0701\n",
       "  -0.0186\n",
       "  -0.0890\n",
       "  -0.0324\n",
       "  -0.0562\n",
       "   0.0311\n",
       "  -0.0279\n",
       "  -0.0539\n",
       "  -0.0108\n",
       "  -0.0579\n",
       "  -0.0389\n",
       "   0.0182\n",
       "  -0.0057\n",
       "   0.0054\n",
       "  -0.0539\n",
       "  -0.0472\n",
       "  -0.0379\n",
       "  -0.0047\n",
       "  -0.0073\n",
       "  -0.0107\n",
       "  -0.0272\n",
       "  -0.0327\n",
       "  -0.0113\n",
       "   0.0064\n",
       "   0.0028\n",
       "  -0.0649\n",
       "   0.0167\n",
       "  -0.0271\n",
       "  -0.0496\n",
       "  -0.0628\n",
       "  -0.0123\n",
       "   0.0063\n",
       "   0.0026\n",
       "   0.0153\n",
       "   0.0811\n",
       "   0.0158\n",
       "   0.0091\n",
       "   0.0067\n",
       "  -0.0393\n",
       "  -0.0211\n",
       "  -0.0493\n",
       "   0.0469\n",
       "  -0.0339\n",
       "  -0.0591\n",
       "   0.0299\n",
       "   0.0054\n",
       "  -0.0773\n",
       "  -0.0319\n",
       "  -0.0119\n",
       "  -0.0019\n",
       "   0.0436\n",
       "   0.0029\n",
       "  -0.0575\n",
       "  -0.0792\n",
       "  -0.0213\n",
       "  -0.0677\n",
       "  -0.0637\n",
       "   0.0460\n",
       "  -0.0200\n",
       "  -0.0162\n",
       "  -0.0296\n",
       "  -0.0223\n",
       "   0.0088\n",
       "  -0.0088\n",
       "  -0.0643\n",
       "  -0.0470\n",
       "  -0.0096\n",
       "   0.0218\n",
       "   0.0474\n",
       "  -0.0236\n",
       "   0.0588\n",
       "  -0.0416\n",
       "  -0.0045\n",
       "   0.0135\n",
       "   0.0105\n",
       "  -0.0071\n",
       "   0.0083\n",
       "  -0.0535\n",
       "  -0.0389\n",
       "   0.0029\n",
       "   0.0138\n",
       "  -0.0188\n",
       "   0.0254\n",
       "   0.0399\n",
       "  -0.0390\n",
       "   0.0202\n",
       "  -0.0048\n",
       "  -0.0654\n",
       "  -0.0029\n",
       "  -0.0585\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -2.0946e-02 -4.7143e-03 -1.9494e-02\n",
       "    2.5304e-02  2.8960e-02 -3.1437e-03\n",
       "    1.3141e-02  2.5003e-03  3.1358e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -4.3318e-03 -1.1775e-02 -2.3479e-02\n",
       "   -1.5015e-02 -2.3483e-02  4.4217e-03\n",
       "   -8.1222e-03 -2.8643e-03 -4.0659e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -8.9223e-03  1.3537e-02  1.0429e-03\n",
       "   -1.0736e-02  1.2900e-02 -5.1195e-03\n",
       "    2.9613e-02  7.7776e-03  3.6216e-04\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,509,.,.) = \n",
       "    3.1886e-02 -4.0244e-03  1.9518e-02\n",
       "    3.6008e-03  1.2692e-02  1.7235e-02\n",
       "   -2.8395e-03 -8.8739e-04 -1.6815e-02\n",
       "  \n",
       "  ( 0 ,510,.,.) = \n",
       "    3.4209e-03  1.7916e-03 -2.0718e-02\n",
       "   -3.0869e-02 -1.9301e-02  1.6241e-04\n",
       "   -1.8920e-02  1.0513e-02 -2.0826e-03\n",
       "  \n",
       "  ( 0 ,511,.,.) = \n",
       "    6.6162e-03  3.7199e-02  1.5646e-02\n",
       "    9.2626e-03  1.2703e-02  3.3453e-03\n",
       "   -8.7470e-03  2.6307e-03  4.1497e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    1.7505e-02 -3.8346e-04  1.4063e-03\n",
       "    6.9494e-03  4.3824e-02 -1.1377e-03\n",
       "    2.5306e-02  2.4736e-02 -4.5452e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    2.4573e-02 -1.8377e-02 -1.0609e-02\n",
       "    1.2893e-02 -3.8331e-03  1.6343e-02\n",
       "    2.7222e-02  1.4982e-02 -1.7353e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -1.8245e-02  1.4752e-02  1.2913e-02\n",
       "    9.0758e-03 -7.3429e-03 -1.2243e-02\n",
       "   -4.4566e-03 -8.3446e-03  2.4961e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,509,.,.) = \n",
       "   -1.6114e-02  3.4200e-02 -3.4815e-03\n",
       "    8.0812e-03  1.3421e-02  1.5884e-03\n",
       "   -6.8705e-03 -4.1530e-02 -2.0580e-04\n",
       "  \n",
       "  ( 1 ,510,.,.) = \n",
       "    2.5635e-03  2.5327e-02 -5.1622e-03\n",
       "   -5.1391e-03  9.2334e-03 -4.6409e-03\n",
       "    7.7392e-03 -2.0747e-03  1.0109e-02\n",
       "  \n",
       "  ( 1 ,511,.,.) = \n",
       "    4.8135e-03 -1.8559e-02 -2.7769e-05\n",
       "    5.0897e-03 -3.7002e-03  1.7117e-02\n",
       "   -1.9243e-02  4.7512e-02  2.5132e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.2210e-02  1.2592e-02 -1.5728e-03\n",
       "    3.8327e-02  1.6791e-02  1.2747e-02\n",
       "   -1.8688e-02  1.4212e-02 -1.3267e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    2.2330e-02 -3.9550e-04 -3.6267e-02\n",
       "   -8.6574e-03  1.0511e-02 -4.0352e-02\n",
       "   -1.1537e-02  1.4701e-02  3.2828e-03\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    8.4979e-03 -1.2620e-02  2.6863e-02\n",
       "    1.8230e-02  5.6637e-03  3.0110e-02\n",
       "    1.9250e-02  7.4578e-03  1.4194e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,509,.,.) = \n",
       "    3.2828e-02 -1.9868e-04  2.2478e-02\n",
       "    2.7829e-02 -3.9356e-03  2.6401e-02\n",
       "   -1.5955e-02  3.2400e-02 -4.6242e-03\n",
       "  \n",
       "  ( 2 ,510,.,.) = \n",
       "   -2.2794e-02 -5.1182e-03  3.7990e-02\n",
       "    8.2452e-03 -4.2701e-03 -2.1328e-02\n",
       "   -1.0308e-02 -1.3709e-02 -1.0842e-03\n",
       "  \n",
       "  ( 2 ,511,.,.) = \n",
       "    9.1585e-04  4.5476e-03  7.2067e-03\n",
       "    3.1612e-03  1.0279e-02  1.4422e-02\n",
       "    9.8562e-03  7.0300e-03 -1.5518e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "   -2.0643e-03  1.4405e-02 -2.4556e-02\n",
       "   -3.9445e-03  2.5980e-02  4.0171e-03\n",
       "    4.1048e-03 -2.3894e-02 -2.0623e-02\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "   -3.8143e-04 -6.6004e-03 -6.7303e-03\n",
       "   -1.3984e-02 -1.5337e-02 -4.4808e-03\n",
       "   -1.5780e-02 -2.4569e-02 -1.7860e-02\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "   -1.5213e-02  5.1086e-03 -1.4091e-02\n",
       "   -1.0130e-02  4.4623e-02  8.8066e-03\n",
       "    5.0037e-03  4.8515e-03 -9.9266e-03\n",
       "      ... \n",
       "  \n",
       "  (509,509,.,.) = \n",
       "    5.2862e-03  1.8562e-02 -1.9434e-02\n",
       "   -2.6591e-02  3.2471e-02  2.3086e-02\n",
       "   -9.0704e-03 -2.0666e-02  6.4763e-04\n",
       "  \n",
       "  (509,510,.,.) = \n",
       "   -3.7736e-03  1.2179e-02  2.0657e-02\n",
       "   -7.0911e-03  1.4627e-02  2.2409e-02\n",
       "    3.6809e-03 -1.4253e-02  2.2865e-03\n",
       "  \n",
       "  (509,511,.,.) = \n",
       "    3.1938e-02  1.7217e-04  3.6835e-02\n",
       "    3.0383e-03 -1.7927e-02  1.8881e-02\n",
       "    3.9980e-03  2.6172e-02 -9.2331e-03\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "   -7.2706e-03 -3.1985e-02  1.5945e-02\n",
       "   -5.6554e-02 -8.1700e-04 -6.0899e-04\n",
       "   -5.9006e-03 -8.7207e-04 -2.5898e-02\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "   -1.2421e-02  2.1578e-02 -1.9233e-02\n",
       "   -8.2736e-03  2.5366e-02 -9.6396e-03\n",
       "    1.6113e-02  4.9970e-03  1.1667e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "   -2.7554e-02  1.3927e-03 -1.9297e-02\n",
       "    5.5018e-03 -1.9041e-03 -3.5450e-03\n",
       "    2.5240e-03 -7.5074e-04  2.4494e-02\n",
       "      ... \n",
       "  \n",
       "  (510,509,.,.) = \n",
       "   -8.3009e-03 -1.0023e-02 -3.8492e-02\n",
       "   -2.4863e-02  3.7747e-03 -1.9779e-02\n",
       "    1.4034e-02 -2.1366e-02 -1.6655e-03\n",
       "  \n",
       "  (510,510,.,.) = \n",
       "    6.7845e-03  8.1306e-03 -1.9895e-02\n",
       "   -1.4420e-02 -7.9651e-03 -3.3196e-03\n",
       "    2.0240e-02 -8.8666e-03 -2.8564e-02\n",
       "  \n",
       "  (510,511,.,.) = \n",
       "   -1.4043e-02 -1.4864e-03 -4.8855e-03\n",
       "   -1.4290e-02 -1.6935e-02 -4.4670e-03\n",
       "   -2.0611e-02 -8.9727e-03  6.0017e-03\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "    2.4993e-02 -1.5744e-02 -2.2907e-02\n",
       "    7.6349e-03 -1.3241e-02 -2.2524e-02\n",
       "   -8.5304e-04 -4.4431e-02 -2.9105e-02\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "   -4.7141e-03 -1.3613e-02  1.2441e-02\n",
       "   -1.0638e-02 -6.3066e-03  3.3306e-03\n",
       "   -6.9500e-04 -5.4012e-04  2.9151e-03\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "    1.1594e-02  4.2478e-03 -4.0859e-02\n",
       "   -7.2902e-03  1.3440e-03 -2.6772e-02\n",
       "    4.6322e-03  5.1797e-03 -1.1563e-03\n",
       "      ... \n",
       "  \n",
       "  (511,509,.,.) = \n",
       "    4.0341e-02  4.5509e-04 -1.1746e-02\n",
       "    7.5534e-04 -9.5986e-04  1.2469e-02\n",
       "   -9.0002e-03 -7.1072e-03  1.2440e-02\n",
       "  \n",
       "  (511,510,.,.) = \n",
       "   -5.3875e-03  1.8067e-02 -8.4992e-03\n",
       "    3.5578e-02 -2.1961e-03 -2.8740e-02\n",
       "   -2.2029e-02  7.3237e-03 -2.1232e-02\n",
       "  \n",
       "  (511,511,.,.) = \n",
       "    2.6946e-02  8.0545e-03 -5.0660e-03\n",
       "    2.8094e-03  5.7321e-03 -2.2071e-02\n",
       "   -6.2422e-03 -2.4811e-03 -1.6391e-02\n",
       "  [torch.cuda.FloatTensor of size 512x512x3x3 (GPU 0)], Parameter containing:\n",
       "   0.6269\n",
       "   0.7411\n",
       "   0.7621\n",
       "   0.6786\n",
       "   0.7078\n",
       "   0.6730\n",
       "   0.5040\n",
       "   0.6859\n",
       "   0.5408\n",
       "   0.7241\n",
       "   0.7765\n",
       "   0.7504\n",
       "   0.5686\n",
       "   0.8559\n",
       "   0.8387\n",
       "   0.7263\n",
       "   0.7615\n",
       "   0.6802\n",
       "   0.5216\n",
       "   0.7912\n",
       "   0.7258\n",
       "   0.4350\n",
       "   0.4909\n",
       "   0.6158\n",
       "   0.8163\n",
       "   0.7288\n",
       "   0.8206\n",
       "   0.1728\n",
       "   0.6120\n",
       "   0.7903\n",
       "   0.3095\n",
       "   0.3445\n",
       "   0.1860\n",
       "   0.3820\n",
       "   0.5111\n",
       "   0.6825\n",
       "   0.3688\n",
       "   0.6934\n",
       "   0.7760\n",
       "   0.6486\n",
       "   0.6185\n",
       "   0.3302\n",
       "   0.7867\n",
       "   0.6235\n",
       "   0.7381\n",
       "   0.4698\n",
       "   0.5239\n",
       "   0.4135\n",
       "   0.6837\n",
       "   0.6721\n",
       "   0.5723\n",
       "   0.7728\n",
       "   0.3286\n",
       "   0.7551\n",
       "   0.7297\n",
       "   0.3649\n",
       "   0.6712\n",
       "   0.7631\n",
       "   0.7257\n",
       "   0.6514\n",
       "   0.9916\n",
       "   0.6976\n",
       "   0.6418\n",
       "   0.6370\n",
       "   0.7615\n",
       "   0.6427\n",
       "   0.7560\n",
       "   0.6956\n",
       "   0.5313\n",
       "   0.2614\n",
       "   0.3914\n",
       "   0.4866\n",
       "   0.6604\n",
       "   0.7266\n",
       "   0.3202\n",
       "   0.5640\n",
       "   0.5382\n",
       "   0.7823\n",
       "   0.3790\n",
       "   0.8126\n",
       "   0.7921\n",
       "   0.7775\n",
       "   0.6810\n",
       "   0.5221\n",
       "   0.5062\n",
       "   0.6448\n",
       "   0.8229\n",
       "   0.6364\n",
       "   0.7018\n",
       "   0.8220\n",
       "   0.7623\n",
       "   0.7446\n",
       "   0.5959\n",
       "   0.7495\n",
       "   0.6565\n",
       "   0.6856\n",
       "   0.4401\n",
       "   0.8031\n",
       "   0.8154\n",
       "   0.6707\n",
       "   0.7598\n",
       "   0.6656\n",
       "   0.6162\n",
       "   0.4094\n",
       "   0.4773\n",
       "   0.6285\n",
       "   0.8176\n",
       "   0.3882\n",
       "   0.3264\n",
       "   0.6756\n",
       "   0.8539\n",
       "   0.7052\n",
       "   0.4516\n",
       "   0.8018\n",
       "   0.5579\n",
       "   0.7782\n",
       "   0.4953\n",
       "   0.6515\n",
       "   0.6637\n",
       "   0.2432\n",
       "   0.8351\n",
       "   0.5095\n",
       "   0.8045\n",
       "   0.4014\n",
       "   0.6331\n",
       "   0.5103\n",
       "   0.7062\n",
       "   0.3853\n",
       "   0.8005\n",
       "   0.6509\n",
       "   0.4668\n",
       "   0.7561\n",
       "   0.7106\n",
       "   0.5126\n",
       "   0.7630\n",
       "   0.7688\n",
       "   0.7083\n",
       "   0.7484\n",
       "   0.6437\n",
       "   0.7283\n",
       "   0.6333\n",
       "   0.7644\n",
       "   0.3803\n",
       "   0.7932\n",
       "   0.6544\n",
       "   0.6487\n",
       "   0.4743\n",
       "   0.2832\n",
       "   0.6444\n",
       "   0.7104\n",
       "   0.5538\n",
       "   0.6454\n",
       "   0.6413\n",
       "   0.7244\n",
       "   0.6688\n",
       "   0.7690\n",
       "   0.7863\n",
       "   0.8273\n",
       "   0.6638\n",
       "   0.5602\n",
       "   0.4882\n",
       "   0.3345\n",
       "   0.6283\n",
       "   0.1971\n",
       "   0.3430\n",
       "   0.8114\n",
       "   0.6173\n",
       "   0.6859\n",
       "   0.7452\n",
       "   0.6351\n",
       "   0.6975\n",
       "   0.6429\n",
       "   0.6277\n",
       "   0.3540\n",
       "   0.6759\n",
       "   0.7436\n",
       "   0.7701\n",
       "   0.5861\n",
       "   0.3281\n",
       "   0.5026\n",
       "   0.6538\n",
       "   0.5190\n",
       "   0.8458\n",
       "   0.3784\n",
       "   0.8067\n",
       "   0.7078\n",
       "   0.7541\n",
       "   0.6216\n",
       "   0.6140\n",
       "   0.5353\n",
       "   0.7569\n",
       "   0.2152\n",
       "   0.7514\n",
       "   0.7614\n",
       "   0.5354\n",
       "   0.6837\n",
       "   0.6371\n",
       "   0.6132\n",
       "   0.5959\n",
       "   0.6699\n",
       "   0.4784\n",
       "   0.5739\n",
       "   0.4083\n",
       "   0.7904\n",
       "   0.6500\n",
       "   0.7274\n",
       "   0.5882\n",
       "   0.4288\n",
       "   0.5320\n",
       "   0.7822\n",
       "   0.3103\n",
       "   0.7841\n",
       "   0.8095\n",
       "   0.5232\n",
       "   0.6399\n",
       "   0.4665\n",
       "   0.7219\n",
       "   0.6758\n",
       "   0.4522\n",
       "   0.4680\n",
       "   0.6346\n",
       "   0.7562\n",
       "   0.5041\n",
       "   0.5844\n",
       "   0.6871\n",
       "   0.8120\n",
       "   0.2830\n",
       "   0.6554\n",
       "   0.3357\n",
       "   0.6654\n",
       "   0.7482\n",
       "   0.6392\n",
       "   0.6924\n",
       "   0.6844\n",
       "   0.6866\n",
       "   0.6595\n",
       "   0.5930\n",
       "   0.7309\n",
       "   0.7702\n",
       "   0.6558\n",
       "   0.7474\n",
       "   0.7112\n",
       "   0.6155\n",
       "   0.7003\n",
       "   0.7857\n",
       "   0.7922\n",
       "   0.7508\n",
       "   0.5740\n",
       "   0.4166\n",
       "   0.7548\n",
       "   0.6638\n",
       "   0.5967\n",
       "   0.3962\n",
       "   0.6428\n",
       "   0.7316\n",
       "   0.7189\n",
       "   0.5851\n",
       "   0.2940\n",
       "   0.5515\n",
       "   0.4537\n",
       "   0.6844\n",
       "   0.6404\n",
       "   0.7092\n",
       "   0.3048\n",
       "   0.7405\n",
       "   0.4603\n",
       "   0.7287\n",
       "   0.5942\n",
       "   0.8256\n",
       "   0.7379\n",
       "   0.6379\n",
       "   0.5064\n",
       "   0.4367\n",
       "   0.6972\n",
       "   0.3308\n",
       "   0.3114\n",
       "   0.7528\n",
       "   0.6616\n",
       "   0.7488\n",
       "   0.7292\n",
       "   0.3777\n",
       "   0.7043\n",
       "   0.6352\n",
       "   0.7404\n",
       "   0.4212\n",
       "   0.5460\n",
       "   0.7144\n",
       "   0.8410\n",
       "   0.6132\n",
       "   0.6226\n",
       "   0.6242\n",
       "   0.5400\n",
       "   0.4849\n",
       "   0.7228\n",
       "   0.7301\n",
       "   0.7522\n",
       "   0.7016\n",
       "   0.4210\n",
       "   0.5848\n",
       "   0.4596\n",
       "   0.7199\n",
       "   0.5643\n",
       "   0.6172\n",
       "   0.6683\n",
       "   0.6696\n",
       "   0.4704\n",
       "   0.6931\n",
       "   0.2568\n",
       "   0.7743\n",
       "   0.6858\n",
       "   0.6321\n",
       "   0.6778\n",
       "   0.7549\n",
       "   0.7119\n",
       "   0.6990\n",
       "   0.3866\n",
       "   0.4421\n",
       "   0.6672\n",
       "   0.7649\n",
       "   0.7553\n",
       "   0.7687\n",
       "   0.7537\n",
       "   0.7262\n",
       "   0.8192\n",
       "   0.7673\n",
       "   0.8381\n",
       "   0.5092\n",
       "   0.5460\n",
       "   0.8957\n",
       "   0.7651\n",
       "   0.7551\n",
       "   0.7880\n",
       "   0.3132\n",
       "   0.6278\n",
       "   0.7726\n",
       "   0.6456\n",
       "   0.6370\n",
       "   0.7763\n",
       "   0.7232\n",
       "   0.6428\n",
       "   0.6947\n",
       "   0.7628\n",
       "   0.8391\n",
       "   0.6945\n",
       "   0.7628\n",
       "   0.7745\n",
       "   0.5948\n",
       "   0.5471\n",
       "   0.6591\n",
       "   0.7700\n",
       "   0.7083\n",
       "   0.7674\n",
       "   0.7607\n",
       "   0.4997\n",
       "   0.6471\n",
       "   0.4045\n",
       "   0.6351\n",
       "   0.4939\n",
       "   0.7184\n",
       "   0.8114\n",
       "   0.6539\n",
       "   0.6821\n",
       "   0.7483\n",
       "   0.2254\n",
       "   0.3813\n",
       "   0.6105\n",
       "   0.7462\n",
       "   0.5404\n",
       "   0.6099\n",
       "   0.7808\n",
       "   0.5322\n",
       "   0.8078\n",
       "   0.7365\n",
       "   0.7077\n",
       "   0.6787\n",
       "   0.2854\n",
       "   0.2618\n",
       "   0.6058\n",
       "   0.7862\n",
       "   0.7003\n",
       "   0.7488\n",
       "   0.7642\n",
       "   0.7548\n",
       "   0.6169\n",
       "   0.4141\n",
       "   0.6056\n",
       "   0.4299\n",
       "   0.5261\n",
       "   0.7062\n",
       "   0.6093\n",
       "   0.5013\n",
       "   0.4490\n",
       "   0.4770\n",
       "   0.7451\n",
       "   0.6732\n",
       "   0.5473\n",
       "   0.6763\n",
       "   0.7007\n",
       "   0.7663\n",
       "   0.5545\n",
       "   0.7849\n",
       "   0.6709\n",
       "   0.7348\n",
       "   0.5089\n",
       "   0.7402\n",
       "   0.6889\n",
       "   0.7905\n",
       "   0.6128\n",
       "   0.5824\n",
       "   0.7476\n",
       "   0.5392\n",
       "   0.7532\n",
       "   0.7288\n",
       "   0.8294\n",
       "   0.6884\n",
       "   0.2994\n",
       "   0.6593\n",
       "   0.6357\n",
       "   0.7987\n",
       "   0.5328\n",
       "   0.7172\n",
       "   0.8281\n",
       "   0.4951\n",
       "   0.7367\n",
       "   0.7450\n",
       "   0.6862\n",
       "   0.7428\n",
       "   0.6649\n",
       "   0.7167\n",
       "   0.7737\n",
       "   0.8314\n",
       "   0.7666\n",
       "   0.6472\n",
       "   0.5955\n",
       "   0.7289\n",
       "   0.7440\n",
       "   0.8025\n",
       "   0.5017\n",
       "   0.8579\n",
       "   0.6671\n",
       "   0.7849\n",
       "   0.8251\n",
       "   0.7499\n",
       "   0.7455\n",
       "   0.6698\n",
       "   0.7632\n",
       "   0.6215\n",
       "   0.5849\n",
       "   0.6681\n",
       "   0.7133\n",
       "   0.7052\n",
       "   0.5691\n",
       "   0.6977\n",
       "   0.8271\n",
       "   0.7537\n",
       "   0.6057\n",
       "   0.7410\n",
       "   0.6540\n",
       "   0.7719\n",
       "   0.3567\n",
       "   0.7120\n",
       "   0.6881\n",
       "   0.2398\n",
       "   0.6712\n",
       "   0.4894\n",
       "   0.8222\n",
       "   0.2837\n",
       "   0.7885\n",
       "   0.6830\n",
       "   0.8043\n",
       "   0.6896\n",
       "   0.5911\n",
       "   0.4576\n",
       "   0.7357\n",
       "   0.7869\n",
       "   0.5579\n",
       "   0.3290\n",
       "   0.7262\n",
       "   0.6832\n",
       "   0.8107\n",
       "   0.7704\n",
       "   0.6667\n",
       "   0.6724\n",
       "   0.5571\n",
       "   0.7876\n",
       "   0.4516\n",
       "   0.7851\n",
       "   0.6630\n",
       "   0.5425\n",
       "   0.7391\n",
       "   0.6626\n",
       "   0.6921\n",
       "   0.5750\n",
       "   0.7251\n",
       "   0.6144\n",
       "   0.6619\n",
       "   0.4370\n",
       "   0.7693\n",
       "   0.4464\n",
       "   0.6006\n",
       "   0.7563\n",
       "   0.6794\n",
       "   0.7187\n",
       "   0.7167\n",
       "   0.4289\n",
       "   0.7705\n",
       "   0.7197\n",
       "   0.5136\n",
       "   0.6761\n",
       "   0.6629\n",
       "   0.7970\n",
       "   0.3614\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.0748\n",
       "  -0.0512\n",
       "  -0.0435\n",
       "  -0.0439\n",
       "  -0.0400\n",
       "  -0.0683\n",
       "  -0.1210\n",
       "  -0.0702\n",
       "  -0.0971\n",
       "  -0.0976\n",
       "  -0.0575\n",
       "  -0.0403\n",
       "  -0.0998\n",
       "  -0.0509\n",
       "  -0.0525\n",
       "  -0.0474\n",
       "  -0.0740\n",
       "  -0.0547\n",
       "  -0.1319\n",
       "  -0.0384\n",
       "  -0.0637\n",
       "  -0.1385\n",
       "  -0.1467\n",
       "  -0.0746\n",
       "  -0.1070\n",
       "  -0.0628\n",
       "  -0.1494\n",
       "  -0.1937\n",
       "  -0.0917\n",
       "  -0.1098\n",
       "  -0.1867\n",
       "  -0.1713\n",
       "  -0.2316\n",
       "  -0.1686\n",
       "  -0.1348\n",
       "  -0.1334\n",
       "  -0.1847\n",
       "  -0.0886\n",
       "  -0.0265\n",
       "  -0.0636\n",
       "  -0.0756\n",
       "  -0.1627\n",
       "  -0.0484\n",
       "   0.0162\n",
       "  -0.0611\n",
       "  -0.1349\n",
       "  -0.0941\n",
       "  -0.1205\n",
       "  -0.0568\n",
       "  -0.0558\n",
       "  -0.1211\n",
       "  -0.0861\n",
       "  -0.1722\n",
       "  -0.0743\n",
       "  -0.0555\n",
       "  -0.1715\n",
       "  -0.0610\n",
       "  -0.0935\n",
       "  -0.0856\n",
       "  -0.0608\n",
       "   0.5233\n",
       "  -0.0903\n",
       "  -0.1043\n",
       "  -0.1313\n",
       "  -0.0484\n",
       "  -0.0675\n",
       "   0.0776\n",
       "  -0.0495\n",
       "  -0.1698\n",
       "  -0.2054\n",
       "  -0.1605\n",
       "  -0.1073\n",
       "  -0.0724\n",
       "  -0.0021\n",
       "  -0.1844\n",
       "  -0.1064\n",
       "  -0.1191\n",
       "  -0.0602\n",
       "  -0.1482\n",
       "  -0.0886\n",
       "  -0.0849\n",
       "  -0.0227\n",
       "  -0.0644\n",
       "  -0.1377\n",
       "  -0.1137\n",
       "  -0.0768\n",
       "  -0.0329\n",
       "  -0.0752\n",
       "  -0.0362\n",
       "   0.0477\n",
       "  -0.0510\n",
       "  -0.0979\n",
       "  -0.1036\n",
       "  -0.0599\n",
       "  -0.0597\n",
       "  -0.0608\n",
       "  -0.1592\n",
       "  -0.0662\n",
       "  -0.0392\n",
       "  -0.0642\n",
       "  -0.0550\n",
       "  -0.0955\n",
       "  -0.0957\n",
       "  -0.1399\n",
       "  -0.1305\n",
       "  -0.1425\n",
       "  -0.0056\n",
       "  -0.1785\n",
       "  -0.1863\n",
       "  -0.0612\n",
       "  -0.0972\n",
       "  -0.0744\n",
       "  -0.1267\n",
       "  -0.0898\n",
       "  -0.0960\n",
       "  -0.0411\n",
       "  -0.1012\n",
       "  -0.0462\n",
       "  -0.0848\n",
       "  -0.1727\n",
       "  -0.0285\n",
       "  -0.0997\n",
       "  -0.0504\n",
       "  -0.1515\n",
       "  -0.1117\n",
       "  -0.1348\n",
       "  -0.0800\n",
       "  -0.1913\n",
       "  -0.0415\n",
       "  -0.1131\n",
       "  -0.1353\n",
       "  -0.0795\n",
       "  -0.0816\n",
       "  -0.1180\n",
       "  -0.0580\n",
       "  -0.0942\n",
       "  -0.0548\n",
       "  -0.0611\n",
       "  -0.0069\n",
       "  -0.0676\n",
       "  -0.0925\n",
       "  -0.0595\n",
       "  -0.1653\n",
       "   0.0153\n",
       "  -0.0505\n",
       "  -0.0633\n",
       "  -0.1410\n",
       "  -0.1788\n",
       "  -0.0711\n",
       "  -0.1181\n",
       "  -0.1315\n",
       "  -0.0247\n",
       "  -0.1292\n",
       "  -0.0932\n",
       "  -0.0512\n",
       "  -0.0312\n",
       "  -0.1018\n",
       "  -0.0484\n",
       "  -0.0792\n",
       "  -0.1467\n",
       "  -0.1200\n",
       "  -0.1589\n",
       "  -0.0990\n",
       "  -0.2160\n",
       "  -0.1974\n",
       "   0.1412\n",
       "  -0.1077\n",
       "  -0.1457\n",
       "  -0.2410\n",
       "  -0.0917\n",
       "  -0.0605\n",
       "  -0.0772\n",
       "  -0.1007\n",
       "  -0.1723\n",
       "  -0.0551\n",
       "  -0.1637\n",
       "  -0.0764\n",
       "  -0.0799\n",
       "  -0.1604\n",
       "  -0.0860\n",
       "  -0.0659\n",
       "  -0.1394\n",
       "  -0.0268\n",
       "  -0.1719\n",
       "   0.0555\n",
       "  -0.0449\n",
       "  -0.1932\n",
       "  -0.1347\n",
       "  -0.0756\n",
       "  -0.1040\n",
       "  -0.0915\n",
       "  -0.1912\n",
       "  -0.0813\n",
       "  -0.0463\n",
       "  -0.1734\n",
       "  -0.0957\n",
       "  -0.0600\n",
       "  -0.0826\n",
       "  -0.1141\n",
       "  -0.0671\n",
       "  -0.1032\n",
       "  -0.1401\n",
       "  -0.1404\n",
       "  -0.0419\n",
       "  -0.0463\n",
       "  -0.0513\n",
       "  -0.0818\n",
       "  -0.1744\n",
       "  -0.1395\n",
       "  -0.0835\n",
       "  -0.1853\n",
       "  -0.0855\n",
       "  -0.0439\n",
       "  -0.1308\n",
       "  -0.1018\n",
       "  -0.1454\n",
       "  -0.0437\n",
       "  -0.1115\n",
       "  -0.1355\n",
       "  -0.1216\n",
       "  -0.0613\n",
       "  -0.0430\n",
       "  -0.1086\n",
       "  -0.0558\n",
       "  -0.0727\n",
       "  -0.0612\n",
       "  -0.2064\n",
       "  -0.1230\n",
       "  -0.1932\n",
       "  -0.0760\n",
       "  -0.1159\n",
       "  -0.0836\n",
       "  -0.0550\n",
       "  -0.1357\n",
       "  -0.1030\n",
       "  -0.0647\n",
       "  -0.1021\n",
       "  -0.1295\n",
       "   0.0986\n",
       "  -0.0655\n",
       "  -0.0208\n",
       "  -0.0475\n",
       "  -0.0962\n",
       "  -0.1581\n",
       "  -0.0799\n",
       "  -0.0179\n",
       "  -0.0466\n",
       "  -0.1015\n",
       "  -0.1654\n",
       "  -0.0364\n",
       "  -0.0956\n",
       "  -0.0962\n",
       "  -0.1483\n",
       "  -0.0677\n",
       "  -0.1416\n",
       "  -0.0475\n",
       "  -0.1116\n",
       "  -0.1823\n",
       "  -0.1122\n",
       "  -0.1428\n",
       "  -0.0676\n",
       "  -0.0657\n",
       "  -0.0595\n",
       "  -0.2097\n",
       "  -0.0507\n",
       "  -0.1063\n",
       "  -0.0560\n",
       "  -0.1132\n",
       "  -0.0650\n",
       "   0.0051\n",
       "  -0.1258\n",
       "  -0.1305\n",
       "  -0.1950\n",
       "   0.0005\n",
       "  -0.1858\n",
       "  -0.1847\n",
       "  -0.1326\n",
       "  -0.0803\n",
       "  -0.1091\n",
       "  -0.1435\n",
       "  -0.1954\n",
       "  -0.0526\n",
       "  -0.1043\n",
       "  -0.0269\n",
       "  -0.1752\n",
       "  -0.1237\n",
       "  -0.0585\n",
       "   0.0115\n",
       "  -0.1134\n",
       "  -0.0716\n",
       "  -0.0886\n",
       "  -0.0823\n",
       "  -0.1200\n",
       "  -0.0495\n",
       "  -0.1523\n",
       "  -0.1354\n",
       "  -0.0284\n",
       "  -0.1490\n",
       "  -0.1169\n",
       "  -0.1332\n",
       "  -0.0553\n",
       "  -0.1144\n",
       "  -0.0585\n",
       "  -0.0697\n",
       "  -0.0361\n",
       "  -0.1192\n",
       "  -0.0505\n",
       "  -0.1764\n",
       "  -0.0697\n",
       "  -0.0577\n",
       "  -0.0464\n",
       "  -0.0593\n",
       "  -0.1337\n",
       "  -0.1741\n",
       "  -0.0477\n",
       "  -0.1288\n",
       "  -0.1733\n",
       "  -0.0738\n",
       "  -0.0631\n",
       "  -0.1416\n",
       "  -0.0686\n",
       "  -0.0471\n",
       "  -0.0473\n",
       "  -0.0321\n",
       "  -0.0665\n",
       "  -0.0841\n",
       "  -0.1128\n",
       "  -0.1085\n",
       "   0.3917\n",
       "  -0.0962\n",
       "  -0.1016\n",
       "  -0.0078\n",
       "  -0.1875\n",
       "  -0.0594\n",
       "  -0.0799\n",
       "  -0.0809\n",
       "  -0.0675\n",
       "   0.0282\n",
       "  -0.1052\n",
       "  -0.0667\n",
       "  -0.0549\n",
       "  -0.1574\n",
       "   0.2669\n",
       "  -0.0223\n",
       "  -0.0424\n",
       "  -0.0291\n",
       "  -0.0954\n",
       "  -0.0316\n",
       "  -0.1365\n",
       "  -0.0340\n",
       "  -0.1210\n",
       "  -0.1022\n",
       "  -0.1642\n",
       "  -0.1419\n",
       "  -0.0661\n",
       "  -0.1733\n",
       "  -0.1646\n",
       "  -0.1165\n",
       "  -0.0986\n",
       "  -0.0700\n",
       "  -0.0660\n",
       "  -0.0453\n",
       "  -0.1239\n",
       "  -0.2158\n",
       "  -0.1753\n",
       "  -0.0870\n",
       "  -0.0805\n",
       "  -0.1043\n",
       "  -0.0833\n",
       "  -0.0867\n",
       "  -0.1168\n",
       "   0.1512\n",
       "  -0.1405\n",
       "   0.1068\n",
       "  -0.0629\n",
       "  -0.1865\n",
       "  -0.1831\n",
       "  -0.0924\n",
       "  -0.0658\n",
       "  -0.0500\n",
       "  -0.0373\n",
       "  -0.0320\n",
       "  -0.0789\n",
       "  -0.1159\n",
       "  -0.1583\n",
       "  -0.1302\n",
       "  -0.1727\n",
       "  -0.1570\n",
       "  -0.0424\n",
       "  -0.0637\n",
       "  -0.1055\n",
       "  -0.1877\n",
       "  -0.1283\n",
       "  -0.0577\n",
       "  -0.0661\n",
       "  -0.1369\n",
       "  -0.0737\n",
       "  -0.0496\n",
       "  -0.0724\n",
       "  -0.1441\n",
       "  -0.0814\n",
       "  -0.0558\n",
       "  -0.1348\n",
       "  -0.1131\n",
       "  -0.0618\n",
       "  -0.0845\n",
       "  -0.0469\n",
       "  -0.1046\n",
       "  -0.1208\n",
       "  -0.0686\n",
       "  -0.0960\n",
       "  -0.0521\n",
       "  -0.0602\n",
       "  -0.0603\n",
       "  -0.0424\n",
       "  -0.1931\n",
       "  -0.1232\n",
       "  -0.1016\n",
       "  -0.0765\n",
       "   0.1269\n",
       "  -0.0955\n",
       "  -0.0250\n",
       "  -0.1656\n",
       "  -0.1553\n",
       "  -0.0680\n",
       "  -0.0610\n",
       "   0.1635\n",
       "  -0.0767\n",
       "  -0.0724\n",
       "  -0.0850\n",
       "  -0.0101\n",
       "  -0.0792\n",
       "  -0.0789\n",
       "  -0.0868\n",
       "  -0.2325\n",
       "  -0.0609\n",
       "  -0.0273\n",
       "  -0.1678\n",
       "  -0.0398\n",
       "  -0.0443\n",
       "   0.0614\n",
       "   0.2894\n",
       "  -0.1291\n",
       "  -0.0578\n",
       "  -0.0680\n",
       "  -0.1142\n",
       "  -0.0990\n",
       "  -0.0943\n",
       "  -0.0713\n",
       "  -0.0873\n",
       "  -0.1494\n",
       "  -0.0977\n",
       "  -0.1498\n",
       "  -0.0477\n",
       "  -0.0882\n",
       "  -0.1304\n",
       "  -0.0789\n",
       "  -0.1397\n",
       "  -0.1544\n",
       "  -0.1920\n",
       "  -0.0571\n",
       "  -0.0718\n",
       "  -0.2176\n",
       "  -0.0747\n",
       "  -0.1084\n",
       "  -0.0681\n",
       "  -0.1856\n",
       "  -0.0241\n",
       "  -0.0772\n",
       "   0.0081\n",
       "  -0.0620\n",
       "  -0.0879\n",
       "  -0.1675\n",
       "  -0.1651\n",
       "  -0.0461\n",
       "  -0.0871\n",
       "  -0.2092\n",
       "  -0.1024\n",
       "  -0.0553\n",
       "  -0.0875\n",
       "  -0.0876\n",
       "  -0.0618\n",
       "  -0.0660\n",
       "  -0.1234\n",
       "  -0.0482\n",
       "  -0.1256\n",
       "  -0.0921\n",
       "  -0.0754\n",
       "  -0.1728\n",
       "  -0.1249\n",
       "  -0.0606\n",
       "  -0.0609\n",
       "  -0.1272\n",
       "  -0.1076\n",
       "  -0.0874\n",
       "  -0.0493\n",
       "  -0.1324\n",
       "   0.0396\n",
       "  -0.1812\n",
       "  -0.1517\n",
       "  -0.0525\n",
       "  -0.0459\n",
       "  -0.1154\n",
       "  -0.1038\n",
       "  -0.1384\n",
       "  -0.0713\n",
       "  -0.0443\n",
       "  -0.1118\n",
       "  -0.1024\n",
       "  -0.0724\n",
       "  -0.0445\n",
       "  -0.1820\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -1.2902e-01\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -1.1875e-04\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.8198e-01\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,253,.,.) = \n",
       "   -3.6815e-02\n",
       "  \n",
       "  ( 0 ,254,.,.) = \n",
       "   -7.3017e-02\n",
       "  \n",
       "  ( 0 ,255,.,.) = \n",
       "   -1.8965e-01\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    5.0417e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -4.6976e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    1.1058e-01\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,253,.,.) = \n",
       "    8.8714e-02\n",
       "  \n",
       "  ( 1 ,254,.,.) = \n",
       "    2.5534e-02\n",
       "  \n",
       "  ( 1 ,255,.,.) = \n",
       "   -4.5397e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.0894e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -5.5233e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    3.6506e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,253,.,.) = \n",
       "    1.2443e-02\n",
       "  \n",
       "  ( 2 ,254,.,.) = \n",
       "    2.5077e-02\n",
       "  \n",
       "  ( 2 ,255,.,.) = \n",
       "   -1.3064e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "    2.3847e-02\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "   -4.6677e-02\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "   -1.9562e-02\n",
       "      ... \n",
       "  \n",
       "  (509,253,.,.) = \n",
       "    1.8283e-02\n",
       "  \n",
       "  (509,254,.,.) = \n",
       "   -7.2330e-02\n",
       "  \n",
       "  (509,255,.,.) = \n",
       "    1.1499e-02\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "   -6.7698e-02\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "   -2.6842e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "   -4.6418e-02\n",
       "      ... \n",
       "  \n",
       "  (510,253,.,.) = \n",
       "   -2.5012e-02\n",
       "  \n",
       "  (510,254,.,.) = \n",
       "    8.4386e-02\n",
       "  \n",
       "  (510,255,.,.) = \n",
       "    1.6192e-02\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "   -7.5563e-02\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "    1.3209e-02\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "    1.3346e-01\n",
       "      ... \n",
       "  \n",
       "  (511,253,.,.) = \n",
       "    5.2823e-02\n",
       "  \n",
       "  (511,254,.,.) = \n",
       "   -2.2526e-04\n",
       "  \n",
       "  (511,255,.,.) = \n",
       "   -1.5736e-02\n",
       "  [torch.cuda.FloatTensor of size 512x256x1x1 (GPU 0)], Parameter containing:\n",
       "   0.7925\n",
       "   0.7724\n",
       "   0.7747\n",
       "   0.8274\n",
       "   0.8138\n",
       "   0.8333\n",
       "   0.4884\n",
       "   0.8292\n",
       "   0.5475\n",
       "   0.7845\n",
       "   0.7657\n",
       "   0.7815\n",
       "   0.6256\n",
       "   0.6200\n",
       "   0.6591\n",
       "   0.7316\n",
       "   0.7676\n",
       "   0.6915\n",
       "   0.5159\n",
       "   0.7178\n",
       "   0.7998\n",
       "   0.3727\n",
       "   0.4774\n",
       "   0.8252\n",
       "   0.5891\n",
       "   0.7954\n",
       "   0.6770\n",
       "   0.1482\n",
       "   0.5890\n",
       "   0.7147\n",
       "   0.3788\n",
       "   0.4392\n",
       "   0.2269\n",
       "   0.3198\n",
       "   0.4746\n",
       "   0.7550\n",
       "   0.3427\n",
       "   0.8337\n",
       "   0.7964\n",
       "   0.8491\n",
       "   0.6340\n",
       "   0.3200\n",
       "   0.7339\n",
       "   0.6527\n",
       "   0.7825\n",
       "   0.5133\n",
       "   0.7894\n",
       "   0.5417\n",
       "   0.8423\n",
       "   0.8424\n",
       "   0.8586\n",
       "   0.7075\n",
       "   0.3407\n",
       "   0.7374\n",
       "   0.7442\n",
       "   0.3393\n",
       "   0.8430\n",
       "   0.7787\n",
       "   0.7750\n",
       "   0.6968\n",
       "   1.8704\n",
       "   0.8216\n",
       "   0.5726\n",
       "   0.4912\n",
       "   0.7323\n",
       "   0.8494\n",
       "   0.8856\n",
       "   0.7779\n",
       "   0.4421\n",
       "   0.2128\n",
       "   0.3333\n",
       "   0.7062\n",
       "   0.8378\n",
       "   0.6951\n",
       "   0.2453\n",
       "   0.7429\n",
       "   0.5709\n",
       "   0.7641\n",
       "   0.4633\n",
       "   0.5823\n",
       "   0.7302\n",
       "   0.7383\n",
       "   0.7092\n",
       "   0.4802\n",
       "   0.7337\n",
       "   0.7422\n",
       "   0.6950\n",
       "   0.8563\n",
       "   0.8203\n",
       "   0.7595\n",
       "   0.7494\n",
       "   0.7706\n",
       "   0.5381\n",
       "   0.7264\n",
       "   0.8375\n",
       "   0.8263\n",
       "   0.5057\n",
       "   0.7112\n",
       "   0.7075\n",
       "   0.8431\n",
       "   0.7597\n",
       "   0.8399\n",
       "   0.8095\n",
       "   0.6585\n",
       "   0.4310\n",
       "   0.4787\n",
       "   0.7339\n",
       "   0.3659\n",
       "   0.3227\n",
       "   0.8292\n",
       "   0.6034\n",
       "   0.8009\n",
       "   0.4633\n",
       "   0.7103\n",
       "   0.6126\n",
       "   0.7346\n",
       "   0.6114\n",
       "   0.8467\n",
       "   0.5963\n",
       "   0.1949\n",
       "   0.7074\n",
       "   0.4973\n",
       "   0.7203\n",
       "   0.5999\n",
       "   0.8527\n",
       "   0.4806\n",
       "   0.7977\n",
       "   0.2589\n",
       "   0.7135\n",
       "   0.8549\n",
       "   0.4446\n",
       "   0.7868\n",
       "   0.7926\n",
       "   0.4679\n",
       "   0.6984\n",
       "   0.7613\n",
       "   0.8087\n",
       "   0.7775\n",
       "   0.6383\n",
       "   0.7886\n",
       "   0.8550\n",
       "   0.7828\n",
       "   0.3392\n",
       "   0.7897\n",
       "   0.8393\n",
       "   0.8548\n",
       "   0.5514\n",
       "   0.4108\n",
       "   0.8449\n",
       "   0.6801\n",
       "   0.6583\n",
       "   0.6234\n",
       "   0.4646\n",
       "   0.7749\n",
       "   0.8392\n",
       "   0.7415\n",
       "   0.6948\n",
       "   0.6432\n",
       "   0.8286\n",
       "   0.4894\n",
       "   0.4369\n",
       "   0.3574\n",
       "   0.6414\n",
       "   0.1888\n",
       "   0.2523\n",
       "   0.8775\n",
       "   0.5724\n",
       "   0.6802\n",
       "   0.8180\n",
       "   0.8268\n",
       "   0.7431\n",
       "   0.7027\n",
       "   0.8524\n",
       "   0.3862\n",
       "   0.8360\n",
       "   0.7299\n",
       "   0.7664\n",
       "   0.5420\n",
       "   0.3032\n",
       "   0.4522\n",
       "   0.8413\n",
       "   0.4802\n",
       "   0.6594\n",
       "   0.3830\n",
       "   0.7731\n",
       "   0.8218\n",
       "   0.6575\n",
       "   0.5764\n",
       "   0.5443\n",
       "   0.5386\n",
       "   0.4466\n",
       "   0.2517\n",
       "   0.7521\n",
       "   0.7722\n",
       "   0.5351\n",
       "   0.7997\n",
       "   0.8440\n",
       "   0.7962\n",
       "   0.6873\n",
       "   0.8288\n",
       "   0.7255\n",
       "   0.6148\n",
       "   0.4099\n",
       "   0.7477\n",
       "   0.8370\n",
       "   0.7856\n",
       "   0.7383\n",
       "   0.3466\n",
       "   0.4846\n",
       "   0.7409\n",
       "   0.2451\n",
       "   0.7588\n",
       "   0.6935\n",
       "   0.4691\n",
       "   0.5194\n",
       "   0.4100\n",
       "   0.7995\n",
       "   0.8115\n",
       "   0.4910\n",
       "   0.5466\n",
       "   0.8358\n",
       "   0.7682\n",
       "   0.5971\n",
       "   0.7037\n",
       "   0.8229\n",
       "   0.7052\n",
       "   0.2454\n",
       "   0.6499\n",
       "   0.2599\n",
       "   0.8364\n",
       "   0.5378\n",
       "   0.5503\n",
       "   0.8268\n",
       "   0.4820\n",
       "   0.6169\n",
       "   0.8319\n",
       "   0.5807\n",
       "   0.7544\n",
       "   0.7956\n",
       "   0.8470\n",
       "   0.7463\n",
       "   0.8144\n",
       "   0.7081\n",
       "   0.7515\n",
       "   0.6269\n",
       "   0.7621\n",
       "   0.7813\n",
       "   0.5769\n",
       "   0.3743\n",
       "   0.7665\n",
       "   0.5492\n",
       "   0.6893\n",
       "   0.3752\n",
       "   0.8222\n",
       "   0.7562\n",
       "   0.8004\n",
       "   0.5548\n",
       "   0.3567\n",
       "   0.5687\n",
       "   0.4466\n",
       "   0.8258\n",
       "   0.7930\n",
       "   0.8178\n",
       "   0.3756\n",
       "   0.7771\n",
       "   0.7274\n",
       "   0.7470\n",
       "   0.5513\n",
       "   0.6954\n",
       "   0.8165\n",
       "   0.8095\n",
       "   0.6862\n",
       "   0.3088\n",
       "   0.8661\n",
       "   0.2644\n",
       "   0.3079\n",
       "   0.7484\n",
       "   0.7343\n",
       "   0.7434\n",
       "   0.7532\n",
       "   0.3965\n",
       "   0.7780\n",
       "   0.6213\n",
       "   0.8453\n",
       "   0.3729\n",
       "   0.5602\n",
       "   0.7999\n",
       "   0.7067\n",
       "   0.4542\n",
       "   0.8446\n",
       "   0.6371\n",
       "   0.7629\n",
       "   0.5321\n",
       "   0.7993\n",
       "   0.8095\n",
       "   0.7480\n",
       "   0.8279\n",
       "   0.4012\n",
       "   0.5704\n",
       "   0.4278\n",
       "   0.8125\n",
       "   0.6242\n",
       "   0.5886\n",
       "   0.8433\n",
       "   0.8459\n",
       "   0.5497\n",
       "   0.8323\n",
       "   0.2871\n",
       "   0.7503\n",
       "   0.8396\n",
       "   0.8529\n",
       "   0.8434\n",
       "   0.7478\n",
       "   0.6040\n",
       "   0.8244\n",
       "   0.5548\n",
       "   0.4147\n",
       "   0.8086\n",
       "   0.7633\n",
       "   0.7476\n",
       "   0.7615\n",
       "   0.7711\n",
       "   0.7912\n",
       "   0.7254\n",
       "   0.7641\n",
       "   0.6250\n",
       "   0.5810\n",
       "   0.5345\n",
       "   1.0702\n",
       "   0.4780\n",
       "   0.7552\n",
       "   0.7471\n",
       "   0.2825\n",
       "   0.8092\n",
       "   0.7346\n",
       "   0.7529\n",
       "   0.7500\n",
       "   0.7849\n",
       "   0.5073\n",
       "   0.8199\n",
       "   0.8282\n",
       "   0.7152\n",
       "   0.8417\n",
       "   0.8303\n",
       "   0.7851\n",
       "   0.7813\n",
       "   0.5842\n",
       "   0.5020\n",
       "   0.5630\n",
       "   0.7987\n",
       "   0.7678\n",
       "   0.6461\n",
       "   0.8096\n",
       "   0.4354\n",
       "   0.8600\n",
       "   0.2917\n",
       "   0.6517\n",
       "   0.4913\n",
       "   0.7059\n",
       "   0.7220\n",
       "   0.8411\n",
       "   0.8223\n",
       "   0.5963\n",
       "   0.3060\n",
       "   0.4278\n",
       "   0.6315\n",
       "   0.7727\n",
       "   0.5155\n",
       "   0.8767\n",
       "   0.7348\n",
       "   0.4742\n",
       "   0.8911\n",
       "   0.7514\n",
       "   0.8952\n",
       "   0.7968\n",
       "   0.2308\n",
       "   0.2826\n",
       "   0.7555\n",
       "   0.6228\n",
       "   0.8224\n",
       "   0.7102\n",
       "   0.7178\n",
       "   0.7708\n",
       "   0.5767\n",
       "   0.3715\n",
       "   0.4614\n",
       "   0.3415\n",
       "   0.5807\n",
       "   0.8199\n",
       "   0.8639\n",
       "   0.7492\n",
       "   0.3787\n",
       "   0.5954\n",
       "   0.7752\n",
       "   0.8340\n",
       "   0.4950\n",
       "   0.8390\n",
       "   0.8289\n",
       "   0.7642\n",
       "   0.5671\n",
       "   0.6973\n",
       "   0.8365\n",
       "   0.7475\n",
       "   0.6075\n",
       "   0.7705\n",
       "   0.6383\n",
       "   0.7560\n",
       "   0.5263\n",
       "   0.5181\n",
       "   0.7791\n",
       "   0.6932\n",
       "   0.7764\n",
       "   0.7981\n",
       "   0.6952\n",
       "   0.8057\n",
       "   0.2494\n",
       "   0.6148\n",
       "   0.5513\n",
       "   0.5928\n",
       "   0.7003\n",
       "   0.6960\n",
       "   0.6643\n",
       "   0.3816\n",
       "   0.7354\n",
       "   0.7852\n",
       "   0.6375\n",
       "   0.8254\n",
       "   0.8290\n",
       "   0.6919\n",
       "   0.5333\n",
       "   0.6856\n",
       "   0.7688\n",
       "   0.6115\n",
       "   0.7743\n",
       "   0.7809\n",
       "   0.7716\n",
       "   0.7287\n",
       "   0.3768\n",
       "   0.6648\n",
       "   0.8413\n",
       "   0.7120\n",
       "   0.8611\n",
       "   0.7105\n",
       "   0.7294\n",
       "   0.8331\n",
       "   0.7702\n",
       "   0.8442\n",
       "   0.5659\n",
       "   0.6898\n",
       "   0.5084\n",
       "   0.7909\n",
       "   0.6323\n",
       "   0.7659\n",
       "   0.7033\n",
       "   0.7128\n",
       "   0.4880\n",
       "   0.7970\n",
       "   0.8152\n",
       "   0.7376\n",
       "   0.2610\n",
       "   0.8072\n",
       "   0.6901\n",
       "   0.2410\n",
       "   0.8370\n",
       "   0.6429\n",
       "   0.5824\n",
       "   0.2769\n",
       "   0.7400\n",
       "   0.8316\n",
       "   0.7241\n",
       "   0.8266\n",
       "   0.7916\n",
       "   0.4202\n",
       "   0.7654\n",
       "   0.7626\n",
       "   0.7645\n",
       "   0.2558\n",
       "   0.7588\n",
       "   0.8404\n",
       "   0.6990\n",
       "   0.7556\n",
       "   0.8426\n",
       "   0.8266\n",
       "   0.5767\n",
       "   0.7538\n",
       "   0.4322\n",
       "   0.7229\n",
       "   0.8171\n",
       "   0.4895\n",
       "   0.7346\n",
       "   0.8404\n",
       "   0.8300\n",
       "   0.5051\n",
       "   0.7716\n",
       "   0.5963\n",
       "   0.8490\n",
       "   0.3640\n",
       "   0.8519\n",
       "   0.3935\n",
       "   0.8267\n",
       "   0.7603\n",
       "   0.8245\n",
       "   0.6926\n",
       "   0.7514\n",
       "   0.4920\n",
       "   0.7665\n",
       "   0.8100\n",
       "   0.7213\n",
       "   0.8041\n",
       "   0.8424\n",
       "   0.7059\n",
       "   0.3170\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.0748\n",
       "  -0.0512\n",
       "  -0.0435\n",
       "  -0.0439\n",
       "  -0.0400\n",
       "  -0.0683\n",
       "  -0.1210\n",
       "  -0.0702\n",
       "  -0.0971\n",
       "  -0.0976\n",
       "  -0.0575\n",
       "  -0.0403\n",
       "  -0.0998\n",
       "  -0.0509\n",
       "  -0.0525\n",
       "  -0.0474\n",
       "  -0.0740\n",
       "  -0.0547\n",
       "  -0.1319\n",
       "  -0.0384\n",
       "  -0.0637\n",
       "  -0.1385\n",
       "  -0.1467\n",
       "  -0.0746\n",
       "  -0.1070\n",
       "  -0.0628\n",
       "  -0.1494\n",
       "  -0.1937\n",
       "  -0.0917\n",
       "  -0.1098\n",
       "  -0.1867\n",
       "  -0.1713\n",
       "  -0.2316\n",
       "  -0.1686\n",
       "  -0.1348\n",
       "  -0.1334\n",
       "  -0.1847\n",
       "  -0.0886\n",
       "  -0.0265\n",
       "  -0.0636\n",
       "  -0.0756\n",
       "  -0.1627\n",
       "  -0.0484\n",
       "   0.0162\n",
       "  -0.0611\n",
       "  -0.1349\n",
       "  -0.0941\n",
       "  -0.1205\n",
       "  -0.0568\n",
       "  -0.0558\n",
       "  -0.1211\n",
       "  -0.0861\n",
       "  -0.1722\n",
       "  -0.0743\n",
       "  -0.0555\n",
       "  -0.1715\n",
       "  -0.0610\n",
       "  -0.0935\n",
       "  -0.0856\n",
       "  -0.0608\n",
       "   0.5233\n",
       "  -0.0903\n",
       "  -0.1043\n",
       "  -0.1313\n",
       "  -0.0484\n",
       "  -0.0675\n",
       "   0.0776\n",
       "  -0.0495\n",
       "  -0.1698\n",
       "  -0.2054\n",
       "  -0.1605\n",
       "  -0.1073\n",
       "  -0.0724\n",
       "  -0.0021\n",
       "  -0.1844\n",
       "  -0.1064\n",
       "  -0.1191\n",
       "  -0.0602\n",
       "  -0.1482\n",
       "  -0.0886\n",
       "  -0.0849\n",
       "  -0.0227\n",
       "  -0.0644\n",
       "  -0.1377\n",
       "  -0.1137\n",
       "  -0.0768\n",
       "  -0.0329\n",
       "  -0.0752\n",
       "  -0.0362\n",
       "   0.0477\n",
       "  -0.0510\n",
       "  -0.0979\n",
       "  -0.1036\n",
       "  -0.0599\n",
       "  -0.0597\n",
       "  -0.0608\n",
       "  -0.1592\n",
       "  -0.0662\n",
       "  -0.0392\n",
       "  -0.0642\n",
       "  -0.0550\n",
       "  -0.0955\n",
       "  -0.0957\n",
       "  -0.1399\n",
       "  -0.1305\n",
       "  -0.1425\n",
       "  -0.0056\n",
       "  -0.1785\n",
       "  -0.1863\n",
       "  -0.0612\n",
       "  -0.0972\n",
       "  -0.0744\n",
       "  -0.1267\n",
       "  -0.0898\n",
       "  -0.0960\n",
       "  -0.0411\n",
       "  -0.1012\n",
       "  -0.0462\n",
       "  -0.0848\n",
       "  -0.1727\n",
       "  -0.0285\n",
       "  -0.0997\n",
       "  -0.0504\n",
       "  -0.1515\n",
       "  -0.1117\n",
       "  -0.1348\n",
       "  -0.0800\n",
       "  -0.1913\n",
       "  -0.0415\n",
       "  -0.1131\n",
       "  -0.1353\n",
       "  -0.0795\n",
       "  -0.0816\n",
       "  -0.1180\n",
       "  -0.0580\n",
       "  -0.0942\n",
       "  -0.0548\n",
       "  -0.0611\n",
       "  -0.0069\n",
       "  -0.0676\n",
       "  -0.0925\n",
       "  -0.0595\n",
       "  -0.1653\n",
       "   0.0153\n",
       "  -0.0505\n",
       "  -0.0633\n",
       "  -0.1410\n",
       "  -0.1788\n",
       "  -0.0711\n",
       "  -0.1181\n",
       "  -0.1315\n",
       "  -0.0247\n",
       "  -0.1292\n",
       "  -0.0932\n",
       "  -0.0512\n",
       "  -0.0312\n",
       "  -0.1018\n",
       "  -0.0484\n",
       "  -0.0792\n",
       "  -0.1467\n",
       "  -0.1200\n",
       "  -0.1589\n",
       "  -0.0990\n",
       "  -0.2160\n",
       "  -0.1974\n",
       "   0.1412\n",
       "  -0.1077\n",
       "  -0.1457\n",
       "  -0.2410\n",
       "  -0.0917\n",
       "  -0.0605\n",
       "  -0.0772\n",
       "  -0.1007\n",
       "  -0.1723\n",
       "  -0.0551\n",
       "  -0.1637\n",
       "  -0.0764\n",
       "  -0.0799\n",
       "  -0.1604\n",
       "  -0.0860\n",
       "  -0.0659\n",
       "  -0.1394\n",
       "  -0.0268\n",
       "  -0.1719\n",
       "   0.0555\n",
       "  -0.0449\n",
       "  -0.1932\n",
       "  -0.1347\n",
       "  -0.0756\n",
       "  -0.1040\n",
       "  -0.0915\n",
       "  -0.1912\n",
       "  -0.0813\n",
       "  -0.0463\n",
       "  -0.1734\n",
       "  -0.0957\n",
       "  -0.0600\n",
       "  -0.0826\n",
       "  -0.1141\n",
       "  -0.0671\n",
       "  -0.1032\n",
       "  -0.1401\n",
       "  -0.1404\n",
       "  -0.0419\n",
       "  -0.0463\n",
       "  -0.0513\n",
       "  -0.0818\n",
       "  -0.1744\n",
       "  -0.1395\n",
       "  -0.0835\n",
       "  -0.1853\n",
       "  -0.0855\n",
       "  -0.0439\n",
       "  -0.1308\n",
       "  -0.1018\n",
       "  -0.1454\n",
       "  -0.0437\n",
       "  -0.1115\n",
       "  -0.1355\n",
       "  -0.1216\n",
       "  -0.0613\n",
       "  -0.0430\n",
       "  -0.1086\n",
       "  -0.0558\n",
       "  -0.0727\n",
       "  -0.0612\n",
       "  -0.2064\n",
       "  -0.1230\n",
       "  -0.1932\n",
       "  -0.0760\n",
       "  -0.1159\n",
       "  -0.0836\n",
       "  -0.0550\n",
       "  -0.1357\n",
       "  -0.1030\n",
       "  -0.0647\n",
       "  -0.1021\n",
       "  -0.1295\n",
       "   0.0986\n",
       "  -0.0655\n",
       "  -0.0208\n",
       "  -0.0475\n",
       "  -0.0962\n",
       "  -0.1581\n",
       "  -0.0799\n",
       "  -0.0179\n",
       "  -0.0466\n",
       "  -0.1015\n",
       "  -0.1654\n",
       "  -0.0364\n",
       "  -0.0956\n",
       "  -0.0962\n",
       "  -0.1483\n",
       "  -0.0677\n",
       "  -0.1416\n",
       "  -0.0475\n",
       "  -0.1116\n",
       "  -0.1823\n",
       "  -0.1122\n",
       "  -0.1428\n",
       "  -0.0676\n",
       "  -0.0657\n",
       "  -0.0595\n",
       "  -0.2097\n",
       "  -0.0507\n",
       "  -0.1063\n",
       "  -0.0560\n",
       "  -0.1132\n",
       "  -0.0650\n",
       "   0.0051\n",
       "  -0.1258\n",
       "  -0.1305\n",
       "  -0.1950\n",
       "   0.0005\n",
       "  -0.1858\n",
       "  -0.1847\n",
       "  -0.1326\n",
       "  -0.0803\n",
       "  -0.1091\n",
       "  -0.1435\n",
       "  -0.1954\n",
       "  -0.0526\n",
       "  -0.1043\n",
       "  -0.0269\n",
       "  -0.1752\n",
       "  -0.1237\n",
       "  -0.0585\n",
       "   0.0115\n",
       "  -0.1134\n",
       "  -0.0716\n",
       "  -0.0886\n",
       "  -0.0823\n",
       "  -0.1200\n",
       "  -0.0495\n",
       "  -0.1523\n",
       "  -0.1354\n",
       "  -0.0284\n",
       "  -0.1490\n",
       "  -0.1169\n",
       "  -0.1332\n",
       "  -0.0553\n",
       "  -0.1144\n",
       "  -0.0585\n",
       "  -0.0697\n",
       "  -0.0361\n",
       "  -0.1192\n",
       "  -0.0505\n",
       "  -0.1764\n",
       "  -0.0697\n",
       "  -0.0577\n",
       "  -0.0464\n",
       "  -0.0593\n",
       "  -0.1337\n",
       "  -0.1741\n",
       "  -0.0477\n",
       "  -0.1288\n",
       "  -0.1733\n",
       "  -0.0738\n",
       "  -0.0631\n",
       "  -0.1416\n",
       "  -0.0686\n",
       "  -0.0471\n",
       "  -0.0473\n",
       "  -0.0321\n",
       "  -0.0665\n",
       "  -0.0841\n",
       "  -0.1128\n",
       "  -0.1085\n",
       "   0.3917\n",
       "  -0.0962\n",
       "  -0.1016\n",
       "  -0.0078\n",
       "  -0.1875\n",
       "  -0.0594\n",
       "  -0.0799\n",
       "  -0.0809\n",
       "  -0.0675\n",
       "   0.0282\n",
       "  -0.1052\n",
       "  -0.0667\n",
       "  -0.0549\n",
       "  -0.1574\n",
       "   0.2669\n",
       "  -0.0223\n",
       "  -0.0424\n",
       "  -0.0291\n",
       "  -0.0954\n",
       "  -0.0316\n",
       "  -0.1365\n",
       "  -0.0340\n",
       "  -0.1210\n",
       "  -0.1022\n",
       "  -0.1642\n",
       "  -0.1419\n",
       "  -0.0661\n",
       "  -0.1733\n",
       "  -0.1646\n",
       "  -0.1165\n",
       "  -0.0986\n",
       "  -0.0700\n",
       "  -0.0660\n",
       "  -0.0453\n",
       "  -0.1239\n",
       "  -0.2158\n",
       "  -0.1753\n",
       "  -0.0870\n",
       "  -0.0805\n",
       "  -0.1043\n",
       "  -0.0833\n",
       "  -0.0867\n",
       "  -0.1168\n",
       "   0.1512\n",
       "  -0.1405\n",
       "   0.1068\n",
       "  -0.0629\n",
       "  -0.1865\n",
       "  -0.1831\n",
       "  -0.0924\n",
       "  -0.0658\n",
       "  -0.0500\n",
       "  -0.0373\n",
       "  -0.0320\n",
       "  -0.0789\n",
       "  -0.1159\n",
       "  -0.1583\n",
       "  -0.1302\n",
       "  -0.1727\n",
       "  -0.1570\n",
       "  -0.0424\n",
       "  -0.0637\n",
       "  -0.1055\n",
       "  -0.1877\n",
       "  -0.1283\n",
       "  -0.0577\n",
       "  -0.0661\n",
       "  -0.1369\n",
       "  -0.0737\n",
       "  -0.0496\n",
       "  -0.0724\n",
       "  -0.1441\n",
       "  -0.0814\n",
       "  -0.0558\n",
       "  -0.1348\n",
       "  -0.1131\n",
       "  -0.0618\n",
       "  -0.0845\n",
       "  -0.0469\n",
       "  -0.1046\n",
       "  -0.1208\n",
       "  -0.0686\n",
       "  -0.0960\n",
       "  -0.0521\n",
       "  -0.0602\n",
       "  -0.0603\n",
       "  -0.0424\n",
       "  -0.1931\n",
       "  -0.1232\n",
       "  -0.1016\n",
       "  -0.0765\n",
       "   0.1269\n",
       "  -0.0955\n",
       "  -0.0250\n",
       "  -0.1656\n",
       "  -0.1553\n",
       "  -0.0680\n",
       "  -0.0610\n",
       "   0.1635\n",
       "  -0.0767\n",
       "  -0.0724\n",
       "  -0.0850\n",
       "  -0.0101\n",
       "  -0.0792\n",
       "  -0.0789\n",
       "  -0.0868\n",
       "  -0.2325\n",
       "  -0.0609\n",
       "  -0.0273\n",
       "  -0.1678\n",
       "  -0.0398\n",
       "  -0.0443\n",
       "   0.0614\n",
       "   0.2894\n",
       "  -0.1291\n",
       "  -0.0578\n",
       "  -0.0680\n",
       "  -0.1142\n",
       "  -0.0990\n",
       "  -0.0943\n",
       "  -0.0713\n",
       "  -0.0873\n",
       "  -0.1494\n",
       "  -0.0977\n",
       "  -0.1498\n",
       "  -0.0477\n",
       "  -0.0882\n",
       "  -0.1304\n",
       "  -0.0789\n",
       "  -0.1397\n",
       "  -0.1544\n",
       "  -0.1920\n",
       "  -0.0571\n",
       "  -0.0718\n",
       "  -0.2176\n",
       "  -0.0747\n",
       "  -0.1084\n",
       "  -0.0681\n",
       "  -0.1856\n",
       "  -0.0241\n",
       "  -0.0772\n",
       "   0.0081\n",
       "  -0.0620\n",
       "  -0.0879\n",
       "  -0.1675\n",
       "  -0.1651\n",
       "  -0.0461\n",
       "  -0.0871\n",
       "  -0.2092\n",
       "  -0.1024\n",
       "  -0.0553\n",
       "  -0.0875\n",
       "  -0.0876\n",
       "  -0.0618\n",
       "  -0.0660\n",
       "  -0.1234\n",
       "  -0.0482\n",
       "  -0.1256\n",
       "  -0.0921\n",
       "  -0.0754\n",
       "  -0.1728\n",
       "  -0.1249\n",
       "  -0.0606\n",
       "  -0.0609\n",
       "  -0.1272\n",
       "  -0.1076\n",
       "  -0.0874\n",
       "  -0.0493\n",
       "  -0.1324\n",
       "   0.0396\n",
       "  -0.1812\n",
       "  -0.1517\n",
       "  -0.0525\n",
       "  -0.0459\n",
       "  -0.1154\n",
       "  -0.1038\n",
       "  -0.1384\n",
       "  -0.0713\n",
       "  -0.0443\n",
       "  -0.1118\n",
       "  -0.1024\n",
       "  -0.0724\n",
       "  -0.0445\n",
       "  -0.1820\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -4.0595e-04 -2.0437e-03  1.9888e-02\n",
       "   -7.2587e-04 -3.7530e-02 -1.3624e-02\n",
       "   -1.3695e-03 -1.1428e-02 -1.7349e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    7.8937e-03  3.4503e-02  5.9172e-03\n",
       "   -1.2982e-02 -9.6313e-03 -4.9564e-03\n",
       "   -1.0971e-02 -9.3067e-04  1.1841e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "    1.0319e-03  2.1524e-02  1.1408e-02\n",
       "    1.4720e-02  2.6509e-02 -1.4449e-03\n",
       "    1.0020e-02 -2.0327e-02  8.0553e-03\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,509,.,.) = \n",
       "   -2.3089e-02 -5.0809e-03 -1.1474e-02\n",
       "   -2.5683e-03  2.0159e-02 -2.9646e-02\n",
       "   -5.2722e-03 -2.4167e-02 -2.1048e-02\n",
       "  \n",
       "  ( 0 ,510,.,.) = \n",
       "    1.4219e-02  4.2775e-03  9.0465e-03\n",
       "   -1.6794e-02 -1.3480e-02  1.0665e-02\n",
       "   -7.9651e-03 -8.7085e-03 -3.6310e-02\n",
       "  \n",
       "  ( 0 ,511,.,.) = \n",
       "   -2.8644e-03  1.8348e-02  1.2055e-02\n",
       "    2.0169e-02  3.9855e-03 -8.3169e-03\n",
       "   -6.3456e-03 -1.8143e-02 -2.3325e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    1.7929e-02  1.3241e-02  1.3912e-02\n",
       "   -1.9840e-03  1.5411e-02  1.0163e-02\n",
       "    4.2817e-03 -2.1241e-02 -1.2080e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    5.0657e-02  3.4061e-04  5.6773e-03\n",
       "   -5.3680e-03  1.0378e-02 -1.8454e-02\n",
       "    1.2936e-02  1.1112e-02  5.8771e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -1.2215e-02  2.8015e-02 -5.6271e-03\n",
       "   -1.2581e-02 -1.0040e-02  3.2294e-02\n",
       "   -3.1127e-02 -1.3351e-02 -1.3619e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,509,.,.) = \n",
       "    1.7448e-02 -2.1630e-02 -3.6557e-03\n",
       "   -4.0062e-02 -8.1960e-03  2.5439e-02\n",
       "   -2.3548e-02  7.8802e-03  2.3255e-02\n",
       "  \n",
       "  ( 1 ,510,.,.) = \n",
       "    1.6921e-02  4.0783e-03  1.9826e-02\n",
       "   -1.3542e-02  1.9482e-02 -1.1319e-02\n",
       "   -1.2334e-02  3.3612e-03  2.2033e-02\n",
       "  \n",
       "  ( 1 ,511,.,.) = \n",
       "    4.1035e-03  1.8274e-02  4.5961e-03\n",
       "   -1.7951e-02  3.4846e-02  1.7145e-02\n",
       "   -3.8896e-03 -9.0360e-04  2.0883e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.0223e-02 -1.8596e-04 -2.5873e-02\n",
       "   -2.3945e-02  2.7524e-03 -2.1493e-02\n",
       "   -3.2637e-03  2.6416e-02  7.2215e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    1.4252e-03 -3.4761e-02 -2.8218e-02\n",
       "   -5.7526e-03  6.8582e-03 -1.2176e-03\n",
       "   -1.7349e-02  3.4328e-02  2.1111e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -3.8754e-03  4.5850e-03 -1.1412e-02\n",
       "   -6.8577e-03  7.1533e-03  2.5360e-02\n",
       "   -1.9317e-02  9.5303e-03 -4.2570e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,509,.,.) = \n",
       "    7.4742e-03  3.0945e-02  4.1029e-03\n",
       "   -1.4871e-03 -3.1085e-02  1.8258e-02\n",
       "   -1.1928e-02 -2.0392e-02 -5.3793e-03\n",
       "  \n",
       "  ( 2 ,510,.,.) = \n",
       "    1.4055e-03  2.1236e-02 -4.7824e-03\n",
       "   -2.9289e-03 -5.2676e-03  1.0616e-02\n",
       "    2.9043e-02 -4.0966e-03 -1.1735e-02\n",
       "  \n",
       "  ( 2 ,511,.,.) = \n",
       "   -9.4285e-03  1.6020e-02 -1.9712e-02\n",
       "    2.6769e-02  3.8862e-03 -2.0319e-02\n",
       "    8.4984e-03  1.7713e-02 -1.4743e-03\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "   -2.7650e-02  3.5458e-04 -5.8453e-03\n",
       "   -2.3430e-02 -3.6502e-03  6.6551e-03\n",
       "    2.9868e-03 -1.5716e-02 -2.3038e-03\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "    8.6165e-03 -6.7469e-03  9.6365e-03\n",
       "   -2.1037e-02  9.4338e-03 -9.9083e-03\n",
       "    1.9257e-02 -2.1576e-02 -4.6819e-03\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "    3.6159e-03  2.3418e-02  1.1342e-03\n",
       "    2.3013e-03 -7.2733e-03 -3.3338e-02\n",
       "    7.5481e-03 -1.0329e-02 -7.8343e-03\n",
       "      ... \n",
       "  \n",
       "  (509,509,.,.) = \n",
       "    1.0940e-02 -5.2104e-03 -6.8138e-04\n",
       "    1.0358e-02  2.1177e-02  2.5329e-02\n",
       "    2.3208e-02  7.6516e-03  1.9287e-03\n",
       "  \n",
       "  (509,510,.,.) = \n",
       "   -1.4500e-02 -1.8786e-02 -1.6861e-02\n",
       "    1.6925e-02  6.5433e-03 -1.5018e-02\n",
       "   -1.1650e-02  5.7850e-03 -4.0757e-02\n",
       "  \n",
       "  (509,511,.,.) = \n",
       "    1.3922e-02 -6.9069e-03  2.5139e-02\n",
       "    2.0155e-02 -1.2100e-02  3.4155e-03\n",
       "   -2.1798e-03 -2.3359e-02 -7.7976e-03\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "    2.2710e-02 -4.4949e-03  1.6452e-02\n",
       "    2.4127e-02  3.3362e-02  1.5039e-02\n",
       "   -9.4032e-03  5.4043e-03  1.2123e-02\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "   -3.8086e-04  1.3662e-02  1.6698e-02\n",
       "   -1.0862e-02  4.7701e-03  1.5974e-02\n",
       "   -9.2550e-03  2.5606e-03 -2.6363e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "   -2.1849e-02 -2.3293e-02  1.7377e-02\n",
       "   -8.1744e-03  9.8228e-03 -1.1930e-02\n",
       "   -2.3129e-02 -1.7465e-03 -3.9478e-03\n",
       "      ... \n",
       "  \n",
       "  (510,509,.,.) = \n",
       "    1.3667e-02  1.3699e-02  2.0702e-03\n",
       "   -2.0673e-02  4.9449e-03  1.0372e-02\n",
       "    9.7860e-04 -3.0517e-02  1.9251e-02\n",
       "  \n",
       "  (510,510,.,.) = \n",
       "    4.8441e-03 -4.6118e-03  1.1030e-02\n",
       "    6.4117e-03 -8.2602e-03  2.3937e-02\n",
       "   -4.1718e-02  2.9488e-02  1.6507e-02\n",
       "  \n",
       "  (510,511,.,.) = \n",
       "   -1.2396e-03 -1.4488e-02  9.0829e-04\n",
       "    1.4673e-02  2.2179e-02  8.6127e-03\n",
       "    6.4378e-03  3.0045e-02  3.2258e-02\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "   -5.3289e-03 -3.1145e-03 -8.3287e-04\n",
       "   -1.0885e-02  5.9342e-03 -7.9710e-03\n",
       "    4.6672e-03 -2.1423e-02  5.9113e-03\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "   -1.0114e-02  2.3837e-03  1.1347e-02\n",
       "   -9.8652e-03 -3.6659e-03  1.0154e-03\n",
       "   -1.0361e-02 -1.3291e-04  3.3832e-03\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "    6.4211e-03  1.7563e-02  8.8112e-03\n",
       "    2.1972e-03  1.2520e-03 -2.1750e-02\n",
       "    1.5833e-02  2.8150e-03 -2.3422e-02\n",
       "      ... \n",
       "  \n",
       "  (511,509,.,.) = \n",
       "    3.2028e-02  1.9598e-02  3.6145e-02\n",
       "    1.6736e-02 -4.1835e-03  1.1774e-02\n",
       "    3.4445e-03  7.5950e-03 -1.1472e-02\n",
       "  \n",
       "  (511,510,.,.) = \n",
       "   -1.6927e-03  7.6361e-03 -9.6426e-03\n",
       "   -1.4236e-03 -1.5782e-02  5.6845e-03\n",
       "   -2.0844e-02  4.7074e-03 -1.3410e-03\n",
       "  \n",
       "  (511,511,.,.) = \n",
       "    2.6096e-02  1.7828e-03 -1.7706e-02\n",
       "   -9.9760e-03  9.1698e-03 -2.5861e-03\n",
       "    1.8293e-02 -1.9127e-02 -1.8733e-02\n",
       "  [torch.cuda.FloatTensor of size 512x512x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7732\n",
       "   0.7491\n",
       "   0.7906\n",
       "   0.7658\n",
       "   0.7855\n",
       "   0.7495\n",
       "   0.7910\n",
       "   0.7815\n",
       "   0.7550\n",
       "   0.8392\n",
       "   0.7850\n",
       "   0.7321\n",
       "   0.7882\n",
       "   0.7778\n",
       "   0.7878\n",
       "   0.7954\n",
       "   0.7669\n",
       "   0.7866\n",
       "   0.7991\n",
       "   0.7699\n",
       "   0.8418\n",
       "   0.7866\n",
       "   0.7788\n",
       "   0.7525\n",
       "   0.7572\n",
       "   0.7857\n",
       "   0.7377\n",
       "   0.7468\n",
       "   0.7721\n",
       "   0.8058\n",
       "   0.7440\n",
       "   0.7808\n",
       "   0.7579\n",
       "   0.8475\n",
       "   0.7933\n",
       "   0.7858\n",
       "   0.7834\n",
       "   0.7666\n",
       "   0.7964\n",
       "   0.7577\n",
       "   0.7788\n",
       "   0.7863\n",
       "   0.8267\n",
       "   0.7993\n",
       "   0.7691\n",
       "   0.7919\n",
       "   0.8821\n",
       "   0.7819\n",
       "   0.7542\n",
       "   0.8152\n",
       "   0.7583\n",
       "   0.8191\n",
       "   0.7687\n",
       "   0.7857\n",
       "   0.7613\n",
       "   0.7888\n",
       "   0.8048\n",
       "   0.7761\n",
       "   0.9081\n",
       "   0.7400\n",
       "   0.7810\n",
       "   0.7582\n",
       "   0.7817\n",
       "   0.7810\n",
       "   0.7810\n",
       "   0.7799\n",
       "   0.7736\n",
       "   0.7805\n",
       "   0.7906\n",
       "   0.7490\n",
       "   0.7691\n",
       "   0.7772\n",
       "   0.8283\n",
       "   0.7807\n",
       "   0.7793\n",
       "   0.7688\n",
       "   0.7670\n",
       "   0.7449\n",
       "   0.7944\n",
       "   0.7774\n",
       "   0.7677\n",
       "   0.8278\n",
       "   0.7892\n",
       "   0.7846\n",
       "   0.7628\n",
       "   0.7995\n",
       "   0.7898\n",
       "   0.7713\n",
       "   0.7827\n",
       "   0.8068\n",
       "   0.7699\n",
       "   0.8293\n",
       "   0.8250\n",
       "   0.7865\n",
       "   0.7863\n",
       "   0.7885\n",
       "   0.8314\n",
       "   0.7815\n",
       "   0.7874\n",
       "   0.8443\n",
       "   0.7942\n",
       "   0.7905\n",
       "   0.7500\n",
       "   0.7879\n",
       "   0.7902\n",
       "   0.7885\n",
       "   0.7991\n",
       "   0.7755\n",
       "   0.7669\n",
       "   0.7804\n",
       "   0.7913\n",
       "   0.7943\n",
       "   0.7715\n",
       "   0.7744\n",
       "   0.7811\n",
       "   0.7648\n",
       "   0.7879\n",
       "   0.7991\n",
       "   0.7831\n",
       "   0.7819\n",
       "   0.7358\n",
       "   0.7507\n",
       "   0.8559\n",
       "   0.7485\n",
       "   0.7934\n",
       "   0.7719\n",
       "   0.7821\n",
       "   0.7761\n",
       "   0.7837\n",
       "   0.7679\n",
       "   0.7620\n",
       "   0.7684\n",
       "   0.7813\n",
       "   0.7707\n",
       "   0.8184\n",
       "   0.7668\n",
       "   0.7850\n",
       "   0.7426\n",
       "   0.7862\n",
       "   0.7908\n",
       "   0.8029\n",
       "   0.8087\n",
       "   0.8254\n",
       "   0.8057\n",
       "   0.7786\n",
       "   0.7821\n",
       "   0.8147\n",
       "   0.7765\n",
       "   0.7632\n",
       "   0.7719\n",
       "   0.7733\n",
       "   0.8013\n",
       "   0.7909\n",
       "   0.8252\n",
       "   0.7325\n",
       "   0.7820\n",
       "   0.7999\n",
       "   0.8159\n",
       "   0.7844\n",
       "   0.7773\n",
       "   0.7548\n",
       "   0.7669\n",
       "   0.7830\n",
       "   0.7800\n",
       "   0.7789\n",
       "   0.7645\n",
       "   0.7842\n",
       "   0.7715\n",
       "   0.7709\n",
       "   0.7547\n",
       "   0.7916\n",
       "   0.7607\n",
       "   0.7834\n",
       "   0.8031\n",
       "   0.7948\n",
       "   0.8395\n",
       "   0.7564\n",
       "   0.7597\n",
       "   0.7809\n",
       "   0.7920\n",
       "   0.7808\n",
       "   0.7864\n",
       "   0.7777\n",
       "   0.8259\n",
       "   0.7859\n",
       "   0.7838\n",
       "   0.7784\n",
       "   0.7930\n",
       "   0.7742\n",
       "   0.7952\n",
       "   0.7844\n",
       "   0.7882\n",
       "   0.7764\n",
       "   0.7585\n",
       "   0.7963\n",
       "   0.7566\n",
       "   0.7871\n",
       "   0.7787\n",
       "   0.7786\n",
       "   0.7907\n",
       "   0.7866\n",
       "   0.7846\n",
       "   0.7790\n",
       "   0.7948\n",
       "   0.7847\n",
       "   0.7939\n",
       "   0.7953\n",
       "   0.8394\n",
       "   0.7483\n",
       "   0.7800\n",
       "   0.7480\n",
       "   0.7751\n",
       "   0.7752\n",
       "   0.7796\n",
       "   0.8070\n",
       "   0.7969\n",
       "   0.7524\n",
       "   0.7866\n",
       "   0.7820\n",
       "   0.7721\n",
       "   0.7488\n",
       "   0.7752\n",
       "   0.8248\n",
       "   0.7738\n",
       "   0.7868\n",
       "   0.7703\n",
       "   0.7976\n",
       "   0.7798\n",
       "   0.7782\n",
       "   0.7787\n",
       "   0.7776\n",
       "   0.7764\n",
       "   0.8004\n",
       "   0.7700\n",
       "   0.7788\n",
       "   0.7747\n",
       "   0.8090\n",
       "   0.7863\n",
       "   0.8318\n",
       "   0.7752\n",
       "   0.8261\n",
       "   0.7716\n",
       "   0.7779\n",
       "   0.7851\n",
       "   0.7967\n",
       "   0.8001\n",
       "   0.7628\n",
       "   0.8122\n",
       "   0.7954\n",
       "   0.7971\n",
       "   0.8241\n",
       "   0.7312\n",
       "   0.7522\n",
       "   0.8205\n",
       "   0.8021\n",
       "   0.7898\n",
       "   0.7900\n",
       "   0.8093\n",
       "   0.7927\n",
       "   0.7966\n",
       "   0.8189\n",
       "   0.7134\n",
       "   0.7949\n",
       "   0.7500\n",
       "   0.7764\n",
       "   0.7838\n",
       "   0.7862\n",
       "   0.7791\n",
       "   0.7805\n",
       "   0.7815\n",
       "   0.7673\n",
       "   0.7889\n",
       "   0.8153\n",
       "   0.7679\n",
       "   0.7938\n",
       "   0.8411\n",
       "   0.7813\n",
       "   0.7694\n",
       "   0.7950\n",
       "   0.8622\n",
       "   0.7669\n",
       "   0.7813\n",
       "   0.7764\n",
       "   0.7816\n",
       "   0.7459\n",
       "   0.7946\n",
       "   0.7454\n",
       "   0.7653\n",
       "   0.7864\n",
       "   0.7639\n",
       "   0.7972\n",
       "   0.7751\n",
       "   0.7878\n",
       "   0.7795\n",
       "   0.7264\n",
       "   0.7702\n",
       "   0.7873\n",
       "   0.7870\n",
       "   0.7592\n",
       "   0.7922\n",
       "   0.7926\n",
       "   0.7562\n",
       "   0.7981\n",
       "   0.7991\n",
       "   0.7766\n",
       "   0.7531\n",
       "   0.7837\n",
       "   0.7811\n",
       "   0.8098\n",
       "   0.7801\n",
       "   0.7959\n",
       "   0.7764\n",
       "   0.7815\n",
       "   0.7642\n",
       "   0.9105\n",
       "   0.7788\n",
       "   0.7614\n",
       "   0.7767\n",
       "   0.8039\n",
       "   0.7754\n",
       "   0.7817\n",
       "   0.7919\n",
       "   0.7749\n",
       "   0.7474\n",
       "   0.7709\n",
       "   0.8023\n",
       "   0.7842\n",
       "   0.7938\n",
       "   0.7970\n",
       "   0.7931\n",
       "   0.7877\n",
       "   0.7715\n",
       "   0.8081\n",
       "   0.7917\n",
       "   0.7898\n",
       "   0.7823\n",
       "   0.7740\n",
       "   0.7578\n",
       "   0.7808\n",
       "   0.8029\n",
       "   0.7579\n",
       "   0.7646\n",
       "   0.7755\n",
       "   0.7360\n",
       "   0.7991\n",
       "   0.7964\n",
       "   0.7460\n",
       "   0.7766\n",
       "   0.7778\n",
       "   0.7769\n",
       "   0.7524\n",
       "   0.7668\n",
       "   0.8125\n",
       "   0.7739\n",
       "   0.7888\n",
       "   0.7834\n",
       "   0.7854\n",
       "   0.7973\n",
       "   0.7747\n",
       "   0.7554\n",
       "   0.7904\n",
       "   0.7843\n",
       "   0.7988\n",
       "   0.7803\n",
       "   0.7864\n",
       "   0.7756\n",
       "   0.7778\n",
       "   0.7647\n",
       "   0.7894\n",
       "   0.7843\n",
       "   0.7827\n",
       "   0.7382\n",
       "   0.7842\n",
       "   0.7760\n",
       "   0.8334\n",
       "   0.7560\n",
       "   0.7913\n",
       "   0.7814\n",
       "   0.8006\n",
       "   0.7750\n",
       "   0.7980\n",
       "   0.7518\n",
       "   0.8284\n",
       "   0.8117\n",
       "   0.7772\n",
       "   0.7816\n",
       "   0.7970\n",
       "   0.7870\n",
       "   0.7762\n",
       "   0.7830\n",
       "   0.7830\n",
       "   0.7867\n",
       "   0.7762\n",
       "   0.8094\n",
       "   0.7571\n",
       "   0.7777\n",
       "   0.8096\n",
       "   0.7580\n",
       "   0.7753\n",
       "   0.7669\n",
       "   0.7811\n",
       "   0.8128\n",
       "   0.7659\n",
       "   0.7664\n",
       "   0.7763\n",
       "   0.7871\n",
       "   0.7698\n",
       "   0.8448\n",
       "   0.7575\n",
       "   0.7814\n",
       "   0.7873\n",
       "   0.7956\n",
       "   0.8368\n",
       "   0.8707\n",
       "   0.7998\n",
       "   0.7637\n",
       "   0.7887\n",
       "   0.7705\n",
       "   0.7821\n",
       "   0.8704\n",
       "   0.8019\n",
       "   0.7679\n",
       "   0.7662\n",
       "   0.7758\n",
       "   0.7945\n",
       "   0.7474\n",
       "   0.7532\n",
       "   0.7923\n",
       "   0.7480\n",
       "   0.7674\n",
       "   0.7782\n",
       "   0.7663\n",
       "   0.7762\n",
       "   0.7979\n",
       "   0.7482\n",
       "   0.7531\n",
       "   0.7635\n",
       "   0.7748\n",
       "   0.8079\n",
       "   0.7996\n",
       "   0.7942\n",
       "   0.7828\n",
       "   0.7886\n",
       "   0.7831\n",
       "   0.7539\n",
       "   0.8115\n",
       "   0.8284\n",
       "   0.7659\n",
       "   0.8007\n",
       "   0.7686\n",
       "   0.7899\n",
       "   0.7724\n",
       "   0.8106\n",
       "   0.7852\n",
       "   0.7824\n",
       "   0.7795\n",
       "   0.7700\n",
       "   0.8000\n",
       "   0.8131\n",
       "   0.7876\n",
       "   0.8064\n",
       "   0.7863\n",
       "   0.7873\n",
       "   0.7485\n",
       "   0.8047\n",
       "   0.7801\n",
       "   0.8100\n",
       "   0.7720\n",
       "   0.7551\n",
       "   0.7756\n",
       "   0.7877\n",
       "   0.7902\n",
       "   0.7630\n",
       "   0.8115\n",
       "   0.7785\n",
       "   0.7863\n",
       "   0.8003\n",
       "   0.7749\n",
       "   0.7939\n",
       "   0.7199\n",
       "   0.8206\n",
       "   0.7757\n",
       "   0.7816\n",
       "   0.7881\n",
       "   0.7800\n",
       "   0.7706\n",
       "   0.7796\n",
       "   0.7731\n",
       "   0.7735\n",
       "   0.7818\n",
       "   0.7762\n",
       "   0.7928\n",
       "   0.7845\n",
       "   0.7859\n",
       "   0.8102\n",
       "   0.8323\n",
       "   0.7493\n",
       "   0.8118\n",
       "   0.7668\n",
       "   0.7764\n",
       "   0.7617\n",
       "   0.7488\n",
       "   0.8025\n",
       "   0.7985\n",
       "   0.8886\n",
       "   0.7660\n",
       "   0.7420\n",
       "   0.7482\n",
       "   0.7701\n",
       "   0.7870\n",
       "   0.7800\n",
       "   0.7763\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.0835\n",
       "  -0.1353\n",
       "   0.0508\n",
       "  -0.0046\n",
       "  -0.0073\n",
       "  -0.1208\n",
       "  -0.0533\n",
       "  -0.0133\n",
       "  -0.1347\n",
       "   0.0751\n",
       "   0.0019\n",
       "  -0.1302\n",
       "  -0.0444\n",
       "   0.0150\n",
       "   0.0546\n",
       "  -0.0390\n",
       "  -0.0631\n",
       "   0.0137\n",
       "  -0.0194\n",
       "  -0.0554\n",
       "  -0.0082\n",
       "  -0.0499\n",
       "   0.0153\n",
       "  -0.0352\n",
       "  -0.0561\n",
       "  -0.0411\n",
       "  -0.1316\n",
       "  -0.0746\n",
       "  -0.0536\n",
       "   0.0156\n",
       "  -0.1528\n",
       "  -0.0579\n",
       "  -0.0248\n",
       "   0.0033\n",
       "  -0.0236\n",
       "  -0.0465\n",
       "   0.0498\n",
       "  -0.0925\n",
       "   0.0057\n",
       "  -0.0947\n",
       "   0.0474\n",
       "   0.0534\n",
       "  -0.0112\n",
       "  -0.0387\n",
       "  -0.0096\n",
       "  -0.0341\n",
       "  -0.0100\n",
       "  -0.0002\n",
       "  -0.1351\n",
       "  -0.0100\n",
       "  -0.0506\n",
       "  -0.0364\n",
       "  -0.0969\n",
       "   0.0303\n",
       "  -0.0711\n",
       "   0.0309\n",
       "  -0.0377\n",
       "  -0.0321\n",
       "   0.0068\n",
       "  -0.1388\n",
       "  -0.0129\n",
       "  -0.0685\n",
       "  -0.0120\n",
       "   0.0168\n",
       "   0.0263\n",
       "   0.0090\n",
       "  -0.0302\n",
       "   0.0074\n",
       "  -0.0285\n",
       "  -0.1348\n",
       "  -0.0280\n",
       "  -0.0371\n",
       "  -0.0460\n",
       "  -0.0155\n",
       "  -0.0210\n",
       "  -0.0179\n",
       "  -0.1094\n",
       "  -0.1014\n",
       "   0.0322\n",
       "   0.0098\n",
       "  -0.0376\n",
       "  -0.0303\n",
       "  -0.0563\n",
       "   0.0243\n",
       "  -0.0327\n",
       "  -0.0667\n",
       "   0.0369\n",
       "  -0.0220\n",
       "  -0.0887\n",
       "  -0.0367\n",
       "  -0.0608\n",
       "  -0.0330\n",
       "  -0.0257\n",
       "  -0.1112\n",
       "   0.0181\n",
       "   0.0130\n",
       "   0.0367\n",
       "   0.0318\n",
       "  -0.0113\n",
       "   0.1477\n",
       "  -0.0339\n",
       "  -0.0654\n",
       "  -0.0874\n",
       "  -0.0805\n",
       "   0.0143\n",
       "   0.0194\n",
       "   0.0299\n",
       "  -0.0240\n",
       "  -0.0477\n",
       "   0.0198\n",
       "   0.0677\n",
       "  -0.0595\n",
       "  -0.0372\n",
       "  -0.0300\n",
       "  -0.0087\n",
       "  -0.0251\n",
       "  -0.0413\n",
       "  -0.0997\n",
       "  -0.0076\n",
       "   0.0076\n",
       "  -0.0631\n",
       "  -0.0650\n",
       "  -0.0017\n",
       "  -0.1006\n",
       "  -0.0649\n",
       "  -0.0655\n",
       "  -0.0474\n",
       "  -0.0130\n",
       "  -0.0202\n",
       "  -0.0556\n",
       "  -0.0924\n",
       "  -0.0210\n",
       "   0.0321\n",
       "  -0.0193\n",
       "  -0.0171\n",
       "  -0.1279\n",
       "   0.0318\n",
       "  -0.1134\n",
       "   0.0228\n",
       "  -0.0444\n",
       "  -0.0509\n",
       "   0.0607\n",
       "  -0.0029\n",
       "  -0.0350\n",
       "   0.0179\n",
       "  -0.0434\n",
       "   0.0196\n",
       "  -0.0171\n",
       "  -0.0638\n",
       "  -0.0134\n",
       "  -0.0144\n",
       "  -0.0126\n",
       "  -0.0220\n",
       "   0.0258\n",
       "  -0.1450\n",
       "   0.0287\n",
       "  -0.0317\n",
       "  -0.0381\n",
       "   0.0228\n",
       "   0.0012\n",
       "   0.0166\n",
       "  -0.0349\n",
       "  -0.0229\n",
       "  -0.0853\n",
       "   0.0150\n",
       "  -0.0600\n",
       "   0.0193\n",
       "  -0.0925\n",
       "  -0.0650\n",
       "  -0.0941\n",
       "  -0.0196\n",
       "  -0.1313\n",
       "   0.0169\n",
       "  -0.0426\n",
       "  -0.0103\n",
       "  -0.0135\n",
       "  -0.1184\n",
       "  -0.1075\n",
       "  -0.0075\n",
       "  -0.0194\n",
       "   0.0065\n",
       "   0.0624\n",
       "  -0.0030\n",
       "  -0.0325\n",
       "   0.0707\n",
       "   0.0330\n",
       "   0.0172\n",
       "  -0.0260\n",
       "  -0.0037\n",
       "  -0.0605\n",
       "  -0.0505\n",
       "   0.0112\n",
       "  -0.0135\n",
       "  -0.0146\n",
       "  -0.0576\n",
       "  -0.0348\n",
       "  -0.0192\n",
       "   0.0180\n",
       "  -0.0390\n",
       "  -0.0478\n",
       "  -0.0337\n",
       "   0.0083\n",
       "   0.0115\n",
       "  -0.0400\n",
       "  -0.0558\n",
       "  -0.0341\n",
       "  -0.0328\n",
       "  -0.0270\n",
       "  -0.0696\n",
       "   0.0214\n",
       "  -0.0884\n",
       "  -0.0071\n",
       "  -0.0314\n",
       "   0.0210\n",
       "   0.0260\n",
       "   0.0315\n",
       "  -0.1405\n",
       "  -0.0279\n",
       "   0.0153\n",
       "  -0.0560\n",
       "  -0.1158\n",
       "  -0.0774\n",
       "  -0.0101\n",
       "  -0.0072\n",
       "   0.0549\n",
       "  -0.0610\n",
       "  -0.0586\n",
       "  -0.0005\n",
       "  -0.0107\n",
       "  -0.0305\n",
       "  -0.0537\n",
       "  -0.0662\n",
       "  -0.0408\n",
       "  -0.1127\n",
       "  -0.0182\n",
       "  -0.0413\n",
       "  -0.0008\n",
       "  -0.0134\n",
       "  -0.0056\n",
       "   0.0144\n",
       "  -0.0137\n",
       "  -0.0937\n",
       "  -0.0057\n",
       "  -0.0473\n",
       "  -0.0051\n",
       "   0.0089\n",
       "  -0.0192\n",
       "   0.0001\n",
       "  -0.0276\n",
       "   0.0060\n",
       "  -0.0186\n",
       "  -0.1255\n",
       "  -0.0755\n",
       "   0.0208\n",
       "  -0.0050\n",
       "   0.0620\n",
       "  -0.0082\n",
       "  -0.0487\n",
       "  -0.0562\n",
       "  -0.0091\n",
       "  -0.0188\n",
       "  -0.1393\n",
       "  -0.0130\n",
       "  -0.1289\n",
       "   0.0120\n",
       "   0.0281\n",
       "  -0.0508\n",
       "  -0.0014\n",
       "  -0.0409\n",
       "  -0.0457\n",
       "  -0.0377\n",
       "  -0.0652\n",
       "  -0.0265\n",
       "   0.0147\n",
       "  -0.0338\n",
       "  -0.0048\n",
       "   0.0245\n",
       "  -0.0120\n",
       "  -0.0479\n",
       "   0.0222\n",
       "  -0.0351\n",
       "  -0.0589\n",
       "  -0.0602\n",
       "  -0.0156\n",
       "  -0.0644\n",
       "   0.0388\n",
       "  -0.1284\n",
       "  -0.0542\n",
       "  -0.0313\n",
       "  -0.0102\n",
       "   0.0452\n",
       "  -0.0368\n",
       "  -0.0027\n",
       "   0.0159\n",
       "  -0.0971\n",
       "  -0.0520\n",
       "  -0.0373\n",
       "  -0.0313\n",
       "  -0.0060\n",
       "  -0.0629\n",
       "  -0.0469\n",
       "  -0.0676\n",
       "  -0.0196\n",
       "  -0.0554\n",
       "  -0.0313\n",
       "  -0.0743\n",
       "   0.0565\n",
       "   0.0173\n",
       "  -0.0628\n",
       "   0.0058\n",
       "  -0.0397\n",
       "   0.0105\n",
       "  -0.0402\n",
       "  -0.0923\n",
       "  -0.0026\n",
       "  -0.0214\n",
       "  -0.0757\n",
       "   0.0144\n",
       "  -0.0082\n",
       "  -0.0067\n",
       "  -0.1052\n",
       "   0.0419\n",
       "  -0.0731\n",
       "  -0.0626\n",
       "  -0.0380\n",
       "   0.0239\n",
       "   0.0590\n",
       "  -0.0044\n",
       "   0.0407\n",
       "   0.0086\n",
       "   0.0754\n",
       "   0.0143\n",
       "  -0.0245\n",
       "  -0.0512\n",
       "  -0.0354\n",
       "   0.0079\n",
       "  -0.1210\n",
       "  -0.0332\n",
       "  -0.0117\n",
       "   0.0177\n",
       "  -0.0584\n",
       "  -0.0772\n",
       "  -0.0647\n",
       "  -0.1195\n",
       "  -0.0192\n",
       "   0.0244\n",
       "  -0.0167\n",
       "  -0.0658\n",
       "  -0.0413\n",
       "  -0.0150\n",
       "  -0.0820\n",
       "  -0.0268\n",
       "   0.0107\n",
       "  -0.1001\n",
       "   0.0515\n",
       "  -0.0027\n",
       "   0.0067\n",
       "   0.0629\n",
       "  -0.0168\n",
       "  -0.0645\n",
       "  -0.0510\n",
       "  -0.0579\n",
       "  -0.0302\n",
       "   0.0064\n",
       "   0.0401\n",
       "  -0.0069\n",
       "  -0.0057\n",
       "  -0.0638\n",
       "  -0.0555\n",
       "  -0.0231\n",
       "  -0.0493\n",
       "  -0.1067\n",
       "   0.0494\n",
       "  -0.0341\n",
       "  -0.0166\n",
       "  -0.0748\n",
       "  -0.0254\n",
       "   0.0224\n",
       "   0.0472\n",
       "   0.0047\n",
       "  -0.0363\n",
       "  -0.0756\n",
       "  -0.0362\n",
       "   0.0322\n",
       "   0.0408\n",
       "   0.0203\n",
       "  -0.0130\n",
       "   0.0512\n",
       "  -0.0472\n",
       "   0.0278\n",
       "   0.0328\n",
       "  -0.0089\n",
       "  -0.0630\n",
       "  -0.0337\n",
       "  -0.0734\n",
       "  -0.0073\n",
       "  -0.0489\n",
       "  -0.0920\n",
       "  -0.0522\n",
       "  -0.0355\n",
       "  -0.0629\n",
       "  -0.0532\n",
       "  -0.0243\n",
       "  -0.0636\n",
       "  -0.0621\n",
       "   0.0206\n",
       "  -0.0368\n",
       "  -0.0083\n",
       "  -0.0779\n",
       "   0.0004\n",
       "   0.0893\n",
       "   0.0473\n",
       "  -0.0221\n",
       "  -0.0139\n",
       "  -0.0168\n",
       "  -0.0354\n",
       "  -0.0152\n",
       "  -0.0126\n",
       "  -0.0487\n",
       "   0.0074\n",
       "   0.0495\n",
       "   0.0247\n",
       "  -0.0671\n",
       "  -0.0038\n",
       "  -0.0526\n",
       "  -0.0767\n",
       "  -0.1109\n",
       "   0.0432\n",
       "  -0.0949\n",
       "  -0.0628\n",
       "   0.0045\n",
       "  -0.0395\n",
       "  -0.0038\n",
       "  -0.0416\n",
       "  -0.0475\n",
       "  -0.0996\n",
       "  -0.0530\n",
       "  -0.0587\n",
       "   0.0051\n",
       "  -0.0396\n",
       "  -0.0538\n",
       "  -0.0780\n",
       "  -0.0285\n",
       "   0.0360\n",
       "  -0.0577\n",
       "   0.0079\n",
       "   0.0109\n",
       "  -0.0739\n",
       "   0.0498\n",
       "  -0.0566\n",
       "  -0.0452\n",
       "  -0.0108\n",
       "  -0.0342\n",
       "   0.0250\n",
       "   0.0367\n",
       "   0.0012\n",
       "  -0.0141\n",
       "  -0.0196\n",
       "  -0.0588\n",
       "   0.0249\n",
       "  -0.0122\n",
       "   0.0290\n",
       "  -0.0256\n",
       "  -0.1225\n",
       "  -0.0749\n",
       "  -0.0649\n",
       "  -0.0664\n",
       "  -0.0304\n",
       "  -0.0356\n",
       "  -0.0112\n",
       "  -0.0405\n",
       "   0.0565\n",
       "  -0.0551\n",
       "   0.0430\n",
       "   0.0177\n",
       "  -0.0607\n",
       "   0.0468\n",
       "  -0.0710\n",
       "   0.0567\n",
       "  -0.1184\n",
       "   0.0888\n",
       "   0.0090\n",
       "   0.0128\n",
       "  -0.0130\n",
       "  -0.0111\n",
       "  -0.0184\n",
       "  -0.0351\n",
       "  -0.0148\n",
       "  -0.0098\n",
       "   0.0215\n",
       "  -0.0312\n",
       "   0.0057\n",
       "   0.0277\n",
       "   0.0447\n",
       "   0.0951\n",
       "   0.0140\n",
       "  -0.0122\n",
       "  -0.0113\n",
       "  -0.1267\n",
       "   0.0068\n",
       "  -0.1246\n",
       "  -0.1239\n",
       "  -0.0589\n",
       "  -0.0389\n",
       "  -0.0244\n",
       "  -0.0193\n",
       "  -0.0702\n",
       "  -0.1372\n",
       "  -0.0787\n",
       "   0.0217\n",
       "  -0.0419\n",
       "  -0.0267\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -6.9538e-03 -1.5417e-02 -2.0398e-02\n",
       "    1.0394e-02  3.3343e-02  5.1667e-03\n",
       "   -6.8423e-03  1.2846e-02 -3.8525e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    4.0658e-03  3.1052e-02 -1.0118e-02\n",
       "    2.2269e-02  1.5843e-02 -7.3932e-03\n",
       "   -1.6524e-02  5.9130e-03 -9.2521e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -7.3133e-03 -6.8861e-03 -2.0348e-03\n",
       "    1.3904e-02  1.5155e-02 -3.9110e-03\n",
       "   -5.7208e-03 -7.8487e-04 -1.7022e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,509,.,.) = \n",
       "    3.1123e-02 -2.3575e-02 -1.4002e-02\n",
       "   -2.2821e-03 -4.5719e-02  1.3511e-02\n",
       "    2.9874e-02  7.2661e-03 -1.3506e-03\n",
       "  \n",
       "  ( 0 ,510,.,.) = \n",
       "    2.1296e-02  1.8106e-02  6.9725e-04\n",
       "    1.3123e-02  2.0995e-02 -4.0373e-02\n",
       "    4.2342e-03 -2.0407e-02 -1.3740e-02\n",
       "  \n",
       "  ( 0 ,511,.,.) = \n",
       "    7.2172e-03  1.4894e-02 -1.0343e-02\n",
       "    2.0367e-02  2.5294e-03 -1.2503e-02\n",
       "   -5.5481e-03  3.0225e-02  1.7871e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    4.8742e-03 -4.1583e-02  3.3240e-02\n",
       "   -1.0519e-02 -2.5164e-02  4.3439e-03\n",
       "    2.9554e-03 -8.8029e-03 -1.9127e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -5.6339e-03  1.4240e-02 -7.3750e-03\n",
       "   -1.7462e-02  2.6609e-03  3.3506e-03\n",
       "    6.2613e-03  8.0069e-03 -6.8740e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "    2.0613e-02 -1.3270e-02 -1.0915e-02\n",
       "    5.1804e-03 -6.5781e-04 -1.8181e-03\n",
       "   -7.9023e-03 -6.9920e-03  2.6362e-02\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,509,.,.) = \n",
       "   -6.1596e-03  2.0246e-02  1.2382e-02\n",
       "    1.5802e-02 -2.2843e-04  9.9106e-03\n",
       "    9.0350e-03  3.9009e-03  2.4561e-02\n",
       "  \n",
       "  ( 1 ,510,.,.) = \n",
       "    3.1671e-02 -1.2657e-02 -2.2097e-02\n",
       "   -4.5150e-03 -2.1936e-02  1.4419e-02\n",
       "   -3.2379e-03 -2.4504e-02 -7.1135e-04\n",
       "  \n",
       "  ( 1 ,511,.,.) = \n",
       "    1.7959e-02 -4.3515e-02 -1.3244e-02\n",
       "   -5.6630e-03 -4.6560e-03  1.3633e-02\n",
       "    2.2849e-02 -3.0770e-02 -6.1742e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    1.9051e-03 -3.6111e-02 -3.6231e-02\n",
       "    4.6613e-03 -1.9519e-02 -4.1727e-02\n",
       "   -1.8011e-02 -2.7147e-02 -1.9641e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "   -2.4562e-02  1.5360e-02  5.8636e-03\n",
       "   -3.2433e-02  9.8552e-03 -3.5192e-02\n",
       "   -1.9140e-02 -4.7970e-03 -2.4431e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "    2.3227e-05  8.8038e-03 -1.1939e-03\n",
       "   -1.2458e-02 -2.3145e-02  1.6964e-02\n",
       "   -1.8783e-02 -9.6412e-03  2.3703e-03\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,509,.,.) = \n",
       "    3.3139e-02  1.3817e-02 -8.8585e-03\n",
       "    9.2264e-03  1.1160e-02 -8.9036e-03\n",
       "   -2.7039e-03  9.6839e-04 -6.6392e-05\n",
       "  \n",
       "  ( 2 ,510,.,.) = \n",
       "   -1.4779e-02 -1.9948e-02 -1.8777e-02\n",
       "   -2.6529e-03 -5.2279e-03 -1.7414e-02\n",
       "   -2.2996e-02 -1.4424e-02  1.9011e-02\n",
       "  \n",
       "  ( 2 ,511,.,.) = \n",
       "    4.0280e-03 -3.0822e-02 -1.6872e-02\n",
       "   -1.9486e-02 -2.7105e-02 -3.0332e-02\n",
       "   -3.8619e-02 -2.7803e-02 -4.8515e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "    2.3582e-02  2.5358e-02  2.4092e-02\n",
       "    1.3733e-02  3.5897e-03  1.6714e-03\n",
       "    2.8176e-04  1.7221e-02 -1.8275e-02\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "    3.7584e-02 -1.4705e-02 -2.5339e-03\n",
       "   -1.3286e-02  2.1344e-02 -2.4665e-02\n",
       "    1.0730e-02  2.6745e-02 -1.7935e-03\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "   -1.2895e-02 -7.1227e-03 -1.3873e-02\n",
       "    1.1314e-02  1.3492e-02  7.6375e-03\n",
       "    1.2781e-03 -1.6227e-03 -2.5874e-02\n",
       "      ... \n",
       "  \n",
       "  (509,509,.,.) = \n",
       "   -2.0151e-02 -1.3239e-02 -4.4184e-03\n",
       "    1.3196e-02  2.1353e-02 -7.0913e-03\n",
       "    1.7218e-03  9.5798e-03  5.2404e-04\n",
       "  \n",
       "  (509,510,.,.) = \n",
       "   -1.5147e-02  1.6418e-03 -1.2679e-02\n",
       "   -2.1330e-02  1.0968e-02 -8.5933e-03\n",
       "   -8.7988e-03  7.2404e-03  1.1084e-02\n",
       "  \n",
       "  (509,511,.,.) = \n",
       "    2.5850e-03  2.1471e-03  3.3358e-03\n",
       "   -2.8632e-02 -1.1545e-02  3.2041e-02\n",
       "    2.1080e-02 -1.1205e-03 -2.0392e-02\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "    1.8713e-02  2.0283e-02 -7.6902e-03\n",
       "    3.6320e-03  1.2324e-02  2.4901e-02\n",
       "   -2.3268e-02  1.1383e-02 -2.5639e-03\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "   -1.2089e-02  6.1173e-02 -1.6604e-02\n",
       "    1.1604e-02  2.3750e-02 -8.9505e-04\n",
       "    6.4413e-04 -2.7836e-03  1.6046e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "   -1.3089e-02 -5.8643e-03  1.5969e-02\n",
       "   -5.3814e-03 -5.2517e-03 -1.6620e-02\n",
       "   -9.4657e-03 -1.2518e-02  2.6367e-03\n",
       "      ... \n",
       "  \n",
       "  (510,509,.,.) = \n",
       "    8.9764e-03 -2.2554e-02 -7.7939e-03\n",
       "    7.7965e-04 -2.7327e-03  1.4127e-02\n",
       "    1.4205e-02 -7.7699e-03  5.2173e-03\n",
       "  \n",
       "  (510,510,.,.) = \n",
       "   -5.5441e-03  1.2476e-03  1.4003e-03\n",
       "   -3.4256e-03  2.3045e-02  1.1763e-04\n",
       "   -2.1701e-02 -4.5321e-03  4.8819e-03\n",
       "  \n",
       "  (510,511,.,.) = \n",
       "   -1.2985e-02  1.3770e-02 -1.1162e-02\n",
       "   -2.2048e-02 -2.3208e-02 -4.0167e-02\n",
       "   -2.5616e-02 -1.1849e-02 -5.9568e-03\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "    3.3652e-02  1.8999e-02  4.0791e-03\n",
       "    1.1252e-02 -1.6806e-02  7.1695e-03\n",
       "   -4.1144e-03 -2.3581e-02 -1.7103e-03\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "   -1.7713e-02  5.7138e-03 -8.9829e-03\n",
       "    8.5229e-03  2.9297e-04 -1.3813e-02\n",
       "    1.6755e-03 -6.4032e-03  8.5143e-03\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "   -1.5459e-02  2.0122e-02  4.7976e-03\n",
       "   -1.6954e-02 -4.8940e-04  4.1800e-03\n",
       "    2.0513e-02  2.5290e-02 -1.8468e-02\n",
       "      ... \n",
       "  \n",
       "  (511,509,.,.) = \n",
       "   -2.1090e-02 -1.7420e-03  2.3603e-02\n",
       "   -2.4827e-03 -3.1556e-03 -2.8054e-02\n",
       "    1.6128e-02  6.9620e-04  2.6950e-02\n",
       "  \n",
       "  (511,510,.,.) = \n",
       "   -6.9092e-03 -1.9631e-03  2.3028e-03\n",
       "    7.9888e-03 -3.5021e-02 -4.4462e-02\n",
       "    8.9237e-03 -9.2700e-03 -1.0843e-02\n",
       "  \n",
       "  (511,511,.,.) = \n",
       "   -1.4151e-02 -2.3076e-02  3.5237e-02\n",
       "   -1.6707e-02 -3.0783e-02  1.2599e-02\n",
       "   -8.8679e-03  1.1913e-02 -7.1835e-03\n",
       "  [torch.cuda.FloatTensor of size 512x512x3x3 (GPU 0)], Parameter containing:\n",
       "   0.5811\n",
       "   0.7653\n",
       "   0.7511\n",
       "   0.6245\n",
       "   0.6578\n",
       "   0.5830\n",
       "   0.4443\n",
       "   0.5709\n",
       "   0.6356\n",
       "   0.6676\n",
       "   0.7361\n",
       "   0.7367\n",
       "   0.5866\n",
       "   0.4832\n",
       "   0.5018\n",
       "   0.6077\n",
       "   0.7411\n",
       "   0.6820\n",
       "   0.7150\n",
       "   0.6692\n",
       "   0.6649\n",
       "   0.5933\n",
       "   0.5191\n",
       "   0.4752\n",
       "   0.4897\n",
       "   0.6869\n",
       "   0.5930\n",
       "   0.5175\n",
       "   0.9200\n",
       "   0.6252\n",
       "   0.5303\n",
       "   0.3465\n",
       "   0.3147\n",
       "   0.6042\n",
       "   0.8514\n",
       "   0.6216\n",
       "   0.4708\n",
       "   0.5662\n",
       "   0.7358\n",
       "   0.5314\n",
       "   0.7165\n",
       "   0.5792\n",
       "   0.7258\n",
       "   0.4745\n",
       "   0.7135\n",
       "   0.5522\n",
       "   0.3675\n",
       "   0.3324\n",
       "   0.5966\n",
       "   0.5378\n",
       "   0.3734\n",
       "   0.4294\n",
       "   0.5507\n",
       "   0.7354\n",
       "   0.8001\n",
       "   0.4661\n",
       "   0.5291\n",
       "   0.7446\n",
       "   0.7090\n",
       "   0.8405\n",
       "   0.7229\n",
       "   0.6033\n",
       "   0.5924\n",
       "   0.4659\n",
       "   0.5029\n",
       "   0.5229\n",
       "   0.5924\n",
       "   0.5802\n",
       "   0.4684\n",
       "   0.4171\n",
       "   0.5850\n",
       "   0.4244\n",
       "   0.5006\n",
       "   0.7877\n",
       "   0.3436\n",
       "   0.3823\n",
       "   0.8091\n",
       "   0.8165\n",
       "   0.5621\n",
       "   0.4258\n",
       "   0.6607\n",
       "   0.7326\n",
       "   0.8829\n",
       "   0.5752\n",
       "   0.3258\n",
       "   0.6351\n",
       "   0.5246\n",
       "   0.4870\n",
       "   0.6465\n",
       "   0.6471\n",
       "   0.7534\n",
       "   0.7054\n",
       "   0.9344\n",
       "   0.7064\n",
       "   0.5868\n",
       "   0.5599\n",
       "   0.8961\n",
       "   0.7090\n",
       "   0.6707\n",
       "   0.6112\n",
       "   0.7718\n",
       "   0.4587\n",
       "   0.4930\n",
       "   0.3637\n",
       "   1.0112\n",
       "   0.4635\n",
       "   0.6861\n",
       "   0.4332\n",
       "   0.4981\n",
       "   0.5449\n",
       "   0.5154\n",
       "   0.6315\n",
       "   0.5546\n",
       "   0.6138\n",
       "   0.6075\n",
       "   0.6157\n",
       "   0.4897\n",
       "   0.5409\n",
       "   0.6422\n",
       "   0.1882\n",
       "   0.6126\n",
       "   0.8253\n",
       "   0.6627\n",
       "   0.4918\n",
       "   0.4571\n",
       "   0.9991\n",
       "   0.6639\n",
       "   0.3146\n",
       "   0.6722\n",
       "   0.5145\n",
       "   0.5530\n",
       "   0.7432\n",
       "   0.6021\n",
       "   0.6534\n",
       "   0.7084\n",
       "   0.7488\n",
       "   0.6449\n",
       "   0.7382\n",
       "   0.5446\n",
       "   0.7058\n",
       "   0.4456\n",
       "   0.7097\n",
       "   0.5902\n",
       "   0.8176\n",
       "   0.4727\n",
       "   0.4059\n",
       "   0.4607\n",
       "   0.2922\n",
       "   0.5187\n",
       "   0.6033\n",
       "   0.4650\n",
       "   0.8811\n",
       "   0.4656\n",
       "   0.5325\n",
       "   0.5784\n",
       "   0.5678\n",
       "   0.6173\n",
       "   0.5037\n",
       "   0.5311\n",
       "   0.5268\n",
       "   0.7042\n",
       "   0.6926\n",
       "   0.7339\n",
       "   0.5061\n",
       "   0.3996\n",
       "   0.7155\n",
       "   0.9345\n",
       "   0.8359\n",
       "   0.7452\n",
       "   0.5342\n",
       "   0.8125\n",
       "   0.8127\n",
       "   0.3495\n",
       "   0.4651\n",
       "   0.5947\n",
       "   0.5256\n",
       "   0.7801\n",
       "   0.4981\n",
       "   0.6253\n",
       "   0.7220\n",
       "   0.5404\n",
       "   0.4827\n",
       "   0.5265\n",
       "   0.5295\n",
       "   0.6673\n",
       "   0.6265\n",
       "   0.5061\n",
       "   0.5426\n",
       "   0.4975\n",
       "   0.9817\n",
       "   0.4243\n",
       "   0.3767\n",
       "   0.7662\n",
       "   0.7255\n",
       "   0.5202\n",
       "   0.4165\n",
       "   0.5149\n",
       "   0.4366\n",
       "   0.5367\n",
       "   0.5331\n",
       "   0.3552\n",
       "   0.8295\n",
       "   0.6479\n",
       "   0.7309\n",
       "   0.5107\n",
       "   0.7405\n",
       "   0.5017\n",
       "   0.4227\n",
       "   0.4561\n",
       "   0.7204\n",
       "   0.4590\n",
       "   0.6651\n",
       "   0.4898\n",
       "   0.8792\n",
       "   0.5363\n",
       "   0.7600\n",
       "   0.7071\n",
       "   0.6169\n",
       "   0.5255\n",
       "   0.4404\n",
       "   0.4952\n",
       "   0.7995\n",
       "   0.4398\n",
       "   0.5889\n",
       "   0.6338\n",
       "   0.6263\n",
       "   0.5000\n",
       "   0.7991\n",
       "   0.4444\n",
       "   0.5019\n",
       "   0.3698\n",
       "   0.5165\n",
       "   0.6101\n",
       "   0.5038\n",
       "   0.7350\n",
       "   0.5607\n",
       "   0.8651\n",
       "   0.4933\n",
       "   0.5901\n",
       "   0.5019\n",
       "   0.4835\n",
       "   0.6745\n",
       "   0.6988\n",
       "   0.7256\n",
       "   0.5674\n",
       "   0.6144\n",
       "   0.7274\n",
       "   0.6928\n",
       "   0.6171\n",
       "   0.4750\n",
       "   0.5232\n",
       "   0.7480\n",
       "   0.4325\n",
       "   0.4680\n",
       "   0.5096\n",
       "   0.7095\n",
       "   0.9906\n",
       "   0.5481\n",
       "   0.5882\n",
       "   0.5640\n",
       "   0.6312\n",
       "   0.4913\n",
       "   0.6126\n",
       "   0.5291\n",
       "   0.7395\n",
       "   0.3988\n",
       "   0.6594\n",
       "   0.5405\n",
       "   0.5786\n",
       "   0.7791\n",
       "   0.6191\n",
       "   0.4386\n",
       "   0.3731\n",
       "   0.5525\n",
       "   0.6503\n",
       "   0.4700\n",
       "   0.4746\n",
       "   0.6030\n",
       "   0.7546\n",
       "   0.7118\n",
       "   0.5685\n",
       "   0.6595\n",
       "   0.9207\n",
       "   0.6822\n",
       "   0.5824\n",
       "   0.9591\n",
       "   0.6286\n",
       "   0.5615\n",
       "   0.4799\n",
       "   0.5326\n",
       "   0.8598\n",
       "   0.4644\n",
       "   0.5688\n",
       "   0.6927\n",
       "   0.7334\n",
       "   0.5098\n",
       "   0.6184\n",
       "   0.7618\n",
       "   0.5099\n",
       "   0.4653\n",
       "   0.5995\n",
       "   0.4106\n",
       "   0.9541\n",
       "   0.5108\n",
       "   0.6205\n",
       "   0.9783\n",
       "   0.6225\n",
       "   0.6620\n",
       "   0.7594\n",
       "   0.5786\n",
       "   0.4896\n",
       "   0.5048\n",
       "   0.5238\n",
       "   0.5956\n",
       "   0.6148\n",
       "   0.3142\n",
       "   0.5120\n",
       "   0.5763\n",
       "   0.7480\n",
       "   0.7486\n",
       "   0.5477\n",
       "   0.7579\n",
       "   0.7493\n",
       "   0.7078\n",
       "   0.7570\n",
       "   0.5115\n",
       "   0.5681\n",
       "   0.7169\n",
       "   0.4828\n",
       "   0.3406\n",
       "   0.7405\n",
       "   0.7191\n",
       "   0.3440\n",
       "   0.5872\n",
       "   0.6267\n",
       "   0.6609\n",
       "   0.5661\n",
       "   0.4529\n",
       "   0.3921\n",
       "   0.4937\n",
       "   0.6318\n",
       "   0.6089\n",
       "   0.6679\n",
       "   0.5992\n",
       "   0.7146\n",
       "   0.7491\n",
       "   0.6277\n",
       "   0.9578\n",
       "   0.6371\n",
       "   0.7305\n",
       "   0.6053\n",
       "   0.5061\n",
       "   0.7192\n",
       "   0.4769\n",
       "   0.4721\n",
       "   0.4264\n",
       "   0.3707\n",
       "   0.5896\n",
       "   0.3726\n",
       "   0.6284\n",
       "   0.4903\n",
       "   0.5769\n",
       "   0.4904\n",
       "   0.1555\n",
       "   0.4583\n",
       "   0.5818\n",
       "   0.7427\n",
       "   0.8758\n",
       "   0.4116\n",
       "   0.7275\n",
       "   0.4657\n",
       "   0.5470\n",
       "   0.6537\n",
       "   0.6378\n",
       "   0.7310\n",
       "   0.4030\n",
       "   0.3184\n",
       "   0.5036\n",
       "   0.5932\n",
       "   0.6186\n",
       "   0.8524\n",
       "   0.7268\n",
       "   0.7806\n",
       "   0.9385\n",
       "   0.5756\n",
       "   0.4775\n",
       "   0.4110\n",
       "   0.8071\n",
       "   0.5904\n",
       "   0.5068\n",
       "   0.4080\n",
       "   0.4549\n",
       "   0.4460\n",
       "   0.8065\n",
       "   0.4787\n",
       "   0.6170\n",
       "   0.5416\n",
       "   0.6555\n",
       "   0.7639\n",
       "   0.8774\n",
       "   0.5916\n",
       "   0.5415\n",
       "   0.7211\n",
       "   0.5447\n",
       "   0.8058\n",
       "   0.8443\n",
       "   0.7094\n",
       "   0.4756\n",
       "   0.4613\n",
       "   0.7279\n",
       "   0.5271\n",
       "   0.7471\n",
       "   0.7036\n",
       "   0.4368\n",
       "   0.5742\n",
       "   0.4906\n",
       "   0.6474\n",
       "   0.5359\n",
       "   0.4786\n",
       "   0.7871\n",
       "   0.7282\n",
       "   0.5418\n",
       "   0.3395\n",
       "   0.7320\n",
       "   0.6705\n",
       "   0.4783\n",
       "   0.7151\n",
       "   0.5668\n",
       "   0.7947\n",
       "   0.3366\n",
       "   0.5681\n",
       "   0.7928\n",
       "   0.8832\n",
       "   0.4758\n",
       "   0.5207\n",
       "   0.7325\n",
       "   0.7527\n",
       "   0.3317\n",
       "   0.3327\n",
       "   0.5911\n",
       "   0.7679\n",
       "   0.3751\n",
       "   0.4534\n",
       "   0.7949\n",
       "   0.4640\n",
       "   0.7446\n",
       "   0.4658\n",
       "   0.8619\n",
       "   0.6981\n",
       "   0.4373\n",
       "   0.5664\n",
       "   0.5327\n",
       "   0.6639\n",
       "   0.6222\n",
       "   0.6517\n",
       "   0.4711\n",
       "   0.7162\n",
       "   0.3414\n",
       "   0.6225\n",
       "   0.4013\n",
       "   0.6463\n",
       "   0.8403\n",
       "   0.4697\n",
       "   0.4987\n",
       "   0.4466\n",
       "   0.4725\n",
       "   0.5867\n",
       "   0.6510\n",
       "   0.5813\n",
       "   0.6714\n",
       "   0.6106\n",
       "   0.4941\n",
       "   0.5324\n",
       "   0.6441\n",
       "   0.7270\n",
       "   0.4949\n",
       "   0.3788\n",
       "   0.5125\n",
       "   0.5467\n",
       "   0.6098\n",
       "   0.7584\n",
       "   0.5317\n",
       "   0.5112\n",
       "   0.7791\n",
       "   0.7160\n",
       "   0.9940\n",
       "   0.6613\n",
       "   0.5387\n",
       "   0.4595\n",
       "   0.6265\n",
       "   0.5940\n",
       "   0.5870\n",
       "   0.4720\n",
       "   0.7282\n",
       "   0.9685\n",
       "   0.5157\n",
       "   0.4945\n",
       "   0.7836\n",
       "   0.4222\n",
       "   0.4220\n",
       "   0.7500\n",
       "   0.6089\n",
       "   0.7829\n",
       "   0.5558\n",
       "   0.3869\n",
       "   0.7434\n",
       "   0.6524\n",
       "   0.3437\n",
       "   0.6254\n",
       "   0.4778\n",
       "   0.6200\n",
       "   0.6618\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.1838\n",
       "  -0.0783\n",
       "  -0.0873\n",
       "  -0.1141\n",
       "  -0.1538\n",
       "  -0.1429\n",
       "  -0.1314\n",
       "  -0.1306\n",
       "  -0.1450\n",
       "  -0.1745\n",
       "  -0.1596\n",
       "  -0.0261\n",
       "   0.0769\n",
       "  -0.1578\n",
       "  -0.1754\n",
       "  -0.1866\n",
       "  -0.1301\n",
       "  -0.1544\n",
       "  -0.1387\n",
       "  -0.1763\n",
       "  -0.1307\n",
       "  -0.1407\n",
       "  -0.1205\n",
       "  -0.1661\n",
       "  -0.1974\n",
       "  -0.1566\n",
       "  -0.2107\n",
       "  -0.1754\n",
       "  -0.1579\n",
       "  -0.1767\n",
       "  -0.1543\n",
       "  -0.1632\n",
       "  -0.1931\n",
       "  -0.1615\n",
       "  -0.0935\n",
       "  -0.1861\n",
       "  -0.1399\n",
       "  -0.1929\n",
       "  -0.1835\n",
       "  -0.1420\n",
       "  -0.0947\n",
       "  -0.1558\n",
       "  -0.1125\n",
       "  -0.1598\n",
       "   0.0313\n",
       "  -0.1248\n",
       "  -0.1696\n",
       "  -0.1394\n",
       "  -0.1442\n",
       "  -0.1754\n",
       "  -0.1893\n",
       "  -0.1636\n",
       "  -0.1418\n",
       "  -0.1605\n",
       "  -0.1112\n",
       "  -0.1489\n",
       "  -0.1394\n",
       "  -0.1382\n",
       "  -0.1596\n",
       "  -0.1573\n",
       "  -0.1018\n",
       "  -0.1191\n",
       "  -0.1438\n",
       "  -0.1338\n",
       "  -0.1739\n",
       "  -0.1658\n",
       "  -0.3231\n",
       "  -0.1453\n",
       "  -0.1294\n",
       "  -0.1517\n",
       "  -0.1336\n",
       "  -0.1429\n",
       "  -0.1783\n",
       "   0.0203\n",
       "  -0.1645\n",
       "  -0.1602\n",
       "  -0.1727\n",
       "   0.1611\n",
       "  -0.2408\n",
       "  -0.1448\n",
       "  -0.1618\n",
       "  -0.0834\n",
       "  -0.0167\n",
       "  -0.2016\n",
       "  -0.1907\n",
       "  -0.1925\n",
       "  -0.1590\n",
       "  -0.1452\n",
       "  -0.1012\n",
       "  -0.0446\n",
       "  -0.1343\n",
       "  -0.1619\n",
       "  -0.2359\n",
       "   0.0447\n",
       "  -0.0770\n",
       "  -0.1809\n",
       "  -0.1793\n",
       "  -0.1063\n",
       "  -0.1685\n",
       "   0.0074\n",
       "  -0.0950\n",
       "  -0.1708\n",
       "  -0.1636\n",
       "  -0.1686\n",
       "  -0.1642\n",
       "  -0.1411\n",
       "  -0.0444\n",
       "  -0.1489\n",
       "  -0.1518\n",
       "  -0.1605\n",
       "  -0.1494\n",
       "  -0.1001\n",
       "  -0.1362\n",
       "  -0.1591\n",
       "  -0.1435\n",
       "  -0.2496\n",
       "  -0.1289\n",
       "  -0.1431\n",
       "  -0.0822\n",
       "  -0.1667\n",
       "  -0.1692\n",
       "  -0.1892\n",
       "  -0.1587\n",
       "  -0.2753\n",
       "  -0.1955\n",
       "  -0.1884\n",
       "  -0.1645\n",
       "  -0.1544\n",
       "  -0.1143\n",
       "  -0.1855\n",
       "  -0.1402\n",
       "  -0.0753\n",
       "  -0.1614\n",
       "  -0.1409\n",
       "   0.0642\n",
       "  -0.1277\n",
       "  -0.1493\n",
       "  -0.1599\n",
       "  -0.1540\n",
       "  -0.1429\n",
       "  -0.1651\n",
       "  -0.1438\n",
       "  -0.1414\n",
       "   0.0777\n",
       "  -0.2012\n",
       "  -0.1638\n",
       "  -0.2005\n",
       "  -0.1932\n",
       "  -0.1440\n",
       "  -0.1622\n",
       "  -0.1516\n",
       "  -0.2389\n",
       "  -0.1296\n",
       "  -0.1988\n",
       "  -0.1939\n",
       "  -0.1525\n",
       "  -0.1472\n",
       "  -0.1794\n",
       "  -0.1491\n",
       "  -0.1530\n",
       "  -0.1801\n",
       "  -0.0903\n",
       "  -0.1479\n",
       "  -0.1544\n",
       "  -0.1465\n",
       "   0.0039\n",
       "  -0.2056\n",
       "  -0.1931\n",
       "  -0.2680\n",
       "  -0.1477\n",
       "  -0.0360\n",
       "   0.0064\n",
       "  -0.1744\n",
       "  -0.1481\n",
       "  -0.1527\n",
       "  -0.2114\n",
       "  -0.0945\n",
       "  -0.1293\n",
       "  -0.1494\n",
       "  -0.1021\n",
       "  -0.1461\n",
       "  -0.1158\n",
       "  -0.1470\n",
       "  -0.2365\n",
       "  -0.0845\n",
       "  -0.1743\n",
       "  -0.2496\n",
       "  -0.1937\n",
       "  -0.1719\n",
       "  -0.1569\n",
       "  -0.1404\n",
       "  -0.1722\n",
       "  -0.1508\n",
       "  -0.0376\n",
       "  -0.1885\n",
       "  -0.1864\n",
       "  -0.1985\n",
       "  -0.2015\n",
       "  -0.1967\n",
       "  -0.1901\n",
       "  -0.1847\n",
       "  -0.2061\n",
       "  -0.1651\n",
       "  -0.0067\n",
       "  -0.1837\n",
       "  -0.1075\n",
       "  -0.1298\n",
       "  -0.1487\n",
       "  -0.1705\n",
       "  -0.1782\n",
       "  -0.1521\n",
       "  -0.1598\n",
       "  -0.1871\n",
       "  -0.1607\n",
       "  -0.1387\n",
       "  -0.1978\n",
       "  -0.0312\n",
       "  -0.1639\n",
       "  -0.1378\n",
       "  -0.1598\n",
       "  -0.1505\n",
       "   0.0110\n",
       "  -0.1841\n",
       "  -0.1542\n",
       "  -0.0846\n",
       "  -0.0880\n",
       "  -0.1554\n",
       "  -0.2086\n",
       "  -0.1556\n",
       "  -0.1657\n",
       "  -0.1894\n",
       "  -0.1624\n",
       "  -0.0766\n",
       "  -0.1325\n",
       "   0.1000\n",
       "  -0.1401\n",
       "   0.0495\n",
       "  -0.2061\n",
       "  -0.1958\n",
       "  -0.1631\n",
       "  -0.2004\n",
       "  -0.1564\n",
       "  -0.1661\n",
       "  -0.1654\n",
       "  -0.1732\n",
       "  -0.2007\n",
       "  -0.1198\n",
       "  -0.0427\n",
       "  -0.1538\n",
       "  -0.1600\n",
       "  -0.1445\n",
       "  -0.0577\n",
       "  -0.1420\n",
       "  -0.1586\n",
       "  -0.1977\n",
       "  -0.1188\n",
       "  -0.0025\n",
       "  -0.1634\n",
       "  -0.1447\n",
       "  -0.1088\n",
       "   0.0285\n",
       "  -0.1547\n",
       "  -0.1554\n",
       "  -0.1975\n",
       "  -0.1104\n",
       "  -0.1698\n",
       "  -0.1547\n",
       "  -0.2114\n",
       "  -0.1699\n",
       "  -0.2619\n",
       "  -0.1900\n",
       "  -0.1514\n",
       "  -0.1610\n",
       "  -0.1678\n",
       "  -0.1520\n",
       "  -0.1530\n",
       "  -0.1914\n",
       "  -0.1209\n",
       "  -0.1004\n",
       "  -0.1929\n",
       "  -0.2458\n",
       "  -0.1539\n",
       "   0.0640\n",
       "  -0.2214\n",
       "  -0.1569\n",
       "  -0.0526\n",
       "  -0.1084\n",
       "  -0.1893\n",
       "  -0.1373\n",
       "  -0.1201\n",
       "  -0.2276\n",
       "  -0.1346\n",
       "  -0.1521\n",
       "  -0.1321\n",
       "  -0.1643\n",
       "  -0.1963\n",
       "  -0.1122\n",
       "  -0.1430\n",
       "  -0.1355\n",
       "  -0.1445\n",
       "  -0.1627\n",
       "  -0.1926\n",
       "  -0.0501\n",
       "  -0.1497\n",
       "  -0.1715\n",
       "  -0.1939\n",
       "  -0.1365\n",
       "  -0.1581\n",
       "  -0.0923\n",
       "  -0.1560\n",
       "  -0.1195\n",
       "  -0.1625\n",
       "  -0.2125\n",
       "  -0.1877\n",
       "  -0.1265\n",
       "  -0.1608\n",
       "  -0.1152\n",
       "  -0.1595\n",
       "  -0.1411\n",
       "  -0.1617\n",
       "  -0.2188\n",
       "  -0.0571\n",
       "  -0.0007\n",
       "  -0.0653\n",
       "  -0.0062\n",
       "  -0.1576\n",
       "  -0.1753\n",
       "  -0.0630\n",
       "  -0.0617\n",
       "  -0.1790\n",
       "  -0.1423\n",
       "  -0.1945\n",
       "  -0.1888\n",
       "  -0.1683\n",
       "  -0.1113\n",
       "  -0.0616\n",
       "  -0.1800\n",
       "  -0.2416\n",
       "  -0.1551\n",
       "  -0.1284\n",
       "  -0.1492\n",
       "  -0.1870\n",
       "  -0.0710\n",
       "  -0.1197\n",
       "  -0.0059\n",
       "  -0.1265\n",
       "  -0.1496\n",
       "  -0.1277\n",
       "  -0.1537\n",
       "  -0.1920\n",
       "  -0.2075\n",
       "  -0.1586\n",
       "  -0.2480\n",
       "  -0.1448\n",
       "  -0.1835\n",
       "  -0.1450\n",
       "  -0.2118\n",
       "  -0.1517\n",
       "  -0.2024\n",
       "  -0.1776\n",
       "  -0.1924\n",
       "  -0.1473\n",
       "  -0.1744\n",
       "  -0.2520\n",
       "  -0.1356\n",
       "  -0.1443\n",
       "  -0.1531\n",
       "  -0.1925\n",
       "  -0.1747\n",
       "  -0.1539\n",
       "  -0.1366\n",
       "   0.0086\n",
       "  -0.1848\n",
       "  -0.0183\n",
       "  -0.2136\n",
       "  -0.1427\n",
       "  -0.1844\n",
       "  -0.1750\n",
       "  -0.1554\n",
       "  -0.1202\n",
       "   0.0653\n",
       "  -0.0994\n",
       "  -0.0081\n",
       "  -0.1187\n",
       "  -0.1513\n",
       "  -0.1313\n",
       "  -0.1479\n",
       "  -0.2385\n",
       "  -0.1437\n",
       "  -0.1747\n",
       "  -0.1519\n",
       "  -0.1652\n",
       "  -0.2186\n",
       "  -0.0485\n",
       "  -0.1330\n",
       "  -0.1830\n",
       "  -0.1150\n",
       "  -0.0958\n",
       "   0.0027\n",
       "  -0.1471\n",
       "   0.0130\n",
       "  -0.1459\n",
       "  -0.1886\n",
       "  -0.1275\n",
       "   0.1661\n",
       "  -0.0800\n",
       "  -0.1464\n",
       "  -0.1256\n",
       "  -0.1325\n",
       "  -0.1778\n",
       "  -0.1464\n",
       "  -0.1481\n",
       "  -0.1006\n",
       "  -0.1662\n",
       "  -0.1466\n",
       "  -0.1509\n",
       "  -0.1614\n",
       "  -0.1183\n",
       "  -0.1798\n",
       "  -0.0489\n",
       "  -0.1628\n",
       "  -0.0921\n",
       "  -0.1547\n",
       "  -0.1877\n",
       "  -0.1620\n",
       "  -0.1104\n",
       "  -0.0467\n",
       "  -0.1292\n",
       "  -0.0495\n",
       "  -0.1896\n",
       "  -0.1132\n",
       "   0.1138\n",
       "  -0.1547\n",
       "  -0.1399\n",
       "  -0.2611\n",
       "  -0.2032\n",
       "  -0.1681\n",
       "  -0.1689\n",
       "  -0.1196\n",
       "  -0.1319\n",
       "  -0.0479\n",
       "  -0.3163\n",
       "  -0.1690\n",
       "  -0.0142\n",
       "  -0.1990\n",
       "  -0.1218\n",
       "  -0.1685\n",
       "  -0.0555\n",
       "  -0.2611\n",
       "  -0.1380\n",
       "  -0.1747\n",
       "  -0.1646\n",
       "  -0.1652\n",
       "  -0.1536\n",
       "  -0.1696\n",
       "  -0.1722\n",
       "  -0.2107\n",
       "  -0.2243\n",
       "  -0.1821\n",
       "  -0.1446\n",
       "  -0.1426\n",
       "  -0.0426\n",
       "  -0.2438\n",
       "  -0.1250\n",
       "  -0.1835\n",
       "  -0.1529\n",
       "  -0.1477\n",
       "  -0.1830\n",
       "  -0.1249\n",
       "   0.0352\n",
       "  -0.1280\n",
       "  -0.1278\n",
       "  -0.1526\n",
       "  -0.1985\n",
       "  -0.0289\n",
       "  -0.1288\n",
       "  -0.1455\n",
       "  -0.1760\n",
       "  -0.1562\n",
       "  -0.1952\n",
       "  -0.0663\n",
       "  -0.1741\n",
       "  -0.1742\n",
       "  -0.1404\n",
       "  -0.0622\n",
       "  -0.1601\n",
       "  -0.1377\n",
       "  -0.1338\n",
       "  -0.2351\n",
       "  -0.1532\n",
       "  -0.1547\n",
       "  -0.0995\n",
       "  -0.1479\n",
       "  -0.1605\n",
       "   0.0392\n",
       "  -0.1546\n",
       "  -0.1872\n",
       "  -0.0624\n",
       "  -0.1423\n",
       "  -0.2167\n",
       "  -0.0847\n",
       "  -0.1498\n",
       "  -0.2180\n",
       "  -0.1534\n",
       "  -0.1543\n",
       "   0.0190\n",
       "  -0.1560\n",
       "  -0.1731\n",
       "  -0.1684\n",
       "  -0.1948\n",
       "  -0.1571\n",
       "  -0.1790\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "    4.1740e-03  3.4258e-02  3.1596e-02\n",
       "    6.4798e-03 -6.3237e-03 -1.6645e-02\n",
       "   -8.7145e-03 -2.4100e-02  1.3848e-02\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "    5.6548e-03 -1.4473e-02 -6.7250e-03\n",
       "   -4.4684e-02 -3.1352e-02  9.2398e-03\n",
       "   -5.5704e-03  1.8357e-02 -3.6389e-03\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -2.1113e-04 -4.5365e-04 -1.4350e-03\n",
       "    2.1793e-02  1.5142e-03  2.6593e-03\n",
       "    1.9707e-02  2.0633e-04 -1.6122e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,509,.,.) = \n",
       "   -1.3446e-02 -9.1089e-03 -3.1658e-03\n",
       "    2.5989e-02 -6.2251e-03 -1.6130e-02\n",
       "   -2.2481e-02 -1.3993e-02 -1.9374e-02\n",
       "  \n",
       "  ( 0 ,510,.,.) = \n",
       "   -1.8949e-02 -9.7360e-03 -1.3763e-03\n",
       "    1.0829e-02  1.2911e-03  1.2984e-02\n",
       "    2.2681e-02 -1.8767e-04 -2.7610e-02\n",
       "  \n",
       "  ( 0 ,511,.,.) = \n",
       "    1.6969e-02  2.5306e-02 -1.7508e-02\n",
       "    2.4134e-02  8.4346e-03 -1.5394e-02\n",
       "   -1.5526e-03  1.9643e-02  1.5636e-03\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    9.9326e-03  3.0378e-02  1.6828e-02\n",
       "    2.0841e-02 -1.0329e-02  3.1833e-04\n",
       "    3.3631e-02 -2.3362e-02 -1.0288e-02\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "   -7.0726e-03  6.3297e-03  3.5231e-02\n",
       "    4.3635e-04  2.0820e-03 -1.0894e-02\n",
       "   -2.7129e-03  1.2324e-02 -1.5932e-02\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -6.1197e-03  2.1004e-02  6.6270e-03\n",
       "    1.2542e-02 -1.8784e-02 -8.2946e-03\n",
       "    6.5605e-03  3.3454e-02  8.2317e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,509,.,.) = \n",
       "   -9.3779e-03  1.5653e-02  1.2510e-02\n",
       "    1.0529e-02  7.5243e-03 -2.1480e-02\n",
       "    3.6524e-04  9.7541e-03 -3.2123e-02\n",
       "  \n",
       "  ( 1 ,510,.,.) = \n",
       "   -1.1384e-02 -2.0087e-02  3.2143e-03\n",
       "    1.2786e-02 -2.4493e-03  9.1272e-03\n",
       "   -2.4888e-02 -3.1740e-02  3.1871e-03\n",
       "  \n",
       "  ( 1 ,511,.,.) = \n",
       "    9.8764e-03  2.1202e-02  2.6665e-02\n",
       "    2.5124e-02 -8.4679e-03  1.5894e-02\n",
       "   -1.5781e-02  9.9365e-03  1.1642e-02\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.4097e-02 -9.8507e-03  3.1644e-02\n",
       "   -1.6417e-02  4.2393e-02  1.2028e-02\n",
       "    8.1739e-03 -1.3683e-02  1.2335e-02\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    1.8404e-02  5.1341e-03  1.6426e-02\n",
       "    5.7792e-03 -2.8064e-02 -2.0445e-02\n",
       "   -3.7788e-03 -3.3133e-02 -2.6050e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -6.2134e-04  5.1072e-03 -2.5585e-02\n",
       "   -4.3535e-03 -1.3180e-02 -1.6722e-03\n",
       "    3.3900e-03  6.9000e-03  8.9298e-03\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,509,.,.) = \n",
       "   -1.4751e-02  2.1579e-02 -8.9753e-04\n",
       "    1.4762e-02  3.7662e-03  2.9872e-02\n",
       "   -6.7647e-03  1.2232e-03 -6.4097e-04\n",
       "  \n",
       "  ( 2 ,510,.,.) = \n",
       "    1.2910e-02  3.2809e-02  7.1716e-03\n",
       "   -7.0231e-03  1.0029e-02  1.9681e-02\n",
       "   -1.6767e-02 -5.8192e-03  1.8985e-02\n",
       "  \n",
       "  ( 2 ,511,.,.) = \n",
       "    2.9245e-02  1.1512e-02  1.2090e-02\n",
       "   -1.3886e-02 -4.0287e-03 -1.1879e-02\n",
       "    2.2822e-02 -1.3340e-02 -2.5632e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "   -1.9886e-02  1.5945e-02  1.4016e-02\n",
       "   -1.5236e-02  3.8288e-03  1.7689e-02\n",
       "   -1.9154e-02  6.8108e-04  2.4946e-02\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "   -1.5462e-02 -1.1155e-02 -9.3102e-03\n",
       "   -2.0432e-02  9.9794e-03 -1.9856e-02\n",
       "   -1.4340e-03 -2.9350e-03 -2.2426e-02\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "    4.1404e-03  5.3910e-03 -2.0561e-02\n",
       "    1.0000e-02 -4.3189e-03  1.5072e-02\n",
       "   -3.0181e-02 -9.0815e-03  2.1457e-02\n",
       "      ... \n",
       "  \n",
       "  (509,509,.,.) = \n",
       "   -1.1118e-02 -2.3479e-02 -2.9094e-02\n",
       "   -2.4062e-02  2.2540e-02 -1.4270e-02\n",
       "   -2.0749e-02  8.4326e-03 -1.8143e-02\n",
       "  \n",
       "  (509,510,.,.) = \n",
       "   -2.2487e-02 -4.0245e-04 -2.0544e-04\n",
       "   -1.1766e-02  1.1037e-02  9.8962e-04\n",
       "   -1.7469e-02 -4.8587e-03 -1.3759e-03\n",
       "  \n",
       "  (509,511,.,.) = \n",
       "    6.0335e-03  9.1521e-03  5.5753e-03\n",
       "   -2.5022e-02 -4.5729e-04  8.0434e-03\n",
       "    5.9977e-05  1.8447e-02  3.4952e-02\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "    2.1406e-03  1.1163e-02  2.9068e-02\n",
       "    3.4671e-03 -3.3156e-03  1.8109e-02\n",
       "    1.6740e-02  1.8418e-03  2.4351e-02\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "   -8.1442e-03  2.4159e-02 -3.5739e-03\n",
       "   -5.7374e-03 -1.2657e-02  2.8313e-02\n",
       "   -2.8423e-02 -7.7241e-03  1.8645e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "    1.2000e-02 -9.4664e-03  2.3036e-02\n",
       "    9.5002e-03  1.0766e-02  1.4532e-03\n",
       "    2.7975e-02 -6.4600e-03  2.4594e-02\n",
       "      ... \n",
       "  \n",
       "  (510,509,.,.) = \n",
       "    1.4144e-02  3.3042e-02 -4.2175e-04\n",
       "    3.5919e-02 -1.3303e-02  8.1758e-03\n",
       "   -5.1728e-03  2.5844e-03 -2.0108e-02\n",
       "  \n",
       "  (510,510,.,.) = \n",
       "    7.7157e-03  9.5256e-03 -5.8746e-03\n",
       "   -1.0644e-02  8.2716e-03 -2.8883e-02\n",
       "    1.0444e-03  1.3083e-02 -5.8212e-03\n",
       "  \n",
       "  (510,511,.,.) = \n",
       "    1.0930e-02  2.3443e-02  3.5945e-03\n",
       "    1.4833e-02 -1.0107e-02  2.0147e-02\n",
       "    9.4119e-04  2.9601e-02 -2.1610e-02\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "   -2.5311e-02 -4.7837e-03  6.2101e-03\n",
       "   -3.0017e-02 -3.9982e-02 -3.4941e-02\n",
       "   -1.3033e-02  1.4250e-02 -2.0242e-02\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "    2.4502e-03 -2.5231e-03  1.1599e-02\n",
       "    2.1894e-02 -3.6752e-03 -5.0927e-04\n",
       "    2.7813e-02 -1.5431e-02 -2.9315e-02\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "    4.5379e-03 -1.6094e-02 -5.4687e-03\n",
       "    8.2646e-03  5.7896e-03 -1.6709e-02\n",
       "   -1.2363e-03 -7.5128e-03 -1.9452e-02\n",
       "      ... \n",
       "  \n",
       "  (511,509,.,.) = \n",
       "    9.9600e-03  6.4821e-03  1.2191e-02\n",
       "   -1.1968e-02  4.0820e-03 -1.4233e-02\n",
       "   -3.6776e-02 -3.8499e-02 -1.3158e-02\n",
       "  \n",
       "  (511,510,.,.) = \n",
       "   -8.0473e-03 -9.0733e-04 -1.0397e-02\n",
       "   -1.3433e-03  7.7613e-03 -1.9006e-02\n",
       "   -3.7571e-03  1.3351e-02 -7.6042e-03\n",
       "  \n",
       "  (511,511,.,.) = \n",
       "    3.1412e-02  2.0919e-03  3.7380e-03\n",
       "    5.6612e-03  3.2909e-02  9.3483e-03\n",
       "   -1.3436e-02 -1.1490e-02  8.7820e-03\n",
       "  [torch.cuda.FloatTensor of size 512x512x3x3 (GPU 0)], Parameter containing:\n",
       "   0.7832\n",
       "   0.7602\n",
       "   0.7813\n",
       "   0.7418\n",
       "   0.7799\n",
       "   0.7741\n",
       "   0.7486\n",
       "   0.7651\n",
       "   0.7953\n",
       "   0.7690\n",
       "   0.7791\n",
       "   0.7742\n",
       "   0.8153\n",
       "   0.7978\n",
       "   0.7851\n",
       "   0.7931\n",
       "   0.7837\n",
       "   0.7959\n",
       "   0.8167\n",
       "   0.7449\n",
       "   0.7860\n",
       "   0.8154\n",
       "   0.8168\n",
       "   0.7678\n",
       "   0.7744\n",
       "   0.7904\n",
       "   0.7810\n",
       "   0.7720\n",
       "   0.8039\n",
       "   0.7820\n",
       "   0.7953\n",
       "   0.7794\n",
       "   0.7849\n",
       "   0.8069\n",
       "   0.7900\n",
       "   0.7591\n",
       "   0.7948\n",
       "   0.7977\n",
       "   0.8032\n",
       "   0.8147\n",
       "   0.7917\n",
       "   0.8076\n",
       "   0.7863\n",
       "   0.7825\n",
       "   0.7896\n",
       "   0.7815\n",
       "   0.7925\n",
       "   0.7789\n",
       "   0.7928\n",
       "   0.8444\n",
       "   0.8491\n",
       "   0.7868\n",
       "   0.8055\n",
       "   0.7737\n",
       "   0.7769\n",
       "   0.7788\n",
       "   0.7740\n",
       "   0.7496\n",
       "   0.7858\n",
       "   0.7857\n",
       "   0.8096\n",
       "   0.7396\n",
       "   0.7526\n",
       "   0.7956\n",
       "   0.7748\n",
       "   0.7890\n",
       "   0.7501\n",
       "   0.7753\n",
       "   0.8312\n",
       "   0.7695\n",
       "   0.7874\n",
       "   0.8002\n",
       "   0.8057\n",
       "   0.7732\n",
       "   0.7681\n",
       "   0.7898\n",
       "   0.7761\n",
       "   0.7895\n",
       "   0.7791\n",
       "   0.7992\n",
       "   0.7678\n",
       "   0.7861\n",
       "   0.8030\n",
       "   0.7801\n",
       "   0.8040\n",
       "   0.7958\n",
       "   0.7443\n",
       "   0.7681\n",
       "   0.7958\n",
       "   0.8070\n",
       "   0.8041\n",
       "   0.7870\n",
       "   0.7849\n",
       "   0.7790\n",
       "   0.7865\n",
       "   0.7658\n",
       "   0.7982\n",
       "   0.7852\n",
       "   0.8041\n",
       "   0.7751\n",
       "   0.7655\n",
       "   0.8151\n",
       "   0.7836\n",
       "   0.7898\n",
       "   0.7710\n",
       "   0.8361\n",
       "   0.7887\n",
       "   0.7803\n",
       "   0.7766\n",
       "   0.8032\n",
       "   0.7850\n",
       "   0.7926\n",
       "   0.7875\n",
       "   0.7524\n",
       "   0.7994\n",
       "   0.7542\n",
       "   0.7936\n",
       "   0.7652\n",
       "   0.7962\n",
       "   0.8282\n",
       "   0.7523\n",
       "   0.7870\n",
       "   0.7784\n",
       "   0.7456\n",
       "   0.7991\n",
       "   0.7709\n",
       "   0.7935\n",
       "   0.7551\n",
       "   0.7832\n",
       "   0.7552\n",
       "   0.8125\n",
       "   0.8004\n",
       "   0.7910\n",
       "   0.7604\n",
       "   0.7889\n",
       "   0.7853\n",
       "   0.7614\n",
       "   0.8011\n",
       "   0.8412\n",
       "   0.7518\n",
       "   0.7734\n",
       "   0.7798\n",
       "   0.8037\n",
       "   0.7844\n",
       "   0.7896\n",
       "   0.7692\n",
       "   0.7789\n",
       "   0.7760\n",
       "   0.7901\n",
       "   0.7510\n",
       "   0.7897\n",
       "   0.8040\n",
       "   0.7714\n",
       "   0.7831\n",
       "   0.7892\n",
       "   0.7902\n",
       "   0.7529\n",
       "   0.7880\n",
       "   0.7984\n",
       "   0.7640\n",
       "   0.7900\n",
       "   0.7903\n",
       "   0.7924\n",
       "   0.7713\n",
       "   0.7667\n",
       "   0.7858\n",
       "   0.7741\n",
       "   0.7903\n",
       "   0.7701\n",
       "   0.8115\n",
       "   0.8014\n",
       "   0.7861\n",
       "   0.7482\n",
       "   0.7760\n",
       "   0.7784\n",
       "   0.7980\n",
       "   0.7903\n",
       "   0.8017\n",
       "   0.7763\n",
       "   0.7852\n",
       "   0.7509\n",
       "   0.8099\n",
       "   0.7597\n",
       "   0.7919\n",
       "   0.7955\n",
       "   0.7721\n",
       "   0.7829\n",
       "   0.7974\n",
       "   0.7906\n",
       "   0.8075\n",
       "   0.7832\n",
       "   0.7700\n",
       "   0.8793\n",
       "   0.7763\n",
       "   0.8160\n",
       "   0.7933\n",
       "   0.7529\n",
       "   0.7656\n",
       "   0.7949\n",
       "   0.8072\n",
       "   0.7612\n",
       "   0.8628\n",
       "   0.7829\n",
       "   0.7744\n",
       "   0.7861\n",
       "   0.7814\n",
       "   0.7858\n",
       "   0.7857\n",
       "   0.8099\n",
       "   0.7508\n",
       "   0.8340\n",
       "   0.7786\n",
       "   0.7706\n",
       "   0.7863\n",
       "   0.7913\n",
       "   0.7767\n",
       "   0.7676\n",
       "   0.8057\n",
       "   0.7964\n",
       "   0.7678\n",
       "   0.7978\n",
       "   0.8123\n",
       "   0.8046\n",
       "   0.7839\n",
       "   0.7886\n",
       "   0.7890\n",
       "   0.7734\n",
       "   0.7662\n",
       "   0.7901\n",
       "   0.7751\n",
       "   0.7777\n",
       "   0.7816\n",
       "   0.7886\n",
       "   0.7839\n",
       "   0.7599\n",
       "   0.7929\n",
       "   0.7851\n",
       "   0.8050\n",
       "   0.7588\n",
       "   0.7782\n",
       "   0.7787\n",
       "   0.7874\n",
       "   0.7899\n",
       "   0.8140\n",
       "   0.7949\n",
       "   0.7573\n",
       "   0.7398\n",
       "   0.7630\n",
       "   0.7521\n",
       "   0.7924\n",
       "   0.8350\n",
       "   0.7844\n",
       "   0.7964\n",
       "   0.7988\n",
       "   0.8161\n",
       "   0.7789\n",
       "   0.7738\n",
       "   0.7937\n",
       "   0.7715\n",
       "   0.8149\n",
       "   0.7851\n",
       "   0.8091\n",
       "   0.7713\n",
       "   0.7860\n",
       "   0.7289\n",
       "   0.7920\n",
       "   0.7845\n",
       "   0.7696\n",
       "   0.7742\n",
       "   0.7864\n",
       "   0.7771\n",
       "   0.7423\n",
       "   0.7819\n",
       "   0.7829\n",
       "   0.7872\n",
       "   0.7952\n",
       "   0.7676\n",
       "   0.7708\n",
       "   0.7877\n",
       "   0.8515\n",
       "   0.7972\n",
       "   0.7950\n",
       "   0.7501\n",
       "   0.7997\n",
       "   0.8186\n",
       "   0.7928\n",
       "   0.7276\n",
       "   0.7875\n",
       "   0.7719\n",
       "   0.8086\n",
       "   0.7888\n",
       "   0.7924\n",
       "   0.7649\n",
       "   0.7828\n",
       "   0.7848\n",
       "   0.7804\n",
       "   0.7909\n",
       "   0.7784\n",
       "   0.7346\n",
       "   0.8351\n",
       "   0.7847\n",
       "   0.7619\n",
       "   0.7543\n",
       "   0.7738\n",
       "   0.8608\n",
       "   0.7868\n",
       "   0.7871\n",
       "   0.7854\n",
       "   0.7801\n",
       "   0.7974\n",
       "   0.8091\n",
       "   0.7950\n",
       "   0.7720\n",
       "   0.7739\n",
       "   0.7631\n",
       "   0.7814\n",
       "   0.7604\n",
       "   0.7624\n",
       "   0.7741\n",
       "   0.7322\n",
       "   0.7917\n",
       "   0.7836\n",
       "   0.7749\n",
       "   0.7826\n",
       "   0.7844\n",
       "   0.7903\n",
       "   0.7767\n",
       "   0.7860\n",
       "   0.7712\n",
       "   0.7765\n",
       "   0.7775\n",
       "   0.8147\n",
       "   0.8055\n",
       "   0.7674\n",
       "   0.7862\n",
       "   0.7837\n",
       "   0.7849\n",
       "   0.7761\n",
       "   0.7849\n",
       "   0.7392\n",
       "   0.7695\n",
       "   0.7429\n",
       "   0.8000\n",
       "   0.7818\n",
       "   0.7973\n",
       "   0.7895\n",
       "   0.8323\n",
       "   0.7861\n",
       "   0.7763\n",
       "   0.7812\n",
       "   0.7719\n",
       "   0.7693\n",
       "   0.7773\n",
       "   0.7798\n",
       "   0.7803\n",
       "   0.7745\n",
       "   0.7828\n",
       "   0.8136\n",
       "   0.7819\n",
       "   0.7872\n",
       "   0.7936\n",
       "   0.7623\n",
       "   0.7711\n",
       "   0.7650\n",
       "   0.8412\n",
       "   0.7850\n",
       "   0.8047\n",
       "   0.7399\n",
       "   0.7640\n",
       "   0.7812\n",
       "   0.7951\n",
       "   0.8039\n",
       "   0.7527\n",
       "   0.8135\n",
       "   0.7857\n",
       "   0.7815\n",
       "   0.7679\n",
       "   0.8035\n",
       "   0.7753\n",
       "   0.7946\n",
       "   0.7972\n",
       "   0.7950\n",
       "   0.7762\n",
       "   0.7931\n",
       "   0.8224\n",
       "   0.7914\n",
       "   0.7868\n",
       "   0.7926\n",
       "   0.7785\n",
       "   0.8463\n",
       "   0.7818\n",
       "   0.8076\n",
       "   0.7912\n",
       "   0.7997\n",
       "   0.7364\n",
       "   0.7791\n",
       "   0.7494\n",
       "   0.7651\n",
       "   0.7612\n",
       "   0.7615\n",
       "   0.7938\n",
       "   0.7874\n",
       "   0.7628\n",
       "   0.7397\n",
       "   0.7879\n",
       "   0.7827\n",
       "   0.7974\n",
       "   0.7886\n",
       "   0.7939\n",
       "   0.7601\n",
       "   0.7929\n",
       "   0.7816\n",
       "   0.7981\n",
       "   0.7758\n",
       "   0.7894\n",
       "   0.7719\n",
       "   0.7736\n",
       "   0.7550\n",
       "   0.7819\n",
       "   0.8278\n",
       "   0.7932\n",
       "   0.7889\n",
       "   0.7801\n",
       "   0.7551\n",
       "   0.7879\n",
       "   0.7873\n",
       "   0.7725\n",
       "   0.7830\n",
       "   0.7858\n",
       "   0.7752\n",
       "   0.7636\n",
       "   0.7628\n",
       "   0.8217\n",
       "   0.7458\n",
       "   0.7783\n",
       "   0.7974\n",
       "   0.7775\n",
       "   0.7950\n",
       "   0.7455\n",
       "   0.7908\n",
       "   0.7851\n",
       "   0.7927\n",
       "   0.7921\n",
       "   0.7661\n",
       "   0.7795\n",
       "   0.7685\n",
       "   0.7655\n",
       "   0.7932\n",
       "   0.7983\n",
       "   0.8025\n",
       "   0.7935\n",
       "   0.7810\n",
       "   0.7489\n",
       "   0.7894\n",
       "   0.7790\n",
       "   0.7757\n",
       "   0.7679\n",
       "   0.7388\n",
       "   0.7644\n",
       "   0.8124\n",
       "   0.7855\n",
       "   0.7722\n",
       "   0.7811\n",
       "   0.8076\n",
       "   0.7361\n",
       "   0.7921\n",
       "   0.7874\n",
       "   0.7779\n",
       "   0.7650\n",
       "   0.7945\n",
       "   0.7751\n",
       "   0.7468\n",
       "   0.7903\n",
       "   0.7744\n",
       "   0.7518\n",
       "   0.7728\n",
       "   0.7879\n",
       "   0.7749\n",
       "   0.7943\n",
       "   0.7797\n",
       "   0.7939\n",
       "   0.7840\n",
       "   0.7838\n",
       "   0.8224\n",
       "   0.8646\n",
       "   0.7874\n",
       "   0.7862\n",
       "   0.7782\n",
       "   0.7699\n",
       "   0.7671\n",
       "   0.7805\n",
       "   0.8849\n",
       "   0.7735\n",
       "   0.7949\n",
       "   0.7873\n",
       "   0.7437\n",
       "   0.7647\n",
       "   0.7452\n",
       "   0.7665\n",
       "   0.7845\n",
       "   0.7731\n",
       "   0.7798\n",
       "   0.7425\n",
       "   0.8585\n",
       "   0.7578\n",
       "   0.8050\n",
       "   0.7755\n",
       "   0.7960\n",
       "   0.7848\n",
       "   0.7868\n",
       "   0.7660\n",
       "   0.7780\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.0177\n",
       "  -0.0385\n",
       "  -0.0228\n",
       "  -0.0624\n",
       "  -0.0372\n",
       "  -0.0125\n",
       "  -0.0183\n",
       "  -0.0187\n",
       "   0.0348\n",
       "  -0.0391\n",
       "  -0.0394\n",
       "  -0.0425\n",
       "   0.0420\n",
       "  -0.0308\n",
       "  -0.0133\n",
       "  -0.0233\n",
       "   0.0071\n",
       "   0.0472\n",
       "   0.0901\n",
       "  -0.0675\n",
       "   0.0378\n",
       "   0.0309\n",
       "  -0.0226\n",
       "  -0.0480\n",
       "  -0.0414\n",
       "  -0.0030\n",
       "  -0.0210\n",
       "  -0.0615\n",
       "  -0.0192\n",
       "  -0.0148\n",
       "   0.0190\n",
       "   0.0076\n",
       "   0.0326\n",
       "  -0.0361\n",
       "   0.0386\n",
       "  -0.0719\n",
       "  -0.0096\n",
       "   0.0709\n",
       "   0.0189\n",
       "   0.0365\n",
       "  -0.0075\n",
       "  -0.0131\n",
       "  -0.0367\n",
       "   0.0149\n",
       "  -0.0160\n",
       "   0.0030\n",
       "   0.0163\n",
       "   0.0281\n",
       "  -0.0128\n",
       "  -0.0283\n",
       "   0.0105\n",
       "   0.0069\n",
       "  -0.0213\n",
       "  -0.0301\n",
       "  -0.0273\n",
       "  -0.0011\n",
       "  -0.0495\n",
       "  -0.0608\n",
       "   0.0030\n",
       "  -0.0270\n",
       "   0.0027\n",
       "  -0.0208\n",
       "  -0.0264\n",
       "  -0.0325\n",
       "  -0.0452\n",
       "   0.0642\n",
       "  -0.0495\n",
       "  -0.0502\n",
       "   0.0428\n",
       "  -0.0416\n",
       "   0.0130\n",
       "   0.0601\n",
       "  -0.0003\n",
       "  -0.0167\n",
       "  -0.0437\n",
       "  -0.0437\n",
       "  -0.0195\n",
       "  -0.0428\n",
       "  -0.0046\n",
       "  -0.0342\n",
       "  -0.0540\n",
       "   0.0288\n",
       "   0.0307\n",
       "  -0.0072\n",
       "   0.0064\n",
       "  -0.0294\n",
       "  -0.0611\n",
       "  -0.0286\n",
       "  -0.0195\n",
       "   0.0015\n",
       "   0.0322\n",
       "  -0.0312\n",
       "  -0.0228\n",
       "   0.0008\n",
       "   0.0003\n",
       "  -0.0099\n",
       "  -0.0163\n",
       "   0.0241\n",
       "  -0.0221\n",
       "  -0.0196\n",
       "  -0.0157\n",
       "   0.0769\n",
       "   0.0036\n",
       "  -0.0284\n",
       "  -0.0561\n",
       "   0.0468\n",
       "  -0.0258\n",
       "   0.0006\n",
       "  -0.0529\n",
       "  -0.0039\n",
       "  -0.0370\n",
       "  -0.0395\n",
       "  -0.0036\n",
       "  -0.0232\n",
       "   0.0528\n",
       "  -0.0614\n",
       "  -0.0202\n",
       "   0.0109\n",
       "  -0.0248\n",
       "   0.0679\n",
       "  -0.0490\n",
       "   0.0064\n",
       "  -0.0159\n",
       "  -0.0550\n",
       "   0.0637\n",
       "  -0.0343\n",
       "   0.0589\n",
       "  -0.0231\n",
       "  -0.0361\n",
       "  -0.0424\n",
       "   0.0492\n",
       "  -0.0239\n",
       "  -0.0424\n",
       "  -0.0532\n",
       "  -0.0015\n",
       "   0.0275\n",
       "  -0.0629\n",
       "  -0.0412\n",
       "  -0.0197\n",
       "  -0.0763\n",
       "   0.0405\n",
       "  -0.0352\n",
       "  -0.0389\n",
       "  -0.0253\n",
       "  -0.0187\n",
       "  -0.0439\n",
       "  -0.0115\n",
       "  -0.0452\n",
       "  -0.0472\n",
       "  -0.0591\n",
       "   0.0260\n",
       "   0.0556\n",
       "  -0.0014\n",
       "  -0.0455\n",
       "  -0.0150\n",
       "  -0.0159\n",
       "  -0.0547\n",
       "   0.0179\n",
       "  -0.0127\n",
       "  -0.0441\n",
       "  -0.0313\n",
       "  -0.0357\n",
       "   0.1058\n",
       "  -0.0526\n",
       "  -0.0126\n",
       "  -0.0217\n",
       "  -0.0595\n",
       "  -0.0064\n",
       "   0.0164\n",
       "   0.0607\n",
       "   0.0392\n",
       "   0.0284\n",
       "  -0.0353\n",
       "  -0.0163\n",
       "  -0.0196\n",
       "   0.0057\n",
       "  -0.0191\n",
       "   0.0256\n",
       "  -0.0345\n",
       "  -0.0023\n",
       "  -0.0454\n",
       "   0.0604\n",
       "  -0.0151\n",
       "  -0.0213\n",
       "   0.0433\n",
       "  -0.0078\n",
       "  -0.0269\n",
       "  -0.0251\n",
       "   0.0275\n",
       "  -0.0453\n",
       "  -0.0485\n",
       "  -0.0355\n",
       "  -0.0121\n",
       "  -0.0498\n",
       "  -0.0222\n",
       "   0.0128\n",
       "  -0.0746\n",
       "  -0.0583\n",
       "  -0.0263\n",
       "   0.0356\n",
       "  -0.0570\n",
       "  -0.0156\n",
       "  -0.0343\n",
       "  -0.0455\n",
       "  -0.0206\n",
       "  -0.0492\n",
       "  -0.0106\n",
       "  -0.0351\n",
       "   0.0202\n",
       "  -0.0520\n",
       "   0.0545\n",
       "  -0.0123\n",
       "  -0.0001\n",
       "  -0.0092\n",
       "  -0.0147\n",
       "  -0.0346\n",
       "  -0.0413\n",
       "   0.0620\n",
       "  -0.0182\n",
       "  -0.0725\n",
       "  -0.0284\n",
       "   0.0473\n",
       "   0.0559\n",
       "  -0.0341\n",
       "   0.0039\n",
       "  -0.0356\n",
       "  -0.0408\n",
       "  -0.0573\n",
       "  -0.0255\n",
       "  -0.0056\n",
       "  -0.0443\n",
       "  -0.0212\n",
       "   0.0193\n",
       "   0.0214\n",
       "  -0.0286\n",
       "   0.0059\n",
       "  -0.0520\n",
       "  -0.0282\n",
       "  -0.0300\n",
       "  -0.0441\n",
       "  -0.0292\n",
       "   0.0273\n",
       "  -0.0062\n",
       "   0.0711\n",
       "   0.0763\n",
       "  -0.0494\n",
       "  -0.0275\n",
       "  -0.0575\n",
       "  -0.0508\n",
       "  -0.0009\n",
       "   0.0999\n",
       "  -0.0459\n",
       "  -0.0145\n",
       "   0.0312\n",
       "  -0.0338\n",
       "   0.0166\n",
       "  -0.0045\n",
       "   0.0730\n",
       "  -0.0358\n",
       "   0.0777\n",
       "   0.0100\n",
       "  -0.0194\n",
       "  -0.0457\n",
       "   0.0330\n",
       "  -0.0412\n",
       "   0.0019\n",
       "   0.0166\n",
       "  -0.0305\n",
       "  -0.0397\n",
       "  -0.0338\n",
       "  -0.0008\n",
       "  -0.0259\n",
       "  -0.0139\n",
       "  -0.0232\n",
       "  -0.0066\n",
       "   0.0302\n",
       "  -0.0473\n",
       "  -0.0106\n",
       "   0.0497\n",
       "   0.0932\n",
       "   0.0216\n",
       "   0.0460\n",
       "  -0.0286\n",
       "   0.0212\n",
       "   0.0925\n",
       "  -0.0284\n",
       "  -0.0981\n",
       "  -0.0146\n",
       "  -0.0239\n",
       "   0.0712\n",
       "   0.0686\n",
       "   0.0025\n",
       "  -0.0586\n",
       "  -0.0274\n",
       "  -0.0466\n",
       "  -0.0114\n",
       "  -0.0390\n",
       "  -0.0002\n",
       "  -0.0027\n",
       "   0.0663\n",
       "   0.0072\n",
       "  -0.0470\n",
       "   0.0226\n",
       "  -0.0069\n",
       "  -0.0029\n",
       "  -0.0441\n",
       "  -0.0004\n",
       "   0.0257\n",
       "  -0.0267\n",
       "   0.0336\n",
       "   0.0359\n",
       "  -0.0324\n",
       "  -0.0493\n",
       "  -0.0447\n",
       "  -0.0863\n",
       "  -0.0138\n",
       "  -0.0347\n",
       "  -0.0506\n",
       "  -0.0287\n",
       "  -0.0470\n",
       "  -0.0405\n",
       "   0.0246\n",
       "  -0.0190\n",
       "  -0.0294\n",
       "   0.0199\n",
       "  -0.0339\n",
       "  -0.0123\n",
       "   0.0617\n",
       "   0.0534\n",
       "  -0.0546\n",
       "  -0.0076\n",
       "  -0.0237\n",
       "  -0.0044\n",
       "  -0.0508\n",
       "   0.0628\n",
       "  -0.0342\n",
       "  -0.0244\n",
       "  -0.0139\n",
       "  -0.0459\n",
       "  -0.0563\n",
       "  -0.0577\n",
       "  -0.0832\n",
       "   0.0013\n",
       "  -0.0424\n",
       "   0.0377\n",
       "  -0.0231\n",
       "  -0.0281\n",
       "  -0.0249\n",
       "  -0.0252\n",
       "   0.0053\n",
       "  -0.0425\n",
       "  -0.0198\n",
       "  -0.0387\n",
       "   0.0004\n",
       "  -0.0341\n",
       "  -0.0267\n",
       "  -0.0235\n",
       "   0.0715\n",
       "  -0.0174\n",
       "  -0.0312\n",
       "   0.0554\n",
       "  -0.0530\n",
       "  -0.0651\n",
       "   0.0057\n",
       "   0.1183\n",
       "  -0.0207\n",
       "  -0.0041\n",
       "  -0.0283\n",
       "   0.0468\n",
       "  -0.0431\n",
       "   0.0139\n",
       "   0.0912\n",
       "  -0.0531\n",
       "   0.0467\n",
       "   0.0201\n",
       "  -0.0215\n",
       "  -0.0489\n",
       "  -0.0168\n",
       "  -0.0210\n",
       "   0.0043\n",
       "  -0.0085\n",
       "  -0.0294\n",
       "  -0.0415\n",
       "   0.0112\n",
       "   0.0544\n",
       "   0.0094\n",
       "  -0.0592\n",
       "   0.0140\n",
       "  -0.0545\n",
       "  -0.0258\n",
       "  -0.0444\n",
       "   0.0736\n",
       "  -0.0232\n",
       "   0.1052\n",
       "  -0.0784\n",
       "  -0.0028\n",
       "   0.0169\n",
       "  -0.0342\n",
       "  -0.0512\n",
       "  -0.0872\n",
       "  -0.0492\n",
       "  -0.0320\n",
       "  -0.0397\n",
       "  -0.0554\n",
       "   0.0136\n",
       "  -0.0264\n",
       "   0.0391\n",
       "   0.0621\n",
       "  -0.0265\n",
       "  -0.0543\n",
       "  -0.0393\n",
       "   0.0141\n",
       "  -0.0339\n",
       "  -0.0394\n",
       "  -0.0658\n",
       "  -0.0651\n",
       "  -0.0573\n",
       "  -0.0065\n",
       "  -0.0264\n",
       "  -0.0031\n",
       "   0.0361\n",
       "  -0.0215\n",
       "  -0.0044\n",
       "  -0.0300\n",
       "  -0.0031\n",
       "   0.0121\n",
       "  -0.0395\n",
       "  -0.0395\n",
       "  -0.0225\n",
       "  -0.0009\n",
       "  -0.0294\n",
       "  -0.0401\n",
       "  -0.0287\n",
       "  -0.0498\n",
       "   0.0166\n",
       "  -0.0032\n",
       "  -0.0664\n",
       "  -0.0287\n",
       "  -0.0203\n",
       "  -0.0235\n",
       "   0.0410\n",
       "  -0.0123\n",
       "  -0.0278\n",
       "  -0.0155\n",
       "  -0.0005\n",
       "  -0.0382\n",
       "  -0.0751\n",
       "  -0.0038\n",
       "   0.0111\n",
       "   0.0794\n",
       "  -0.0100\n",
       "   0.0560\n",
       "  -0.0465\n",
       "  -0.0154\n",
       "  -0.0364\n",
       "  -0.0369\n",
       "  -0.0230\n",
       "  -0.0466\n",
       "  -0.0357\n",
       "   0.0001\n",
       "  -0.0320\n",
       "  -0.0257\n",
       "  -0.0177\n",
       "  -0.0034\n",
       "  -0.0130\n",
       "  -0.0234\n",
       "   0.0223\n",
       "  -0.0537\n",
       "  -0.0178\n",
       "  -0.0060\n",
       "  -0.0211\n",
       "  -0.0563\n",
       "   0.0473\n",
       "  -0.0246\n",
       "  -0.0570\n",
       "  -0.0114\n",
       "   0.0542\n",
       "  -0.0198\n",
       "   0.0268\n",
       "   0.0022\n",
       "  -0.0340\n",
       "   0.0249\n",
       "  -0.0459\n",
       "  -0.0250\n",
       "  -0.0186\n",
       "  -0.0409\n",
       "  -0.0329\n",
       "   0.0000\n",
       "   0.0207\n",
       "  -0.0155\n",
       "   0.0024\n",
       "  -0.0059\n",
       "  -0.0446\n",
       "   0.0506\n",
       "  -0.0253\n",
       "  -0.0596\n",
       "  -0.0217\n",
       "  -0.0341\n",
       "  -0.0590\n",
       "  -0.0252\n",
       "  -0.0027\n",
       "  -0.0349\n",
       "  -0.0158\n",
       "   0.1469\n",
       "  -0.0601\n",
       "   0.0953\n",
       "   0.0078\n",
       "  -0.0097\n",
       "   0.0133\n",
       "   0.0270\n",
       "  -0.0469\n",
       "   0.0119\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  ( 0 , 0 ,.,.) = \n",
       "   -1.8994e-02  3.1259e-03 -1.6567e-02\n",
       "   -2.0080e-02 -1.7308e-02  2.1032e-02\n",
       "    5.1545e-03 -5.5708e-03  8.8981e-03\n",
       "  \n",
       "  ( 0 , 1 ,.,.) = \n",
       "   -5.9831e-03 -2.1349e-02 -2.8085e-02\n",
       "    3.5786e-03  1.7651e-03 -3.9433e-02\n",
       "   -2.1829e-02 -6.2188e-03 -1.0850e-02\n",
       "  \n",
       "  ( 0 , 2 ,.,.) = \n",
       "   -1.0531e-02 -3.2771e-03 -8.1178e-04\n",
       "   -2.5645e-02  1.5440e-02 -4.4430e-02\n",
       "   -3.2273e-02  4.4727e-03 -1.3181e-02\n",
       "      ... \n",
       "  \n",
       "  ( 0 ,509,.,.) = \n",
       "    1.9763e-02  1.9698e-02  2.0018e-02\n",
       "   -1.1657e-02  1.1971e-02  1.9733e-03\n",
       "    4.4129e-02  1.4642e-02  2.4721e-02\n",
       "  \n",
       "  ( 0 ,510,.,.) = \n",
       "   -1.3089e-02 -2.8597e-02  1.3345e-02\n",
       "   -1.2364e-02 -2.4829e-02  1.0577e-03\n",
       "   -1.9522e-03 -1.4312e-03 -1.1603e-02\n",
       "  \n",
       "  ( 0 ,511,.,.) = \n",
       "    8.6869e-03 -2.0490e-02 -6.7392e-03\n",
       "   -2.0967e-02 -1.5726e-03  1.1185e-02\n",
       "    3.5068e-02  3.1704e-02  2.7728e-02\n",
       "          \n",
       "  \n",
       "  ( 1 , 0 ,.,.) = \n",
       "    5.9133e-04  1.0665e-02  3.8149e-03\n",
       "   -5.3510e-03  3.8794e-03 -2.3545e-03\n",
       "    9.1984e-03  7.7809e-04  6.9865e-03\n",
       "  \n",
       "  ( 1 , 1 ,.,.) = \n",
       "    9.9122e-03  3.4505e-03 -1.6343e-02\n",
       "    7.4979e-03  9.9734e-03  5.0292e-03\n",
       "   -1.4524e-02  5.6135e-03 -1.5644e-03\n",
       "  \n",
       "  ( 1 , 2 ,.,.) = \n",
       "   -5.0528e-03 -2.0092e-02  1.8799e-02\n",
       "    7.2575e-03 -2.9231e-02  4.0982e-03\n",
       "    2.1705e-03 -5.5829e-03  5.7975e-03\n",
       "      ... \n",
       "  \n",
       "  ( 1 ,509,.,.) = \n",
       "    2.1443e-02 -1.0388e-02  3.0068e-02\n",
       "    3.5086e-03 -1.2448e-02 -6.4802e-03\n",
       "   -7.1002e-03 -2.3293e-02  6.9675e-03\n",
       "  \n",
       "  ( 1 ,510,.,.) = \n",
       "   -2.6557e-03  2.0668e-02  1.1029e-02\n",
       "    4.7958e-02 -2.4087e-02  1.8890e-02\n",
       "    3.1797e-02  1.6747e-02  2.8820e-02\n",
       "  \n",
       "  ( 1 ,511,.,.) = \n",
       "   -7.5833e-04  8.1661e-03 -1.0342e-02\n",
       "    6.6714e-04  8.9675e-03  9.8559e-03\n",
       "   -9.9952e-03  3.4103e-02 -2.8504e-03\n",
       "          \n",
       "  \n",
       "  ( 2 , 0 ,.,.) = \n",
       "    2.9419e-02  6.0626e-03  1.1345e-03\n",
       "   -7.2819e-03  6.9901e-03 -3.0096e-02\n",
       "    5.2732e-03 -3.2657e-02  9.2930e-03\n",
       "  \n",
       "  ( 2 , 1 ,.,.) = \n",
       "    8.3089e-03  1.1266e-03  5.1190e-03\n",
       "    7.7101e-03  1.9887e-03  3.0445e-02\n",
       "    1.1839e-02  2.0539e-03  1.1598e-02\n",
       "  \n",
       "  ( 2 , 2 ,.,.) = \n",
       "   -1.6821e-02  4.6096e-03  1.9103e-02\n",
       "    3.7660e-02 -9.5727e-03  2.8823e-02\n",
       "    1.5019e-02  3.4212e-02  1.2880e-02\n",
       "      ... \n",
       "  \n",
       "  ( 2 ,509,.,.) = \n",
       "    1.3707e-02  1.5729e-02  1.4349e-02\n",
       "   -7.1524e-03  4.5917e-03 -2.3954e-02\n",
       "   -2.7482e-02  1.7684e-02  2.0127e-02\n",
       "  \n",
       "  ( 2 ,510,.,.) = \n",
       "    3.8885e-02  2.6743e-02 -2.8434e-03\n",
       "    1.1628e-02  2.0537e-02 -2.3090e-02\n",
       "   -8.7735e-03 -1.5184e-02  1.0046e-02\n",
       "  \n",
       "  ( 2 ,511,.,.) = \n",
       "    2.2059e-02 -3.2170e-02 -2.3526e-02\n",
       "   -6.3260e-03 -1.5903e-02  1.7120e-02\n",
       "   -7.4089e-04 -3.4131e-03 -1.6273e-02\n",
       "  ...     \n",
       "          \n",
       "  \n",
       "  (509, 0 ,.,.) = \n",
       "   -5.9979e-03  4.1559e-02  1.3514e-02\n",
       "   -2.9180e-02 -2.2101e-02  4.6931e-03\n",
       "    3.1057e-02  2.5237e-02 -3.6394e-02\n",
       "  \n",
       "  (509, 1 ,.,.) = \n",
       "    2.4093e-02 -2.2452e-02  5.0977e-03\n",
       "   -3.0024e-03 -2.0226e-02 -1.0698e-02\n",
       "    1.7102e-02  1.7836e-02 -3.7790e-02\n",
       "  \n",
       "  (509, 2 ,.,.) = \n",
       "    8.2104e-03 -1.6755e-03  1.2547e-02\n",
       "   -3.1537e-03 -1.4481e-03  1.1322e-02\n",
       "   -1.1046e-02 -5.4828e-03 -1.1687e-02\n",
       "      ... \n",
       "  \n",
       "  (509,509,.,.) = \n",
       "    4.1630e-03 -1.8947e-02 -2.2968e-02\n",
       "   -1.3972e-03 -2.8387e-02 -2.2718e-02\n",
       "   -1.0745e-02 -5.0362e-03 -2.4432e-02\n",
       "  \n",
       "  (509,510,.,.) = \n",
       "   -1.1274e-02  2.4606e-05  2.8191e-02\n",
       "   -1.0886e-02 -4.0098e-04 -1.6655e-02\n",
       "    1.3007e-02 -6.2804e-03 -2.0793e-02\n",
       "  \n",
       "  (509,511,.,.) = \n",
       "   -1.3765e-02  3.7675e-02 -1.2271e-03\n",
       "    1.1687e-02 -1.0700e-02  1.5435e-02\n",
       "    2.8736e-03 -9.5372e-04  1.4444e-03\n",
       "          \n",
       "  \n",
       "  (510, 0 ,.,.) = \n",
       "   -1.0877e-03  7.0400e-03  2.9821e-04\n",
       "    3.0185e-03 -1.7028e-02 -1.8617e-02\n",
       "    3.8950e-03  3.3813e-03 -1.5285e-03\n",
       "  \n",
       "  (510, 1 ,.,.) = \n",
       "    5.7953e-03 -1.9294e-03 -4.4487e-03\n",
       "   -1.5629e-03  2.0408e-03  1.3140e-02\n",
       "   -2.0388e-02 -1.3953e-02 -2.2164e-02\n",
       "  \n",
       "  (510, 2 ,.,.) = \n",
       "    1.0754e-02 -1.7144e-02 -2.6745e-02\n",
       "   -5.3042e-04 -2.5652e-03 -4.2163e-02\n",
       "   -1.7137e-03  2.5087e-03 -3.3142e-02\n",
       "      ... \n",
       "  \n",
       "  (510,509,.,.) = \n",
       "    5.1905e-03  4.8754e-03 -2.0282e-02\n",
       "   -2.2649e-02  3.0087e-02 -9.4772e-03\n",
       "    1.9762e-02  2.9706e-03  2.2424e-02\n",
       "  \n",
       "  (510,510,.,.) = \n",
       "    2.0134e-02 -3.0952e-02 -1.2252e-02\n",
       "    1.4083e-02 -1.8453e-02  5.2416e-03\n",
       "   -8.7264e-03 -2.8479e-03 -2.1697e-02\n",
       "  \n",
       "  (510,511,.,.) = \n",
       "    1.5528e-02 -2.4088e-02 -2.0504e-02\n",
       "    1.0994e-02 -2.2540e-02  1.3290e-03\n",
       "    2.8872e-03 -1.4046e-02 -9.0121e-03\n",
       "          \n",
       "  \n",
       "  (511, 0 ,.,.) = \n",
       "    2.6804e-02 -1.5249e-02  2.6518e-02\n",
       "    7.5452e-03 -1.5573e-02 -8.9947e-03\n",
       "    1.4894e-03 -2.8205e-02 -8.7300e-04\n",
       "  \n",
       "  (511, 1 ,.,.) = \n",
       "    1.7702e-03  7.4771e-03  2.5801e-03\n",
       "   -1.5103e-02  3.8345e-02  5.2914e-04\n",
       "    1.5219e-02  1.6040e-02  1.7785e-02\n",
       "  \n",
       "  (511, 2 ,.,.) = \n",
       "   -8.7691e-03  1.2976e-02  1.0493e-02\n",
       "   -2.1948e-02 -1.4408e-02  7.3437e-03\n",
       "   -8.4705e-03 -5.8164e-03 -1.7130e-02\n",
       "      ... \n",
       "  \n",
       "  (511,509,.,.) = \n",
       "   -4.7640e-03 -1.5817e-04 -1.7343e-02\n",
       "   -1.0685e-02 -5.3455e-03  2.3549e-02\n",
       "   -3.1484e-03 -5.9241e-02 -8.4493e-03\n",
       "  \n",
       "  (511,510,.,.) = \n",
       "    2.7143e-02  3.5919e-03  2.5521e-04\n",
       "   -1.4225e-02 -8.3871e-03 -1.0189e-02\n",
       "    1.6349e-02 -1.8249e-02  4.1761e-02\n",
       "  \n",
       "  (511,511,.,.) = \n",
       "   -6.6957e-03  1.8473e-02  3.6592e-03\n",
       "   -2.5449e-02 -1.7152e-02 -1.2557e-02\n",
       "    1.3344e-02 -2.3976e-02  1.3944e-02\n",
       "  [torch.cuda.FloatTensor of size 512x512x3x3 (GPU 0)], Parameter containing:\n",
       "   0.9073\n",
       "   0.6178\n",
       "   0.5908\n",
       "   0.5481\n",
       "   0.5974\n",
       "   0.5435\n",
       "   0.4186\n",
       "   0.6063\n",
       "   0.5337\n",
       "   0.7949\n",
       "   0.7181\n",
       "   0.6105\n",
       "   0.4759\n",
       "   0.5753\n",
       "   0.5812\n",
       "   0.6789\n",
       "   0.7158\n",
       "   0.8325\n",
       "   0.4781\n",
       "   0.7504\n",
       "   0.6091\n",
       "   0.4307\n",
       "   0.4155\n",
       "   0.4974\n",
       "   0.5017\n",
       "   0.6268\n",
       "   0.5428\n",
       "   0.3301\n",
       "   0.5509\n",
       "   0.5806\n",
       "   0.3866\n",
       "   0.3541\n",
       "   0.3804\n",
       "   0.3770\n",
       "   0.4689\n",
       "   0.7297\n",
       "   0.3547\n",
       "   0.7651\n",
       "   0.6272\n",
       "   0.5639\n",
       "   0.5212\n",
       "   0.4255\n",
       "   0.6525\n",
       "   0.4191\n",
       "   0.5891\n",
       "   0.4900\n",
       "   0.3752\n",
       "   0.5402\n",
       "   0.5907\n",
       "   0.5120\n",
       "   0.5275\n",
       "   0.7343\n",
       "   0.4202\n",
       "   0.7167\n",
       "   0.6581\n",
       "   0.3601\n",
       "   0.5175\n",
       "   0.7329\n",
       "   0.4070\n",
       "   0.6201\n",
       "   0.4384\n",
       "   0.5579\n",
       "   0.4745\n",
       "   0.4478\n",
       "   0.5821\n",
       "   0.4803\n",
       "   0.7978\n",
       "   0.5707\n",
       "   0.3886\n",
       "   0.3483\n",
       "   0.4008\n",
       "   0.4594\n",
       "   0.5009\n",
       "   0.6018\n",
       "   0.3550\n",
       "   0.3661\n",
       "   0.8038\n",
       "   0.7568\n",
       "   0.9122\n",
       "   0.5613\n",
       "   0.7745\n",
       "   0.5925\n",
       "   0.5599\n",
       "   0.3494\n",
       "   0.3274\n",
       "   0.8746\n",
       "   0.5608\n",
       "   0.5349\n",
       "   0.5779\n",
       "   0.6257\n",
       "   0.7122\n",
       "   0.7586\n",
       "   0.5938\n",
       "   0.2446\n",
       "   0.5134\n",
       "   0.5733\n",
       "   0.7456\n",
       "   0.7629\n",
       "   0.7912\n",
       "   0.5291\n",
       "   0.6190\n",
       "   0.6364\n",
       "   0.6056\n",
       "   0.3703\n",
       "   0.4800\n",
       "   0.4697\n",
       "   0.6069\n",
       "   0.3284\n",
       "   0.5450\n",
       "   0.5683\n",
       "   0.4401\n",
       "   0.6122\n",
       "   0.4415\n",
       "   0.7578\n",
       "   0.5470\n",
       "   0.5874\n",
       "   0.4872\n",
       "   0.5051\n",
       "   0.4954\n",
       "   0.5376\n",
       "   0.5560\n",
       "   0.5036\n",
       "   0.6091\n",
       "   0.9123\n",
       "   0.4897\n",
       "   0.5348\n",
       "   0.7752\n",
       "   0.3157\n",
       "   0.7752\n",
       "   0.6429\n",
       "   0.4713\n",
       "   0.3126\n",
       "   0.7656\n",
       "   0.4581\n",
       "   0.7052\n",
       "   0.7547\n",
       "   0.8088\n",
       "   0.7674\n",
       "   0.4561\n",
       "   0.6504\n",
       "   0.5250\n",
       "   0.5518\n",
       "   0.4496\n",
       "   0.7559\n",
       "   0.5446\n",
       "   0.7124\n",
       "   0.8208\n",
       "   0.2575\n",
       "   0.5964\n",
       "   0.8115\n",
       "   0.4695\n",
       "   0.5503\n",
       "   0.4468\n",
       "   0.6792\n",
       "   0.6196\n",
       "   0.7837\n",
       "   0.7500\n",
       "   0.4493\n",
       "   0.6909\n",
       "   0.4362\n",
       "   0.5184\n",
       "   0.4573\n",
       "   0.7994\n",
       "   0.3687\n",
       "   0.3093\n",
       "   0.7396\n",
       "   0.5907\n",
       "   0.6039\n",
       "   0.5880\n",
       "   0.2280\n",
       "   0.6119\n",
       "   0.5669\n",
       "   0.4682\n",
       "   0.3468\n",
       "   0.5089\n",
       "   0.7154\n",
       "   0.7346\n",
       "   0.5036\n",
       "   0.4381\n",
       "   0.4316\n",
       "   0.5259\n",
       "   0.4221\n",
       "   0.6360\n",
       "   0.3114\n",
       "   0.7660\n",
       "   0.5842\n",
       "   0.4875\n",
       "   0.7393\n",
       "   0.6520\n",
       "   0.5387\n",
       "   0.4040\n",
       "   0.4876\n",
       "   0.7405\n",
       "   0.6109\n",
       "   0.5414\n",
       "   0.5416\n",
       "   0.5062\n",
       "   0.5098\n",
       "   0.8529\n",
       "   0.5394\n",
       "   0.3512\n",
       "   0.6222\n",
       "   0.4552\n",
       "   0.6193\n",
       "   0.5089\n",
       "   0.7353\n",
       "   0.4849\n",
       "   0.3724\n",
       "   0.5460\n",
       "   0.4984\n",
       "   0.3304\n",
       "   0.7138\n",
       "   0.5145\n",
       "   0.5174\n",
       "   0.4946\n",
       "   0.4848\n",
       "   0.5430\n",
       "   0.7866\n",
       "   0.4332\n",
       "   0.3126\n",
       "   0.6283\n",
       "   0.6034\n",
       "   0.5324\n",
       "   0.6048\n",
       "   0.5801\n",
       "   0.5657\n",
       "   0.3823\n",
       "   0.7508\n",
       "   0.3501\n",
       "   0.5016\n",
       "   0.4988\n",
       "   0.4627\n",
       "   0.5710\n",
       "   0.5120\n",
       "   0.1344\n",
       "   0.5557\n",
       "   0.5464\n",
       "   0.5263\n",
       "   0.5034\n",
       "   0.5202\n",
       "   0.6288\n",
       "   1.0855\n",
       "   0.6081\n",
       "   0.6286\n",
       "   0.8648\n",
       "   0.6037\n",
       "   0.6337\n",
       "   0.5389\n",
       "   0.4311\n",
       "   0.6127\n",
       "   0.2596\n",
       "   0.4865\n",
       "   0.3925\n",
       "   0.4692\n",
       "   0.5350\n",
       "   0.5936\n",
       "   0.4873\n",
       "   0.4496\n",
       "   0.4652\n",
       "   0.4461\n",
       "   0.5961\n",
       "   0.5460\n",
       "   0.6176\n",
       "   0.4824\n",
       "   0.6134\n",
       "   0.4234\n",
       "   0.5824\n",
       "   0.9170\n",
       "   0.5474\n",
       "   0.7593\n",
       "   0.7948\n",
       "   0.3848\n",
       "   0.3175\n",
       "   0.6107\n",
       "   0.4148\n",
       "   0.3237\n",
       "   0.5383\n",
       "   0.5474\n",
       "   0.7313\n",
       "   0.6194\n",
       "   1.0176\n",
       "   0.7693\n",
       "   0.5204\n",
       "   0.5302\n",
       "   0.3875\n",
       "   0.6082\n",
       "   0.6173\n",
       "   0.5899\n",
       "   0.4845\n",
       "   0.5321\n",
       "   0.6098\n",
       "   0.4636\n",
       "   0.4090\n",
       "   0.7680\n",
       "   0.6050\n",
       "   0.5238\n",
       "   0.5781\n",
       "   0.4433\n",
       "   0.5030\n",
       "   0.6591\n",
       "   0.6164\n",
       "   0.4707\n",
       "   0.5396\n",
       "   0.5222\n",
       "   0.8900\n",
       "   0.5167\n",
       "   0.5519\n",
       "   0.4774\n",
       "   0.5966\n",
       "   0.5989\n",
       "   0.4575\n",
       "   0.5577\n",
       "   0.5325\n",
       "   0.4831\n",
       "   0.6283\n",
       "   0.5229\n",
       "   0.3655\n",
       "   0.5678\n",
       "   0.6798\n",
       "   0.7833\n",
       "   0.5851\n",
       "   0.6066\n",
       "   0.6532\n",
       "   0.5620\n",
       "   0.6603\n",
       "   0.3577\n",
       "   0.5186\n",
       "   0.4600\n",
       "   0.5715\n",
       "   0.4065\n",
       "   0.6821\n",
       "   0.6488\n",
       "   0.5294\n",
       "   0.5432\n",
       "   0.5266\n",
       "   0.5335\n",
       "   0.6415\n",
       "   0.5759\n",
       "   0.3888\n",
       "   0.4887\n",
       "   0.5928\n",
       "   0.7555\n",
       "   0.5651\n",
       "   0.6619\n",
       "   0.5812\n",
       "   0.6538\n",
       "   0.5828\n",
       "   0.5212\n",
       "   0.6490\n",
       "   0.7064\n",
       "   0.7684\n",
       "   0.6546\n",
       "   0.6207\n",
       "   0.5073\n",
       "   0.5738\n",
       "   0.3725\n",
       "   0.3890\n",
       "   0.4413\n",
       "   0.4990\n",
       "   0.5812\n",
       "   0.5047\n",
       "   0.5700\n",
       "   0.3577\n",
       "   0.4361\n",
       "   0.3705\n",
       "   0.3042\n",
       "   0.6277\n",
       "   0.5190\n",
       "   0.5071\n",
       "   0.7268\n",
       "   0.5315\n",
       "   0.5405\n",
       "   0.7381\n",
       "   0.6174\n",
       "   0.5264\n",
       "   0.3829\n",
       "   0.5741\n",
       "   0.5336\n",
       "   0.5123\n",
       "   0.8015\n",
       "   0.5947\n",
       "   0.5674\n",
       "   0.3550\n",
       "   0.5338\n",
       "   0.3977\n",
       "   0.4808\n",
       "   0.4222\n",
       "   0.8010\n",
       "   0.5227\n",
       "   0.6069\n",
       "   0.3544\n",
       "   0.8040\n",
       "   0.9281\n",
       "   0.5974\n",
       "   0.5957\n",
       "   0.9160\n",
       "   0.5311\n",
       "   0.5635\n",
       "   0.6118\n",
       "   0.7748\n",
       "   0.5502\n",
       "   0.5632\n",
       "   0.7106\n",
       "   0.4855\n",
       "   0.7643\n",
       "   0.5568\n",
       "   0.7624\n",
       "   0.4788\n",
       "   0.4732\n",
       "   0.6897\n",
       "   0.4656\n",
       "   0.5925\n",
       "   0.5775\n",
       "   0.4822\n",
       "   0.6844\n",
       "   0.3711\n",
       "   0.8179\n",
       "   0.5275\n",
       "   0.5577\n",
       "   0.6327\n",
       "   0.7929\n",
       "   0.5414\n",
       "   0.3942\n",
       "   0.7022\n",
       "   0.7630\n",
       "   0.4265\n",
       "   0.5160\n",
       "   0.6683\n",
       "   0.5555\n",
       "   0.4329\n",
       "   0.5211\n",
       "   0.7402\n",
       "   0.5626\n",
       "   0.4798\n",
       "   0.3034\n",
       "   0.6229\n",
       "   0.6969\n",
       "   0.3862\n",
       "   0.5823\n",
       "   0.5695\n",
       "   0.6086\n",
       "   0.4839\n",
       "   0.5402\n",
       "   0.6025\n",
       "   0.5174\n",
       "   0.5266\n",
       "   0.6110\n",
       "   0.5108\n",
       "   0.6974\n",
       "   0.4309\n",
       "   0.5070\n",
       "   0.5284\n",
       "   0.7690\n",
       "   0.5908\n",
       "   0.6509\n",
       "   0.4892\n",
       "   0.7325\n",
       "   0.4448\n",
       "   0.5727\n",
       "   0.3337\n",
       "   0.6149\n",
       "   0.5739\n",
       "   0.5376\n",
       "   0.5997\n",
       "   0.4074\n",
       "   0.5446\n",
       "   0.3966\n",
       "   0.6303\n",
       "   0.5574\n",
       "   0.6381\n",
       "   0.5726\n",
       "   0.5151\n",
       "   0.3630\n",
       "   0.6781\n",
       "   0.6006\n",
       "   0.4172\n",
       "   0.3486\n",
       "   0.5455\n",
       "   0.5520\n",
       "   0.6001\n",
       "   0.5952\n",
       "   0.5242\n",
       "   0.5522\n",
       "   0.8116\n",
       "   0.6321\n",
       "   0.5653\n",
       "   0.7857\n",
       "   0.6578\n",
       "   0.7964\n",
       "   0.7253\n",
       "   0.7546\n",
       "   0.4793\n",
       "   0.4480\n",
       "   0.7080\n",
       "   0.3700\n",
       "   0.5568\n",
       "   0.6648\n",
       "   0.6299\n",
       "   0.3819\n",
       "   0.4941\n",
       "   0.5819\n",
       "   0.5686\n",
       "   0.7458\n",
       "   0.4923\n",
       "   0.3589\n",
       "   0.5885\n",
       "   0.6052\n",
       "   0.3577\n",
       "   0.7876\n",
       "   0.5086\n",
       "   0.6411\n",
       "   0.4023\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "   0.0149\n",
       "  -0.1243\n",
       "  -0.1891\n",
       "  -0.1025\n",
       "  -0.0740\n",
       "  -0.1465\n",
       "  -0.1205\n",
       "  -0.1288\n",
       "  -0.0781\n",
       "  -0.1851\n",
       "  -0.2030\n",
       "  -0.1790\n",
       "  -0.1827\n",
       "  -0.0894\n",
       "  -0.1557\n",
       "  -0.0327\n",
       "  -0.1972\n",
       "  -0.0553\n",
       "  -0.1474\n",
       "  -0.2346\n",
       "  -0.1338\n",
       "  -0.1393\n",
       "  -0.1459\n",
       "  -0.1665\n",
       "  -0.1411\n",
       "  -0.0875\n",
       "  -0.1791\n",
       "  -0.1284\n",
       "  -0.1859\n",
       "  -0.2694\n",
       "  -0.1161\n",
       "  -0.1486\n",
       "  -0.1716\n",
       "  -0.1571\n",
       "  -0.2108\n",
       "  -0.1733\n",
       "  -0.1349\n",
       "  -0.2006\n",
       "  -0.1548\n",
       "  -0.1196\n",
       "  -0.1478\n",
       "  -0.1622\n",
       "  -0.1851\n",
       "  -0.1733\n",
       "  -0.1847\n",
       "  -0.1426\n",
       "  -0.1959\n",
       "  -0.1707\n",
       "  -0.1952\n",
       "  -0.0542\n",
       "  -0.1998\n",
       "  -0.1969\n",
       "  -0.1638\n",
       "  -0.2189\n",
       "  -0.1411\n",
       "  -0.1201\n",
       "  -0.1367\n",
       "  -0.1595\n",
       "  -0.0900\n",
       "  -0.1118\n",
       "  -0.8609\n",
       "  -0.1222\n",
       "  -0.1958\n",
       "  -0.1617\n",
       "  -0.1712\n",
       "  -0.1624\n",
       "   0.0894\n",
       "  -0.0454\n",
       "  -0.1799\n",
       "  -0.1108\n",
       "  -0.1104\n",
       "  -0.1390\n",
       "  -0.1683\n",
       "  -0.1944\n",
       "  -0.1422\n",
       "  -0.1798\n",
       "   0.0081\n",
       "  -0.2037\n",
       "  -0.3471\n",
       "  -0.1874\n",
       "  -0.1613\n",
       "  -0.1685\n",
       "  -0.2686\n",
       "  -0.2483\n",
       "  -0.2078\n",
       "  -0.0164\n",
       "  -0.1702\n",
       "  -0.0489\n",
       "  -0.1346\n",
       "  -0.1860\n",
       "  -0.1177\n",
       "  -0.1985\n",
       "  -0.0446\n",
       "  -0.1973\n",
       "  -0.1628\n",
       "  -0.1585\n",
       "  -0.0602\n",
       "  -0.2126\n",
       "  -0.1489\n",
       "  -0.1866\n",
       "  -0.1611\n",
       "  -0.2680\n",
       "  -0.2221\n",
       "  -0.1950\n",
       "  -0.2616\n",
       "  -0.1597\n",
       "  -0.2028\n",
       "  -0.1514\n",
       "  -0.2005\n",
       "  -0.0318\n",
       "  -0.1866\n",
       "  -0.0833\n",
       "  -0.1165\n",
       "  -0.2239\n",
       "  -0.1580\n",
       "  -0.0626\n",
       "  -0.0487\n",
       "  -0.1741\n",
       "  -0.2217\n",
       "  -0.1362\n",
       "  -0.1528\n",
       "  -0.1816\n",
       "  -0.0868\n",
       "  -0.2540\n",
       "  -0.2099\n",
       "  -0.1957\n",
       "  -0.1793\n",
       "  -0.1392\n",
       "  -0.1919\n",
       "  -0.1304\n",
       "  -0.1722\n",
       "  -0.1963\n",
       "  -0.2160\n",
       "  -0.1512\n",
       "  -0.0930\n",
       "  -0.1217\n",
       "   0.0647\n",
       "  -0.1075\n",
       "  -0.2198\n",
       "  -0.0985\n",
       "  -0.0959\n",
       "  -0.1837\n",
       "  -0.1096\n",
       "  -0.2290\n",
       "  -0.1505\n",
       "  -0.0338\n",
       "   0.0467\n",
       "  -0.1973\n",
       "  -0.0427\n",
       "  -0.2613\n",
       "  -0.0810\n",
       "  -0.2267\n",
       "  -0.1240\n",
       "  -0.2390\n",
       "  -0.1614\n",
       "  -0.2679\n",
       "  -0.2562\n",
       "  -0.1656\n",
       "  -0.2576\n",
       "  -0.1581\n",
       "  -0.1483\n",
       "  -0.1482\n",
       "  -0.2811\n",
       "  -0.1281\n",
       "  -0.1483\n",
       "  -0.3304\n",
       "  -0.1782\n",
       "  -0.1320\n",
       "  -0.2637\n",
       "  -0.2172\n",
       "  -0.1751\n",
       "  -0.1956\n",
       "  -0.2022\n",
       "  -0.1311\n",
       "  -0.1443\n",
       "  -0.2288\n",
       "  -0.1777\n",
       "  -0.0351\n",
       "  -0.1435\n",
       "  -0.1957\n",
       "  -0.1881\n",
       "  -0.1572\n",
       "  -0.1321\n",
       "  -0.2639\n",
       "  -0.2186\n",
       "  -0.0972\n",
       "  -0.2077\n",
       "  -0.0054\n",
       "  -0.3724\n",
       "  -0.2132\n",
       "  -0.1880\n",
       "  -0.1594\n",
       "  -0.1703\n",
       "  -0.2113\n",
       "  -0.2992\n",
       "  -0.1710\n",
       "  -0.1445\n",
       "  -0.0439\n",
       "  -0.2519\n",
       "  -0.1548\n",
       "  -0.2019\n",
       "  -0.3388\n",
       "  -0.1500\n",
       "  -0.1544\n",
       "  -0.1309\n",
       "  -0.2046\n",
       "  -0.0980\n",
       "  -0.0147\n",
       "  -0.2249\n",
       "  -0.2781\n",
       "  -0.1297\n",
       "  -0.2725\n",
       "  -0.1551\n",
       "  -0.2273\n",
       "  -0.1552\n",
       "  -0.1547\n",
       "  -0.2282\n",
       "  -0.1893\n",
       "  -0.1676\n",
       "  -0.1086\n",
       "  -0.1565\n",
       "  -0.2275\n",
       "  -0.1236\n",
       "  -0.1604\n",
       "  -0.0894\n",
       "  -0.1367\n",
       "  -0.1110\n",
       "  -0.2282\n",
       "  -0.1557\n",
       "  -0.1431\n",
       "  -0.1957\n",
       "  -0.1645\n",
       "  -0.1064\n",
       "  -0.0569\n",
       "  -0.2806\n",
       "  -0.0950\n",
       "  -0.2066\n",
       "  -0.1736\n",
       "  -0.2010\n",
       "  -0.1215\n",
       "  -0.1631\n",
       "   0.2545\n",
       "  -0.1089\n",
       "  -0.1956\n",
       "  -0.1194\n",
       "  -0.0755\n",
       "  -0.1081\n",
       "  -0.2400\n",
       "  -0.1388\n",
       "  -0.1521\n",
       "  -0.1089\n",
       "  -0.2694\n",
       "  -0.1094\n",
       "  -0.1578\n",
       "  -0.2020\n",
       "  -0.1554\n",
       "  -0.2248\n",
       "  -0.1865\n",
       "  -0.1591\n",
       "  -0.1378\n",
       "  -0.1453\n",
       "  -0.1206\n",
       "  -0.2450\n",
       "  -0.2562\n",
       "  -0.1196\n",
       "  -0.1560\n",
       "  -0.0971\n",
       "  -0.2509\n",
       "  -0.1472\n",
       "  -0.2060\n",
       "  -0.2267\n",
       "  -0.1894\n",
       "  -0.1238\n",
       "  -0.0395\n",
       "  -0.1270\n",
       "  -0.1514\n",
       "  -0.1742\n",
       "  -0.1523\n",
       "  -0.2151\n",
       "  -0.1855\n",
       "  -0.2287\n",
       "  -0.0183\n",
       "  -0.1790\n",
       "  -0.3033\n",
       "  -0.1367\n",
       "  -0.1884\n",
       "  -0.1791\n",
       "  -0.1661\n",
       "  -0.0215\n",
       "  -0.0641\n",
       "  -0.1416\n",
       "  -0.1180\n",
       "  -0.1602\n",
       "  -0.1499\n",
       "  -0.2389\n",
       "  -0.1632\n",
       "  -0.1326\n",
       "  -0.1432\n",
       "  -0.1110\n",
       "  -0.2947\n",
       "  -0.2625\n",
       "  -0.0592\n",
       "  -0.2568\n",
       "  -0.1771\n",
       "   0.0891\n",
       "  -0.2428\n",
       "  -0.1447\n",
       "  -0.1380\n",
       "  -0.2000\n",
       "  -0.1498\n",
       "  -0.1549\n",
       "  -0.1240\n",
       "  -0.1913\n",
       "  -0.2053\n",
       "  -0.1239\n",
       "  -0.2400\n",
       "  -0.1904\n",
       "  -0.2450\n",
       "  -0.1740\n",
       "  -0.1641\n",
       "  -0.1109\n",
       "  -0.1503\n",
       "  -0.1730\n",
       "  -0.1870\n",
       "  -0.1656\n",
       "  -0.2358\n",
       "  -0.2707\n",
       "  -0.1547\n",
       "  -0.6432\n",
       "  -0.1908\n",
       "  -0.1325\n",
       "  -0.0725\n",
       "  -0.2189\n",
       "  -0.0859\n",
       "  -0.1986\n",
       "  -0.2013\n",
       "  -0.1800\n",
       "  -0.1663\n",
       "  -0.1978\n",
       "  -0.1467\n",
       "  -0.0635\n",
       "  -0.2544\n",
       "  -0.3871\n",
       "  -0.0296\n",
       "  -0.2245\n",
       "  -0.1132\n",
       "  -0.0493\n",
       "  -0.2004\n",
       "  -0.2153\n",
       "  -0.2131\n",
       "  -0.2410\n",
       "  -0.2470\n",
       "  -0.1554\n",
       "  -0.1466\n",
       "  -0.0230\n",
       "  -0.1098\n",
       "  -0.1741\n",
       "  -0.1438\n",
       "  -0.1957\n",
       "  -0.0826\n",
       "  -0.1424\n",
       "  -0.0774\n",
       "  -0.2037\n",
       "  -0.1784\n",
       "  -0.1300\n",
       "  -0.2426\n",
       "  -0.1504\n",
       "  -0.2296\n",
       "  -0.1757\n",
       "  -0.2264\n",
       "  -0.2602\n",
       "  -0.2750\n",
       "  -0.2176\n",
       "  -0.1874\n",
       "  -0.0250\n",
       "  -0.1071\n",
       "  -0.1348\n",
       "  -0.1697\n",
       "  -0.1163\n",
       "  -0.1516\n",
       "  -0.1950\n",
       "  -0.1192\n",
       "  -0.2384\n",
       "  -0.2098\n",
       "  -0.1322\n",
       "  -0.1576\n",
       "  -0.1472\n",
       "  -0.2484\n",
       "  -0.1466\n",
       "  -0.0260\n",
       "  -0.2025\n",
       "  -0.3655\n",
       "  -0.3370\n",
       "  -0.2462\n",
       "  -0.1856\n",
       "  -0.2589\n",
       "  -0.1435\n",
       "  -0.1128\n",
       "  -0.1900\n",
       "  -0.2394\n",
       "  -0.1807\n",
       "  -0.0396\n",
       "  -0.2350\n",
       "  -0.1693\n",
       "  -0.2107\n",
       "  -0.1533\n",
       "  -0.2068\n",
       "  -0.0610\n",
       "  -0.1038\n",
       "  -0.2045\n",
       "  -0.1064\n",
       "  -0.1818\n",
       "  -0.1741\n",
       "  -0.1876\n",
       "  -0.2208\n",
       "  -0.1095\n",
       "  -0.2360\n",
       "  -0.1406\n",
       "  -0.1306\n",
       "  -0.3152\n",
       "  -0.2977\n",
       "  -0.0312\n",
       "  -0.1345\n",
       "  -0.2296\n",
       "  -0.1881\n",
       "  -0.1877\n",
       "  -0.2982\n",
       "  -0.1874\n",
       "  -0.1479\n",
       "  -0.1799\n",
       "  -0.1468\n",
       "  -0.2563\n",
       "  -0.1719\n",
       "  -0.1478\n",
       "  -0.2250\n",
       "  -0.0612\n",
       "  -0.0471\n",
       "  -0.1320\n",
       "  -0.1447\n",
       "  -0.1084\n",
       "  -0.1818\n",
       "  -0.2908\n",
       "  -0.1455\n",
       "  -0.1748\n",
       "  -0.0900\n",
       "  -0.1611\n",
       "  -0.2055\n",
       "  -0.1552\n",
       "  -0.2949\n",
       "  -0.1428\n",
       "  -0.1865\n",
       "  -0.1893\n",
       "  -0.1853\n",
       "  -0.0865\n",
       "  -0.0577\n",
       "  -0.1349\n",
       "  -0.2183\n",
       "  -0.2499\n",
       "  -0.2196\n",
       "  -0.1573\n",
       "  -0.0964\n",
       "  -0.1533\n",
       "  -0.2780\n",
       "  -0.2144\n",
       "  -0.1497\n",
       "  -0.0307\n",
       "  -0.1489\n",
       "  -0.0549\n",
       "  -0.0749\n",
       "  -0.2133\n",
       "  -0.1142\n",
       "  -0.0649\n",
       "  -0.1591\n",
       "  -0.1935\n",
       "  -0.1506\n",
       "  -0.1928\n",
       "  -0.1243\n",
       "  -0.1727\n",
       "  -0.1194\n",
       "  -0.0526\n",
       "  -0.1441\n",
       "  -0.1407\n",
       "  -0.1421\n",
       "  -0.2398\n",
       "  -0.1509\n",
       "  -0.0482\n",
       "  -0.1874\n",
       "  -0.1826\n",
       "  -0.3855\n",
       "  -0.0379\n",
       "  -0.0433\n",
       "  -0.1896\n",
       "  -0.1226\n",
       "  -0.2293\n",
       "  -0.1989\n",
       "  -0.1470\n",
       "  -0.3205\n",
       "  -0.2027\n",
       "  -0.0320\n",
       "  -0.2176\n",
       "  -0.1304\n",
       "  -0.1521\n",
       "  -0.2316\n",
       "  -0.1730\n",
       "  -0.1662\n",
       "  -0.2325\n",
       "  -0.0849\n",
       "  -0.2336\n",
       "  -0.1791\n",
       "  -0.1549\n",
       "  -0.2688\n",
       "  -0.1284\n",
       "  [torch.cuda.FloatTensor of size 512 (GPU 0)], Parameter containing:\n",
       "  -0.3468  0.1209  0.0423  ...   0.1610  0.0767  0.0355\n",
       "   0.3534 -0.1090  0.0209  ...  -0.1103 -0.0909  0.0001\n",
       "  [torch.cuda.FloatTensor of size 2x512 (GPU 0)], Parameter containing:\n",
       "  -0.3526\n",
       "   0.3223\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]],\n",
       " 'weight_decay': 0.0001}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optimizer.param_groups[0])\n",
    "optimizer.param_groups[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
