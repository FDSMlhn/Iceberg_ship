{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ReduceLROnPlateau\n",
    "#torch.multiprocessing.set_start_method(\"spawn\")\n",
    "import cnn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import progress_bar\n",
    "from skimage import transform as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_dir = 'data/processed/'\n",
    "\n",
    "train = pd.read_json(BASE_dir + 'train.json')\n",
    "test = pd.read_json(BASE_dir + 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "use_cuda= True if torch.cuda.is_available() else False\n",
    "#use_cuda =False\n",
    "#dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor \n",
    "dtype = torch.FloatTensor \n",
    "data=  pd.read_json(BASE_dir + 'train.json')\n",
    "\n",
    "class iceberg_dataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None, test=False): #data: 1604 * 3 *75* 75\n",
    "        self.data =data\n",
    "        self.label = torch.from_numpy(label).type(torch.LongTensor)\n",
    "        self.transform= transform\n",
    "        self.test= test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img, label=  self.data[idx], self.label[idx]\n",
    "        if self.transform is not None:\n",
    "            #Random Horizontal Flip and Vertical Flip \n",
    "            #https://discuss.pytorch.org/t/torch-from-numpy-not-support-negative-strides/3663\n",
    "            \n",
    "            #rotate, scale, shear, translation\n",
    "#             if self.test is False:\n",
    "#                 angle = np.random.uniform(0,360)\n",
    "#                 img = tf.rotate(img,angle=angle,resize=False)\n",
    "#                 scale1 = np.exp(np.random.uniform(np.log(1/1.2), np.log(1.2)))\n",
    "#                 scale2 = np.exp(np.random.uniform(np.log(1/1.2), np.log(1.2)))\n",
    "#                 #shear = np.random.uniform(-np.pi/18, np.pi/18)\n",
    "#                 #tran = np.random.uniform(-5, 5)\n",
    "#                 #aug = tf.AffineTransform(shear = shear, translation=tran, scale= (scale1, scale2))\n",
    "#                 aug = tf.AffineTransform(scale= (scale1, scale2))\n",
    "#                 img = tf.warp(img, inverse_map=aug)\n",
    "            \n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=1).copy()\n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=2).copy()\n",
    "            \n",
    "#             if self.test is False:\n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=1).copy()\n",
    "#                 if np.random.uniform()>0.5:\n",
    "#                     img = np.flip(img,axis=2).copy()\n",
    "#                 rotate = np.random.randint(4, size=1)\n",
    "#                 if rotate:\n",
    "#                     img = np.rot90(img,k=rotate,axes=(1,2)).copy()\n",
    "            pass\n",
    "        img = torch.from_numpy(img).type(dtype)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "def stack(row):\n",
    "    return np.stack(row[['c1','c2','c3']]).reshape(3,75,75)\n",
    "\n",
    "def raw_to_numpy(data):\n",
    "    img = []\n",
    "    data['c1'] = data['band_1'].apply(np.array)\n",
    "    data['c2'] = data['band_2'].apply(np.array)\n",
    "    data['c3'] = (data['c1'] + data['c2'])/2\n",
    "#     data['c3'] = (data['c1'] + data['c2'])/2\n",
    "    for _, row in data.iterrows():\n",
    "        img.append(stack(row))\n",
    "    return np.stack(img)\n",
    "\n",
    "def transform_compute(img):\n",
    "    train_mean = img.mean(axis=(0,2,3))\n",
    "    train_std = img.std(axis=(0,2,3))\n",
    "    return train_mean, train_std\n",
    "\n",
    "# def data_aug(X, y):    \n",
    "#     X_rot_30 = []\n",
    "#     X_rot_60 = [] \n",
    "#     X_h = np.flip(X, 3)\n",
    "#     X_v = np.flip(X, 2)\n",
    "#     for i in X:\n",
    "#         X_rot_30.append(tf.rotate(i,angle=30,resize=False))\n",
    "#         X_rot_60.append(tf.rotate(i,angle=60,resize=False))\n",
    "        \n",
    "#     X_rot_30 = np.stack(X_rot_30)\n",
    "#     X_rot_60 = np.stack(X_rot_60)\n",
    "#     ch_y = np.concatenate((y,y,y,y,y))\n",
    "#     ch_X = np.concatenate((X, X_h, X_v, X_rot_30, X_rot_60))\n",
    "#     return ch_X, ch_y\n",
    "\n",
    "def data_aug(X, y):    \n",
    "    X_rot_30 = []\n",
    "    X_rot_60 = [] \n",
    "    X_h = np.flip(X, 3)\n",
    "    X_v = np.flip(X, 2)\n",
    "    for i in X:\n",
    "        X_rot_30.append(tf.rotate(i,angle=90,resize=False))\n",
    "        X_rot_60.append(tf.rotate(i,angle=270,resize=False))\n",
    "        \n",
    "    X_rot_30 = np.stack(X_rot_30)\n",
    "    X_rot_60 = np.stack(X_rot_60)\n",
    "    ch_y = np.concatenate((y,y,y,y,y))\n",
    "    ch_X = np.concatenate((X, X_h, X_v, X_rot_30, X_rot_60))\n",
    "    return ch_X, ch_y\n",
    "\n",
    "\n",
    "def data_aug2(X, y):    \n",
    "    X_rot_90 = []\n",
    "    X_rot_180 = []\n",
    "    X_rot_270 = []\n",
    "    X_rot_90_hflip = []\n",
    "    X_rot_270_hflip = []\n",
    "    \n",
    "    X_h = np.flip(X, 3)\n",
    "    X_v = np.flip(X, 2)\n",
    "    for i in X:\n",
    "        X_rot_90.append(tf.rotate(i,angle=90,resize=False))\n",
    "        X_rot_180.append(tf.rotate(i,angle=180,resize=False))\n",
    "        X_rot_270.append(tf.rotate(i,angle=270,resize=False))\n",
    "        X_rot_90_hflip.append(np.flip(tf.rotate(i,angle=90,resize=False),2))\n",
    "        X_rot_270_hflip.append(np.flip(tf.rotate(i,angle=270,resize=False),2))\n",
    "    \n",
    "    \n",
    "    X_rot_90 = np.stack(X_rot_90)\n",
    "    X_rot_180 = np.stack(X_rot_180)\n",
    "    X_rot_270 = np.stack(X_rot_270 )\n",
    "    X_rot_90_hflip = np.stack(X_rot_90_hflip)\n",
    "    X_rot_270_hflip = np.stack(X_rot_270_hflip)\n",
    "    \n",
    "    ch_y = np.concatenate((y,y,y,y,y,y,y,y))\n",
    "    ch_X = np.concatenate((X, X_h, X_v,X_rot_90,X_rot_180,X_rot_270,X_rot_90_hflip,X_rot_270_hflip))\n",
    "    return ch_X, ch_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_X = raw_to_numpy(data)#.transpose(0,2,3,1)\n",
    "train_X.shape     #1604 * 3 *75* 75   N*c*H*W\n",
    "train_y = data['is_iceberg'].values # if iceberg then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.inc_angle = data.inc_angle.map(lambda x: 0.0 if x == 'na' else x)\n",
    "sum(np.where(data.inc_angle > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index=list(range(1300))\n",
    "# val_index= list(range(1300,1604))\n",
    "# train_index=list(range(304,1604)) \n",
    "# val_index= list(range(304))\n",
    "# # train_X[train_index].shape\n",
    "\n",
    "# # seed= np.random.RandomState(123)\n",
    "# # spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "# # train_index, val_index = next(spliter.split(train_X))\n",
    "# train_mean, train_std = transform_compute(train_X[train_index])\n",
    "# train_transform = T.Compose([\n",
    "#     T.Normalize(train_mean, train_std)\n",
    "# ])\n",
    "\n",
    "# train_dataset = iceberg_dataset(data= train_X[train_index], label=train_y[train_index], transform=train_transform)\n",
    "# val_dataset = iceberg_dataset(data= train_X[val_index], label=train_y[val_index], transform=train_transform, test=True)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "#                           shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "## add augmentation \n",
    "# seed= np.random.RandomState(123)\n",
    "# spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "# train_index, val_index = next(spliter.split(train_X))\n",
    "\n",
    "# train_X_af,train_y_af = data_aug(train_X[train_index], train_y[train_index])\n",
    "# train_mean, train_std = transform_compute(train_X_af)\n",
    "# train_transform = T.Compose([\n",
    "#     T.Normalize(train_mean, train_std)\n",
    "# ])\n",
    "\n",
    "# train_dataset = iceberg_dataset(data= train_X_af, label=train_y_af, transform=train_transform)\n",
    "# val_dataset = iceberg_dataset(data= train_X[val_index], label=train_y[val_index], transform=train_transform, test=True)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "#                           shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "#data.inc_angle = data.inc_angle.map(lambda x: 0.0 if x == 'na' else x)\n",
    "# train_X_del = train_X[data.inc_angle!='na',:,:,:]\n",
    "# train_y_del = train_y[data.inc_angle!='na']\n",
    "# # # train_X_del = train_X\n",
    "# # # train_y_del = train_y\n",
    "\n",
    "# seed= np.random.RandomState(123)\n",
    "# spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "# train_index, val_index = next(spliter.split(train_X_del))\n",
    "# # # train_index=list(range(284,1471)) \n",
    "# # # val_index= list(range(284))\n",
    "\n",
    "# train_mean, train_std = transform_compute(train_X_del[train_index])\n",
    "# train_transform = T.Compose([\n",
    "#     T.Normalize(train_mean, train_std)\n",
    "# ])\n",
    "# #af_train_X, af_train_y = data_aug(train_X_del[train_index], train_y_del[train_index])\n",
    "# af_train_X, af_train_y = data_aug2(train_X_del[train_index], train_y_del[train_index])\n",
    "# #af_train_X, af_train_y = train_X_del[train_index], train_y_del[train_index]\n",
    "\n",
    "# train_dataset = iceberg_dataset(data= af_train_X, label=af_train_y, transform=train_transform)\n",
    "# val_dataset = iceberg_dataset(data= train_X_del[val_index], label=train_y_del[val_index], transform=train_transform, test=True)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "#                           shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "###########################################################################\n",
    "# train_index=list(range(1604)) \n",
    "# seed= np.random.RandomState(123)\n",
    "# spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "# train_index, val_index = next(spliter.split(train_X))\n",
    "# train_mean, train_std = transform_compute(train_X[train_index])\n",
    "# train_transform = T.Compose([\n",
    "#     T.Normalize(train_mean, train_std)\n",
    "# ])\n",
    "\n",
    "\n",
    "## For final training\n",
    "train_X_del = train_X[data.inc_angle!='na',:,:,:]\n",
    "train_y_del = train_y[data.inc_angle!='na']\n",
    "\n",
    "train_mean, train_std = transform_compute(train_X_del)\n",
    "train_transform = T.Compose([\n",
    "    T.Normalize(train_mean, train_std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "# torch.from_numpy(train_X).type(torch.FloatTensor)[1].shape\n",
    "# train_X[1]\n",
    "# use_cuda\n",
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,early_stopping = None):\n",
    "    global train_data#,out,y,predicted\n",
    "    acc=0\n",
    "    best_acc =0\n",
    "    best_val_loss= 100\n",
    "    loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    train_data={}\n",
    "    train_data['loss_hist'] = loss_hist\n",
    "    train_data['val_loss_hist'] = val_loss_hist\n",
    "    train_data['train_acc_hist'] = train_acc_hist\n",
    "    train_data['val_acc_hist'] =  val_acc_hist\n",
    "    e_s= 0\n",
    "    last_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        print('\\nThis is epoch:{}'.format(i+1))\n",
    "        total= 0\n",
    "        correct=0\n",
    "        loss_avg= 0\n",
    "        #scheduler.step()\n",
    "        scheduler.step(acc)\n",
    "        if optimizer.param_groups[0]['lr'] < last_lr:\n",
    "            print('lr change from %f to %f\\n' %(last_lr,optimizer.param_groups[0]['lr']))\n",
    "            last_lr = optimizer.param_groups[0]['lr']\n",
    "        net.train()\n",
    "        for j,(batch_x, batch_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "            x = Variable(batch_x)\n",
    "            y = Variable(batch_y)\n",
    "            out = net(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y.data).cpu().sum()\n",
    "            progress_bar(j, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "            if j % 5==0:\n",
    "                loss_hist.append(loss_avg/total)\n",
    "            \n",
    "        train_acc_hist.append(100.*correct/total)\n",
    "        e_s+=1\n",
    "        if i %1 == 0:\n",
    "            acc, val_loss = test(val_loader)\n",
    "            val_acc_hist.append(acc)\n",
    "            if acc >best_acc:\n",
    "                best_acc= acc\n",
    "                e_s = 0\n",
    "                print('acc: Save it!')\n",
    "                torch.save(net.state_dict(), 'cnn_acc.pth')\n",
    "            if val_loss <best_val_loss and loss_avg/total <=val_loss :\n",
    "                best_val_loss= val_loss\n",
    "                e_s = 0\n",
    "                print('loss: Save it!')\n",
    "                torch.save(net.state_dict(), 'cnn_loss.pth')\n",
    "                \n",
    "        if loss_avg/total < 0.18 and val_loss < 0.18:\n",
    "            torch.save(net.state_dict(), 'spec_cnn_acc.pth')\n",
    "#             if best_val_loss >= val_loss:\n",
    "#                 best_val_loss= val_loss\n",
    "#                 torch.save(net.state_dict(), 'resnet34_loss%d.pth'%i)\n",
    "        if early_stopping is not None and e_s >= early_stopping:\n",
    "            return best_acc,i\n",
    "\n",
    "    return best_acc,i\n",
    "#         if i%50==0 and save:\n",
    "#             torch.save(net.state_dict(), 'resnet50.pth')\n",
    "        \n",
    "def test(val_load):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_avg= 0\n",
    "    for k, (val_x, val_y) in enumerate(val_load):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "        #print(out.size())\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += predicted.eq(y.data).cpu().sum()\n",
    "        total += out.size()[0]\n",
    "        progress_bar(k, len(val_load), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "    train_data['val_loss_hist'].append(loss_avg/total) #also keep track of loss of val set\n",
    "    acc =  (correct*100.0)/total\n",
    "    return acc,loss_avg/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.590 | Acc: 67.815% (6380/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.447 | Acc: 80.000% (236/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.490 | Acc: 76.637% (7210/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.389 | Acc: 84.407% (249/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.461 | Acc: 78.306% (7367/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.370 | Acc: 84.407% (249/295)\n",
      "\n",
      "This is epoch:4\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.431 | Acc: 79.826% (7510/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.375 | Acc: 83.051% (245/295)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.408 | Acc: 80.729% (7595/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 86.102% (254/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.397 | Acc: 81.930% (7708/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 85.763% (253/295)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s7ms|Loss: 0.382 | Acc: 81.983% (7713/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 87.119% (257/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:8\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.370 | Acc: 82.876% (7797/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.364 | Acc: 82.972% (7806/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 87.458% (258/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.348 | Acc: 83.748% (7879/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 88.814% (262/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.349 | Acc: 84.439% (7944/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 87.797% (259/295)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.341 | Acc: 84.513% (7951/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 86.102% (254/295)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.339 | Acc: 84.237% (7925/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.492% (264/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.337 | Acc: 84.386% (7939/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.311 | Acc: 85.424% (252/295)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.335 | Acc: 84.343% (7935/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.326 | Acc: 84.960% (7993/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 87.797% (259/295)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.323 | Acc: 84.917% (7989/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.312 | Acc: 85.597% (8053/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.318 | Acc: 85.395% (8034/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.312 | Acc: 85.789% (8071/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 87.458% (258/295)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.304 | Acc: 86.171% (8107/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.314 | Acc: 85.353% (8030/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 89.831% (265/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:23\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.307 | Acc: 85.746% (8067/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.270 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.301 | Acc: 86.469% (8135/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.311 | Acc: 85.736% (8066/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 91.186% (269/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:26\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.302 | Acc: 86.437% (8132/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.294 | Acc: 86.798% (8166/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.303 | Acc: 86.076% (8098/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.297 | Acc: 86.480% (8136/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 91.864% (271/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:30\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.297 | Acc: 86.809% (8167/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.250 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.301 | Acc: 86.299% (8119/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.293 | Acc: 86.692% (8156/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.297 | Acc: 86.713% (8158/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.298 | Acc: 86.809% (8167/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.290 | Acc: 86.809% (8167/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.300 | Acc: 86.469% (8135/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.295 | Acc: 86.841% (8170/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.292 | Acc: 86.937% (8179/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.295 | Acc: 86.884% (8174/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.295 | Acc: 86.607% (8148/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.291 | Acc: 86.915% (8177/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.287 | Acc: 86.852% (8171/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.291 | Acc: 86.671% (8154/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.281 | Acc: 87.277% (8211/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.286 | Acc: 87.128% (8197/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:46\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.248 | Acc: 89.062% (8379/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.239 | Acc: 89.722% (8441/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.231 | Acc: 90.168% (8483/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.228 | Acc: 90.115% (8478/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.592 | Acc: 68.931% (6485/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.485 | Acc: 81.017% (239/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.507 | Acc: 75.202% (7075/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.397 | Acc: 83.729% (247/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.463 | Acc: 78.242% (7361/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.359 | Acc: 85.763% (253/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.443 | Acc: 79.039% (7436/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.340 | Acc: 85.763% (253/295)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.416 | Acc: 80.315% (7556/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.327 | Acc: 85.085% (251/295)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.396 | Acc: 81.303% (7649/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 86.102% (254/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.386 | Acc: 81.707% (7687/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.326 | Acc: 84.746% (250/295)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.375 | Acc: 81.920% (7707/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.295 | Acc: 86.441% (255/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.365 | Acc: 82.642% (7775/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 86.780% (256/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.359 | Acc: 82.929% (7802/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 87.797% (259/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.361 | Acc: 83.142% (7822/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 87.458% (258/295)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.347 | Acc: 83.418% (7848/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 88.136% (260/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.342 | Acc: 83.673% (7872/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 89.153% (263/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.345 | Acc: 83.397% (7846/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.341 | Acc: 84.152% (7917/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.332 | Acc: 84.534% (7953/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.324 | Acc: 85.098% (8006/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.326 | Acc: 84.991% (7996/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.315 | Acc: 85.395% (8034/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.321 | Acc: 85.204% (8016/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.275 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.315 | Acc: 85.342% (8029/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.310 | Acc: 85.555% (8049/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.310 | Acc: 85.714% (8064/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.305 | Acc: 86.161% (8106/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 90.169% (266/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:25\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.302 | Acc: 86.511% (8139/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.275 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.299 | Acc: 85.852% (8077/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 90.847% (268/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:27\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.305 | Acc: 85.789% (8071/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.304 | Acc: 86.214% (8111/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.301 | Acc: 86.341% (8123/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.297 | Acc: 86.618% (8149/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.296 | Acc: 86.522% (8140/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 85.763% (253/295)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.294 | Acc: 86.682% (8155/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.295 | Acc: 86.320% (8121/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.295 | Acc: 86.288% (8118/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.294 | Acc: 86.884% (8174/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.289 | Acc: 87.022% (8187/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.282 | Acc: 87.511% (8233/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.287 | Acc: 87.341% (8217/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.281 | Acc: 87.394% (8222/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.525% (270/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:40\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.291 | Acc: 86.639% (8151/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.281 | Acc: 87.659% (8247/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.327 | Acc: 86.441% (255/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:42\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.288 | Acc: 86.958% (8181/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.286 | Acc: 87.245% (8208/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.276 | Acc: 87.606% (8242/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.276 | Acc: 87.659% (8247/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.284 | Acc: 87.436% (8226/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.288 | Acc: 87.277% (8211/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.280 | Acc: 87.702% (8251/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.275 | Acc: 87.968% (8276/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.277 | Acc: 87.957% (8275/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.282 | Acc: 87.117% (8196/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.275 | Acc: 87.702% (8251/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.276 | Acc: 87.723% (8253/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.271 | Acc: 88.159% (8294/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.274 | Acc: 88.148% (8293/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:56\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.240 | Acc: 89.955% (8463/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.223 | Acc: 90.466% (8511/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.222 | Acc: 90.795% (8542/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.213 | Acc: 90.955% (8557/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 91.864% (271/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:60\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.209 | Acc: 91.188% (8579/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.207 | Acc: 91.284% (8588/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.188 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.197 | Acc: 91.624% (8620/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 92.881% (274/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:63\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.191 | Acc: 92.071% (8662/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 91.525% (270/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:64\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.192 | Acc: 92.251% (8679/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.188 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.192 | Acc: 91.901% (8646/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 93.220% (275/295)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:66\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.189 | Acc: 92.156% (8670/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.188 | Acc: 92.209% (8675/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 91.186% (269/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:68\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.184 | Acc: 92.443% (8697/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 91.864% (271/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:69\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.185 | Acc: 92.251% (8679/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.179 | Acc: 92.751% (8726/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.179 | Acc: 92.708% (8722/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.173 | Acc: 92.921% (8742/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.171 | Acc: 92.900% (8740/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.174 | Acc: 92.560% (8708/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.171 | Acc: 92.783% (8729/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.170 | Acc: 93.165% (8765/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 93.220% (275/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:77\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.162 | Acc: 93.463% (8793/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.162 | Acc: 93.410% (8788/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.194 | Acc: 93.559% (276/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:79\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.161 | Acc: 93.357% (8783/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.160 | Acc: 93.495% (8796/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.156 | Acc: 93.761% (8821/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.220% (275/295)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.157 | Acc: 93.622% (8808/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.156 | Acc: 93.601% (8806/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.151 | Acc: 93.888% (8833/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.148 | Acc: 94.186% (8861/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.152 | Acc: 93.676% (8813/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.142 | Acc: 94.122% (8855/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.152 | Acc: 93.739% (8819/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.142 | Acc: 94.228% (8865/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.301 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.143 | Acc: 94.473% (8888/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.139 | Acc: 94.313% (8873/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.139 | Acc: 94.228% (8865/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.142 | Acc: 94.058% (8849/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.141 | Acc: 94.228% (8865/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:95\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s6ms|Loss: 0.123 | Acc: 95.291% (8965/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.115 | Acc: 95.599% (8994/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.113 | Acc: 95.578% (8992/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 294/294 ======>]Step: 0ms| Tot: 4s5ms|Loss: 0.106 | Acc: 96.195% (9050/9408)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 90.847% (268/295)\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(2):\n",
    "    cnn_net = cnn.plain_cnn(num_classes=2)\n",
    "    net= cnn_net\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Adam does not perform so good here   \n",
    "    #(0.1, 0.0001) (50, 80, 110, 170) 52 epoch reaches the maximum.\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00175, nesterov= True)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    #scheduler = MultiStepLR(optimizer, [100, 150,200], gamma=0.1)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max', patience =15,min_lr= 0.0001)\n",
    "    #5e-3 86\n",
    "    if use_cuda:\n",
    "        criterion.cuda()\n",
    "        net.cuda()\n",
    "    #     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "    #     cudnn.benchmark = True   \n",
    "\n",
    "    result.append(train(epoch=200,early_stopping= 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91.86440677966101, 48), (93.55932203389831, 97)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s272ms | Loss: 0.175 | Acc: 92.538% (1203/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 171ms | Loss: 0.194 | Acc: 93.092% (283/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s848ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s282ms | Loss: 0.169 | Acc: 92.846% (1207/1300)\n",
      "[=================== 5/5 ============>........]  Step: 34ms | Tot: 168ms | Loss: 0.195 | Acc: 92.434% (281/304)\n",
      "[=================== 132/132 ================>]  Step: 32ms | Tot: 5s827ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s279ms | Loss: 0.176 | Acc: 92.154% (1198/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 170ms | Loss: 0.194 | Acc: 92.763% (282/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s807ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s266ms | Loss: 0.185 | Acc: 92.462% (1202/1300)\n",
      "[=================== 5/5 ============>........]  Step: 34ms | Tot: 170ms | Loss: 0.190 | Acc: 92.763% (282/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s823ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s273ms | Loss: 0.179 | Acc: 92.385% (1201/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 168ms | Loss: 0.194 | Acc: 92.434% (281/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s810ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 66ms | Tot: 3s288ms | Loss: 0.174 | Acc: 93.000% (1209/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 169ms | Loss: 0.191 | Acc: 92.105% (280/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s820ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s273ms | Loss: 0.168 | Acc: 93.462% (1215/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 168ms | Loss: 0.190 | Acc: 93.092% (283/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s827ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 66ms | Tot: 3s278ms | Loss: 0.170 | Acc: 93.462% (1215/1300)\n",
      "[=================== 5/5 ============>........]  Step: 34ms | Tot: 171ms | Loss: 0.187 | Acc: 93.092% (283/304)\n",
      "[=================== 132/132 ================>]  Step: 32ms | Tot: 5s819ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s289ms | Loss: 0.183 | Acc: 92.846% (1207/1300)\n",
      "[=================== 5/5 ============>........]  Step: 33ms | Tot: 169ms | Loss: 0.195 | Acc: 92.105% (280/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s822ms\n",
      "\n",
      "This is epoch:1\n",
      "[=================== 41/41 =================>.]  Step: 65ms | Tot: 3s272ms | Loss: 0.176 | Acc: 93.000% (1209/1300)\n",
      "[=================== 5/5 ============>........]  Step: 34ms | Tot: 169ms | Loss: 0.195 | Acc: 92.105% (280/304)\n",
      "[=================== 132/132 ================>]  Step: 33ms | Tot: 5s810ms\n"
     ]
    }
   ],
   "source": [
    "##For continue training\n",
    "resnet34 = resnet.resnet34(num_classes=2)\n",
    "net= resnet34\n",
    "net.load_state_dict(torch.load('save_resnet34_acc.pth'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Adam does not perform so good here\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00012, nesterov= True)\n",
    "scheduler = MultiStepLR(optimizer, [50,100], gamma=0.1)\n",
    "#5e-3 86\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "    net.cuda()\n",
    "#     resnet101 = torch.nn.DataParallel(resnet101, device_ids=range(torch.cuda.device_count()))\n",
    "#     cudnn.benchmark = True   \n",
    "\n",
    "#train(epoch=150)\n",
    "\n",
    "\n",
    "test_set = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test_set)\n",
    "test_X.shape \n",
    "fake_label = np.zeros(len(test_X))\n",
    "\n",
    "test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform,test=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "result = []\n",
    "for i in range(10):\n",
    "    train(epoch=1)\n",
    "\n",
    "    prob = [] \n",
    "    net.eval()\n",
    "    for k, (val_x, val_y) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        #prevent overflow\n",
    "        temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "        ans= temp[:,1]/(temp.sum(axis=1))\n",
    "        prob.append(ans)\n",
    "        #print(out.size())\n",
    "        progress_bar(k, len(test_loader))\n",
    "    result.append(np.concatenate(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 3, 75, 75)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test_set)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2facb6ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "\n",
    "gs = gridspec.GridSpec(2,1)\n",
    "gs.update(hspace=0.5)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "fig1 = fig.add_subplot(gs[0,0])\n",
    "fig2 = fig.add_subplot(gs[1,0])\n",
    "fig1.spines['right'].set_visible(False)\n",
    "fig1.spines['top'].set_visible(False)\n",
    "# for item in [fig1.xaxis.label, fig1.yaxis.label,fig2.xaxis.label, fig2.yaxis.label]:\n",
    "#     item.set_fontsize(10)\n",
    "\n",
    "\n",
    "# fig1.plot([i * 0.005 for i in range(1,len(train_data['loss_hist'])+1)],train_data['loss_hist'],color='black')\n",
    "fig1.plot([i * 0.005 for i in range(1,len(train_data['val_loss_hist'])+1)],train_data['val_loss_hist'],color='red')\n",
    "fig1.set(title= 'Loss trajectory of training',ylabel='Loss',xlabel='Iter.(1e4)',ylim=(0,0.8))\n",
    "fig1.axhline(y=[0.2],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "\n",
    "fig2.plot([100-i for i in train_data['train_acc_hist']], color='red',linestyle='-.',label = 'train')\n",
    "fig2.plot([100-i for i in train_data['val_acc_hist']], color='green',linestyle='-',label='val')\n",
    "fig2.legend(frameon=True)\n",
    "fig2.spines['right'].set_visible(False)\n",
    "fig2.spines['top'].set_visible(False)\n",
    "fig2.axhline(y=[5],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "fig2.axhline(y=[10],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "_=fig2.set(title= 'Top-1 Accuracy of Resnet34',ylim=(0,20),xlabel='Epoch',ylabel='Error(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8UAAAJwCAYAAACgQsMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzsnXlcVOUXxp9BFkHcSyBcwAXcEsEFS9RSU3PXNHdTs7R+apmZWhZlmWWuWWa570suuaC54EouGOZW7iuQC6CgbAJyf3+cXhhghrkzc2fmDpzv5+Nn5M7ce9+ZuXPvfd5zznM0kiRJYBiGYRiGYRiGYZhiiIOtB8AwDMMwDMMwDMMwtoJFMcMwDMMwDMMwDFNsYVHMMAzDMAzDMAzDFFtYFDMMwzAMwzAMwzDFFhbFDMMwDMMwDMMwTLGFRTHDMAzDMAzDMAxTbGFRzDAMwzAm4O/vj0GDBtl6GEWaFStWoGPHjmjQoAH8/f2xbNkyWw+pAEodB4MGDYK/v78CI2IYhmGMhUUxwzBMMcbf379I3IhPnDgR/v7+iImJsfVQLEZMTAz8/f0xceJEWw/FKoSFhWHq1KlwcXHBG2+8gVGjRqFhw4aFrlMcjgOGYRhGeRxtPQCGYRiGsUd27twJV1dXWw+jyHLgwAEAwIIFC+Dh4WHj0ehHqePg22+/RVpamgIjYhiGYYyFRTHDMAzDmECNGjVsPYQizf379wFA1YIYUO44eO655xTZDsMwDGM8GkmSJFsPgmEYhrENInX60qVLsl5/7NgxLFq0COfOnUNqaiq8vb3xyiuvYMSIEShdunSe10ZHR+OXX37B8ePHce/ePZQsWRIeHh4IDAzE2LFjUb58eQBARkYG1q1bhy1btiAmJgYZGRmoWLFiTq3miy++KOs95Mfb2xv79+8HQPWakZGROHfuHH755Rds374dsbGx6Ny5M7755hs8fvwY69evx+HDh3Hz5k08ePAA7u7uaNiwIUaMGIHAwECd+23atClWrlyZZ3lWVhbWr1+PrVu34urVq3j69Cl8fX3Rq1cv9O/fHw4OBSuXzp49iyVLliAqKgoPHz5EuXLl4Ofnh169eqFjx46YN28efvjhB53vc9q0aejZsycAIDs7G+vXr8fGjRtx/fp1SJKEGjVq4LXXXkPfvn0L7Fu8h1mzZmHOnDk4fPgw4uPjMXXqVERERCAsLAwrV65E06ZNC+x39+7dGDNmDAYMGIDPPvtM59i0ycjIwLJly7B9+3bcvn0bJUqUQO3atTFw4EB07Ngx53WFvdfCjlM1HQfiPaxYsQIPHz7EokWLcOXKFbi4uKB58+aYOHFiAbEvxqb9Hk+cOIHBgwdj1KhRaNu2LWbPno1Tp04hMzMTzz//PD744AMEBQUVGNP9+/cxe/ZsHDx4ECkpKfD19cWQIUPw3HPP5Wxv9OjRej9LhmGY4gZHihmGYRhZrFu3Dp9//jlcXV3RoUMHVKxYEZGRkVi4cCEOHDiAtWvXokyZMgDoprxXr15ITk5Gy5Yt0a5dOzx58gQxMTHYtm0bBg4cmCOKJ02ahB07dsDPzw/dunVDyZIlcf/+fURFReHIkSMGRfGoUaOwb98+XLx4EYMHD84ZQ36RDgBjxozBuXPn0LJlS7Rt2xYVK1YEAFy7dg1z5sxB48aN8dJLL6FMmTK4c+cO9u/fjyNHjuCnn35Cy5YtDX5GmZmZGDlyJCIiIuDr64vOnTvDxcUFJ06cwJdffokzZ87gu+++y7POhg0b8Pnnn8PBwQGtW7eGj48PEhIScP78eaxduxYdO3ZE06ZNMXjwYKxYsQK1a9dG27Ztc9avU6dOzv/Hjx+PHTt2wMvLC7169YJGo8G+ffvwxRdfICoqCjNnziww5sTERPTp0wdubm5o164dNBoNKlasiH79+iEsLAzr16/XKYrXr18PAOjbt6/BzyUjIwNvvvkmIiMjUb16dfTv3x/p6enYvXs3xo4di4sXL+KDDz4AADRt2hSjRo3Cli1bEBsbi1GjRhncPqCu40CwZs0a7N+/H61bt0aTJk1w9uxZ7Ny5ExcvXsTWrVvh7Owsazvnz5/HokWL0LBhQ/Tu3Rv//vsv9uzZgyFDhuC3335D9erVc16bkJCAvn37IjY2Fk2aNEFgYCDi4+PxxRdfoHnz5rLHzjAMU6yQGIZhmGKLn5+f5OfnZ/B1MTExUr169aTAwEDp6tWreZ4LDQ2V/Pz8pMmTJ+csW7FiheTn5yctW7aswLZSUlKktLQ0SZIk6dGjR5K/v7/Uo0cPKSsrq8BrHzx4IOt9TJgwQfLz85Oio6N1Pj9w4EDJz89P6ty5s5SQkFDg+UePHulcfufOHal58+ZShw4dCjzn5+cnDRw4MM+y77//XvLz85OmTJmS5/1kZWVJkyZNkvz8/KS9e/fmLL9y5YpUt25dqUmTJtLly5d17l8QHR0t+fn5SRMmTND5Hrdv3y75+flJ3bt3l5KTk3OWp6SkSD169JD8/Pykbdu2FXgPfn5+0vjx46XMzMwC2+zUqZNUv379At/D7du3JX9/f6lPnz46x5KfBQsWSH5+ftLw4cPz7Cc+Pl56+eWXJT8/PykqKirPOuI7Mwa1HQeBgYHSxYsX8zz3wQcfSH5+flJYWJjOsWlz/PjxnO9o06ZNeZ5bu3at5OfnJ4WGhuZZLo6z6dOn51l+4cIFqV69epKfn5/0/fffF3gfDMMwxRl2n2YYhmEMsm3bNmRmZmLgwIEFaijHjh2LUqVKYevWrcjIyMjzXMmSJQtsy83NLWe5RqOBJElwdnbWmVYsoslK8d5776FChQoFlpcuXVrnck9PT3To0AHXr1/Hv//+W+i2s7OzsWrVKjz77LOYNGkSSpQokfNciRIlMHHiRGg0Gmzfvj1n+dq1a5GVlYV3330XtWrV0rl/uWzatAkAMG7cOJQqVSpnuZubG8aPHw8A+PXXXwus5+TkhAkTJsDRsWDyWL9+/ZCRkYEtW7bkWb5hwwZIkiQrSizGptFoMHHixDz7qVixIt555x29Y7MUljwOtNHVZql3794AgHPnzsneTlBQUE6KvOC1116Do6Mjzp49m7MsIyMDYWFhKF26dM7nKqhduza6d+8ue58MwzDFCU6fZhiGYQzyzz//AACaNWtW4LmyZcuibt26OHnyJK5fv47atWujdevWmDVrFqZMmYKIiAiEhIQgKCgINWvWhEajyVnX3d0dL7/8Mg4cOIBu3bqhXbt2aNy4MQICAizi7NygQQO9z0VFRWHFihU4ffo0EhISkJmZmef5e/fuFWqGdOPGDSQmJsLHxwc//fSTzteULFkS169fz/n79OnTAIAWLVoY8zZ08s8//8DBwUFnqnOTJk1QokQJXLhwocBz3t7eOenD+enWrRtmzJiB9evXY9iwYQAoRXzLli0oW7YsXn31VYPjSk5Oxq1bt+Dh4aHTlEocU7rGZikseRxo8/zzzxdY5uXlBQBISkqSPd769esXWObk5ISKFSvi0aNHOctu3LiB9PR01K9fH+7u7gXWadSokVUnHxiGYewFFsUMwzCMQR4/fgwAePbZZ3U+L5aLG3Rvb29s3LgR8+bNw5EjR7Bnzx4AJAiGDRuGwYMH56w7Z84cLFy4EDt27MC8efMAAC4uLmjfvj0mTJiAZ555RrH3oW/8e/fuxZgxY+Di4oIXX3wRVatWhaurKxwcHBAZGYnIyMgCUfD8JCYmAgBu3ryp1ygKAFJSUnL+Lz5XJRyWHz9+jLJly+qsU3V0dET58uWRkJBQ4Dl9nwlAkxZdu3bFunXrcPz4cTRr1gz79+9HXFwc3njjDbi4uBgcV3JycqH7qVSpEgDkEXeWxpLHgTa66plFBkF2drbs7Yj66Pw4Ojrm2Y44nvRNcuhbzjAMU9xhUcwwDMMYRNzcx8fH60zzjYuLy/M6gFrVzJkzB1lZWbh48SKOHj2KVatWYerUqXB1dc1JIy1ZsiRGjx6N0aNH486dOzh58iS2bNmCbdu2ITY2FmvWrFHsfWhHqbWZO3cunJycsGnTpgLRzM8++wyRkZEGty3e+yuvvFKoKNa1zr1793RG9oyhdOnSSEpKQmZmJpycnPI8l5WVhYcPH+rch77PRNCvXz+sW7cO69evR7NmzXIMtvr06SNrXGKf8fHxOp8XrZd0CUhLYcnjwJaIz1rX5EdhyxmGYYo7XFPMMAzDGEQ4HJ84caLAc48ePcKFCxfg4uKiMz3W0dER9evXx9tvv41Zs2YBAMLDw3Xux8vLC127dsXixYtRrVq1nBZFhhD1yMZE37S5desWatasWWD82dnZiIqKkrWN6tWro0yZMjh9+nSBlFt9NGzYEABw5MgRg68VEcanT5/qfL5OnTrIzs7Gn3/+WeC5kydP4unTp6hbt66scWlTu3ZtBAUFYe/evThz5gyOHj2KJk2ayO7P6+7ujqpVq+LevXu4efNmgefFMWXK2PKjhuPAllSvXh0lS5bEpUuXciL02tjDe2AYhrEFLIoZhmEYg3Tt2hVOTk5YtWoVbt26lee5uXPnIjk5GV27ds1J3T1//nxOKqc2IloojLYePHigs/dsamoqUlNT4ejoWCDqqYty5coBgFEmSNp4e3vj5s2buHfvXs4ySZIwb948XL16VdY2HB0dMXDgQMTFxeGrr75Cenp6gdfcv38/z/b69esHR0dHzJ8/X+d+7t69m/P/MmXKQKPR4M6dOzr3/9prrwEAZs6cibS0tJzlaWlpOa2YevXqJeu95Kdfv37IzMzE6NGjjTLY0h6bJEmYPn16HlH/4MEDzJ8/P8/4zUENx4EtcXZ2RseOHfH48eMCde0XL17Eb7/9ZqORMQzDqBtOn2YYhmEwceJEvc+FhoaicuXKmDRpEqZMmYIePXrg1VdfRYUKFXDy5En89ddfqF69Oj788MOcdbZu3Yr169ejUaNGqFKlCsqWLYvbt2/jwIEDcHZ2xhtvvAGA0oa7d+8OPz8/+Pv7w8vLC8nJyTh48CDi4uIwaNAgWWnFL7zwAhYvXoxPP/0U7dq1Q6lSpVCmTBkMHDhQ1vsfMmQIQkND0aNHD7Rr1w6Ojo44deoUrl27lmMEJod3330XFy9exLp163DgwAE0a9YMHh4eSEhIwK1bt3Dq1CmMHTsWNWvWBADUrFkToaGhCA0NRffu3dGmTRv4+Pjg4cOHOH/+PEqVKoWVK1cCAEqVKoWAgAD8+eefGDduHHx9fXN6G9euXRtdunRBeHg4du3ahU6dOqFt27Y5fYpjYmLQsWNHdO3aVdb7yE+HDh0wbdo03Lt3D+XLl0e7du2MWn/YsGE4fPgwwsPD0a1bN7Rs2RLp6en4/fffkZCQgOHDh6Nx48YmjU0btRwHtmTcuHE4fvw4Fi1ahLNnzyIwMBBxcXHYtWsXWrVqhX379hlMmWcYhilusChmGIZhCrTc0ebjjz+Gq6srBgwYgGrVqmHJkiXYs2cP0tLS4OXlhTfffBMjR47MYwbUuXNnZGRk4K+//sLff/+N9PR0eHh4oFOnThg6dCj8/PwAUGRu9OjRiIyMxIkTJ/Dw4UOUK1cOvr6+GDduHDp16iRr/C1atMDEiROxYcMGLF++HJmZmfD29pYthvr27QtnZ2csX74cv/32G1xcXNC4cWNMmzYNe/bskS2GnJycMH/+fGzduhVbtmzBwYMHkZqaivLly6Ny5cp477330KVLlzzrvP7666hVqxaWLFmCyMhIhIeHo1y5cvD398+puxZMnz4d06ZNQ0REBMLCwiBJEjw9PVG7dm0AwKxZs9CkSRNs2rQpp/a3Ro0aGDZsGPr16yfrPejC2dkZXbp0wfLly9GjRw+dZl6G1l+6dCmWLl2KHTt2YNWqVShRogRq166Njz/+GJ07dzZ5bNqo5TiwJc888wzWrVuHWbNm4dChQzhz5gx8fX0RGhoKV1dX7Nu3z+z6dYZhmKKGRpIkydaDAChFbO7cuThy5AgSExNRqVIltGnTBqNGjULZsmVN2ubJkycxePBgZGdnY+TIkRg7dqzCo2YYhmGKI0+ePEGDBg0QEhKCxYsX23o4VmHQoEE4efIkfv/9d/j4+Nh6OIwJzJ49GwsWLMCiRYsUaQPGMAxTVFBFTfHt27fRs2dPbN68GQ0aNMCQIUNQuXJlrFixAn369JFlspKf5ORkTJgwIadujWEYhmGU4saNGwCUaaVkD5w9exaRkZEICQlhQWwHaNdECy5duoQVK1agXLlyOntZMwzDFGdUkT79xRdfICEhAZMnT8agQYNylk+bNg3Lli3D7NmzMWXKFKO2OXXqVCQnJ2PEiBGYPXu20kNmGIZhiiGxsbHYsGEDdu/eDQBo3769jUdkWdasWYN79+5h8+bNcHBwwJgxY2w9JEYGr732GqpVq4ZatWrB1dUVt27dwqFDh5CdnY0pU6bI6i/NMAxTnLB5pPj27duIiIiAt7c3BgwYkOe50aNHw83NDdu2bUNqaqrsbe7btw+bN2/GJ598gkqVKik9ZIZhGKaYEhMTg8WLF6NEiRKYOnUqWrVqZeshWZRFixZh4cKFcHNzw/Tp09GgQQNbD4mRQd++fZGSkoKwsDAsX74cUVFRCAkJwbJlywrUtDMMwzAqiBSL/oQhISE5/QUF7u7uCAoKQkREBM6cOYMXXnjB4PYSEhLw6aefom3btujWrRs2b95skXEzDMMwxY/g4GCcP3/e1sOwGvv377f1EBgTGDVqFEaNGmXrYTAMw9gNNo8UX79+HQD01ihVq1YNQG79liEmT56M7OxsfPHFF7LHkJWVhZiYGGRlZcleh2EYhmEYhmEYhrF/bC6Kk5OTAQClS5fW+bxY/vjxY4Pb2rhxI/bv34/Q0FA888wzssdw9+5dtGnTBnfv3pW9DmNB3n8f0Gjo39GjlttPzZqAGS1KiiRpafS5T5tm2vqjRgEVKig7JsHYsYCe84RReHgAI0cWXB4cDLRtW/i6r78O+PubPwaGYYo3Bw7QuVZOi6ebN+m1S5ZYfFh5ENeDr782/NoGDQC1pmWXKUPXD7n06WP8eb5DB6BRI+D0afrMNmwwbn1748wZwM2NrskaDXDrlq1HxDBmY3NRrBQxMTH4+uuv0aFDB3Ts2NHWw2HMoXLl3P+7ulpuPz4+dLPB5JKQQI8VK5q2vqcn8PAh8OSJcmMSJCcrI4rd3YGUlILLr14FatUqfF1PT0CHqyvDMIxRxMXR47PPGn6tpyc93rljufHoIjaWHr29Db+2Zk3g2jXLjscUnj4FHj8GjGntWa4ckJRk3H6uXKHrR506gKMjicaiysOHQM+eQPnywH+90PFfKSTD2DM2F8Wigby+SLBYri+SLPj4449RsmRJhIaGKjtAxvpoi2I3N8vtx8cHkJmWX2xQQhQDwP37yoxHm+RkErTmUqoUbUubBw/oX82aha/r6Uk3S2lppu9/2DDgP+dihmGKKcaI4pIlSajZgyh++tSyYzKWR4/osVw5+euUKwckJsp/fUYGTbDXqgW4uAC1axddUZydDQwcCERHAxs3Aq+8Qscni2KmCGBzo63q1asDAG7qidjd+i8lw9fXt9Dt/PPPP3j8+LFeM64FCxZgwYIFaNOmDebPn2/6gBnLY61Isa8vRf3S0iy7H3tCKVF89y5QpYoyYxIoJYp1RYpFhMOQKBY9ae/do0kVY0lIAJYuBZycgCLeyodhmEIQoljuudbLy3aiWPuarI+aNUkcxsYCVatadlzGIMStsZHiJ0+A9HQSfIa4cYPEosg0CggADh0yfqz2wJQpwM6dwPz5gLjfDgpiUcwUCWwuioODgwEAERERyM7OzuNAnZycjFOnTsHV1RUBAQGFbqd79+5I0xG9uXXrFk6ePIk6deqgXr16qFu3rrJvgFEea0aKAZrhrVPHcvuxJ4QoNqImPw/aolhplBTF+SPFV6/So5xIMWC6KL58mR65/ophijfx8eS/4CjzNswWojgmhh7lRooBOpeqSRSLNGhjI8UACWpxzi8Mcf3QFsWrV1P2kaU8NmxBWBjwxRfAG2/k9eVo2hT4+WcgM5MmfBnGTrG5KK5atSpCQkIQERGB1atXY9CgQTnPzZs3D6mpqejTpw/ctMTRtf+iOjVq1MhZNnnyZJ3b37x5M06ePIlWrVphrDFGC4zteO45Mm6QJMtHigEWxdrEx9OjEpFipUlOlpdqaIhSpQqO78oVevwvc0Uv5r4/FsUMwwAUKTZm8tHLC/jjD8uNRxexseTjIMfLQVsUt25t2XEZg6mRYrGuHFEsrh/iMxBBnDNngJdflr9fNXP1KqVNBwYCP/1E92iC4GBgzhzg/Hl6nmHsFJuLYgAIDQ1F37598dVXX+HYsWOoUaMGzpw5gxMnTsDHx6eAmBVGWpcuXbLFcBlL4+xMaap371reaAtgsy1tzE2frlSJHi0lig2UUchCV/r01auU7m3oeFNSFEtS3hsLhmGKD3Fxxk3yiUixNc8bsbHyosQAvc7ZWX1mW+ZGiuVw5QqJbjHJUdREcUoKGWs5OACbNhW8Tv6X8YkTJ1gUM3aNzY22AIoWb9q0CT179sTZs2exdOlSREdHY/DgwdiwYQPKly9v6yEy1qZyZTKscLDgIerpSftgs61cEhJINDo7m7a+szMJakuJYiXcp3UZbV29ajh1GjBf9IuJvLS03Kg8wzDFD1NE8ZMnxhlAmUtsrLx6YgAoUYIybUQqsVowN1IsB+E8LSYrPDzoX1Ew25Ik4O23KQq8dq3uiWkfHzqWua6YsXNUESkGAC8vL0yT2RvVmAhxz5490bNnT1OHxdiKypUtP+Ps4ABUq8aRYm0SEkyvJxZ4etpnTXH37obXdXIi0W9qW6bLl2niICODosVKpIMzDGN/xMfnGhXJwcuLHu/coVY41iAmBmjTRv7ra9ZUnyi2RqT46lWgWbO8ywICioYonjcPWLMG+OoroF073a/RaKiumEUxY+eoIlLMMAV46SXjbhhMhdsy5SU+3vTUaYElRLEkUa9JpURxaiq5hQJ00xQXJy9SDJj+/rKzKaIQEkJ/c10xwxRPJInOtcbWFAPWM9t6+pT2JTd9GsgVxZJkuXEZixC2ZcrIX8cYUSwmOPNfPwICgL//JvMpeyUiAhg3DujWDZg0qfDXBgcDFy8a39+ZYVQEi2JGnbz3HjkdWhpfX44Ua5OQYL4oFvXgSvLkCd2kKdWnGCBhDMhvxyQw9f3FxFCLj1deob9ZFDNM8SQxEcjKMj59GrCeKL5/n865xori1FTLZAqZSlISnfONcUU2RhRfv563HZMgIIAEs7163/z7L9C7N6XEL19uuJQtOJgmQ/780zrjYxgLwKKYKd74+NCMff502uKKEqJYRFKVjBaI70epSDGQa7aV3znUEJ6epqVPC5Ot4GAaA4tihimeiB7FahbFxvQoFmg7UKuFxETj6okB6k3s7CxPFIvrhy5RDNhnCrUkAf37U3bW5s3yPr+mTemRU6gZO4ZFMVO8YQfqvChVU5yaquxEgyVEsdimuIHTavFWKKaKfiGK/f2plp1FMcMUT4TJnjGiuHRpwM3NeqLYmB7FAiGK1eRAnZRkXD0xQDWy5crJE8X5exQL/P1JWNujKF67Fjh0iNos1asnb51y5eg9syhm7BgWxUzxRrtXcXEnK4tuApSIFAPKptApKYpF+rS2KH7uudzlhjBV9F++TPvw8ipeojglBXj33dxJAYYp7pgSKdZoctsyWQMRKTZGFFetSi7U9h4pBuSL4itX6LUVKuRd7uREgtLeRHFKCjBhAtCoETBsmHHrCrMtNdWUM4wRsChmijciUsxmW8CDB/SoZlGsREum/OnTctsxCTw86NHY93fpEuDnRze3xUkUjx4N/PQT1aUxDJMrio3NyrG2KHZ0zG1DJwcnJ7qmqkkUmxIpBkhIyzGNyt+OSRt7dKD+7jvKEpgzx/iWmMHBVFoUHW2ZsTGMhWFRzBRvKlWiRvQcKabUaUDdothSkWJjRLF4f8bWFV++TKIYIFH88CHVbBVlVq8Gli6l6NEff9h6NExRJDERGDAA+O03W49EPqZEigHriuKYGMqgMVYYqa0tkzUixflTpwUBAXSdMLWFn7WJjgamTwf69MntkmAMwcH0yCnUjJ3Copgp3mg03JZJUFxEsXZNcXIyjdMUUWzM+3vyhCZe/P3p72rV6PH2bfnbsDeuXgVGjqSbq3ffpRuljAxbj4opSty/T+371qwBFi609WjkExdHk3OursatZ+1IsTGp0wK1tWVKSrKcKH7yhM7hhYliwH6ixRMm0Pc2fbpp6zdoALi4sChm7BYWxQzj48ORYiBXFJtrtFWxIrl3Kmm2Yin3aRHRsHT6tGjboR0pBopuCvWTJxRtcHIiwdKqFbWjOnXK1iNjigrR0UCLFpSBERhIrWDUIsQMER9vfJQYIFH8+HFu6YclMUcUJyXlXk9siSSRsDUlfVqOKL5+nfahTxQ3aECP9iCKjx4lg63x46k23BScnem3yKKYsVNYFDMM9yomhCOquZFiBwcy3FAyXdZS6dP6nEML45ln6D0akxInTKaKiyieOJEE8LJlQJUqQPPmtJxTqBkluHyZMhDu3gX27AGGDqWosTCHUjtxcaZNPlqrLZMkUfq0Me2YBGpyoE5PBzIzLRcpNtTOr2JFmlhQuyjOzgbee4/GOmGCedsKDgaiouhzZxg7g0Uxw/j4UH2nHFONooxS6dMA0LIliSKlambFdpROnza2HRNA9bGVKhkXKRaiWIhvT0+aVS+Konj7djJpGTMG6NqVlnl60mccEWHbsTH2z9mzFCFOTQUOHiRx3KgRPRcVZdOhySYuzvRIMWB5UfzoEUWjTY0UA+qoKxai1tRIcXo6/dOHvh7F2tiD2dbKlZRp8c038rsw6CM4GEhLA/7+27T1k5KAXbvMGwPDmAiLYobhtkxEQgIJNXMvigDdtGZnA8eOmb8tIDdS7OZm/rbENkT6tIeH8a7WolexXC5fJiEtbs4cHCiCWtREcUwMRe0CAwvWpYWEUKTYXlJcGfVx/Dil4js5AUeO0HEGAA0b0m+KRbEymNKOSeDrS14dahDFYqLb1Eix9jZ0cfUqtWLK3453tIygAAAgAElEQVRJm4AA4OJFKilRI48fA5MmkZjt39/87ZlrtvXll0DHjsCGDeaPhWGMhEUxw3BbJiIhgVL6dLWWMJYXXqCb1CNHzN8WQKLY3d14J1RdODiQMBaRYmPqiQUeHsaJYtGOSZui1pbp6VNyAU5PB9atI8MVbUJCSAyI6EpRRpKA33+niSFGGcLDgbZt6RwVEQHUrp37nJsbUKeO/Yhic2qKAXWLYhcXmvBTkyg2NVIMFJ5CXZjztCAgAMjKAi5cMH4M1mDaNDqe5s5V5vrq60u/UVNEcUZGbuu+d96xnqkcw/wHi2KGEaK4uEeK4+OVSZ0GKPIaGKi8KFYKd/fcSLEpotjT0/ia4qIuir/8Ejh8mHoS53+vQPGqK96zB3j1VSAszNYjKRps3UrRI19fOqeIc7Y2jRqRKFZ7JkJqKv0zpaa4YkWKkltLFJtSUwyopy2TELTmRIoNiWJD1w81O1DfuAHMmgUMHJgb4TUXjYY8RUwRxdu20X3InDn0G3nrLfX/npkiBYtihqlYkURScRfFCQnKiWKAUqhPnFAmbUxpUVyqVK4xjzEmWwKRPi3ngp2URAJatGMSVKtGN7dFoU3RwYMkigcPBgYN0v2a2rXp+CoOdcWHDtHjn3/adhxFgVWrgNdeoxTpQ4dyW6Llp1Ej+p39+691x2cspvYoBkhweHpaXhTHxNDjc8+Ztr5aRLElI8Xp6eSAbuj6UasWtd5SoygeP548Mr75RtntBgdTZPzRI+PWW7SIsgxGjaIIdlgYsGSJsmMrjDVrcv0/7JkLF4AePYB588x3gb9zB/j6a+D552mid/ly479XO4JFMcNwr2LCEqI4PV2ZlMakJOUjxeImxdT06cxMMmgzhEgX1hUpliS6sVITWVn0nclt+xIfT2nTNWoAP/6o/3UaDfDii8VDFIv3aC/pvGrlp59okqVlS2DfvsJrN+3FbMscUQxYp1dxbGxuaz1TqFmTzgu2Nq+0ZKTYUDsmQYkSQP366hPFhw4BmzZRpwBT0uQLIziYPhtjJgVv3aIMm2HD6DMbM4Z6kL//vnUCFlu30nXshReAyEjL789SxMYC7dvThMKYMTSx1bs3sHMnXdvl8PQprd+9O01SfPIJ/R4uXgSGDCF/lNdeA379lSL6RQgWxQwDcFsmILemWClatKBHc1Oonz4lg5369c0fk8DdPbdliKnp04C8FOr87ZgEohek2lKoly4FGjemi2BwMDBuHLB5s+73Kkl0kYyPB9avNzxxERJCn4cQBkWRJ09yb6q4L7Pp3L4N/O9/QKdOdENnyAzPXsy2ROs7tYtic4SSWtoyWTJSLMd5WiAcqNWSCvz0KbVgqloV+PBD5bffpAk9GpNCvXQpPQ4dSo8ODrRMo6FrjCX9GR49onNN3br0vbdpAxw4YLn9WYrERIrmPnxI90ynT1Nt9sGDdB6tWpUmQS5d0r3+rVtAaCgFiTp3pm18+CFds48coYmgo0eBESPo8fXXKUAwcCCwY0eRyHpjUcwwQG6kWC0XLWsjScpHip99llJmDx82bzuRkTS2Tp2UGReQ12HbmHZMAiGK5ZhtXb5MF/b8+1Frr+KDB2km+KOPKFL04480K+zpScJ+2DBKabt0iWq/wsKAGTNynYALozjUFUdFkTB+6SUSL2wWYxrbt9N5adYseRHLUqXofKN2UWwPkWJTexQL1NKWKTGRoo6mdFSQK4rlTKoGBNA1TC2p/UuWkEifPp1Su5WmQgWaLJArip8+JQHcrl3udRGg+7LZsymq/f33yo9T8Mkn9N0sWUJZPtWqkbjcts1y+1Sa9HSK7F64QJPYQUF03M2ZQ5NcmzfTZPeMGXSefPFFYOFCOi43b6b36+tLZVD161MWQXQ0pdaLiR+NhiLpc+fSOSI8HOjXjyYtu3Shc9Pbb9t11iWLYoYB6OT7+LG8dNiiSFISXZiUFMUARYv/+IO2bSo7d9Kscfv2yo1LRDSfeca0KIKxotjHp6Abc5UqdJFRmyg+epS+t6lT6WYkKYmWTZ9ODr/btgFvvkkX1g8+ALp1oxowOTRuTJ9DURbFInV69Gh6/Osv243Fntm2jerwdZm26aNxY/sRxaZm5Xh50Y2sJaMy5kaKq1enR1uL4qQkSp02paOCqyuZmulLAb9yha6X5csb3paazLaSkkgEhoRQpM9SBAeTKJYTaNi3jzJDhg8v+NywYTQhPmkSpe8qzbFjNPE7ejSN2cuLrnsBAUDPnsDq1crvU2mys8nP49AhYNky4JVX8j7v7Ew1xtu2kZj97js6Dt5+m85Dr70GnD8PfPopCdpdu+i9Oznp32eJEkDr1sAvv9B90PbtJKzXrs2N+tshjrYeAMOoAtGr+MaNwuvWiirCjMESonjhQjrhihsDY9m5k2Y15dx8yEWIYlNSpwFKGQLkiWJd7ZgAulB5ealLFN+9S2UE2iLXxYVmh194gYxZJIneU0QECf6JE+XfdLq4kHApynXFEREk5sSNyalT5JysNuLiyMBOnPvUxKNHlL743nvGrdeoEbBiBUV9TDWJsjRxcXSzaUqdK5DblunePZpYU5qMDDIhNEcUlypF47S1KE5MNP1z1mhowlRfpPjqVfkmjQ0a0OOZM5Y5F8THAy+/TD4X5csX/m/HDnr9rl3KtF/UR3AwmeRFR+eWCulj0SISZ127FnxOo6F7iPr1SfgdPQo4KiRdMjJIGHp7A199lbu8YkUS6t26kadBUhLw7rvK7FNpJAkYO5bqe7/7juqiC8PTk1Kix42jmu/t2+m76tCBhK4pODtTunXnzhQAMXU7KoBFMcMAedsyCcOW4oQQxUrWFAN564pNEcV37pCo+PprZccl0ulMcZ4G6ObCyclwTbEkkXAMCdH9vNraMh07Ro8vvKD/NRoNRYm1+8QaQ0gIpcSmpVkmdc+WZGeTKO7Zk2pg/fzUG7kcMYK+79u3C48I2II9e+gGX9dNcmFom22pWRSb0w9eu1exJUSxSM0213xJDQ7USUmmZQIJypYtPH36pZfkb8fHx3KR4t9/p4nnzp2pdCMujq47Dx/S+PPX4w4bZvn7HNHiKTKycFF8/z6ZXI0eTeJKF15eZLrXpw+5Un/6qTJjnDGDPrdt2wp6FpQuTRPyr79O9cZJScZNAFuL776j1PL33yehKxeNhmq/Rf23UtixIAY4fZphCBEtKa5mW8L8RelIcbVqVJtmqtnW77/To9Kz6+ZGikVrFEOR4rt3KRqnLwVUjaLY2ZnqkSxFSAgJnpMnLbcPW3HhAt2IikmQRo3UabaVlUX1YHfvUuRIbWzfThk7hU3O6MIezLbi402vJwbyimI5nD6de36Xg2jHZE5NMUDnVlsbbZkTKQb0R4rT0igCasz1Q5htWYK9e2miZetWmlA6eZImJBIS6FybmEgmSVFRlIExb55lxqFNgwZ0LTFUV7xyJY3xzTcLf93rr1P96pQpypxTL1+mbfXuTfWwuihZkmprBwwAPv6YRLGafGdWrgQmTKDJgpkz1SfY7RAWxQwD0MWvbFm7NggwC0ulT2s01E7lyBHTLiZhYRSxEOlnSiEixaaKYkCeKNbnPC2oVo1urizprGkMR4+SIDa1FYscXnyRHotiCrV4T0IUBwVRJNYYUWINoqJye00uXGjbseRHtAPp2NH4NEl7MNsSkWJTMUYUb95MEzMDB8rffmwsPZobKa5fn9LYrSHA9GFupFifKBZi35hMo4AAuh6kpZk+Hl1IEqX6tmlDE0L5cXCgextfXzofvfQS4Oam7Bh04eJC5ouFiWJJotTpF18k52dD/PADTSgNHkzGUqYiSZQpU7IkmUYVhpMTlWS88w75aowcaZ5HilLs3k0R/5dfpt7Bur57xmj4U2QYgY9P8Y0UW0oUA5RCfecOzVQbQ2YmzXp37Kj8DKi5kWKA6oqVEMWZmepwKM7IoBojY6NzxlKhAt0AFUWzrYgImiwRTuMi4q42s63wcHocOZKyMdTUK/vYMTofGZs6LWjUSP2i2JxIcaVKdD40dM7Yt48ia25udAP999/ytq+UKH7nHTL3GTOGnOxtMfFnqUixSAs3VhRnZ1O6rpJcuECTD23bKrtdJQgOpt+ivv64x46ReZYugy1dVKgALF5Mx/Jnn5k+rqVLqcvCd9/lTjIVhoMDmXFNmkTGUgMGmG90l5lJmQPLl1NN8JtvAgsW0DJDojsqisyx6tUDtmwpaOLJmAyLYoYR+PoW70ixg4N5s+r6EHXFxrZm+uMPcgS3hDGJvz/VBZtaFwuQ+DFUU3z5Ml2w9NX+qakt0+nTVI9maVEMUGumP/5QT4RcKSIiKEosJnFEmyq1ibTwcLpJnzCB/laTW+j27RSdMdVtvlEjEoxqaX+TH3NFsaMjrV+YKD52jNqz+PtTqmnJktSaRQ6xsfR6c40NXV3J/Ofdd0l8DB5s/T6mwn3aVPSJYmN6FAss5UC9bx895nccVgPBwUBqqv6JgEWLaIK6d2/523z1VTLHmjHDtGyje/fIaKpFC8Mp29poNORt8u23wPr1FEB4/nlKvR41isazcSOlrsfF5c2MS0qibLnvv6foblAQve+GDakH888/U+r7O+/QsrJlydn5k0/ofCgc6wHKUujYkbJNdu0y7/hmCsCimGEEIlKsppoRa5GQQLOwlkjBqVOHtm1sXfHOnXRz3KaN8mPq2pVSWsuUMX0bnp5kElLYrO7ly3TjpO9zVZMolmOypRQhIXSjIDd6ZQ/ExND5Q9tUrXx5mmxTU11xejpNSLRuTee8tm0p+qKGlECATG9eesn036a22ZbaEPWd5ohioPBexWfP0k2zpydl2tSqRYJ05cq8N9f6ED2KlcjOKVGCUl6nTaPWNh075qbtW5qnT2lflkifvnKFvkNjBImvLwkhpUXx3r2U8aTd31ctaJtt5efRIxKX/frlZm7JZcYMOne98YbxbZrefx9ISaGIryn3Ox99RAJ26FBqPXb7Nv22xo8ncd+0KWVzuLtTRlSNGnQctWxJbvo7dtCx8/77wJo1FOl//Jh+m1evkmP3kCF0ffz2W7pXqVSJvuNBg2iyMCuLsj/kRLkZo2D3aYYR+PrSrKa5Rij2SHy8ZVKnAbrwhISYJopbtizoCqnkuMzBw4MinfHxuS2a8nPpEqU46UNNovjoUYpom2uwI4fmzenxjz9otr0oINLB8zuNq81s6+hRyggQk03Dh5NRS3g40K6dbcd25Qrd5JrT/qRhQxJ0UVH6DXRshShTsZQovnqVvsNSpSiCKPqpv/8+iYAFCww795rbozg/Gg0ZFHl7U5SsZUs6t1vaHfzxY3o0N1Kclka/F+0U1StXjC+9cXAgbwwlRXFmJqUBDxqk3DaVpHp1uq84cYKiu9qsW0f3W3JTp7UpXZrqfNu3J+HZrx8d14Yyv3bupP1+8YV5WWJduxYs70hMpOv4zZu5jzdvUmbHm2/SealhQ/rt6ptwqlGD/om2SqmpVNJ0/DhNWu/dS9/5jh2UBcIoDkeKGUYg2jIVxxTqhATLiWKAboSuXpXX1xegi8rff6uzv6tA3HDqS6HOyqJUp8IuXu7uFEVXgyg+dsw6UWKAbpY8PYuW2daRIyRG8rceCwqi40BfaxdrEx5OEbyWLenvbt3ot68Gw63t2+nRHDHr7q5esy0RqTW39Z0uURwTQ1H/rCy6eRbXM4CydTp0oLrIJ08K37bSolgwaBAZqF27RueZCxeU34c24vdmbqQYoKidNsb0KNamQQOK5CuVjXbiBHU3UGM9MUDir2lT3WZbixbRhKipLYFCQuhe7cMPgd9+I3Hcv7/+4yo5mSbb6tTJLRtRknLl6NzfrRvV0c+aRUZ3GzaQc3XHjjQRZEwGhpsbnac/+ohqh+/coew0a12niyEsihlGUJzbMllaFGv3K5bDzp302KmTZcajBEIU6xP6N2/SDao+ky2BGtoyxcaS2ZK1LrYaDd3UFCWzrYgI+vzyOyYLs63Tp60/Jl2Eh9ONqsjAcHGh9NqtW+mGy5Zs3043ytqCzhTUarYlRLESkeJ793JT3uPiqKb0wQNKq6xTp+A6H3xA66xdq3+7kkTnAktli7RrR94SGRmULWLJSTEhZM2NFAN5J7RSU2kCwhRRHBBA41LqfL9vH0WgX35Zme1ZguBg4J9/8qbNnz1LtbfDh5uXpl+pEjlC37xJwnHbNsrM6tu3YGnOZ5/R575wof0aU2k0dt8HWO2wKGYYgUhlLa6RYnOjF4URGEiznsaI4urVDQtKW2JIFBtynhaoQRSLemLRLskaNG9ONzOiL6o9k5REN3pi8kcbNZltJSXRzWj+Ov3hwyktb+VK24wLoP7OR44ok/IszLbU4OqujWjNpYQofvqUtvfoEZkP3bxJkwqipjo/bdtSm6TZs/VHKuPjSbBaIlIsCAyk802lSjSmzZstsx8lI8XaotiUdkwCpc229u4FGjc23xTNkgQH0/H255+5yxYvph7GIk3YXJ59FvjmG/oNTJxIGQnPP09lIefP077nziW3fVG6wzA6YFHMMIIyZSiVtThGii1ZUwyQYdYLL8hzoE5Pp2iWJVoxKYmoI1ZKFNvS4O3YMXKcbdjQevsUtbdFIVp87Bh9f/nriQG6+a9cWR11xYcPUx18flFcty5NiCxaZLvjcNcuEnqmtmLSRq1mW0pGigFqc9elC4msjRuBVq30r6PRUG3x2bPAgQO6X6NUOyZD+PjQ7z4oCOjVyzK9jC0VKRbO06a083v+efoelBDFjx5RWrJaU6cFIj1amG2lp9PkW8+eyt9zPPMMOUTfvEntk3btos+8fXu6Xn/zjbL7Y4ocLIoZRhtf3+InilNT6UJlSVEMUBTt7FnDtZWHDpG5iZrriQGqXXRz019TfPkyzeAb+lyrVSM3zAcPlB+jXI4eJSHh7Gy9fQYE0OdXFERxRASltQm31fyoxWwrPJwmP3SlyQ8fTiZXR49af1wARTk9PEyvMdQmMDDXbEtNCFFcoYJ52xGiuF8/iq6vXCmv1GTAABLks2frft5aohig82J4eG4N5vHjym7fUpFiU3oUC9zdyUjp7FnTxyQ4eJAmkdTYikmbihVpAkHUFW/ZQlkhphhsGbPPqVPpXm7yZLrO/PILty9iDMKimGG08fEpfunTwhHVGqJYkgzfdIeF0Y37Sy9ZdjzmotFQCnVhkWI/P8PRbls7UD95QoLN2uYdTk5As2ZFw2wrIoKiXqVK6X4+KIicyJOTrTuu/ISHUzRbV01d795UZ7xokfXHlZlJUZ1OnZRpC6dWs624OBLE+evOjUWI4lu3gJ9+ohpKOZQsSWZDO3bQ8ZgfUcpgDQd6gHoZr1hBomXxYmW3rWSkWNto68oVyv4wtWVYQIAykeJ9++hzswfTpeBgEsWSROcXX1/r1EFXqAB8+SX5ZXTubPn9MXYPi2KG0cbX1/aprNZGiGJL1hQDJIAcHQuvK5YkEsWtW9MNk9rx8NAvii9dktc2wdai+NQpqiO0Zj2xoHlzukEU7VPskYwMuuHTlTotCAqiY9uWZlv37lF9nb6+3+7uFHlcv76g266lOXKE9qlE6rRAjWZbcXHKtPvz9iZDoRkzgBEjjFv3nXcoI2Tu3ILPxcbSpITwS7AGpUsDr79Ox11KinLbtWT6tClRYkFAANUlmztBtm8fORPbg2lUcDDV9x8+DOzfTy2KlJj8YhiF4aOSYbTx8aFUYrmtg4oCwnHW0pFiNzcyBSlMFF+5QnVyanad1sbTU3f6dEoKRV3kGIXZWhQLky1bRBxCQqjGVenUSWsSFUXnDEOiGLBtCrWoI9UnigFKaUxLK9yh2BJs304390rWRzZqBPz7r7rO5fHxyohiZ2ea4Bg3zvh1PTwojXr58oIlG7Gx9Ly5kWxjGTqUJsaUNN1KTKSJVXNKQtzc6LPIL4pNqScWBATQBNm5c6ZvIyaGWg+pvZ5YIMpK/vc/EsNDhth0OAyjDxbFDKONaAWi5rribduoN59S/P47pbI+/7xy29RHixbkfpuervt50Yrp1VctPxYl0Jc+LerO5IjiihXp5stWovjoUTrurRkdEjRrRjdJ9pxCLcZemKuplxeJDVuK4vBwipoJga6Lxo3ppt2aKdSSROe0tm31p5+bghrNtuLiLJ+RI4exY8lL4pdf8i63VI9iQ7RoQUJzyRLltpmUZF49MUClL2XL5orilBSaaDE3UgyYl0IdHk6P9iKKAwJocuLvv+nabotjjGFkwKKYYbQRImb3btuOQx+SBIwfD8ycqb9JvTE8fQqsW0emVtZo69CiBaWbCifK/OzcST02Rc9otePpSennGRl5l8t1ngboxstWbZkkiSLFtqpLK1MGaNDAvs22IiLoexZu5LrQaGxvtrV/P9XpF9bnUqOhaHFUFPDXX9YZ14ULuS7KSqJGsy2l0qfN5fnnSVDNm5f33BUTY716Ym00GooeHjxIx4ISJCYqY6xUrlyuKDanHZOgalXapjmieO9eqmu2xkS2Eri45HY2sKTBFsOYCYtihtGmVi0ynPnmm9xon5rYvz9XcK1YYf72Dh6kWh+l+gUaQkTTdLVmSk4m52m1u05rI4SQSEEXiO9IbpqdrURxdDRFPmxRTywICaH06aws243BVLKzSdAXljotCAoC/vmH0pOtzc2bJDYKS50WDBhAN7FKGx/pY9s2elTaCMfdnWr61SKKs7OVS59WgrFj6bf/66+5y2wVKQaAwYNJHC9bpsz2lIgUA3lFsWjHZI4o1mhoItBUUSxJVE/cpo191eW2b0+T3fZSGsUUS+zoF8UwVmL2bEr1+d//1Ge4NX8+pd+1bQusWkWRXnNYvZqMTqzlzFihAlC/vu664vBwilrYkygWKcf564ovX6aIi9x0UFuJYlvWEwuaN6e0RCUcWa3NpUuUKSBXFD99qkw7FmMR6ZZyRHH58tQ7dtUqSrG1NNu3UxTdEmJMTWZbSUn0/atFFHfoQJMGs2fTdS4lhcSfrURxlSpAu3Ykis29rgGWiRSb06NYm4AAOg+YMhF4/jxdb9Teiik/n39OWSFOTrYeCcPoRTWi+O7du5g0aRJCQkJQv359tG7dGlOnTkWSES6YixYtwltvvYXWrVsjMDAQQUFB6NKlC6ZNm4a7ajLbYNSNtzfw1VfAnj3Ahg22Hk0usbHA1q3AsGHAW29RqtvBg6ZvLz0d2LQJ6NnTuk7PLVtSHWv+G4KdO0mgyxEYakGI4vznF9GOSS7VqpG4UtJ9VQ5Hj9J336CBdferjfi+7bGuWIxZrigGbJNCHR5Ox2qdOvJeP3w4ibhNmyw7rrg4mphROnVa0KgRnTfVcP0XPYrVIoodHID336dJg4gI6/Yo1sfQoZS9sn+/+dtKSlJeFF+9StlBpUubt81XXqFz/fLlxq+7bx892ks9scDBwT6csplijSpE8e3bt9GzZ09s3rwZDRo0wJAhQ1C5cmWsWLECffr0wcOHD2VtZ/369bh//z6aNGmCfv36oVevXihXrhyWLVuGTp064Z9//rHwO2GKDP/7H91Qvf++9duT6GPhQkrBGzGCbiLLljXtoioICwMePbJe6rSgRQtKldaODEoSieJXXjHPLdTaiPRp7ZtuSZLfjklgKwfqY8eAJk1sO3tfuTLV2dmrKK5USV7kqGpVypSwtiiWJBIZrVsb7pktaNWK3pOlDbfCwmh8SrZi0kZNZltCFKvBaEsweDAdk7Nm5YpiW9QUC7p1o0yFpUvN31ZiomXSp81JnRZ07kwmg6Ghxmdj7N1L15YqVcwfB8MweVCFKP7iiy+QkJCAyZMnY/78+fjwww+xYsUKDBkyBDdu3MDs2bNlbWfHjh3YunUrvv32W3z00Uf4+OOPsXLlSnz55ZdITk6WvR2GQYkSwIIFlKb0ySe2Hg2QmUlOoR06ANWrU3Tv9dcpkmNqv8PVq0nUvfyysmM1RIsW9KidQn3+PEW+7Sl1GsgVxdrp0wkJwMOHxkWKq1alR2uK4rQ0MlOyZT2xICSEanPllivExdGEjq05coTGLkds2sps659/6PiUkzotEIZbhw/n1sdbgu3bSYQJEx6lUZPZltoixQC53o8cSRlI4nxsy0hxyZJA//7UmklmMEQvlogUKyWKNRpg+nSaiPj+e/nrZWSQ74a9RYkZxk6wuSi+ffs2IiIi4O3tjQH5IlajR4+Gm5sbtm3bhlQZs2kuelIzXv2vvcstW7U8YeyTxo0pYjx/PrURsiXbtpEh1rvv5i574w2aZTalt2NiIkVp+va1fk9Kb28y3NAWxfbWikng6ko3XtqRYmOcpwW2iBRHRVEKuy3riQUhIXR837hR+OvS04EvvqAoSZ8+1hmbPmJjabxikkcOQUHUn/TJE8uNKz/G1BNr88YbNDloKcOt9HRy+e/cWX4E21hKl6bfoRpEcXw8PapJFAN0jXN0BGbMoL9t3S5n6FD6faxbZ/o20tNpG0pFilNTSaTfuaOMKAbovNGlC5l6JiTIW+fYMRoLi2KGsQg2F8UnTpwAAISEhMAhn5Oeu7s7goKCkJaWhjNmmLDs/68+xd+YdEaGAai22NOTUpZt6Y47fz4JJ23R+OKLFDU2xYV60yaadbZ26rSgRQsSxSIyGBZG0aLnnrPNeMwhf69iU0Txc8/Rjak1RfHRo/TYrJn19qkP4UpeWGumnTuBevXIsKVqVeqvLVqk2AIxVmNq4IOCKOvj778tMyZdhIfTeUJMvMjF05Nu2pctK9hyTAkOHqS6SkulTgvUYralxvRpgM49ffoAjx9TizR3d9uOJyiIPA7MSaEWJU9KRYoB4M8/6dFcky1tpk2jz/3rr+W9ft8+qs21dnYXwxQTbC6Kr//Xk87Hx0fn89X+u5DfMBRB0OLXX3/FvHnz8O233+LNN9/ExIkT4e3tjXHjxpk9XqaYUbYsMGcOpZn++KNtxnDxItUEjhbsVAkAACAASURBVBiRt8eoRkM1Yfv3kzmJMaxZQxf3xo2VHatcWrSgm8RLl2gG/uhR+0udFnh4FBTFjo6AnnOaTkqUoDRSa4riY8eAGjWoJtbW1KtHvzVddcW3bgE9elArD2dnujE8cIBuDq3VNkgXERHkLm5M6q+1zbayskh8GhslFgwfTu3GduxQdFgAKHW6VCnL3+ALs638DvHWJi6O3q81TQ3lMnYsPdqynlig0VC0+ORJKqsxBZHurFSkGMgVxUpFigE67w0ZAvzwA7VNM8S+fUDTpsqIfYZhCmBzUZz8Xz1kaT1ufmL548ePZW/z119/xQ8//IAlS5YgIiIC9erVw9KlS/UKb4YplN69qcfe5Mm5ZiTWZMECMkJ6882Czw0aRNHWVavkby82lkTFgAGWS1s0RMuW9HjkCBmHPH1qv/0LPT3z3nBfvkxi09i0dGu2ZZIkEsVqqCcGaFLghRfyiuInTyiCUqcOOcF/8w2Zs7VpQymenTpRNCkz0zZjjoigKLsx33P16hSNs5YoPnWKaq9NFcXt29NnrbThliSRKG7XjupILYlazLbi4tSXOi0ICqI09iZNbD0SYsAA+l2ZGi22l0gxQOUgDg7Ap58W/rrERCAy0v5aMTGMHWFzUWwJNmzYgEuXLuH48eNYsmQJAKBnz544oqs3KsMYQqOhKHFWFrlRW5OUFEpf7NVLd0SvenWKuq5YId+kaN06em3//ooO1Shq1aL3c+QIpcVWqAAEB9tuPOagK33amNRpgTVF8c2bJOTVUE8sCAkhU6gHD2iipEEDMrnr2JH6W06YkNeZ/K236HO3RBTTEI8ekUA3tn2YgwMJEGsJNFFPbGo01tGRosW7dpHBj1KcOUPZLZZqxaSNWsy21CyKATLbWrbM1qMgnn2W0upXrjRt0ssSkeKTJwEvL+XTyytXBt57j4wvT5/W/7qDB6n7BNcTM4zFsLkodv/vBKMvEiyW64skF0b58uXRvHlzLFmyBCVLlsRHH32E9PR00wfLFF9q1KBI8caNuaZQ1mDdOpr11jbYys/gwZRiLWayDbFmDaVNmyLclEKjITF/+DDdcLdvnzc13J7w8CCRlJZGNy1XrhjXjklQrRrw77+Wqd/Mz7Fj9KgmUSzqitu1o3+SRHXDGzfmunNr8+qrFMVcuNC64wSA48fpuzalp3ZQEIlCY27209Mpu8JQNCk/4eHA88+blyI/fjxNvg0bZrrTfX62baNzgDWyQ8qUUYfZVny8ukWxg81vB/MydChNJISFGb+uJSLF0dHKR4kFEydSK6qJE/W/Zu9eSr9XgwcEwxRRbH4WrF69OgDgpp56CuEY7evra/I+ypQpg4YNG+LBgwe4cuWKydthijkffgjUrk1uncb2FjQFSSKDrfr1cwWDLnr3Blxc5BluXbxIKZW2MtjSpkULiozev2+/9cQARYoBirxGR5OAMTVSLEnWSdE/epRusOrXt/y+5NK0KR3Hf/8NfPkluTS3b6//9Y6OJNR+/x24fdt64wQow6FECdNuUIOCKDX84kX568yaRfv86iv5LVzS08kMzNTUaUGpUhRBvHGj8Jt2Y9i+nT47a9Wzq8FsS+2RYrXRoQOdW01JobZEpBhQtp44/z4++YTc2EV2R3727aP+4drZMgzDKIrNRXHwfymTERERyM7OzvNccnIyTp06BVdXVwQEBJi1n3v/1fw5Wrv9DFN0cHEBfvqJUk+/+sry+zt5kgTsu+8WXvtbtizQvTuwdq3hKOOaNRQRsHU7GyC3lY1GU7j4UTtCFN+9a5rztMCabZmOHaN0dTWdD93cqE730iXKytDTYi8Pos7+vzIZqxERQWm5pqRSGmu2FR0NTJ1KZmM9elAJx5Ythtc7doyEsbmiGKDf6pgxVEZy4IB527p6lbJarJE6LWjUiPqg379vvX3mJy5Ofc7TasbRkbKgwsLylqfIwRKRYsByohigyfZq1YCPPqIsFG1u36ZrC6dOM4xFsbkorlq1KkJCQhAbG4vVq1fneW7evHlITU1F165d4ebmlrP82rVruJavFce///6LeNEHMB/r1q3DuXPn4OXlBT9bpowy9s9LL1H/zu++s3xblfnz6aZ74EDDrx08mHodFpbaLUlUt9S6NdVG2ZqAAOojGhxs3xEUexPFKSmUvqum1GlB48a6U6X1Ua0apVovWUJmbaZy9y7VVMppu5aRAZw4YVrqNEDHRqlS8kWxuEmeNYsM9YKDyQ9ApMDrIzycotnC1M5cvv6a0kfNSaN++JBqRcuVs66nga3NtlJSqLzCns9ztmDoUPpdG2MkCVCk2MFBmfrfUqVyS3ssKYpdXChD5tQpYMOGvM/t20ePbLLFMBbF5qIYAEJDQ1GxYkV89dVXePfddzFz5kwMHjwYy5Ytg4+PD8aKdgH/0bFjR3TMl275zz//oFWrVhgwYAAmTZqEmTNn4tNPP0WXLl0QGhoKNzc3TJ8+HSXstW6RUQ/ffUdibuTIgjO6SpGQAKxfT+7Scurp27Wj2tbCUqgjI4Hr19WROg3QjcaSJcCMGbYeiXl4eNCjEMXu7rlC2RiqVKFHS4viP/+kG001imJTeOstiqbu3m3a+pIE9O1L2Rb16lHGRWG/67/+IoFjqiguUYLaOMkRaIcPk6/AxInU4svNjepxK1emSGth5UD795ObcJkypo0zP25ulEZ96xYJdWNJT6fP+No14LffjO+bbA6BgfRoK1EsJuxZFBtH7dp0nlqyRL6RJECR4jJllKmT1mhyI86WqikWDBhAk8WffJI362vvXrqm1Ktn2f0zTDFHFaK4atWq2LRpE3r27ImzZ89i6dKliI6OxuDBg7FhwwaUL1/e4Dbq1q2LwYMHIyMjA4cOHcKSJUuwY8cOaDQaDBs2DDt37kTTpk2t8G6YIs+zzwLTp1MKpdKtSgTLltFN5DvvyHu9oyNdUHfsIEGti9WraTa6Rw/Fhmk2vXoVXi9tD4i6yHv3cp2nTWl1VbIk3fhYWhQfPUqPRcWwpUsX+g5MNdxau5aclUeOpHq9/v3J+XrzZt034qJtlDnHbVAQOc0WFt3OygJGj85NqRQ8+yyZ02k0ZDYWF1dw3UePaBJMidRpbZo3p562P/2UG72SQ3Y2ZdgcPgwsX061kdbEUmZbO3bQZ9y/PwmZhQvpc7l2La+oEd8Ri2LjGTqU3OcjI+Wvk5ioTD2xQGzL0qLYwQH49luavF6wgJZlZ1PWR9u2tmuhyDDFBYmRoqOjJT8/Pyk6OtrWQ2HshadPJal1a0lydZWkv/9Wfts1a0pSSIhx650+LUmAJP3wQ8HnMjMlqVIlSerVS5kxMnl55hlJGjlSkqpXl6R+/UzfTnCwJLVpo9y4dNGliyT5+1t2H9bmo48kqUQJSfr3X+PWS0qSJE9PSWrSRJKysui3t3YtfT6AJAUGStKOHZKUnZ27Tvfu9Ps0h6VLafsXLuh/zY8/0ms2btT9/LFjklSyJB0zKSl5n9u+ndYNDzdvnLpITZUkPz9JqlqVPj85jBtH4/nuO+XHI5d+/SSpShXltvfXX3T+r1JFknx86PijaRT65+BAz7VoQdcKQJKOHlVu/8WFpCT6nEeMkL9Oly6SFBCg3BiCgiTpueeU215hZGfT8fLMM/Te//qLjp1ly6yzf4YpxqgiUswwdoeDA9U5ubuTaVVamnLb3rePzGgKa8Oki4AAinDpSqEODyeTGVv2Ji7KiAjvzZvmtboypVfx6NEUefzrL8OvlSSqRS0qqdOC4cMp6mqsU+3nn1OE/8cfKa3ZwYFSqc+fp4hmYiLQuTN9Xnv30ucXEWF66rTAkNlWQgKZjbVuDfTsqfs1zZqRcV5kJGWJaEedw8Mp8+DFF80bpy5cXSmTJSaG2jUZYu5cYOZMOk7HjVN+PHJp1IjS7HVF1o0lLg7o1g2oWJEMEW/coMyeGzfIiGzpUvr+RH/oK1eozMKSNalFlTJlKKNo7Vr5XR+SkpSNFNeqRe741kCjoUy0+Hgq1RIZGWyyxTCWx9aqXA1wpJgxmV27aBbXmFlsQ3TvLknPPitJ6enGrztzpu4I1KBBklSunGnbZAzTpg19voAkrV5t+nbGj5ckZ2eKWMohOlqSHB0pKuXkJEnffEMRT31cuUJj/Pln08eoVl56SZJ8feV/dmfPUnSvsN9uRoYk/fILRfwASWrUiB4XLzZvrBkZkuTiIkkffKD7+XfeobGdP294W3Pn0phGj86NaDdoYPmMg/Hjab+7d+t/zcaNkqTRSFKPHoUfl9bgwAEa765d5m0nI0OSWrWiKP3Jk0qMjDHE/v303a1aJe/1DRpIUteuyu3/yRPrXzv79pUkNzeKUtepY919M0wxhSPFDGMOHTpQtOTnn4FffzV/e9HRZKQzfLi8ljT56d+fol0rV+YuS02lFi69epm2TcYwnp65vTHNjRRnZFD0Ug4//EA1ZydPUuRq4kSKTunp+55TT1zUIsUAGW7duEEGU4aQJGqBUq4ctTvSh5MTbffKFWDePOohrdGY7+js5ESZHboixadP0/lk1Ch5xjpjxlCd77x5wOzZlBFy9qzy9cT5mTKFjJCGD89tgaPNH39QBLtZM/IzsLXJpVJmWx98QDXoCxeSWzpjeVq1Anx95bdeS0pSph2TwNnZ+tfOr74CMjPpHMFRYoaxCiyKGcZcpk6lNinDh5NBhjn88gvdsI8YYdr6np7U83flylwH3e3bqYUKp05bDm23aXNSJI1py5SSQsdLjx6UjrthA6X8nj5NafQrVxY0ijp2jNIR69Y1fYxqpWdPoEIFeYZbq1cDR44A33xDKbCGcHEhkXr9OnDunDKGO0FBdMOr7XQtSZRmXLEipXbLZcYM4LXXKD1ZdGto3dr8MRZGyZJ0vMXGFkyLvnSJWi9Vq0aTfK6ulh2LHMqWpQmr9euBO3dM28bixTQRNW6cvFZ5jDI4OABDhtCEV2go/cZ37KAJjtjYgq3UlDbasgU1apD5H8CimGGsha1D1WqA06cZs7l+XZLKlpWkpk0p1coUnjwh05/Onc0by9q1eU12unSRJG9v26cvFmWmT6fP3MPDvO2cPUvbWbfO8Gvnz6fXRkTkXX7jBpm0AZLUu7ckJSTkPhcQIEmvvGLeGNXM++9TGvn9+/pfk5hI31PTpvJTrS3BL7/Qd3T1au6yNWto2aJFxm8vNVWSXnyR1i9Thsz1rMHEiXnTku/cIeOpSpUk6do164xBLlu2UEpqpUrGm5AdPUrH1iuvWO+zZXKJjiZzN20zM/FPo6GSowYNJKl9e/p78mRbj9h8EhMlafZsStlnGMbicKSYYZTA15faM0VGUmsOU/jtN+p1a6zBVn66daNo4IoVZNizaxeZB9k6fbEoIyLF5qROA/IjxdnZwJw51Ic2v5mSjw9w8CAwbRodU88/TyZRjx9TlLMopk4L3nqLUg4L69f9+eeUYjx/vjJ9TE0lv9lWcjKVYjRuTG1ojMXVlaKytWsDnTpRmzZr8PnnlOY9fDhF7Tp3ps83LAyoXt06Y5BL9+50jq5YEXjlFeDLL+X1mo+NpUyEKlWob7S1Plsml8qV6bz45Alw+zZw4gSwdSu1LvrsM/p+fHyABw/ouLP3Vn8AZTe8/z6VWzAMY3H4zM4wStGrF6U7zZhBqYuvvipvvexsSnUdP54u5u3bmzcOV1fg9dfJrbNBA0otGzDAvG0yhSNEsb+/edspU4bS/gyJ4t9/p57Iq1fr7l1ZogTVF7drR2me7dpR/Xt2dtEWxXXr0iTBwoVU+5n/szl7lmpvR44kN2JbUr8+3exGRQG9ewNff03i69dfTRfrFSsCZ85YdwLMxYXcqJs1o88/JYXEuVrrbevVI2E8ciSJqT/+oPOvvh7C6elUopCcTE7AFSpYd7xMXpydaXKiShVbj4RhmCIGR4oZRklmzSIhOngw8O+/hl9/+jTQogXVS9WoQTPfSkSvBg+mm9PJk4E6dYCGDc3fJqMfpSLFgLy2TLNnA97eJKYKIyiIRNfo0SSkARIvRZm33qKa1iNH8i4X5lrly5OJja1xcSFhfOoUtWCbOZN+t+ZOWjg7Wz8rpHFjYNIk4NEj4KefgI4drbt/Y3F3JyH888+UVREYmGtCp40kkXg+eZJeL8f4jGEYhrFLWBQzjJK4ulJ6XWoqRei0e4dq8/AhGfc0akTOtkuWUMSifn1lxtG8OaV0p6WRwZauaCKjHP7+NLHRo4f52zIkis+do4jVqFHy0upcXYHvv6d1Fi+2fwMaQ/TuTRH3/IZbq1ZRj+Fvv1VPtE9MWowdSyL5m29sPSLTmTIFuHaNJiXsAY0GePttEsMuLuRwPHNmXnO6778nM7HQUEq9ZhiGYYosLIoZRmnq1CGH0gMHKCVSm+xsEiZ+fhRR+d//KA126FBl6xuFW6eDA7tOWwNnZ2DpUmVciYUozu8cLZg7l4Tu228bt902bYBhw8wfn9opVYrKBTZupMkngNxoP/yQouRDhth0eHkICqIayB07KJXXy8vWIzIdjUZ9NcRyEC7gXbrQMdKjBx0v4eHkMt29O303DMMwTJGGRTHDWIIhQ+jG/PPPgcOHaVlUFNU7Dh9OZjinTlEkwlKRu4kTqb7QHm9UizPVqpEpluh7rM39+xTxfOMN9UQ71chbb1Et6KpV9HdoKBAfD/z4o23NtfIjzLb8/KjfMGMbypYFNm2isoSwMPpeXn+dztMrVqjrmGEYhmEsAp/pGcYSaDQUCa5enSK1I0aQU/DNm3STdfgwEBBg2TE4OyuXjs1Yj8IcqBcsIPfV996z7pjsjcBAKk1YuJAmhn74AXjnnVwRqhYCA6mf76JF9HtlbIdGQ06/hw+Tg7kkkXt76dK2HhnDMAxjBTSSpC9Hr/gQExODNm3aIDw8HJUrV7b1cJiixKlTZJzz9CmZHX3+OUUlGEYfkZFAcDDdkHfrlrv8yRMSzEFBwM6dthufvfDzz2SS5OtLzsGXLpHJFsMYIjmZjAo9PGw9EoZhGMZKcEsmhrEkQUHkglu6NNUaM4wh9EWK160D7t0jUybGMP36UVumGzeo3psFMSMXd3f6xzAMwxQbWBQzjKVp2tTWI2DsiUqVgJIl84piSaJ6x3r1gLZtbTc2e6JMGZpAOHeOWh0xDMMwDMPogUUxwzCMmtBogKpV84riQ4eoNnbhQm6vZQxq6EfMMAzDMIzqYaMthmEYtZG/V/Hs2cAzz5CjOcMwDMMwDKMoLIoZhmHUhrYovnoV2L6d3JNdXW07LoZhGIZhmCIIi2KGYRi1Ua0aEBcHpKZSL2tHRxLFDMMwDMMwjOKwKGYYhlEbwoH63DlgyRJyUvbysu2YGIZhGIZhiigsihmGYdSGEMWffkr9Ut9/37bjYRiGYRiGKcKwKGYYhlEbQhTv3Qu0agUEBtp2PAzDMAzDMEUYFsUMwzBqw9sbKFGC/j92rG3HwjAMwzAMU8ThPsUMwzBqw9ERqFyZHjt3tvVoGIZhGIZhijQsihmGYdTITz8BFSrkRowZhmEYhmEYi8CimGEYRo28+qqtR8AwDMMwDFMs4JpihmEYhmEYhmEYptiiqChOSkpCamqqkptkGIZhGIZhGIZhGIthtCg+duwYpk+fjqSkpJxlCQkJGDhwIJo1a4amTZti2rRpig6SYRiGYRiGYRiGYSyB0aJ45cqV2Lt3L8qWLZuz7Ntvv8Wff/6JqlWroly5clixYgV27typ6EAZhmEYhmEYhmEYRmmMFsUXL15Eo0aNcv5OT0/H7t270bx5c+zevRu///47vLy8sG7dOkUHyjAMwzAMwzAMwzBKY7QofvDgASpVqpTz95kzZ/DkyRP06NEDAODu7o6XXnoJN27cUG6UDMMwDMMwDMMwDGMBjBbFzs7OSE9Pz/n7zz//hEajQZMmTXKWubu756k5ZhiGYRiGYRiGYRg1YrQorly5Mo4fP57z9549e1CtWjV4eHjkLLtz5w7Kly+vzAgZhmEYhmEYhmEYxkIYLYq7d++Oy5cvo3fv3ujfvz8uX76Mzp0753nNpUuX4Ovrq9ggGYZhGIZhGIZhGMYSGC2K+/Xrh06dOuH8+fM4der/7N15fIzn/v/xdwiJSMQWWyxBO5FjTxEqlorW0pbaitrbcnrOsRzVqjqcU9TSRZXooe2pVkRrV0pLbSVRgkajpagQsYtISERE5P794Tvz63QmkZCYMK/n45FH5bqu+7o/91xzTfOZ616i1bZtWw0bNsxSf/ToUR09elTNmjXL10ABAAAAAMhvLoZhGHezYWpqqqTb1w//0eXLl3Xx4kX5+vrKy8vr3iO8D06fPq2QkBBt2bJFVatWdXQ4AAAAAID7xPVuN/xzMmxWtmxZlS1b9q4DAgAAAADgfslzUnzlyhUlJCSoevXqKl68uKV85cqV2rx5szw8PDRo0CA1aNAgXwMFAAAAACC/5Tkp/uCDD7R27Vrt2rXLUrZo0SJNmzZN5jOxN2/erJUrV+qRRx7Jdb/nz5/X7NmzFRERoeTkZFWoUEEhISEaPny4vL2977h9WlqaNm/erO3bt+vgwYM6f/68XFxcVLNmTT3zzDPq37+/VRIPAAAAAECeb7QVHR2tFi1ayN3d3VK2YMECVaxYUeHh4frwww8lSZ9//nmu+4yPj1f37t21atUqNWjQQIMHD1bVqlUVFham3r17Kykp6Y597Nu3T6+//roiIyNlMpnUv39/Pfvss7p48aLeeecdDRw4UDdu3Mjr4QIAAAAAHmJ5Xim+ePGiWrRoYfn92LFjOnfunF577TU1adJEkrRhwwbt27cv131OmjRJiYmJmjBhggYMGGApnz59ur744gvNmjVLkydPzrEPHx8fvffee+rYsaPVivDYsWM1cOBA7d+/X4sXL9aLL76Y67gAAAAAAA+3PK8Up6eny83NzfJ7dHS0XFxc9Pjjj1vKqlevrgsXLuSqv/j4eEVGRsrX11f9+vWzqhsxYoQ8PDy0du1apaWl5dhPQECAunTpYnOKtKenp4YMGSJJ2rNnT65iAgAAAAA4hzwnxRUrVtTx48ctv0dGRsrT01N16tSxlF25csUqcc5JVFSUJCk4OFhFiliH4+npqcDAQF2/fl0xMTF5DdXC1fX2gnjRokXvug8AAAAAwMMnz0lxUFCQtm/frvDwcC1fvlxbt25Vq1atrBLaU6dOqXLlyrnqz5xg+/n52a2vUaOGJOnEiRN5DdVi5cqVkqRWrVrddR8AAAAAgIdPnq8pHjZsmL7//ntNnTpVhmHIw8NDw4cPt9Snpqbqp59+Uvfu3XPVX2pqqiTJy8vLbr25PCUlJa+hSpLCw8MVERGhgIAA9ejR4676AAAAAAA8nPKcFFerVk3r1q3Txo0bJUnt2rVTlSpVLPUnT55U79699cwzz+RflHfp+++/17Rp0+Tj46PQ0FAVK1bM0SEBAAAAAAqRPCfF0u07Pffv399uXd26dVW3bt1c9+Xp6Skp+5Vgc3l2K8nZ2bx5s1599VWVLVtWYWFhqlatWp62BwAAAAA8/O4qKTa7efOmjh8/rpSUFHl6eqp27dp5Xo2tVauWJCkuLs5u/cmTJyVJNWvWzHWf3333nV577TWVL19eCxcuzPZ6ZQAAAACAc7urpDg1NVXvvvuu1q5dqxs3bljK3dzc1KVLF7322msqVapUrvoKCgqSdPsu1llZWVY37EpNTVV0dLRKlCihhg0b5qq/tWvXaty4capYsSIrxAAAAACAHOX57tOpqanq27evli1bpqJFi6pJkybq1KmTmjRpIldXVy1btkwvvPCC5QZad1K9enUFBwfrzJkzWrx4sVVdaGio0tLS1KVLF3l4eFjKY2NjFRsba9PX6tWr9cYbb6hy5coKDw8nIQYAAAAA5MjFMAwjLxvMnDlTn376qfr27avRo0dbrQinpKToww8/1OLFizV06FCNGTMmV33Gx8erT58+SkxMVEhIiGrXrq2YmBhFRUXJz89PS5YsUZkyZSzt/f39JUlHjhyxlO3evVtDhgxRVlaWevToYfeRUF5eXho8eLBN+enTpxUSEqItW7aoatWquX0pAAAAAAAPuDwnxR06dFCZMmW0ZMmSbNv06dNHSUlJljtU58a5c+c0Z84cRUREKDk5WT4+Pmrfvr2GDx8ub29vq7b2kuJVq1bpzTffzHEfvr6+2rp1q005STEAAAAAOKc8X1N89uxZdejQIcc2zZo10xdffJGnfitXrqzp06fnqu0fk2Gz7t275/rZyAAAAAAASHdxTbGHh4cSExNzbHP58mWVKFHiroMCAAAAAOB+yHNSXK9ePW3YsCHbRyjFx8fru+++U7169e41NgAAAAAAClSeT59++eWX9eKLL6pnz57q37+/goKCVKFCBSUkJGjPnj0KDw9XWlqaXnrppYKIFwAAAACAfJPnG21J0pIlSzR16lRlZmZalRuGIVdXV40fP14vvPBCvgVZ0LjRFgAAAAA4pzyvFEu37y7dunVrrVmzRr/99ptSUlLk5eWlgIAAdenSRb6+vvkdJwAAAAAA+e6ukmJJqlKliv72t7/Zrbtx44Zu3rwpT0/Puw4MAAAAAICClucbbeXGW2+9pWbNmhVE1wAAAAAA5JsCSYql29cXAwAAAABQmBVYUgwAAAAAQGFHUgwAAAAAcFokxQAAAAAAp0VSDAAAAABwWiTFAAAAAACnlavnFAcEBBR0HAAAAAAA3He5Sorv5vFKLi4ued4GAAAAAID7KVdJ8eHDhws6DgAAAAAA7juuKQYAAAAAOC2SYgAAAACA0yIpBgAAAAA4LZJiAAAAAIDTIikGAAAAADgtkmIAAAAAgNMiKQYAAAAAOC2SYgAAAACA0yIpBgAAAAA4LZJiAAAAAIDTIikGAAAAADgtkmIAAAAAgNMiKQYAAAAAOC2SYgAAAACA0yIpBgAAAAA4LZJiAAAAAIDTKCjxcQAAIABJREFUIikGAAAAADgtkmIAAAAAgNMiKQYAAAAAOC2SYgAAAACA0yIpBgAAAAA4LZJiAAAAAIDTIikGAAAAADgtkmIAAAAAgNNydXQAZufPn9fs2bMVERGh5ORkVahQQSEhIRo+fLi8vb1z1cfOnTsVERGh3377TYcPH1ZycrICAwP11VdfFXD0AAAAAIAHUaFIiuPj49WnTx8lJiYqJCREtWrV0oEDBxQWFqaIiAh99dVXKlOmzB37Wbx4sbZs2SI3NzfVqFFDycnJ9yF6AAAAAMCDqlCcPj1p0iQlJiZqwoQJ+u9//6vXXntNYWFhGjx4sE6cOKFZs2blqp+hQ4dq3bp12r9/v+bNm1fAUQMAAAAAHnQOT4rj4+MVGRkpX19f9evXz6puxIgR8vDw0Nq1a5WWlnbHvho3bqxHH31URYsWLahwAQAAAAAPEYcnxVFRUZKk4OBgFSliHY6np6cCAwN1/fp1xcTEOCI8AAAAAMBDzOFJ8fHjxyVJfn5+dutr1KghSTpx4sT9CgkAAAAA4CQcnhSnpqZKkry8vOzWm8tTUlLuW0wAAAAAAOfg8KQYAAAAAABHcXhS7OnpKSn7lWBzeXYryQAAAAAA3C2HJ8W1atWSJMXFxdmtP3nypCSpZs2a9yskAAAAAICTcHhSHBQUJEmKjIxUVlaWVV1qaqqio6NVokQJNWzY0BHhAQAAAAAeYg5PiqtXr67g4GCdOXNGixcvtqoLDQ1VWlqaunTpIg8PD0t5bGysYmNj73eoAAAAAICHjIthGIajg4iPj1efPn2UmJiokJAQ1a5dWzExMYqKipKfn5+WLFmiMmXKWNr7+/tLko4cOWLVz759+7RixQpJUlpamjZu3Khy5cqpdevWljYzZsyw2f/p06cVEhKiLVu2qGrVqgVxiAAAAACAQsjV0QFIt1eLV65cqTlz5igiIkI7duyQj4+PBg4cqOHDh8vb2ztX/cTHx2v16tVWZYmJiVZl9pJiAAAAAIBzKhQrxY7GSjEAAAAAOCeHX1MMAAAAAICjkBQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGm5OjoAs/Pnz2v27NmKiIhQcnKyKlSooJCQEA0fPlze3t657ic5OVkfffSRtmzZoosXL6p06dJq1aqVRo0apUqVKhXgEQAAAAAAHjSFIimOj49Xnz59lJiYqJCQENWqVUsHDhxQWFiYIiIi9NVXX6lMmTJ37CcpKUl9+vRRXFycmjdvrs6dO+v48eNatWqVtm/frqVLl6patWr34YgAAAAAAA+CQpEUT5o0SYmJiZowYYIGDBhgKZ8+fbq++OILzZo1S5MnT75jP7NmzVJcXJyGDBmicePGWcrDwsI0depUvfXWW/rss88K5BgAAAAAAA8eh19THB8fr8jISPn6+qpfv35WdSNGjJCHh4fWrl2rtLS0HPu5du2a1qxZIw8PDw0fPtyqrn///vL19VVkZKROnTqV78cAAAAAAHgwOTwpjoqKkiQFBwerSBHrcDw9PRUYGKjr168rJiYmx35iYmKUnp6uwMBAeXp6WtUVKVJEwcHBkqTdu3fnY/QAAAAAgAeZw0+fPn78uCTJz8/Pbn2NGjUUGRmpEydOqEWLFtn2c+LEiTv2I0lxcXE2dbdu3ZJ0+2ZfAAAAAICHU6VKleTqap0GOzwpTk1NlSR5eXnZrTeXp6Sk5NiPuf7Pq8S56SchIUGSbE7fBgAAAAA8PLZs2aKqVatalTk8KS4M6tWrp8WLF8vHx0dFixZ1dDgAAAAAgAJg7zG9Dk+KzSu72a0Em8uzW0k2M9ebV57z0o+7u7uaNGmSu4ABAAAAAA8Nh99oq1atWpLsX+srSSdPnpQk1axZM8d+zPV36ie7a44BAAAAAM7H4UlxUFCQJCkyMlJZWVlWdampqYqOjlaJEiXUsGHDHPtp2LCh3N3dFR0dbbNanJWVpcjISElS8+bN8zF6AAAAAMCDzOGnT1evXl3BwcGKjIzU4sWLNWDAAEtdaGio0tLS1Lt3b3l4eFjKY2NjJUm1a9e2lJUsWVJdu3bV0qVLNXfuXI0bN85SFx4erjNnzig4OFjVqlW755jPnz+v2bNnKyIiQsnJyapQoYJCQkI0fPhweXt757qf5ORkffTRR9qyZYsuXryo0qVLq1WrVho1apTdc93zc98PI0eNS7t27XTmzBm7fZUvX147d+6862N60OXHmOzcuVMRERH67bffdPjwYSUnJyswMFBfffVVjtsdO3ZMoaGh2rNnj1JTU1WlShU9/fTTGjZsmNzd3fPj8B5YjhoXf3//bOsaNmyoZcuW5flYHhb3OiZpaWnavHmztm/froMHD+r8+fNycXFRzZo19cwzz6h///4qXry43W2ZK/Y5akyYJznLj8+v//3vf4qKilJsbKySkpLk4uIiX19fPf744xoyZEi2f4MxV+xz1JgwV3JWEDnD3r17NXDgQGVlZemVV17R6NGj7baLjo7WvHnzLI/MrVGjhnr06KEBAwYU2vs3uRiGYTg6iPj4ePXp00eJiYkKCQlR7dq1FRMTo6ioKPn5+WnJkiUqU6aMpb15Ehw5csSqn6SkJPXp00dxcXFq3ry5GjRooNjYWG3ZskXlypXTkiVLVL169XyNtVatWjpw4ICioqJUs2ZNffXVV1axZufPsdavX1/Hjx+3xLp06VKbBD6/9v0wcuS4tGvXTlevXtWgQYNs+vPw8NBLL72Ub8f5IMmvMfn73/+uLVu2yM3NTTVq1NDRo0fvmHzFxMRo0KBByszMVIcOHVSpUiXt3r1bv/76qwIDA7Vw4cJsE4SHnSPHxd/fX76+vurWrZtNXaVKldSrV697OrYHVX6MyY4dOzR06FCVLl1aQUFBql69uq5evaqtW7cqISFBjRs31sKFC+Xm5ma1HXPFPkeOCfMke/n1+fXkk0/Kw8NDderUUbly5ZSZmanffvtNe/bskaenpxYtWqS//OUvVtswV+xz5JgwV7JXEDlDamqqunTpoqSkJKWlpWWbFG/evFkjR46Um5ubOnXqJG9vb23btk0nTpxQhw4dNGfOnPw6zPxlFBJnz541xo0bZ7Rs2dKoW7eu0bZtW+Ptt982kpOTbdqaTCbDZDLZ7ScpKcmYMmWK0bZtW6Nu3bpGy5YtjXHjxhnnzp3LlzhffPFFw2QyGWFhYVbl06ZNM0wmkzFx4sRc9TNx4kTDZDIZ06dPtypfuHChYTKZjBdffLHA9v0wcuS4PPHEE8YTTzxx98E/pPJrTKKjo42jR48amZmZxqlTpwyTyWT06dMn2/aZmZlGp06dDJPJZGzevNlSfuvWLWPEiBGGyWQyPv7447s7qIeAo8bFMG5/dvfv3/+uY39Y5ceYHDp0yFizZo1x48YNq/KUlBSjW7duhslkMj777DOrOuZK9hw1JobBPMlJfn1+paen2y1funSpYTKZjJdfftmqnLmSPUeNiWEwV3JSEDnDuHHjjKZNmxrz5s0zTCaT8cEHH9i0SUlJMZo3b27UrVvXOHDggKU8PT3d6N27t2EymYx169bl/YDug0KTFD8ITp48aZhMJuOJJ54wbt26ZVWXkpJiNGrUyGjYsKFx7dq1HPtJTU01GjRoYDRq1MhISUmxqrt165bxxBNPGCaTyYiPj8/3fT+MHDkuhkFSbE9BvV9zk3z9+OOPhslkMvr162dTFx8fb4krKysrT/t+GDhyXAyDP2DsuR+f7WvXrjVMJpPx17/+1aqcuWKfI8fEMJgn2bkf43L16lXDZDIZTz75pFU5c8U+R46JYTBXslMQ47Jp0ybDZDIZX3/9tbFy5cpsk+Lly5cbJpPJGDt2rE1dTvOoMHD4jbYeJFFRUZKk4OBgFSli/dJ5enoqMDBQ169fV0xMTI79mM+vDwwMtDySyqxIkSIKDg6WJO3evTvf9/0wcuS4mGVkZGjNmjWaP3++Fi5cqN27d+vWrVv3clgPNEe+X83j06pVK5u6atWqyc/PT2fOnNGpU6fyfd+FXWH4HLl69apWrFih+fPna/Hixfr5558LbF8PgvsxJq6ut28f8ufruJgr9jlyTMyYJ7bux7hs3bpVku21qswV+xw5JmbMFVv5PS6JiYmaOHGi2rdvr65du+bYNqe50rRpU5UoUUL79+9XRkZGrvZ9Pzn8RlsPkuPHj0vK/rFONWrUUGRkpE6cOKEWLVpk28+JEyfu2I9k/Xip/Nr3w8iR42KWkJCgsWPHWpVVrVpV06dPV7Nmze5wBA8fR75f7zSOfn5+iouL04kTJ+75HgMPmsLwOXL48GH961//siqrU6eO3n333RxvmvKwuh9jsnLlSkm2f6QwV+xz5JiYMU9sFcS4LF++XOfPn1daWpqOHj2qH3/8Ub6+vhozZoxVO+aKfY4cEzPmiq38HpcJEyYoKytLkyZNumPbnOaKq6urqlatqt9//12nTp2yumFyYUBSnAfmRz15eXnZrTeXp6Sk5NiPuf7Pq5E59ZNf+34YOXJcJKl79+567LHH9Oijj6pkyZI6deqUwsPDtWzZMg0dOlRLly5VnTp1cn9ADwFHvl/vtG/z+DJXbBX058iQIUP01FNPyc/PT25ubjp+/Lg+/fRTbdy4UYMGDdKaNWtUsWLFAtl3YVXQYxIeHq6IiAgFBASoR48eedq3s84VR46JxDzJTkGMy/Lly61Wy+rXr6+ZM2davgTP7b6ZK/d/TCTmSnbyc1xWrFihrVu3atasWSpfvvw979s8V65evXrHvu43Tp8G7tHw4cPVokULlS9fXiVKlJDJZNLkyZM1ZMgQpaenKzQ01NEhAoXCuHHjFBgYqLJly6pkyZKqX7++5syZow4dOigpKUmfffaZo0N8qHz//feaNm2afHx8FBoaqmLFijk6JKeXmzFhntw/y5Yt05EjR7R7924tWLBA0u0vuiMiIhwcmfPKy5gwVwrW6dOnNW3aNHXs2FGdO3d2dDgFjqQ4D+70TaC5PLtvR8zM9eZvU3LTT37t+2HkyHHJSZ8+fSRJ+/bty1X7h4kj36932vedvsV8mBXWzxHmSv6PyebNm/Xqq6+qbNmyCgsLs3mUXG727axzxZFjkhNnnidSwX5+lSlTRi1bttSCBQvk7u6usWPHKj09Pdf7Zq7c/zHJCXMlf8Zl/Pjxcnd313/+859827d5rpQqVSrXfd4vJMV5UKtWLUn2rymVpJMnT0qSatasmWM/5vo79fPH8/Hza98PI0eOS07Kli0rSUpLS8tV+4eJI9+vdxpHczlzxZajPkeYK/k7Jt99951GjRqlcuXKKTw83LKPP2Ou2OfIMcmJM88T6f58fpUqVUqNGjXS5cuX9fvvv1vKmSv2OXJMcsJcyZ9xOXTokBITE9WiRQv5+/tbft58801J0vz58+Xv76+///3vlm1ymiuZmZk6ffq0XF1d8/yl4P1AUpwHQUFBkqTIyEhlZWVZ1aWmpio6OlolSpRQw4YNc+ynYcOGcnd3V3R0tM2qZFZWliIjIyVJzZs3z/d9P4wcOS45Md8BsTBO/ILmyPereXzsnWp16tQpxcXFydfXl3EpRJ8jzJX8G5O1a9dqzJgxqlChgsLDw3P8Eo+5Yp8jxyQnzjxPpPv3+XXhwgVJ//8O4RJzJTuOHJOcMFfyZ1yee+459ezZ0+anadOmkqSAgAD17NlTLVu2tGyT01zZu3evrl+/rsaNG6t48eL3dIwFgaQ4D6pXr67g4GCdOXNGixcvtqoLDQ1VWlqaunTpIg8PD0t5bGysYmNjrdqWLFlSXbt2VVpamubOnWtVFx4erjNnzig4ONhqMt/Nvp2FI8clNjbW7jeRp0+f1pQpUyRJXbp0uedjfNDk15jcjWbNmql27drau3evtmzZYinPysrSe++9J+n2qVUuLi73vK8HjSPH5fDhw7p586bd8lmzZklirtzrmKxevVpvvPGGKleurPDw8Dv+Qchcsc+RY8I8yV5+jcvZs2d16dIlu/tYsmSJfvnlF1WuXFkmk8lSzlyxz5FjwlzJXn6Ny4QJEzR16lSbn+7du0uS2rRpo6lTp6pfv36WbTp27KgyZcpo/fr1+uWXXyzlN27c0OzZsyVJffv2zfdjzg8uhmEYjg7iQRIfH68+ffooMTFRISEhql27tmJiYhQVFSU/Pz8tWbJEZcqUsbQ33w7+yJEjVv0kJSWpT58+iouLU/PmzdWgQQPFxsZqy5YtKleunJYsWWJzW/+87tuZOGpcQkNDtWDBAjVt2lRVqlSx3H36hx9+0I0bN9SmTRvNnTu3UH4jVtDya0z27dunFStWSLp9KtTGjRtVrlw5tW7d2tJmxowZVtvExMRo0KBByszMVIcOHVS5cmXt2rVLv/76qwIDA7Vw4UKnHBPJceMybtw4bdu2TY899pgqV66s4sWL6/jx44qIiNCtW7f0/PPPa/LkyU73R6WUP2Oye/duDRkyRFlZWerRo4cqV65ssx8vLy8NHjzYqoy5Yp+jxoR5krP8GJfNmzdr1KhRatSokapXr67y5csrOTlZP//8s44ePSoPDw99/PHHNo9TZK7Y56gxYa7kLL/+X2/PqlWr9Oabb+qVV17R6NGjbeo3b96skSNHys3NTZ07d5a3t7e2bt2qEydOqEOHDpo9e3ahHBeS4rtw7tw5zZkzRxEREUpOTpaPj4/at2+v4cOHy9vb26ptTm+y5ORkzZ07V1u2bFFCQoJKly6tVq1aadSoUapUqdI979vZOGJc9uzZoyVLlujQoUO6dOmSrl+/Li8vLwUEBKhr167q2rVroZz490t+jIn5wzcn9sbx2LFjmjNnjqKionTt2jX5+vrq6aef1rBhw+Tu7n6PR/Zgc8S4bN68WV9//bWOHDmixMREZWRkqHTp0qpXr5569eqlkJCQfDq6B9O9jkluxsPX11dbt261KWeu2OeIMWGe3Nm9jsvZs2e1aNEi7du3T2fOnNGVK1dUvHhxVatWTS1bttTAgQPtfoEhMVey44gxYa7cWX79Xfxnd0qKJemnn37S/Pnz9fPPP+vGjRuqUaOGevTooQEDBqho0aL3fnAFgKQYAAAAAOC0uKYYAAAAAOC0SIoBAAAAAE6LpBgAAAAA4LRIigEAAAAAToukGAAAAADgtEiKAQAAAABOi6QYAAAAAOC0SIoBAAAAAE6LpBgAACfSt29fde3aVYZhODqUOxo6dKg6dOigmzdvOjoUAMBDjKQYAIB75O/vL39/f6uy06dPy9/fX+PGjXNQVLbWr1+v6OhojRw5Ui4uLpbyjIwMLVy4UOPGjVPXrl1Vr149+fv7a9WqVQUaT2hoqOW1i4qKsqkfNWqU4uLitHjx4gKNAwDg3EiKAQBwAllZWfrwww/1yCOPKCQkxKouNTVV06ZN0+rVq3Xp0iWVL1++wOM5cOCA5s+fLw8Pj2zb1KtXTy1bttS8efOUnp5e4DEBAJwTSTEAAE4gIiJC8fHxeu6552zqPD099emnn2rnzp3auXOnunbtWqCxpKena+zYsWrUqJHatWuXY9vnnntOycnJ+vbbbws0JgCA8yIpBgAgn4WGhlpWY1evXm05RdjeKckREREaOnSogoKCVK9ePbVv317vvPOOrl69atNvu3bt1K5dO6Wmpmr69Olq166d6tatq9DQ0DvGtHLlSklS586dbeqKFy+u1q1b53mFOC0tTfPnz1eXLl3UqFEjNW7cWH369LljAvvee+/pwoULmj59utVp3PY8+eSTKlasmFasWJGn2AAAyC1XRwcAAMDDplmzZho4cKDCwsJUp04dtW/f3lIXEBBg+ffcuXMVGhqq0qVLq23btipbtqyOHj2qBQsWaMeOHVq6dKk8PT2t+s7IyNDAgQN15coVtWzZUp6enqpatWqO8WRlZWn37t2qVKmSfH198+UYr1y5ooEDB+rw4cOqW7euevTooaysLEVERGj06NGKjY3ViBEjbLbbuXOnFi9erIkTJ6p69ep33E+JEiX0l7/8RTExMbp27ZpKliyZL/EDAGBGUgwAQD4LCgqSr6+vwsLCFBAQYDc53L17t0JDQ9W4cWN98sknKlWqlKVu1apVevPNNzVnzhyNHz/earuEhAQ98sgjCg8Pz/F63D86duyYrly5oqZNm97bgf3BlClTdPjwYY0bN05DhgyxlKenp+tvf/ubPvroIz311FNWNyC7cuWK3nzzTQUFBemFF17I9b7q16+vmJgY7d+/X8HBwfl2DAAASJw+DQCAQyxatEjS7eTyjwmxJHXv3l0BAQH65ptv7G47bty4XCfEknTu3DlJko+Pz11Gay0xMVHr169Xo0aNrBJiSXJ3d9eYMWNkGIbWr19vVTd58mTLTb3udNr0H5lP6zYfBwAA+YmVYgAAHODnn39WsWLFtGHDBm3YsMGm/ubNm7p8+bKSkpJUpkwZS7mbm5vN45/uJCkpSZLk7e19b0H/nwMHDigrK0uGYdi9njkjI0OSFBsbayn79ttvtW7dOk2ePDnPp3Cb4zYfBwAA+YmkGAAAB0hOTlZmZqbmzp2bY7u0tDSrpLhcuXJ5WmWVbq/eStKNGzfyHqgdycnJkqSYmBjFxMRk2y4tLU2SdPnyZU2aNEnBwcHq3bt3nvdnjtvNze0uogUAIGckxQAAOICnp6cMw9CePXvytF1eE2LpdiIt/f9k9l55eXlJkl566SWNHTv2ju3PnDmj5ORkRUZGZrvKPXDgQEnSxIkT1b9/f6s6c9zm4wAAID+RFAMAUACKFi0qSbp165bd+kaNGumHH37Q77//rkcffbRAY3n00Ufl4uKi48eP50t/DRo0kIuLi3766adctS9btqx69uxpt27Pnj2Kj49XmzZt5OPjo0ceecSmjTnuP965GwCA/EJSDABAAShVqpRcXFyyvTnU4MGD9cMPP2jixImaPXu2KlasaFWflpamo0ePqlGjRrne5/Xr13X27Fl5eHiocuXKlvLSpUvL399fhw4dUkZGhooXL353B/V/KlSooKefflrr1q3Txx9/rJdfftnyJYDZyZMn5erqKl9fX/n6+mrq1Kl2+3rttdcUHx+vl156SUFBQXbbxMTEyMfHR7Vr176nuAEAsIekGACAAlCyZEk1bNhQ+/bt05gxY1SzZk0VKVJE7dq1U506ddSiRQuNGTNGH3zwgTp06KDWrVuratWqSktL09mzZ7V3714FBgbqs88+y/U+9+/fryFDhqhFixb64osvrOqeeuopzZkzR1FRUWrVqpXNtvPnz1dcXJwk6dChQ5Kk5cuXW07vbtq0qXr06GFp/9Zbb+nkyZP64IMPtGrVKj322GMqW7asEhISdOzYMf3666+aPXv2PT8X+ffff9eFCxfy9AgnAADygqQYAIAC8u6772r69OmKjIzU+vXrZRiGKlWqpDp16kiShg0bpsDAQC1atEg//fSTtm7dKk9PT1WsWFHPP/+8nnnmmXyL5fnnn9e8efP09ddf202Kt2/frujoaKuy6OhoS1nRokWtkmIvLy99+eWXWrJkidavX6+NGzcqIyND5cuXV40aNTR+/Hg1b978nuNevXq1JKlv37733BcAAPa4GIZhODoIAABQ8MaPH6/169dr69atD8RNq9LT0xUSEqI6derkacUcAIC8KOLoAAAAwP3xz3/+U0WKFNHHH3/s6FByZfHixUpKStIbb7zh6FAAAA8xkmIAAJxEhQoV9N5776l8+fJ6EE4Uc3d317Rp02QymRwdCgDgIcbp0wAAAAAAp8VKMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAAAAnBZJMQAAAADAaZEUAwAAAACcFkkxAAAAAMBpkRQDAAAAAJwWSTEAAAAAwGmRFAMAAIf76aefNGDAAAUFBcnf3199+/Z1dEgAACfh6ugAAAD3zt/fP0/tp0+fru7duxdQNLl3+fJlrVixQocPH9ahQ4d08uRJZWVlaenSpWrUqNE99d27d2/9/PPP8vPz08aNG/MpYhSEy5cv65VXXpGLi4u6dOkib29vVa5cOcdtjh49qmeffdaqzNXVVd7e3qpXr5769eunNm3aFGTYDvHOO+9owYIFWrFiherXr29Tf+rUKa1du9Yyp06fPi1JioyMlI+PT7b9/vrrr/r000918OBBXbx4UaVLl1atWrX0wgsv6Kmnniqw4wGAwoCkGAAeAsPdittnAAAgAElEQVSHD7cpW7hwoVJSUjRw4ECVKlXKqi4gIOB+hZaj48ePa+bMmZIkX19feXt7Kykp6Z77PXLkiH7++We5uLgoLi5OUVFRCgoKuud+UTCio6N19epV/etf/9LAgQPztG3ZsmX1wgsvSJLS09N19OhR7dixQ9u3b9dbb73ldCvO0dHRmjNnjlxcXFSjRg2VLFlS165dy3Gbb7/9VmPGjJGrq6vat2+vqlWr6tKlS9q0aZNGjBihQYMGafz48ffpCADg/iMpBoCHwIgRI2zKVq9erZSUFA0aNEhVq1Z1QFR3VrNmTS1cuFABAQHy9vbWyJEj82VVd9myZZKkoUOH6pNPPtGyZctIiguxCxcuSJIqVKiQ523LlStn8/5fvny5JkyYoA8++EC9evWSq6vz/Lnz2GOP6csvv1SdOnVUsmRJde/eXQcPHsxxm/fee0+GYejLL7+0Wn0eMWKEunbtqkWLFumVV15R2bJlCzp8AHAIrikGACd37NgxjRkzRsHBwapXr55at26tN99803La5R+988478vf31y+//KKlS5fq2WefVYMGDdSyZUv9+9//1uXLl/O073Llyql58+by9vbOr8NRenq61q5dq3LlymnkyJGqVauWvv/++xxXoC9fvqx3331XnTp1UoMGDdSkSRM999xzmjVrljIyMu6qbVBQkJ555hm7+/vj62h27do1+fv7669//avOnTunsWPHKjg4WAEBAdqwYYOk22P1zjvvqFu3bgoKClK9evXUrl07vfXWW0pISMj2+LZt26ahQ4eqefPmqlevntq2basRI0Zo7969kqSNGzfK399fU6ZMsbv9tWvXFBgYqNatW+vWrVvZ7uePtm/frsGDB6tJkyaqX7++OnbsqNmzZ1utWh49elT+/v6aPHmyJGnUqFHy9/eXv7+/5ZjvRteuXeXq6qqrV6/q5MmTNvWGYWjVqlXq16+fHnvsMdWvX1/PPPOMPvnkE928edOm/a5du/Tyyy+rVatWqlevnoKDg9WnTx998sknVu1Gjhwpf39/Xb58WQsXLlTnzp1Vv359BQcHa/LkyUpLS7Mb7+nTp/Xvf/9b7dq1U7169RQUFKThw4frt99+s2oXFBSkBQsWSJJ69uxpea0aN25saVO1alU99thjKlmyZK5eq8zMTJ09e1Y+Pj42p2NXqVJFAQEBysrKUnJycq76A4AHkfN8dQoAsLFv3z4NHTpU6enpevLJJ1WjRg39/vvvWrVqlbZu3aqwsDC71yv/97//1e7du9WpUye1bdtWUVFRWrp0qfbs2aNly5bZnK59P23YsEFXr17V4MGDVaxYMXXr1k0zZ87UmjVrNHjwYJv2sbGxGjx4sC5evKiGDRuqX79+yszM1PHjx/XZZ59p0KBBlhWyvLS9WwkJCerVq5fKlSunjh07KisrS6VLl5YkffPNN1q1apWaNWumJk2aqGjRojpy5IiWLFmi7du3a+XKlTb7nzFjhj7//HN5eXkpJCREFStW1IULF7Rv3z599913atq0qUJCQlShQgWtXbtWr7/+utzd3a36WLduna5du6YhQ4aoaNGidzyGzz//XDNmzJCXl5c6duwob29v7dq1S//973/1ww8/KDw8XCVLllS5cuU0fPhwHThwQDt27FDHjh31yCOPSJLlv/eqWLFiVr8bhqFXX31V3377rXx9fdWpUyeVLFlSP/30k2bOnKl9+/Zp/vz5KlLk9rrBxo0bNXLkSJUuXVrt2rWTj4+PkpKSdOzYMS1dulTDhg2z2eekSZO0e/dutWnTRq1atdKPP/6oxYsX6+zZs5o/f75V2+joaA0bNkzXrl1T69at1aFDByUmJmrTpk3asWOHPv30U8tZDi+//LK2bNmi/fv36/nnn7esrP/5GPPC1dVVNWvWVFxcnA4ePKi6deta6i5cuKDDhw/L19dX1atXv+t9AEChZwAAHkpPPPGEYTKZjFOnTtmtv3nzpqXNpk2brOqWLVtmmEwmo1u3blblM2bMMEwmk9GwYUPj999/t6qbMGGCYTKZjClTptx1zCNGjDBMJpOxf//+u+6jT58+hslkMg4fPmwYhmGcP3/eqFOnjtGpUyebtllZWUaXLl0Mk8lkLFy40KY+ISHByMjIyHNbwzCMZs2aGU8//bTdGM2v44EDByxlqamphslkMkwmkzFx4kTj1q1bNtudPXvWuHHjhk35pk2bDJPJZMyYMcOqfOPGjYbJZDI6duxoXLp0yebYz58/b/l9zpw5hslkMlauXGnTf7du3YyAgADj3Llzdo/nj44dO2YEBAQYzZo1M+Lj4632N3bsWMNkMhnTpk2z2mbRokWGyWQyvvvuuzv2b3bkyBHDZDLZfY2//PJLw2QyGa1btzYyMzPt7mvMmDFWr2VWVpZlXJYtW2Ypf/HFFw2TyWTExcXZ7CcxMdHqd/P796mnnjIuXLhgKb9x44bRrVs3w2QyWc2b9PR0o1WrVkajRo2MmJgYq75OnTplBAUFGU888YRx8+ZNS7m9905OzPu9ePFitm0iIyONRo0aGQ0aNDBeffVV4/333zfefPNNo2nTpkbnzp2N3377LVf7AoAHFadPA4CT2rVrl86cOaOWLVuqffv2VnW9evVSQECADh48aPd6xJ49e9qs5I0ePVru7u76+uuvlZWVVaCxZyc2NlbR0dGqW7euZYW7YsWKevzxxxUbG6t9+/ZZtd+7d68OHz6swMBAuzd4Kl++vGUVLi9t74WHh4def/11y0rlH1WuXFnFixe3KTffHCkyMtKqfNGiRZKkCRMmqFy5clZ1Li4uqlixouX3559/Xq6urlq6dKlVu19//VUHDx5U69atValSpTvG//XXX+vWrVsaMmSIqlWrZrW/1157TW5ublq1alW+vUcSExMVGhqq0NBQvf/++3r55Zf11ltvyc3NTVOmTLFZ2Q4LC1OJEiU0ZcoUq9fSxcVFo0ePVokSJfTNN99YbePi4iI3NzebfWd3VsDIkSOtro8uXry4unXrJkk6cOCApXzjxo26cOGCXnrpJTVo0MCqj6pVq2rQoEE6c+aM9u/fn8tX4+60bNlSX375pSpVqqR169bpk08+0cqVK2UYhrp3767atWsX6P4BwNE4fRoAnNShQ4ckSc2bN7db37x5c/322286dOiQ1SmVktSsWTOb9mXLllXt2rV18OBBnTp1SjVq1NC3336r2NhYq3YNGjQosEflmBO6Pz9uqnv37oqMjNSyZcvUpEkTS/nPP/8sSWrVqtUd+85L23tRs2ZNeXl52a3LysrSqlWrtGbNGh09elQpKSlW1/iaT7M2i4mJUbFixdSiRYs77rdixYpq166dvv/+ex0+fFh16tSR9P9vWpbbuzjn9L7y8fHRI488ooMHD+r06dP5ckru5cuXNXfuXKuyEiVK6NNPP1XTpk1t2p48eVIVK1bU//73P7v9ubu76/jx45bfn332WUVGRqpr167q3LmzgoKCFBgYmONNwerVq2dTZn7E1NWrVy1l5vdUXFycQkNDbbb5/fffJd3+sufPx5Kftm7dqtdff11NmzbV7Nmz5efnpwsXLmjBggV69913FRERoc8//1wuLi4FFgMAOBJJMQA4qZSUFEnK9tml5nJzuz/686pjdtts2LDB5m7SBfX82IyMDK1Zs0bFihWzucFV+/btVapUKW3cuFH/+te/LDf2Msf5xxXT7OSl7b0oX758tnX//ve/tXz5clWqVElt2rRRhQoVLCuYS5cutbqJVUZGhm7cuKEqVarYXXW254UXXtD333+vpUuX6j//+Y+uXbumdevWqUqVKrn+MiC376s/Jof34tFHH9W6dessfe7YsUMTJ07U8OHDtXz5cqvE23yzqAsXLtgk0n/k4eFh+fdzzz0nDw8PLVy4UEuXLtWXX34pSWrUqJHGjBlj9wsie19qmFes//glhjmeP69M/1l2N+jKDwkJCRozZozKly+vOXPmWFbPa9SooUmTJik+Pl4//vijNm7cqI4dOxZYHADgSCTFAOCkzH+4Z3fXYnO5vT/wExMTc7XNnDlz7jnO3NqwYYMlycjp8Utr1qyxnP5sjtP8SKCc5KWtJBUpUkSZmZl263JKCLNbjTt9+rSWL1+u+vXrKzw83OZmWOYVXbPixYvL3d1dCQkJysrKylVi3Lx5c/n5+VluuGW+wdbLL7+c68Ta/DpdunRJvr6+NvU5va/uValSpfTMM8+oSJEiGj16tMaPH6/w8HCb2Jo0aaLFixfnut+nnnpKTz31lFJTUxUTE6OtW7dabrL1zTffWJ0mnheenp6SpC+++CJXq/kFYc+ePUpLS1NgYKDdU/ODgoL0448/6uDBgyTFAB5aXFMMAE4qICBA0u0/iu0xl//lL3/Jtu6PLl++rNjYWHl5ed11knAvli9fLkl68skn1bNnT5ufZ5991qqddHu1T5IiIiLu2H9e2kq3E7QLFy7IMAybujs9N9ae+Ph4SVLr1q1tEuK4uDhdvHjRZpsGDRro5s2b2rVrV6724eLior59+yo1NVXr16/X0qVL5erqqp49e+Y6TvP7Kioqyqbu0qVLOnbsWIG/Rzp37qwmTZpo79692rx5s6Xcx8dHvr6+OnTokNWqem55enqqZcuWmjhxogYNGqTr169r586ddx2n+T31008/5Xob85cT+XVNtvkxYtk9Ts1cnh/XywNAYUVSDABO6vHHH1eVKlUUERGhHTt2WNWtWrVKBw8eVEBAgM31xJK0YsUKHTt2zKps1qxZSk9P13PPPZfrVcX8cuLECe3Zs0c+Pj6aPXu2pk6davPz/vvvKyAgQEePHrXcuKhp06aqU6eOoqOjLTel+qPExETLc2vz0la6nZCmpaVZTu01Cw8Pt3n+bG6YV1337t1rlWinpKRo4sSJdrcxr4i//fbbNqv7hmHYXfXu3r273N3dFRoaqoMHD6pdu3Y5Xj/7Z926dVPRokX1+eef69y5c1b7mzlzpm7cuKHu3bsX+Htk1KhRkqTZs2dbJZCDBw9WWlqaJk6cqNTUVJvtLl++rMOHD1t+j4qKsvtsZvPr+ecvKPKic+fOqlixohYsWGD3iwvDMLRv3z6r95X5uvGzZ8/e9X7/KDAwUC4uLvrxxx9tbkR38uRJrVq1SpIctpINAPcDp08DgJNydXXVO++8o6FDh+qVV16xek7xtm3b5O3trRkzZtjdtkWLFurVq5c6deqkcuXKKSoqSjExMfLz89PIkSPzFMeUKVMsq3a//vqrpNvPQTbf2bdz585q3bp1jn2YTx3u3r17js/R7dWrlyZPnqxly5apcePGcnFx0QcffKBBgwbp7bff1rp16/TYY4/p1q1biouL086dO7Vjxw6VLVs2T20ladCgQfr22281btw4/fDDD6pQoYJ+/fVXHTp0SK1atcr1irNZjRo19MQTT2jbtm3q3r27mjdvruTkZEVGRqpMmTKqVauWzp8/b7XNk08+qUGDBmnhwoXq0KGD2rdvrwoVKighIUH79u1Tq1at9O9//9tqm1KlSunpp5/WypUrJUm9e/fOU5y1a9fW6NGj9f7776tLly7q1KmTSpUqpV27dunXX39VnTp18vweuRvNmjVTixYttGvXLq1bt05dunSRJA0YMECHDh3S6tWrtWvXLsuXQ0lJSYqPj1d0dLQGDBhgudHYhAkTlJaWpsaNG8vX11dFihTRgQMHtG/fPvn5+enJJ5+86xjd3d01d+5cDR06VIMHD1bTpk3l7++v4sWL6+zZs/rll1905swZRUdHW1ZqzTcwmz59ug4cOCAvLy8VK1ZMQ4cOlXR75fePY3rmzBlJ0tSpUy0JfL9+/VS/fn1Jt99XL774oj777DMNHDhQISEhql69ui5cuKBNmzYpPT1dXbp0KdAbfQGAo5EUA4ATa9asmZYvX6558+YpKipKW7ZsUZkyZfTcc8/pH//4R7anuP79739XmzZttHjxYsXFxcnLy0u9e/fWP//5T5UqVSpPMaxbt85yLbDZ9u3bLf9+9NFHc0yKMzIytHr1arm4uNzxNN9nn31W7777rr777juNHz9eXl5eql27tr7++mt9+umn2rZtm+WRPdWqVdOwYcMs131KylPbevXq6X//+59mz56tTZs2yc3NTU2bNtWyZcu0YsWKPCfFkvT+++/ro48+0qZNmxQeHq7y5curY8eOGjlypAYNGmR3m/Hjx6tZs2ZavHixtmzZouvXr6t8+fJq0KCBOnfubHebHj16aOXKlapWrZpatmyZ5ziHDh2q2rVra+HChVq/fr1u3LghX19fvfLKKxo6dKjV61SQRo0apV27dik0NFSdO3eWq6urXFxcNGPGDLVr105Lly5VZGSkrl27ptKlS6tKlSoaNmyYunbtaunjH//4h7Zt26ZDhw5p586dKlKkiKpUqaIRI0aof//+Klmy5D3F2KBBA33zzTf6/PPP9cMPP2j58uUqWrSoKlSooIYNG2rMmDEqUaKEpX39+vX19ttvKywsTOHh4crIyJCHh4clKb5586ZWr15ts5/vvvvO8u+2bdtakmJJGjt2rOrXr69ly5Zpz5492rJlizw8PFS3bl1169YtT6fPA8CDyMWwd7FTIZCUlKTNmzfrhx9+0NGjR3XhwgUVK1ZMJpNJ3bt3V48ePeyeehUdHa158+YpJiZG6enpqlGjhnr06KEBAwbkuHoAALizd955RwsWLNCKFSus/qjGwyU8PFxTpkzRmDFjNGzYMEeHAwBAgSq0K8UbNmzQW2+9JR8fHwUFBalKlSq6dOmSNm3apAkTJigiIkKzZ8+2ukvn5s2bNXLkSLm5ualTp07y9vbWtm3bNH36dEVHR9/Xu6ACAPAgysjIUFhYmNzc3FghBAA4hUKbFPv5+WnevHlq27at1Yrwq6++ql69emnjxo36/vvv1aFDB0lSamqqJk6cqCJFiigsLMyygvHPf/5TgwYN0saNG7V+/Xo9/fTTDjkeAAAKs927d2v//v3auXOnTp48qWHDhlmujwYA4GFWaO8+3aJFC7Vr187mFGkfHx/16dNHkvUjQTZs2KDLly/r6aeftjqlz83NzXIHyq+++uo+RA4AwINn+/bt+vDDD3Xs2DH1799fI0aMcHRIAADcF4V2pTgnrq63w/7jNcK7d++WJLVq1cqmfdOmTVWiRAnt379fGRkZdh9ODwC4szfeeENvvPGGo8NAAWBsAQDOqtCuFGcnMzNTa9askWSdAJ84cULS7dOu/8zV1VVVq1ZVZmamTp06ZbfP06dPKzMzs2CCBgAAAAAUSg9cUjxz5kwdPXpUbdq0sUqKU1NTJUleXl52tzM//uHq1as2defPn1dISIjN8x0fOpmZ0uHDUkaGoyOxkWVkqeS0khq9YbRV+cDVA1Vzds176tswDJWYWkKvf//6PfXj7NqHtZfLJBe5THLR5euXHR2OJOlaxjW5THLRO5Hv2K0f+d1IlZ5R+j5HBQAAgAfJA5UUh4WFacGCBapVq5beffddR4fz4HF1lerUkQrh6eNFXIoooHyADiYctCo/m3JWlT0r31PfLi4uqlqqqk5dtT1LALkXfyVeJYvdfh5n7OVYB0dzW+L1RElSOY9ydut9PHx05cYVZdwqfF8EAQAAoHB4YJLi8PBwTZ06VY888ojCwsJUurT16o95JTglJcXu9uaV5FKlShVsoIXd+vXStGmOjsKuuhXq2iTF51LPqbLXvSXFklStVDWS4ntgGIbir8SrdY3WkqRjl485OKLbzCvW5UrYT4orlKwgSbqUdumu+v8t4TdVfL+i4pLj7mp7AAAAFH4PRFL8xRdfaMqUKTKZTAoLC5OPj49Nm5o1b59iGxcXZ1NnvmbY1dVV1apVK+hwC7etW6XZsyXDcHQkNur61NXZlLNKTk+2lJ1LOXfPK8WSVM27mk5dISm+WwlpCbpx64ba+rWVJP1++XfHBvR/EtNurxSXLWH/sTE+JW9/Vly8dvGu+t95aqcuXruoAxcO3F2AAAAAKPQKfVL8ySefaPr06QoICNDChQtVrpz9FaHmzZtLkiIiImzq9u7dq+vXr6tx48bceXrqVOn8ecnFxdGR2PiLz18kSYcSDkmS0jPTlZSelD9JcalqOptyVreybt1zX87oZPJJSVKd8nVUtVTVQrNSnJvTpyUp4VrCXfVvPs7zqQ/5/QYAAACcWKFOij/66CPNnDlTdevW1RdffKGyZe2vBklSx44dVaZMGa1fv16//PKLpfzGjRuaPXu2JKlv374FHnOh5+5eKBNi6fZKsfT/2Lvv8CjL7OHj30nvvdOCBAIEghJERFQICIKKgAUFBWwsFuyrsurqqz8VFV0X2BXsiKCrYkARFVEQQUGD0klMaCE9mZDek3n/eHiGhLTpM0nO57q4ZKc8c6LsMGfOuc+BQ/lKC7WaiFiqfbpB10BOeY7Z1+qOMkoyAOjt35v+Qf0dJik2tH26oNK8pDinTP7cCCGEEEJ0VQ67pzgpKYmlS5fi7OzMiBEjWL16dYvH9OjRgxkzZgDKmeL/+7//4/7772fOnDlMmTIFf39/fvzxR44fP86kSZOYMmWKrX8Mx1NVBQsWwDXXwPXX2zuaZvoE9MHL1Ut/rlhNRCxRKY4OiAbg2Olj9PTrafb1upumSXFMUAxJKUl2jkhh7fZptU1cKsVCCCGEEF2XwybFmZmZADQ0NLBq1apWHzNy5Eh9UgwwYcIEVq9ezYoVK9i8eTM1NTX06dOHRYsWceutt6Jx0AqpTXl4QFIS+Po6XFKsTqBW26fVqq4lKsWDQgcBSmu2OixKGE6dPB3oEUhMUAyFlYUUVxcT4GHfdUdFVUV4u3rj7uLe6v0BHgE4a5xNap/W6XRn26crJCkWQgghhOiqHDYpXrhwIQsXLjT6eQkJCbz99ttWiKiL0GggNhZSU+0dSaviwuLYcmwLYNlKcS+/Xvi4+egTbmGckyUn6RPQB41GQ/+g/oCylikhKsGucWmrtG2eJwbli5ZQ71CT2qdzy3OprKvU/14IIYQQQnRNDn2mWFiJIyfFTSZQ55Tn4Kxx1rfAmkOj0TA4dHCLlU/CMBklGfT27w1ATFAM4BgTqLVV2jZbp1WhXqEmtU+rP1+Yd5gkxUIIIYQQXZjDVoqFFcXGwpo1UFkJXl72jqYZdQL1ofxD5JTlEO4TjpPGMt/dxIXGsSltk0Wu1d1klGSQEKlUhfsF9QMcY1dxUVVRm0O2VKZWitWf79Lel7Lxr43odDo5giGEEEJ0cjU1NRQVFVFWVkZDg2wl6cycnZ3x9fUlKCgId/fWj9IZSpLi7ig2VvlnWhoMG2bfWM6hTqA+XHCYnHLL7Chueu33976PtrL9llvRXFVdFQWVBfpKsZerFz18ezhEUqyt1BIfHt/uY8K8w0jOTjb62ulF6bg4uTCyx0jWHVlHSU2J3c9QCyGEEMJ0NTU1ZGRkEBgYSHR0NK6urvKFdyel0+moq6ujtLSUjIwMevfubVZiLO3T3ZGaCP/3v6DT2TeWczSdQJ1TnmORIVuquLCzCbcwnDp5uk9AH/1tMUExDtM+3WGl2CvUpEFb6UXp9A3oq59WLi3UQgjRdZwsPklxdbG9wxA2VlRURGBgICEhIbi5uUlC3IlpNBrc3NwICQkhMDCQoqIis64nSXF3FBsLjz8Ob70F//mPvaNpxknjpD/7m1Nm2UqxvjVbzhUbpek6JlVMUIzdK8WNukalfbqDqn+oVyglNSXUNtQadf20ojT6B/fX/xmUpFgIIbqOCasn8NSPT9k7DGFjZWVl+Pn52TsMYWF+fn6UlZWZdQ1JirurF1+EqVPhoYfgxAl7R9PM4NDB7M/bT35FvkWT4l5+vfB18+VQviTFxmgtKe4f1J/8inxKa0rtFRalNaU06ho7HLQV5h0GYFS1WF3HFBMYQ4RPBHB2GroQQojOrVHXyPHTxzl2+pi9QxE21tDQgKurq73DEBbm6upq9vlwSYq7KycnZdjWV19BdLS9o2kmLjSO/Ip8dOgs2j4tE6hNk1GSgZPGiR6+PfS3qROojxYdtVdYFFUpbTKGDNoCjBq2lV+RT3ltOTFBZ5NiqRQLIUTXUFRVRIOugbyKPHuHIuxAWqa7Hkv8N5WkuDvz8YErr1R+v307aLX2jecMddgWWGZHcVODQwfLmWIjnSw5SZRvFK7OZ79ZdYS1TNpK5c9rR+3TplSK1Z+rf3B/AjwCcHN2k6RYCCG6CPX9XN7XhRAqSYqFkgxPmQKLFtk7EuDs2V/AopViUBLuvIo8fUIlOtZ0R7FKTYrtea5YW6X8NzRkTzFg1K5i9eeKCYpBo9EQ4RNBboV8eBJCiK4gr1ypEOdX5NOoa7RzNEIIRyBJsYDgYFi/HpYssXckwNkJ1GD5SrE6gVpaqA3XWlLs7eZNpE+kXZNia7ZPpxel46xxpo+/MnE70idSKgpCCNFFqO/n9Y31+r9LhBDWsWzZMmJjY9m9e7e9Q2mXJMVCMWEC+PlBVRVs2mTXUNQJ1ADhPuEWvXbTPciiY426Rk6VntInh03Zey2TWu3vqFIc4BGAi5OL0e3TfQP76lvGI3wiZNCWEEJ0EU3PEqtVYyG6i8zMTGJjY3niiSfsHYpDkaRYNPf883DNNXZPjM8PP58evj1wc3az6HV7+vWUCdRGyCvPo7ahtkWlGOy/lkltnw70DGz3cU4aJ0K8Qoxun1ZbxEFJiqVSLIQQXUPT93N5bxfCumbPns2mTZuIj4+3dyjtkqRYNPfkkxAfDzfdBIfslzi+NOElvr/1e4tfVyZQG6e1dUyq/kH9yS3Ppby23NZhAUr7tFoF7kioV6jB7dNN1zGpInwiKKwspK6hzuR4hRBCOIa8ijw0aPS/F0JYT1BQEP369cPT09PeobRLkmLRnLc3fPml8s9rroECw1tOLSnEK4RBoYOscu240OrpD24AACAASURBVDhJig3UXlJs72Fb2ipth63TqjDvMIMrxYWVhZTWlLaoFOvQGXUuWQghhGPKK8/Tv8dL+7ToTpYtW8b48eMBSEpKIjY2Vv/riy++YPfu3cTGxrJs2TL279/P/PnzGTlyJLGxsWRmZgKwa9cunn76aaZMmcLw4cOJj4/n6quvZvny5dTU1LT6mq2dKY6NjeXWW2+lqKiIp59+mjFjxjBkyBCuuuoq1q1bZ/1/GeeQpFi01KsXbNgAOTlw3XVQW2vviCwqLkzZg1xYWWjvUByemhS3daYY7JcUF1UVdThkSxXqbXiluOk6JpU68E3a7IQQovPLLc8lNiRW1u2JbmfkyJHMmTMHgIEDB3Lffffpfw0adLYYtXfvXmbNmkVNTQ3XXXcd06dPx9VVmbPy9ttvs3PnTgYNGsTMmTO54YYbcHV1ZdmyZdx55500NDQYHE9paSk333wze/fuZdKkSUyfPp38/Hz+8Y9/kJSUZNkfvgMd9x2K7mnkSPjgA6WNeuJEWLsWoqLsHZVFqEO8Dhcc5rI+l9k5Gsd2suQkfu5++Hv4t7jP3kmxtlLb4Y5iVahXqMGDtpquY1JF+EQAKMO2LDsQXQghhI3lVeRxYdSFhHuHS/u06FYuuugievTowYcffsigQYNYuHBhs/vVau6OHTv4f//v/3HTTTe1uMazzz5Lz5490Wg0zW5/4403ePPNN/nuu++YMmWKQfGkpKRw/fXX89xzz+Hs7AzA3LlzmTp1Km+//TbTp0835cc0iSTFom0zZypV4gUL4Pzz4aOPlAS5k1MnUB/KPyRJcQdaW8ek8nX3Jdw7nDStfSZQa6u0zaq57QnzDqOkpoSa+hrcXdzbfWx6UTpOGieiA6L1t6lJsVQUhBCic2tobCC/Ip8InwgZoihaGju248dcfTU8+ujZx8+bp/wqLITrr+/4+ec+/pFHlCOLqanwt7+1/9xt2zq+vgUMGjSo1YQYoFevXq3ePm/ePN58801+/vlng5NiT09PFi1apE+IAWJiYhg+fDi///47FRUVeHt7G/8DmECSYtG+W2+FhAS48UZ4550ukRSrE6hlLVPH2kuK4cwE6tOdoH3aS9lVXFhZSA+/Hu0+Nq0ojeiA6GaTz9XVYPLhSQghOjdtlZZGXSPhPuGE+4STWZpp75CEcDjtTYqurKzkww8/5Pvvv+fEiRNUVFSg0+n09+fnG77to0+fPvj4+LS4PSJCKUaUlpZKUiwcyODB8NtvUF+v/O/jx8HNDXq0n1w4KplAbbiMkgxG9RzV5v39g/uz+ehmG0akqG+sp7i62OBBW6HeSlJcUFnQYVJ87jomAA8XDwI8AiQpFkJYTU5ZDqPfG81XN3/FkLAh9g6ny1LfxyN8IojwjiA5O9nOEQmHYmwltunjQ0KMe/65j4+NtVkluCMhISGt3l5XV8fcuXPZv38/AwYMYMqUKQQFBeHioqSUy5cvp9aIWUR+fn6t3q5ez5jzyeaSpFgYxsvr7O/nzYPcXDh8GJq0O3QmcaFxbEzbaO8wHFpFbQXaKm37leLAGD4o+4CK2gq83WzzTR7A6arTAAZXisO8wwA6nECt0+lI06Yxe+jsFvdF+kSSU55jZKRCCGGYfXn7OFF8gt+yfpOk2IrUadPh3kqluKCigEZdI04amT0rhOrc88KqH374gf379zNjxgxeeumlZvfl5+ezfPlyW4RnFfIOIIy3ciX8979KQtzYeLaC3InIBOqOtbeOSaVWVI+ePmqTmFRFVUUARg3aAjoctqWt0lJSU9LqWWU5eyaEsKas0iwAssuy7RxJ16YO1gr3CSfcO5wGXQPaSq2doxLCdtTzu6ZUYTMylM+GV1xxRYv7fv/9d/MCszNJioXxBg6EMzvOeP11GDcOMjvXmRx12JacK26bIUmxmjzaegK1tkr5AGPMnmKgw7VMrU2eVklSLISwpqwySYptoVn7tAxRFN2Qn58fGo2GnBzju996nDk6+dtvvzW7/dSpUyxZssQi8dmLtE8L8/TsCXv3KtOpP/4YWvnmyBGpa5lkAnXb2ttRrOoX2A+wfVKsrxQb2D4d4BGAi5NLh+3TkhQLIexFKsW2kVeeh4eLB75uvvohinkVeQxlqJ0jE8I2vL29GTZsGMnJyTzyyCP07dsXJycnEhMTO3zuuHHj6NOnD++//z5//fUXgwYNIicnh61btzJ27Fiyszvv+5dUioV5broJkpOVHcZTpsDq1faOyCA9/Xri5+4nw7bacbLkJM4aZyJ9217M6+/hT6hXqM3XMqmtboa2T2s0GkK8Qjpsn1bXMfUN6NvivgifCCrqKiivLTc+YCGE6IBUim0jtyKXCJ8INBqNVIpFt/XKK68wduxYduzYwfLly/n3v//N4cMdd096eXmxatUqrr76atLS0li9ejWpqancc889vPrqqzaI3HqkUizMFxsLO3bA9OkwZw7k5MDf/w5tHNJ3BOoEammfbltGSQY9/Hrg4tT+20T/4P42X8tkbPs0KC3U+ZXtV4rTitLo7d+71V3GkT7KlwM5ZTkG70cWQghDSVJsG3nleYR7KxVi9Z/q8C0huos+ffqwYsWKVu9LTU1t97mRkZG89tprBj934cKFLFy40KjXWbx4MYsXL243DkuTSrGwDD8/2LRJqRw//jg89JAyhMuBDQ6RtUzt6WhHsSomKMYu7dPOGmf83f0Nfk6oV6hBleLWWqcBqSgIIaxKTYZzy3Np1Dn235+dWW55rv793M/dDw8XD3lfF0JIUiwsyN0d1qxREuJ//xtuvhlqauwdVZtkAnX7Mkoy2j1PrIoJjCGzNJPKukobRKXQVmoJ9Axsc2VAa0K9Qw0atNU/qPUqsCTFQghrqW2oJb8inzDvMBp0DR1+gSdMl1dxtlKs0WgI9w7XT6QWQnRfkhQLy3JyUiZSL1kC27cr+4wdlDqB+lC+VIvP1dDYwKnSUwZXigGOnT5m7bD0tFVag4dsqcK8wtodtFVUVURRVZFUioUQNpdTpkyBvTDqQkBaqK2lobGBwspC/YAtUFYzSVIshJCkWFjHI49ASgr06QM6HWgdbwdgXJisZWpLbnku9Y31BiXF9ljLVFRVZPCQLVWodyilNaXU1LfevdDe5GlQhnq5OLlIUiyEsDj1PLEkxdZVUFlAo65R/yUnyGYBIYRCkmJhPf5nzns++ywkJECBY7WD9fDtIROo22DIjmKVupbJlhOotVVao4ZsgXKmGGizXb6jpNhJ40S4dzg55cbv9RNCiPao65hGRI0AJCm2FnWglto+rf5eBm0JIWT6tLC+qVOhvh5CQuwdSTPqBGpJilsyZEexKtAzkGDPYJtXioeFDzPqOWHeYQDkV+TTw69Hi/vTtGlo0HBe4HltXkMqCkIIa1ArxQlRCYAkxdaivn+fWykuqCygobEBZydne4UmhLAzqRQL60tIgBdeUFY0HTkC331n74j04kLjpH26FSdLTgLQy7+XQY+39VombaXxZ4pDvZVKcVvDttJPp9PLvxceLh5tXkOSYiGENWSVZuHu7E64dzhh3mGSFFuJena42Zli73AadY0ydFOIbk6SYmFbDz8Md93lMOuaBocOlgnUrcgoySDAIwA/dz+DHh8TFGOz9uma+hoq6ipMbp9ua6pre+uYVJIUCyGsIassix5+PdBoNET6RJJdLkmxNbRVKW56nxCie5KkWNjW3Llw6hRs22bvSACZQN0WQ9cxqWICYzhVeoqquiorRqUoqioCMHrQVtP26dakadPaXMekivSJJK8ij4bGBqNeWwgh2pNVlkUPX+VYR5RvlFSKrSSvPA8vVy983Hz0t6lVY5lALUT3JkmxsK1rr1UGcK1aZe9IgLMTqOVccXMZJRkGDdlSqROojxcft1ZIetoqZZK5sZXiAI8AXJxcWm2fPl11Gm2V1qBKsbTZCSEsLas0Sz/rQJJi62m6o1il/m8ZtiVE9yZJsbAtT0+48Ub4/HMoK7N3NPoJ1HKuuLmTJSeNSorVZNIWw7a0lUpSbOyZYo1GQ6hXaKuV4qOnjwJtT55WSZudEMLSdDod2WXZzSrFeeV51DfW2zmyrie3PLdZ6zTI+7oQQiFJsbC9uXOhshLWrbN3JDKBuhWlNaUUVxeblBTb4lyxqe3ToAzbaq1SrCbzHbVPy4cnIYSlFVcXU1Vf1Swp1qGTyqUV5FXkNRuyBeDj5oOni6e0TwvRzUlSLGxv9GiIiXGcFurQODlT3MSpklOAYeuYVEGeQQR5BtmmUmxi+zQow7ZaG7SlJvPtrWMCSYqFEJanrmNq2j4NspbJGnLLc4nwbl4p1mg0MkRRCCFJsbADjQbmzFGGbZ04Ye9oiAuNo6CyoM2pxN2NuqPYmEoxKNViW6xl0leKjWyfBmXYVmvt0+mn0+np1xNPV892n68mxTnlOUa/thBCtCarVEmK1WRYkmLrqGuoQ1upbVEpBmXYllSKhbCMxMREEhMT7R2G0Rw6Kf722295/vnnmTVrFsOHDyc2NpZHH3201cdmZmYSGxvb5q+HHnrIxtGLdt16q/LP1avtGwfKWiZAzhWfoe4oNiUptkX7tLZSi7uzO16uXkY/N9Sr7fbpjlqnAbzdvPF185WKghDCYvSVYl+pFFtTQWUBOnQtzhSDrNsTQoCLvQNoz5tvvklKSgpeXl5ERERw7NixDp8zcOBAJkyY0OL2/v07/sArbCg6GqZPB53O3pE0m0B9efTldo7G/jJKMnBxcmn1g0N7+gf15+MDH1NTX4O7i7uVolPap4M8g9BoNEY/N9Q7lNKa0hYxpmnTmDZwmkHXkA9PQghLOrdSHOYdhpPGSZJiC1PPaJ87fVq9bWfGTluHJIRwIA6dFC9atIiIiAj69OnDb7/9xpw5czp8zqBBg1i4cKENohNm++ILe0cAnJ1ALeeKFRklGfTy64Wzk7NRz4sJikGHjuPFxxkYMtBK0Snt06YM2YKzu4oLKgvo6dcTgJLqEgoqCzqcPK2SpFgIYUlZZVmEeIXov6hzcXIh3DtcjmlYmNoe3Wr7tHc4hZWF1DfW4+Lk0B+NhRBW4tDt06NGjSI6OtqkipDoJHQ6OHnSriFoNBriQuM4XCjt02D8jmKVrSZQq5ViU4R6hQI0Oz+urmMypH0aJCkWQlhWVlmWvnVaJbuKLU99326rfVqHTmaLiC5v7969xMbGcu+997b5mMmTJzNkyBCKi4upra3lo48+4q677mLcuHEMGTKEkSNHMm/ePH766ScbRm59Dp0UmyI/P59PPvmEFStW8Mknn5CSkmLvkER7Hn8c4uOhqsq059fUwJEjZocxOHSwVIrPMHZHsUpNKq09gVpbqTVpyBYo7dNAs3PFahJvaKU40idSKjhCCIvJKs3ST55WSVJsee22T5+pHsuwLdHVnX/++fTt25effvqJ06dPt7h///79HDt2jMTERAICAigpKeGFF16goqKC0aNHc9ttt5GYmMiRI0eYP38+n332mR1+Cuvocj0iO3fuZOfO5udCRo4cycsvv0xUVJSdohJtmjkTYmOVidSm2LkTxo+Hw4dh0CCTw4gLjePdP9+loKJAnzh1R/WN9WSVZpmUFAd5BhHgEWD1pLioqsjkpFhtn246gVqNt6N1TKoInwhKa0qprKs0adiXEEI0lV2WzYioEc1ui/KNYlfmLjtF1DXllufi4+aDt5t3i/tk3Z7oTqZPn87rr7/O119/zS233NLsvqSkJACmTVPmrPj7+7N161YiIpp3WJSVlXHzzTfz6quvcs011+Dh4WGb4K2oyyTFnp6e3HPPPUyYMIFevXoBkJqayrJly9i9ezfz5s1j/fr1eHnJh1iHkpCg/DLV0KHg5gZvvAErV5p8mabDtsZ6jzU9nk4upyyHBl2DUTuKVRqNRplAXWS99mmdTmfx9un00+lE+Ua1+kGpNeqHp7zyPPoG9jUpDiGEAGVNUH5Ffqvt0wWVBdQ21OLm7Gan6LqWvIq8VqvEcLZ6rFaTRff04b4Pee/P9+wdRrtuv+B25gzreMZSe6699lreeOMNkpKSmiXFtbW1bNq0ieDgYC677DIA3NzcWiTEAL6+vlx33XUsXryYAwcOcOGFF5oVkyPoMu3TwcHBPPDAA8TFxeHn54efnx8XXngh7733HsOGDePkyZNdqsTfpRQXw7JlkG1Eq1hBATz5JHh7w7x58OGHym0migtVkuLuvpbJ1B3FqpigGKtWiivrKqltqDV50FaARwAuTi4tKsWGnicGqSgIISwnpzwHHbpW26dB3mcsKbc8t82tCmr7tPz7Ft1BREQEF198MQcPHiQ9/exntq1bt1JcXMw111yDi8vZumlaWhpPPPEE48ePJz4+Xr/udvHixQDk5XWNL5O6TKW4LS4uLtxwww3s27eP5ORk5s6da++QxLkKCuD++5VzxY89ZthzNm6E116DWbPgwQfhrbdgxQp4+mmTQojyjZIJ1Ji+o1jVP6g/nx761GrVDW2VFsDk9mmNRtNiV3GaNo2rB1xt8DXUD1VyrlgIYa5z1zGpmu4qNvX9WDSXV5HX5mYEHzcfvF295UxxNzdn2Byzq7CdxfTp09m5cydJSUn8/e9/B862Tk+fPl3/uL179zJ37lwaGhoYNWoUiYmJ+Pj44OTkxJEjR/jhhx+ora21y89gaV2mUtyewMBAACorK+0ciWhV//4wejSsWmX43uLbboP0dIiLU84ST5kCy5dDdbVJIagTqA8VdO+k2BKV4kZdI8dPH7dkWHraSiUpNrV9GpRhW2pSXFZTRl5FnsFDtgAifSMBqSgIIcyXVaYkxa21TwMybMuC8srbbp8GpVosSbHoLq644gp8fHz48ssvaWhoQKvV8vPPPzNw4EAGDjz75dGbb75JdXU17777Lu+88w5PPvkkDzzwAAsXLmTYsGF2/Aksr1skxfv27QPQnzUWDmjuXGVY1p497T8uPx9271Z+37Pn2dsffli5b+1ak0OIC42T9umSDII9gw0+X3suNbm0Vgt1UVURgMnt06AM21Lbp41dxwTKuWQnjZMkxUIIs6mV4nPbpyN9lC/fJCm2jLqGOrRV2jbbp0HW7YnuxcPDg8mTJ5Ofn88vv/zCV199RX19fbMqMcDJkycJCAjgoosuanGN3377zVbh2kSXSYoPHTpEY2Nji9t//fVXPvjgAwCmTp1q46iEwW68EdzdlWpxe+69F8aNg8LC5rcnJsKwYfD664ZXm88xOHQwBZUF3XpPoak7ilXWXsuktk+bVSn2CtX/NzZ2HROAs5MzoV6hJn140ul0zP9qPluObTH6uUKIrierLAt3Z/cWR0JCvUNx1jhLUmwh6heh7VaKvcNl0JboVtQEeP369WzYsAEXFxeuueaaZo/p0aMHxcXFLVbcfvbZZ+zYscNmsdqCQ58p3rJlC1u2KB8eC84MUdq7dy9PPPEEoLRFP/744wAsXryYEydOcMEFF+inpKWmprJrl7LS4IEHHmD48OG2/hGEoQICYNo0pdK7ZImSIJ/r00/h88/hxRchJKT5fRqNUi2eOxe+/x4mTjQ6BJlArZwp7hfYz+Tnh3iF4OfuZ72kuNK8M8VAszPFapz9goz7mU2tKGSXZfP2H2/T0NjAhPMmGP18IUTXklWWRZRvFJpz1hI6aZyI9I2UpNhC1PfrjirF209ut1VIQthdQkICffr04bvvvqOuro5x48YRHNz889XcuXPZsWMHs2bNYvLkyfj6+nLw4EH27NnDpEmT+O677+wUveU5dKX4yJEjJCUlkZSUpP824tSpU/rbmv6HmDp1KoMHD+bgwYN89tlnrF27lpMnTzJ58mTWrFnDPffcY68fQxhq7lwoKoKvv255X14e3HMPXHghnBkI0MJNN0FkJPzwg0kvr06g7s7DtsytFFt7LZPaPm1OpTjMO4zSmlJq6mtIL0on0icSHzcfo64R4RNh0qCt5OxkAP4q+svo5wohup6s0qwWrdOqKN8oSYotRD0rrE6Zbk24dzjaKi11DXW2CksIu5s2bRp1dcqf+XNbpwEuu+wyVqxYQUxMDJs2beLzzz/Hzc2NDz/8kLFjx9o4Wuty6ErxwoULWbhwoUGPveGGG7jhhhusHJGwqiuugIgIpYV6xoyzt+t0SkJcVgYffAAubfyxdXOD/ftbVpENFOUbhb+7f7c9V1xSXUJpTalJO4qb6h/UX5/8WZq2Sou3qzfuLq10Ehgo1PvMruLKAtKK0oxqnVZF+kaaNJRN/feSWphq9HOFEF1Pdlk2wyNb72KL8o3SH/EQ5jG0UgxKq3VbX1QI0dXcc889HRYOx40bx7hx41rcfuGFFzKj6ef1M3788UeLxWdLDl0pFt2Miwvccgts2tR85/D//gdffAHPPQeDB7d/DTUhLi83+uU1Gg2DQwd32wnU5k6eVsUExXCi+IRVvm0vqioya8gWKO3TAAUVBaQXpZuUFEd4R5BXnkejruUcg/Yk5yhJcUFlAaerThv9ukKIrkOn05FVltVi8rQqykcqxZainhXuaPo0IBOoheimJCkWjmXePLjySjh9JmHIy4P77oORI+GRRwy7xurVEBWlPNdI3Xktk7k7ilUxQTE06Bo4UXzCAlE1p63SmnWeGJT2aYDjxcfJKc8xavK0KsIngrrGOqMSW51OR3J2sv71rdViLoToHEpqSqisq2y3ffp09Wmq6qpsHFnXk1eRh6+bL56unm0+Rk2YZdiWEN2TJMXCscTFwVdfwYABStv03XcrVd/22qbPddFFyvlkE6ZQx4XFUVhZ2C0nUKuV4j4B5rdPg3UmUGsrtWadJ4az7dO7MpUhfCZVis+02RkzbCujJIPCykJmxs0E4C+tnCsWojtT1zGpO4nPpd5uyvwC0VxueW67rdNg2vu6EKLrkKRYOKaTJ+H332H7dqVtetAgw587YAAsW6acTzbS4FClPftg/kGjn9vZZZRk4Obspq9kmkpNMq1RCbVk+/Qvp34BzEuKjfmwuidH2cE9M24mThonSYqF6Oayys7sKG6rffpMUiwt1ObLq8hrd8gWSPu0EN2dJMXC8ZSWKontp5/CkSOGt003pdMpCfXmzUY9LSEyAVcnVzakbjD+NTu5jJIMevn1wklj3ttCmHcYoV6hVhm2pa3SEuRhXqU4wCMAFycXfXymDtoC4yoKydnJuDq5MiJqBH0D+pKqlWFbQnRnaqW4vfZpgJwyqRSby5BKsZerF75uvlIpFqKbkqRYOB4/P/jwQ+UscWgoODubdp0HH1R+NRo+DCnYK5jrBl/Hqn2rut05rpMlJ80+TwzKwLJxfcfx4/Ef0ZnQwt6WRl2jRSrFGo2GUK9QahpqCPcOx9fd1+hrmNJml5ydzNDwobi7uDMgeIBUioXo5tRKcUft01IpNl9eeV67Q7ZU4T7hUikWopuSpFg4ppkzITra9OdrNPDww0ql2cjF4gsSFlBcXcynhz41/fWtSKfT0dDYYPHrZpRkmH2eWJUYnUhWWZZFW6hLa0pp1DWaPWgLzp4rNqVKDCgDW1w8DU6K1SFbIyJHAOiTYkt+aSCE6FyySrMI9gzGw8Wj1fuDPINwc3ZzuKS4s71v1dTXcLr6tGFJsXe4VIqF6KYkKRZd1403KlOoX3/dqKdd1ucyBoYMZMWeFVYKzDyPb3mcQf8ZZNHEuK6hjuyybHr7mV8pBkjsmwjAj8ctt6tOW6kFMHvQFpydQG1qUqzRaIjwiTD4TPHx4uOcrj7NiCglKY4NjqWyrtLhPuwKIWwnqyyr3X24Go2GKN8osssd533iqR+fIuGthE6VGOdX5APt7yhWRfhEyPTpbqAz/fkVhrHEf1OLJsU7d+7klVde4cYbb2TMmDEMGTKEhIQEJk6cyP3338/atWvJM2FNjhAmcXOD+++HLVtg/37DnlNWhmbTJv4Wfzu7MnexN3evdWM0Ul55Hst+W0ZaURrbTmyz2HWzy7Jp1DVapH0alGSzp19PiybFRVVFAGa3T8PZYVumrGNSRfhEGFxRUM8vJ0QlAEqlGJBzxUJ0Y9ll2W0O2VJF+TrWruJtJ7bxZ+6fner4h9oO3dGgLVAqxdI+3bU5OztTV1dn7zCEhdXV1eFs6nHLM8xOiquqqnjrrbdITEzkzjvv5L333mP//v2UlZURFBSEi4sLp06dYvPmzTz33HOMHz+ehQsX8ueff5r70kJ0bP588PKCf/2r7cc0NsKPP8KcOcrE6quvZs5Tn+Hh7MHK5JW2i9UA/979b2rqa/By9WLNgTUWu66ldhSrNBoNiX0T2XpiK406w890t0dbpVSKLdE+bW6lGJRhW8YkxW7ObgwJGwKcTYo70wdLIYRlZZVldaqkWKfTcbjgMADfpH9j52gMp75PG1opLqoqorah1tphCTvx9fWltLTU3mEICystLcXX1/gZMU2ZlRR//vnnTJw4kddffx0PDw/uvfde3n//fZKTk9m3bx/bt29n9+7dHD58mK+//poXX3yRiRMnsn37dmbNmsWDDz5IdrZjvNmLLiowEG6/HdasgZw2Wl1ffhnGj4cNG2D2bPjXvwjatY+Z6e58tG81ZTVlto25DSXVJfzn9/9w/eDruWHwDaw7so7q+mqLXNtSO4qbSoxOpLCy0GLrrSzZPq1Wis1JiiO8jasUDwsfhpuzG6BMm/V08ZSkuIuqb6znnT/ekQ/Wok11DXXklee12z4NEOXjOElxbnkup6tPA/Bt+rd2jsZwaju0oYO24GzLtTH+0v7Fd+nGzTARthcUFMTp06cpLCyktrZWWqk7MZ1OR21tLYWFhZw+fZqgIPM+H7qY8+SnnnqKCRMmMH/+fOLj49t8nEajoV+/fvTr148ZM2ZQXl5OUlISb731Fl988QX33XefOWEI0b4HHoD//Af++194/nk4dQpmzYLHH4err4abb1aGek2bBp6eynPOP58FC65mVd8KYLUL7AAAIABJREFUPv5uCfOn/j+7/ggAbya/SWlNKYvGLKKwspBV+1bx9V9fc93g68y+tpoU9/LrZfa1VOP6jgOUc8Xx4W2/PxjKku3To3qOYmDIQAaGDDT5GmpFoaa+BncX9zYf16hr5I+cP5g1dJb+NieNE/2D+0tS3EV9/dfX3PXVXXi5ejX77y6EKrc8Fx26NidPqyJ9IymtKaW8thwfNx8bRde6QwWHAIgPj2fbiW1U1lXi5epl15gMoX55aUj7dNPNAj39ehr1Ok/9+BSb0jZRuqjU7NWGwnrc3d3p3bs3RUVFnDhxgoYGyw8uFbbj7OyMr68vvXv3xt297c9ihjArKV63bh1xcXFGP8/Hx4dbb72VG2+8kczMTHNCEKJjMTFKwvvRR/DMM0qLtEYD9fXK/dHRLSddjx3LRZ/+wrC3E1jx4yvcddU/0Zh5VsEcVXVV/GvXv5jUbxIXRF5AQ2MDET4RrDmwxmJJcahXKJ6unhaIVtHbvzcxQTH8ePxHHhz1oNnXU9unAzwCzL7W+PPGc+TeI2ZdQ/3wlFeR127b+dGio5TUlOiHbKlig2Md7sy6sIxdmbsA2JGxQ5Ji0Sp1HZMh7dOg7CruH2z6DARLOJSvJMWPXPwIc9fP5acTPzG5/2S7xmSIvIo8/N3925zy3ZRaTTZl2FZydjIVdRUcO33MrC4kYX3u7u5ERkYSGRlp71CEAzHrqyxTEuKm3N3d6devn1nXEMIgTz6pJMcuLuDqCtu3K4lyOzTx8fztmmf5M7Ca33P32CjQ1r2/933yK/JZNGYRAM5OztwUdxNfp33N6arTZl/fUjuKz5UYnchPJ3+ivrHe7GtpK7UEeATg4mTWd3kWE+mr/GXaUQu1OmTr3KR4QPAAjp0+Ji22XdDurN0A/Jzxs50jEY4qq/RMUtxR+7QD7So+XHCYIM8gboy7EU8Xz05zrji3PNegKjGcrSYbu5ZJW6nlePFxAA7kHTAuQCGEQ5D+DtE9JCTA998b/bTZly/E29Wblckr4JFHYPlyKwTXvvrGel795VUu7nkxl/W57Gxs8bOpbahl3ZF1Zr+GJXcUN5XYN5HSmlL+yPnD7GsVVRdZZMiWpTRts2tPcnYyHi4eDA4d3Oz2AcEDaNA1cPz0cavFaIofj/9IxJIIgl8J7vBXv6X9+D3rd3uH7FAaGhv4Les33JzdOJh/0CJfWomux9hKsSMkxYcKDhEXGoeHiwfj+o7rNElxXkWeQUO2oEml2MgJ1Htyzn5xfiBfkmIhOiOrllzS0tJ49913SUtLA2DAgAHcfvvt9O9v3xYgIQzl5+7H7KGzWb1/Na8dH0uAHc6efHLwE04Un2DplUvRaDT62xMiE+gf1J+1B9Zy5/A7Tb6+TqcjoySDiedNtES4zYyNHgsoidbIHiPNupa2UmuRIVuWYnBSnJPM+RHnt6hwN51AHRsSa50gTfDOH+9Q01DDLUNv6fCxSSlJzPpiFn/+7U+7n3d0FIcKDlFRV8GdF9zJO3++w85TO7l6wNX2Dks4mKzSLNyc3QjxCmn3cY6SFOt0Og4VHOKmuJsAuLLflWxK20R6UbrDtwrnlecZPNfC09UTP3c/o9un1Y6gCJ8I9ucZuAJSCOFQrFYp/uGHH5g2bRpbtmzBycmJuro6vvzyS6ZPn862bdus9bJCWNyCEQuoqq9i9d8nwuuvKzcePw422HPXqGtk8Y7FDAkbwlUDrmp2n0ajYfbQ2Ww7sU3fimeK4upiymvLrdI+He4TzpCwIRbZV1xUVWSRIVuWoq51ai8pbmhs4I+cPxgROaLFfY64lqm2oZav075mxsAZLJuyrMNfa2as4WjRUR781vwz412Fep74/ovux9XJlR0ZO+wckXBEWWVZRPlGNfuiszX+7v54unjaPSnOLc+luLpY3/GiniXuDFOoc8tzDa4Uw5kd9BXGtU8nZycTExTDxT0vlkqxEJ2U1ZLiJUuWMGHCBH7++Wc+++wzvvzyS7799lvCwsJ47bXXrPWyQljcBZEXcGHUhaz48210Gg2UlsKYMXDttVBRYdXX3vjXRg4VHOKJS55odZrl7PjZ6NDx8cGPTX4NS+8oPldidCI7MnZQU19j1nW0VVqHap92c3Yj2DOYnLI2Vn2hJLzlteUtzhODsloqxCuEVG2qNcM0ytbjWymtKWX6oOkGPf7y6Mt5YswTvPvnu3xx5AsrR9c57MrcRYhXCEPChpAQlSDnis2wN3evxdbOORpDdhSD8uVnlG8U2eX2TYrVydNxYcosmZigGGKCYhy+hbq6vpqSmhKD1jGpwr3DTaoUj4gaQXx4POlF6VTWVRobqhDCzsxOitesWdPq7SdPnuTmm2/G0/PsNNtevXoxceJETpw4Ye7LCmFTC0Ys4HDBYXae2gl+fsoU6+++g4ULrfaaOp2Ol3a8RN+AvswcMrPVx8QExTCyx0jWHGj9/4eG2Hx0M3C2cmlpiX0Tqaqv0g8fMpWjtU+DMmyrvYpCW0O2VAOCBzhUpTgpJQlvV28mnDfB4Oc8O/ZZRkSN4K6v7jKrY6Gr2JW5i4t6XIRGo2FMrzH8nvU7VXVV9g6r09mTvYcLVl7ALV/c0iX3iGaXZXc4ZEsV5Wv/XcXq5Om40LMDVq/sdyVbj2916C8u1OTW6EqxEYO28ivyOVV6ihGRIxgaNpRGXSOHCw4bHasQwr7MTooXL17MrbfeyqlTp5rdHhERwffnDDaqqKhg586dMgJddDoz42bi7+7PiuQVyg3z58Ojj8L778POnVZ5zZ9O/sSuzF38ffTf2524PGvILPbm7jXpL+H8inxe+PkFrup/FUPDh5oTbpsuj74cJ42TWS3U9Y31lNSUOFSlGDr+8LQnZw9erl5t7kN2pKS4UdfIhtQNTO4/2aDVJSo3ZzfWzFhDdX018zbMo1HXaMUoHVtxdTFHCo8wqucoAC7tcyl1jXX8ni3DyIz10o6X0KBh3ZF1fLD3A3uHY1E6nY6sUsMqxeAgSXHBIYI8g/THRkBpoa6qr2L7ye12jKx96sAsQ6dPw5lKsRGDtvZkK0O2RkSN0P89KhOoheh8zE6Kk5KSqKmpYerUqXzwwQf6b3TvvPNO1qxZw6RJk3jooYe49957SUxMJC0tjbvuusvswIWwJW83b+YMm8Nnhz+jsLJQufHpp6FXL7j77rM7jy3opR0vEe4dzm0X3Nbu42YOmYmTxom1B9Ya/Rr/3PpPKusqWTJxialhdijAI4DhkcPNSorVCb6OVinuKClOzk5meORwnJ1a33E9IGgAOeU5lNWUWStEg+3O3E1ueS7TBxrWOt3UgOABvDHpDbYc28Ibu96wQnSdw29ZvwHok+JLel0CIOeKjZRSmMIXR77g8UseZ1z0OBZ+s5D0onR7h2UxpTWlVNRV6IdodURNiu1ZMT9ccJi40LhmZ6DHRo/F3dndoc8Vq+/PRrVP+4RTXF1scAU8OTsZDRouiLyAfoH98HTxlGFbQnRCZifFMTExfPLJJ9x333288cYb3HzzzRw7doxZs2axfPlyAgMD+eWXX0hOTqZfv37897//5YYbbrBE7ELY1N8S/kZtQ+3ZqoWPD/z733DgACxbZtHX2pO9h81HN/PQqIc6rNpF+EQw4bwJrD2w1qgPTQfyDvD2H29zz4h72qxkWkpidCK7MndRUWvaGWxtlRbAoQZtAUR4R5BTltPqv/f6xnr+zP2z1SFbKnXqtCNUi5NSknBxcmFK/ykmPf/O4Xdybey1LPphEfty91k4us5hd+ZuNGi4MOpCQPnzOjh0sJwrNtIrO1/B3cWdhy5+iFXTVuHm7MbsL2ZT12D94Ya2YOg6JlWUbxSVdZWU1drnyzN18nTT1mkAL1cvLo++3KHPFZvaPg1KJ5UhknOSiQ2Jxc/dD2cnZ+LC4mTYlhCdkEUGbTk5OXHHHXewfv16nJ2dmTZtGitXriQxMZFPPvmE3bt3s3v3btauXUtiYqIlXlIIm4sLi2NM7zG8teetsy2i06bB5Mnwz39CluXOUy7euRh/d3/uvvBugx4/e+hsjhcf59fMXw16vE6n45HNj+Dv7s8zY58xJ1SDJPZNpK6xTjmTbYKiqiIAh2yfrmmooaSmpMV9KYUpVNZVkhCV0ObzHWUCtU6nIyklicS+iQR4BJh0DY1GwztT3yHIM4hZX8zqludod2XtYnDoYPw9/PW3jek1hl9O/UJDo+3XuXVGp0pOsXr/au684E7CvMPo5d+LlVev5Les33h++/P2Ds8i1LP3xpwpBvutZcopz6G4ulg/ZKupyTGTSSlM4UTxCdsHZgC1Dbpp23dH9LuKDRy2pQ7ZUsWHxUtSLEQnZNHp09HR0axZs4bHHnuMlStXcv3115OSkmLJlxDCrhYkLCCtKI2tx7cqN2g0SpW4rg4eecQir5FSmMK6w+u498J78XP3M+g50wZOw8PFgzX7DRu4tSltE98f+55nLn/GJi3JY3qPwcXJxeQWam2lUil2tPbpSF9lPkJrLdQdDdkC6BfYDw0auyfFhwsOk16UblLrdFMhXiGsmraKwwWHeXzL4xaKrnPQ6XTsytylb51WXdrnUkprSuVDsoFe+1XZTvHo6Ef1t90QdwPzzp/HCz+/0CVa0U2pFIP9kmJ1yJa6jqmpK2OuBBx3NVNueS6BHoG4u7gb/BxDd9CD8t8kuyybhMizX34ODR9KfkW+0ROshRD2ZZWVTLfccgtffvkl/v7+XH/99SxdupR6K5y5FMLWrht8HcGewazYs+Lsjf36wT/+AevWwdGjZr+G2jr4wKgHDH6On7sfU2On8unhTztsMaxrqOORzY8QGxzLPRfeY264BvF282ZUz1EmJ8X6SrGjtU+38+EpOTsZHzefdqd6e7p60tu/N38V2TcpTkpJAmBq7FSzrzWx30QevOhBlv22jG/SHLet0tLSi9IpqipqkRSP6T0GcLxzxZV1lfqz+o6isLKQt/94m1lDZ9EnoE+z+5ZeuZTogGhuTbqVkuqWnRmdiVopNuZMMdgvKVaHOJ7bPg0QGxxLdEC0w7ZQ51XkGTVkC84O5TJk2FbTIVuqoWFnhm3JF2FCdCoWSYpTU1N57rnnWLBgAc8//zypqan07NmT999/n2eeeYbVq1czffp0DhyQNwjRuXm4eHDb+bexPmV980Toscdg/34lQTbDua2Dxpg9dDaFlYV8f+z7dh/3ZvKbpGpTWTJxCa7OruaEa5TE6ET25OyhuLrY6OfqzxQ7YPs0tJ0UJ0QmtLpfuqnYkFi7V4qTUpIY1XOUwR/SO/LShJcYGjaU2zbcZvC5vM5uV+YugBZJcR//PvT06+lw54rv+foeEt5KoLah1t6h6C3dvZTKukoev6Rll4Gvuy8fTf+IUyWnuO+b++wQneVklWUR5BmEp6tnxw8GIn2UjhS7VYoLDhHsGdzq30kajYYr+13JD8d+cKg/S6rc8lyjzhPD2fZpQyrFydnJOGmcOD/ifP1t8eHxgEygFqKzMTsp/vXXX7nuuuv45JNPOHDgAB9//DHXXXcdv/zyCwA33HADGzdupEePHtx00028+uqr1NY63hunEIaanzCf+sZ63vvzvbM3enjAoEHK7zMyTL52a62DLSxdCvHxUNZ86MqVMVcS6BHY7s7ioqoint32LBPOm8BV/a8yOU5TJPZNpFHXaNL6Dm2lFmeNs8Ht5LaiftjKKctpdntdQx17c/e22zqtGhA0gNTCVLtNls0oyeCPnD/Mbp1uysPFg7XXraW4upg7vryjS+6ZPdeuzF34uPkwKGRQs9s1Gg1jeo9hR8YOh/n3oNPp2Hx0M8eLjxt85MLaymrKWPbbMqYNnNZqmy7Axb0u5unLnuaj/R/x8YGPbRyh5WSVGb6OCZQvBHzdfO2aFMeFNZ883dTk/pOpqKtwuG4IUM4FGzN5GsDdxZ0AjwCD2p/35OxhUMggfNx89LeFeocS7h3O/nyZQC1EZ2J2Uvyvf/2LsLAwNm/ezM6dO/n+++8JCwvjjTfOruUIDw9nxYoVvPjii6xbt45rr73W3JcVwm76B/dnfN/xvLXnrZbDc/79bxg4EI4fN/q67bUO6mVnw6JFSuLt66vcdued8PDDuDm7ccPgG1ifsp7y2vJWn/7cT89RUlPC6xNfb/MDjrWM6jkKDxcPk1qoi6qKCPIMsnnMHQn0CMTN2a1FReFwwWFqGmoMS4qDB1BWW2bUXkxLWp+yHsCiSTHAkLAhvHLFK2z8ayMr96y06LUd0a6sXYzsMbLV9VuX9r6U7LJsjhcb/75gDceLj5NTnoOTxomXd77sEEPAVu5ZSXF1MYvGLGr3cU9e9iQX97yYu7++m5PFJ20UnWVll2UbPGRLZa9dxTqdjkP5hxgc0voXFQDjosfh6uTqkMclcstzjU6KQakW51a0XynW6XQthmyp4sPjpVIsRCdjdlKcnp7OpEmT6NmzJwA9evRg0qRJpKe33Cl47bXXsnHjRvr372/uywphVwtGLOBkyUle/PlF/XlXAGbMUM4XR0Yadb1jp4/x4LcPttk6qPf008pQrz/+OHublxd4Km14s4fcTGVdJRtenw8pKdCkMpVamMp/fv8Pdw2/i6HhQ42KzxLcXdwZ03uMSUlxYVWhww3ZAqUKGOET0eLDkyFDtlT2nkCdlJLE4NDB9A+2/PvywpELmdRvEg9/9zDz1s/jtg23tfvr9g2383vW7xaPw9oq6yrZn7efUT1GtXr/pb0vBRznXPHPJ5VW7icvfZJUbar+ixF7qamv4fVfXyexbyIje4xs97EuTi58NOMjGnWNzFk/xyESemNllRpXKQZlqJ89kuKc8hxKakpanTyt8nX35dI+l/LtUccatlVVV0VZbZnR7dOgdAF1VCnOKssiryKv1ff5oWFDOVRwqFP++RSiuzI7KQ4LCyMtLa3Zbenp6YSGhrb6+JCQEJYuXWruywphV9fGXsvoXqP557Z/ErEkgms/uZb/HfwflRHB8NRTSjt1B/LK81i2exkXv3sx/Zb2Y82BNSwcubDN1kH27YP334eFC+G8887evnQpvPACAGM8BtCr0pW1Bz5W2rmHDYNjxwB49PtH8XL14rlxz5n985sqMTqRA/kHjDpneiDvAF+lfmVQgmkPET4RLSrFydnJ+Lv70y+w4zPm9kyKtZVatp/cbvEqsUqj0fD+te9zfsT5bD2xlR+P/9jur48PfsxjWx6zSizW9EfOH9Q31rc4T6yKC4sjwCNAn4za246MHQR6BPL0ZU8TExTDSztesmtr96p9q8gpz+mwSqw6L/A8lk9ZzvaT23ll5ytWjs6y6hvryavIM/r8vr0qxerk6daGbDU1OWYyB/MPcqrklC3CMojafWPsoC31OR1177T35efQ8KFU11eTXtSyQCSEcEwu5l7gpptuYvHixdx2220MHTqUQ4cOsXPnTh5/vHut4xDdi6uzKztu28He3L2sObCGjw9+zJepX+Lt6s30QdOZVT+YCf/9Btevv1UquWeU1pSyPmU9aw+sZcuxLTToGhgWPoyXJ7zMTUNuord/79ZfUKeDRx+FwEAl6W6DU2QUs654mCW/LKFg6f8R+uyrcNllbFn7f2z8ayMvT3jZ6AFelpTYV9lTvu3ENm6Mu7HDx1fXVzP7i9n4e/jz+qTXrR2eSSJ8Ilrs6EzOSSYhKsGgdu/e/r1xd3YntTDVShG27au/vqJR12i1pBiUCtcvd/xi0GNf3vEyT/zwBCmFKQwMGWi1mCxNHbJ1Uc+LWr3fSePEJb0uYccpB6kUZ/zMJb0vwdXZlcdGP8b8jfPZcmwLV/S7wuax1DfW88rOVxgRNYLxfccb/Lxb429lU9om/rntn1zR7wqH/dLsXLnluTTqGo2uFEf5KEmxTqez6TGSQwVtr2Nq6sqYK/n793/n2/RvuSvhLluE1iH1y0qTKsXeLb/sPFdydjLOGmeGhQ9rcZ9+2Fb+AWJDYo1+fSGE7ZldKZ47dy7/+Mc/yMvL48MPPyQ7O5tFixYxb948C4QnhOPSaDRcEHkBSyYuIePBDLbO3cqsobPY+NdGphz+Bz0u/Jn7Fl/GzoydbEjZwI2f3Uj4knDmrp9LqjaVxy95nIN3H2Tvgr08dsljbSfEAN9+C1u2wD//qSTG7Zg1dBYNugY+vcgXtm6lvq6Ghz6/i/O8e/HARYavebKGhKgEfN18DW6hXrRlEQfyD/DBtR/YNZlvT4R3RLNBWzX1NezL3ceISMM+pDs7ORMTFGOXtUxJKUn08uvF8MjhNn/t1tx2wW24OrmyMrlznUHelbmL8wLPa/fP6JjeY0gpTKGgosCGkbVUUFFAqjZV39I9Z9gconyjeGnHS3aJ5/PDn3P09FH+MeYfRiV7Go2GN696k0ifSGatm0VFbYUVo7QcdR2TKWeKaxpqOF1t2zVahwsOtzl5uqm40Dh6+vV0qBZqtf3ZpDPFPuGU1pRSVVfV5mOSs5OJC4trdYr4oJBBOGmc2J8nw7aE6CzMToo1Gg1z5sxh06ZN7N27l2+++Ya5c+c63EAcIazJ2cmZsdFjeeuat8h9JJf1M9czTteHdxv3MOb9MUz73zS2ntjKHRfcwS+3/8Kx+4/xwvgX2j2npVdfr1SJY2Lg7rs7fHh8eDxDwoYoU6jj43n3nXs5GFzPK5+X4H7Y9tXIplycXLg8+nKDkuLNRzfzxu43WDhyIZP7T7ZBdKaJ8ImgsLJQvx/6YP5B6hrrjKpcDQgeYPP26YraCjYf3cy0gdMc5v06zDuMGYNm8MG+D9r9MOpodmXuarN1WqUmoTtP7bRFSG1SzzWr+5PdXdx5eNTDbD2xld2Zu20ai06nY/GOxQwKGcS1A40fwBnoGciH0z8kvSidF39+0QoRWl5W2Zmk2NhKsZ12FXc0eVqlrmbacmyL/r3Q3syqFJ95Tlst1PohW218+enp6smA4AGyq1iITsQie4qFEGe5u7hz7cBr+d+ju8l725+PU+L4ZtYmsh/OZvmU5Vzc62LjkpB334XDh+Hll8HNzaCnzB46m18zf2Vv7l6eTvkvl4VeyIxMH5gwAUpLTfzJLCMxOpG0orR2z54VVhYyd/1c4kLjeHnCyzaMzniRvpHo0FFQqVQAjRmypRoQPICjRUepb6y3Soyt+e7od1TXV1u1ddoUC0YsoLi6mM8Of2bvUAySWZpJVlkWF/VovXVaNSJqBO7O7nY/V7wjYwceLh4kRCbob5ufMJ9Aj0CbV4u/Sf+GfXn7ePySxzvc592WsdFjuTLmSj459InDrLxqjzmVYrBtUqxOnu7oPLFqcv/JlNaU8mvmr1aOzDBqQmtKl5FaXW5r2NbJkpNoq7Ttvs8PDRsqlWIhOhGzkuLq6mqzA7DENYRwSOHh+D3zIjd9cogrd2txdXY17Tp9+8Jtt8F0w5OXm4fcDMBVa6+isLKQ16e9iWb7z7B8OfjZd9eveq5464mtrd6v0+m488s7KaoqYs2MNa22pjkStaKgViWSs5MJ8gwiOiDa4GsMCB5AXWOdTVfMJKUkEeQZxKV9LrXZaxri8j6XExscy4rkFfYOxSDqeeKOKsXuLu6M7DHS7ueKf874mZE9RuLu4q6/zdfdl4UjF7IhdYN+sJItvLTjJXr792bW0FlmXWf6wOkcO32sU1TlssqycHVyJcQrxKjn2SMpzi7LpqSmpMPzxKrxfcfj4uTiMKuZcstzCfIMMunvXnU4V1vnivdk7wHa//JzaNhQjp0+1uaKRCGEYzErKR4/fjyrVq2itrbW6OempKRw99138+6775oTghCO7W9/g9Gj4fbbYcMG064xcSK89x4YUV3uE9BHvxt17vlzSYhKUCZW33hmuNXXX8PP9qlYDQ0fSrBncJst1O/88Q4bUjfw0viXGBbRcoCJo1GTYvVc8Z6cPYyIGmFUN0BssDKIJVVrm/b2uoY6Nv61kWsGXIOLk9nzFi1Ko9GwYMQCfs38lX25++wdTod2Ze7C3dmd8yPO7/CxY3qP4Y+cP+x2/rWitoI/cv7Qt3I3df9F9+Pl6sXLO23TmbEjYwc7Mnbw6MWPmv6F4RlTY6eiQWP31VKGyCrLIso3yujKeKSvsubPlknx4YLDQMeTp1X+Hv6M7jWab9IdIynOq8gzqXUaOm6fTs5OxtXJVT9QqzXqfbb8osnW/sj5g19POUZngBDmMispHjNmDIsXL2bMmDE888wz7Nq1q93K76lTp1i7di0zZ85k+vTppKamctFF7becCdGpOTsrCejw4XD99fCZES2hmZnKYK2yMpNe+u4RdxPhE8ELiS80v6OhAZ58Utl5bId2QyeNE+P6juPH4z+2aHf8S/sXD373IBPOm8CDox60eWymaFoprq6v5kD+AYOHbKlsvZbpp5M/UVxd7HCt06o5w+bg7uzOyj2OP3Brd9ZuhkcOx82546MNl/a+lPrGenZn2fbsrmpX5i4adA3688RNBXsFM3/4fNYeWNtimro1vLTjJUK9Qrlj+B1mXyvcJ5zRvUaTlJJkgcisK7ss2+jWaQAvVy8CPAJsmhSrk6cNmn1xxuSYyezL22eX9VHnyivPM2nIFpxtuW6rfTo5J5mh4UObdVyca2j4UIAu20Kt0+m4ed3NTF4z2e4DBIWwBLOS4pdffpn//e9/DBkyhE8//ZTbbruNESNGMHXqVO644w4efvhh7r33XmbPns3o0aOZOHEizz33HJmZmTz00EN8++23jBjROdYoCGGygADYvBlGjVIqxoWFhj1v40Z49VXQak162ZuH3kzOIzkt92E6O8N338EXXyjVZzskxonRiZwqPcXR00f1t9U21DJr3Sw8XDxYNW2VyWcMba1pUrw/bz/1jfVKZd4IIV4hBHgE2CwpTjqShJerFxP7TbTJ6xkryDOImUNm8tH+jxy69bCuoY7k7OQOW6dVF/e6GA0au50r/jnjZ5w0TozuNbo272NSAAAgAElEQVTV+x8Z/QhOGieW/LLEqnHsy93HprRNPHDRA3i5enX8BANMHzidvbl7OX76uEWuZy1ZpVlGD9lS2XpX8aH8Q4R4hRh1JvfKmCsB+C79O2uFZbDc8lyTK8Vuzm4EeQa12j7d0ZAtVXRAND5uPp2ird8Ue3L28Jf2L0pqSnh227P2DkcIs5n9qTM+Pp733nuPb775hjvuuIPY2FiOHj3Kzp072bRpEz/88AN79ihnL6644gpee+01tm3bxvz583EzcGiQEJ2enx98842SHIcYeJZswQI4ehSioy0fT3g4BAVBdTVMm6Yk4Daknitu2kL97LZn2ZOzh3eueadlIu/APFw8CPAIILc816QhW6C0DNtqAnWjrpH1qeuZ1G+SQ5/XXpCwgLLaMj4+8LG9Q2nT/rz9VNdXG5wUB3gEEB8eb7dzxTsydhAfHo+fe+tzBXr69eTW+Ft5989326yQWcLinYvxdfPl3pH3Wuya0wZOA2BDqonHVGxEbZ82RZRvFDnlOR0/0EIOFRwy+Dyxalj4MCJ9Ih2ihTqvwvRKMSjDtlprnz52+hjF1cUdfvnppHFiSNiQLpsUr9m/BjdnN2YPnc3KPSv17fZCdFYWK8VER0fz6KOPsm7dOpKTk/n222/55JNPWL9+Pdu3b+eXX35h6dKlXHXVVbi6mnd+SIhOyccHLr5Y+f0778DKNlpDdTpIT1d+H2Xl5LC6GrKzYcYM5dyyjQwIHkCUb5Q+Kd5+cjuLdyzmjgvuYPogx2zpbU+ETwS5FUpSHOoVSi+/XkZfIzY41iZnipOzk8kuy3bY1mnVqJ6jiA+P583kNx12qrChQ7aaGtN7DL+e+tWoSeNVdVVMWTOFD/Z+8P/Zu++wqI4uDsC/BaQjRZBiFykWsGDBThQrYo8Fe9coJmpiSYxiiS3WGHvsgiUqKhZAVGJFAUVFwN5AQBSUItJ2vj/mW4pStlyq530eHmH37p25oLjnnplzZJ1itoysDNyIvJHvfuLcZredjbTMNGy4uUHusQrzNP4pjjw4ginNp0BPXU+w85obmMOmqk2ZXkKdmJaI5PTkcpEpZowhLC5M6v3EEiKRCN3rdcf5Z+dLtJr+l1LSU5Ccnix3phj4/+/1fDLFstz8lFSgLqu/w+SVJc7CoQeH4GThhPXd10NbVRuzfGeV9rQIUUixrE/U0NBA7dq10aRJE1hbW6NqVdnL4QOAt7c3lixZAhcXFzRr1gxWVlb4+eefC33N7du3MWHCBLRs2RK2trZwdnbGnj17kJWVJdccCBEcY4CXFy+8JRZ//fzp04CVFXCx6F6+CtPTA/z8AAcHYNw4YMYM3he5mIlEInSq0wkXn19EQmoChh8fDnMDc6zvvr7Yxy4OJtomiE6K5kvqZCyyJWFZxRKRiZHFXoTJM9wTyiJl9LLsVazjKEokEmGS3STcibmT/Sa0rAmICoCJtolMN0Ha12yPlIwUhMSESP2auX5zce7JOfx5/U+531yHxITgU8anfPcT52ZlaIUBDQZgU+AmfPz8Ua6xCrPq2ipUUqpULDUD+ln3w9VXV8vs/kZ52zFJmGmbITopGmKWz/8bApNUnpY1KAb4EuoPnz+UeN/r3CQZXkkVaXkYa+efKQ56EwRVZVU0qtqoyHPYGtsiPjW+RDP8JeHi84uISY7BMJthMNQ0xIKOC+D9xLvMVB4nRB6CBsWdO3fGokWLBDvfli1bcODAAYSHh8PYuOhfbH5+fhg+fDiCgoLg6OiIYcOGISMjA8uXL8eMGTMEmxchChGJeMGtY8cAJSWerZXIyAB++QWwsADal1CrHF1d4OxZ4McfgfXrAScnICGh2IftVLsT4j7FwcnDCdHJ0fDo7wFtVe1iH7c4mGib4FnCMzyIeyDz0mkJSbGtJ/FPhJzaVzwjPOFQ2wH6GvrFOo4QhtsOh1YlrTLbnikgMgD21e1lugkiCUql3Vfs/cQbf936CxYGFgiLC8PdWPkqcl95dSXP+IWZ124eEtMSsSVoi1xjFeRN0hvsubsHY5qMya6mLKR+9ftBzMQ49fCU4OcWQlTS/4NiBTLFGeIMvP8kX50JWUiKbMm6fBoAutTtAiWREryfeAs9LalJMryKLp/ON1McHYTGxo2lKq5nU7ViFtvyCPVAZbXKcLJ0AgBMazkN9QzqYZbvLGRkZZTy7AiRj6BBcXx8PHR0dAQ737x58+Dj44Pbt2/Dzc2t0GOTk5Px+++/Q0lJCfv27cOyZcswZ84cnDx5Ek2bNoWPjw/OnDkj2NwIUYiqKqChASQmAu3aAUuX8sd37AAePgRWrQJKcpuBigoPiP/5B7h0iRcFe1i8S3kl+4pvRN6AW0c3tKjWoljHK04mWiaITuYZHEWD4uLcVxzxLgIP3z8s80unJSqrVYaLjQsOPTiED58/lPZ08nj36R2exD+BfTXpl04DPEtYR6+OVPuK41LiMPrEaDSq2giXRl2CipIK3O+5yzXfq6+uoq5+Xan2szYzbYau5l2xLmAdUjNS5RovP+turEOmOBO/tP1FsHPm1ti4MWrp1sKJh2WzNZPCmeIS7FUsaSMkS+VpCX0NfdhXty/VfcWSPfGKLp9OTk/Gp4xP2Y+JmRi3o29L/XteUoH6fmzF2VecmpGKY2HHMKD+AKirqAPghcn+7PInwt+FY3vw9lKeISHyETQotrCwwKtXrwQ7n729PWrXri3VXXhvb2/Ex8fDyckJNjY22Y+rqanhxx9/BAAcPFh2C7aQb5SmJtCgAW+P9MsvwMKFQMeOgLNz6cxn3Di+bDshAWjVCvAuvjv9tfRqoaFRQ3So1QFz280ttnFKQu6sl7xBsYWBBYDiDYo9w/l+yz7WfYptDKFNspuETxmfcODegdKeSh6SpaGy7CeWaFezHa68vFLoUmjGGMadGocPnz/Ao78HqlWuhu71uuNg6EGZl88yxnD11dUi9xPnNq/dPLxNeYvdIbtlGqsg8anx2Bq8FUMaDUFd/bqCnPNLIpEI/az74fzT80hKk6+VXXESIlMMlExQHBYXJnPl6dx6WfRCcHQwbkffFnhm0hFk+fT/s8y5i849iX+CxLREqX/PG2gYoJpOtQpVbOv0o9NISk/CMJtheR7vY9UH39X+Dgv9FyIhtfhXmxEiNEGD4hEjRuDSpUuIiIgQ8rRSCQjgBU/a57PktEWLFtDQ0MCdO3eQnp5e0lMjpGAqKsDu3TwYXb2at2tas4YvsS4t7doBQUG86vWGDcXasuna2GvwGe4DZSXlYhujJEiyESbaJnJXltVS1UL1ytWLtdiWZ4QnWpi1QPXK1YttDKHZmdmhuVlzbA3aWqaK1dyMugklkZJcN0Ha12yPuE9xeBz/uMBjtgdvh9cjL6xwXJGdbRpmMwxRSVG4/PKyTOM9ev8IcZ/ipFo6LdGxVkfYV7fHn9f/FKRg0t+3/kZyejLmti3eG2D96vdDWlZaqS7dLUhUYhT01fXlrvpeopniuAdy7SeWmNJiCgw1DTHTZ2ap/LuNSY6BCCIYaRrJfY7c7fYk5OkwYGNsU6GWT7vfd4eptikcajvkeVwkEmFtt7WIT43HkstLSmdyhChA0KDYxMQErVu3xtChQ7Fy5UqcPXsWt27dQmBg4FcfQnv+nPcmrJ1P+xoVFRVUr14dmZmZeP36teBjE6IQZWVg+3ZgwQJgyRLATrYet8WiZk3g2jXg4EEeoL97B6SlSffa9HTg8WMgtehll7rqutnLr8ozyZsnebPEEsXZlikyMRKBbwLLzdLp3CbbTcaDuAe49vpaaU8lW0BkAGyNbaGlqiXza4vaVxzxLgIzfGagq3lXTG81Pfvx3la9oa2qLfMSasl+YlkyxSKRCPPazcOLDy9wKPSQTON9KSU9BX/d/Au9LHtlB/jFpW2NtjDUNCyTS6ijkqLkXjoN5PyeKe6gmDEmVzum3PTU9bDIYRH+e/kfTkSU/M8iNjkWVTSroJKy/NuQJFnm3MW2gt4EQV1FXabvjW1VW4S/C68Qe23jU+Nx9vFZDG00NN+b2U1MmmBs07H4+9bfePy+4Jt+hJRFKkKebMSIERCJRGCMYffu3YUuew4PDxdyaCQnJwNAgXuatbV5AZ/ExMQCz7F+/frs4yZOnAgA2L49Z2+Eg4MDHBwcsGbNGiQl8aVZpqammDRpEry8vLL7MQPArFmz8ObNmzxLtp2dnWFnZ5dnf7SlpSVcXFzg4eGBR49y3gy7ubkhODgYXl5e2Y8NHToUZmZmWLNmTfZjdnZ2cHZ2xrZt2xAdHZ39PZg1axb8/f3h7++ffSxdUxm/JpEIyMzExDdvytY1MYahXl4w09XFmg4d+DwZg13t2nCuWRPbdu5E9LNnwPv30ElIwKyEBPiLxfCfOpX3ZH71ChMbNwb69cP2XG2fyu3P6f9y/92LTY4FgoAqulUAQO5r0tfTx+2021i4cGH278+irmnZP8twO4YvUTS2N4aanhpeeedsY6lcuzIMmxoiwjsCeANEpURhza015erfk1MtJ6heUcUPYT+gf/3+gv+OePjuId7gDbzXecPP26/Ia3Lq5YSbUTdhcc8CbtFuMl/TkCFDYKBkgI2rNuK1Nb9RK7mmTVs2YenZpcBnwP47eyiJlPJcU93wujiSfAS/NvkVe3ftlerndPDYQWje0oSH2AMikUjqn1M9i3poaNQQc9fNxcMaD7PfBMv672nM72Pw/uZ7VG1aFWveFP/fveoR1XHM5xhcq7vCvqV9mfgdAQCBwYGoZsuDYnn/PenG6+JN0ptivabEtEQk3k5Ew04NFfo5TZwwESt2rcC4meMQ3CIYKkoqJfa7/M6nOzCpY6LQ7whLO0vgOvBP1D8IMQuBqakpglSDUCumFpYuXlrozyn3NT2OfYz08HSsM1yH2ZNnl+v3RrdxGxkXMpD0IQluN9zy/TnppetBTUcNE7ZNgEO6Q5m/prLyPoKuqeSuqaA6VSIm4LqWjRs3Sl2Fc9q0aTKd++bNmxg5ciScnZ2xevXqr57v1q0bXrx4AV9fX9SqVeur54cMGYI7d+7g0KFDaNq0aZ7nIiMj0blzZ1y4cAHVq5efZYWElJijR3ml7P79gQMHgEmTgE85xUegqQlYWuZ81K0LjB7NA+jJk/nr4+L413//DaSk8J7NzZvz15Zz6VnpmOg1Eb+1/w0WVSzkPs+6G+sw03cm4n6Jg6GmYZHHv/r4ClZ/W8FU21SqDFQjo0bY0kvYisIlxfWsK3bc3oHImZFSfW+kdebRGfQ93BeZ4kw4WTjh+ODjRVaVDYsLQ8PNDbGnzx6MajJKrnH7HuqL0LeheDI9b7XxuX5zsfLaSngO9kRf675fvc77iTd6uPco8Pn8mP9ljsbGjXF88HGZ53ki4gT6He6H+e3nY0kn2ZdEpmelw/wvc9TVr4v/Rv8n8+vlcfrRaTgfdIb3MG90q9etRMaURrW11dDNvBt29ZG/J7ztFlvU0a+Dk0NOCjizvHyf+qLbgW64NOrSV0tkZeXzxAfd3btjdZfVmNWm5PrYttnZBpqVNOE30k/uc2RkZUB1qSrcOrphocNCZImzoLtCF2OajMHGnhulPs/dmLtosq0JDg44iCGNhsg9n7LAYY8DYpJjED41vND3+8uuLMNvF3/DhZEXsotqElLWCZopdnV1FfJ0MpFkeCV3IL4kySRXrly5xOZESIUxcGDO59bWwMSJvJeyJAg2M+NBc342bQLmzcvZJ33uHG8BBfA91VWqfP0aOztAUi3+u++AOnUASZY5NZVX7i5DVJVVsafvHoXPY2VoBQB4+O4hDGsWHfjN9eP7M/1H+6Ombk2Fxy/LJjWfhL8D/8bekL2Cvbm+9PwSBhwZgMbGjeFi44JZvrMwwnMEPPp7FLrPPSCS17BoVb2V3GO3r9keJx+eRHRSdHahNv8X/lh1bRUmNJtQYMDrWNcRVbWqwv2+u1RB8ZukN3iW8AxTW0yVa559rftidJPRWHZ1GbrV6ybTvmQAOHDvACITI7HDeYdc48vDsa4jtCpp4UTEiTITFGeKMxGTHCN3kS0JMx2zYl8+nV15WoE9xRLd6nVDj3o9sPjyYoxsPBJGWvLv8ZVFTHIMWtdordA5KilXQhWNKtl7ih++f4iUjBSZt8lYG1pDRUkF92Pvl+ug+PXH1/jv5X9Y7LC4yATYDPsZ2B68HTN8ZuD2xNvlvm4I+TYIGhSXpjp16iA0NBQvXrxAo0Z5G6pnZmYiMjISKioqqFGjRinNkJAKonlz/iEtZWUg9+qNM2f4HuWAAODGDeB9Pj0369TJ+bxTJ8Do/2+kEhJ4AbCuXXkmuls3HlhXELnbMrWt2bbQYwMiA3Aw9CDmt59f4QNiAGhUtRHa1miLbcHbMLP1TJl6A+fnZuRN9D7UG/UM6sFnuA+qaFaBmInxy/lfoF1JGzt674CSKP8bPQGRAdBT18v+ecmjfS2+v/fqq6v4vuH3SEhNwAjPEbCoYoF13dYV+DoVJRUMbjgY24O34+Pnj9BV1y10nKuveOsnWfYTf+mv7n/h8svLGH58OO5OvlvkmBJZ4iysvLYSTU2aopt5yQWn6irq6GHRAycfnsQmp00F/hxLUmxyLMRMrNCeYoAHxbJUMk5OT4ZmJU2ZvgcP4h7AUNNQsAB2Tdc1sNlig4X+C7HZabMg5yxKbEosTLTkb8ckYaJtkr2nWJ4iWwCgpqIGqypWuPe29IttJaQmQE9dT67fnwdD+XJWFxuXIo/VqKSBlY4rMeTYEOwO2Y3xzcZLNUamOBNP4p9IVWFfq5IWaul9vTKUEHkV27vJoKAghIeHIzExETo6OmjQoAGay/JGWkb29vbw8vLClStX0KtXrzzPBQYGIjU1FS1atICqatHN1gkhxczQEOjVi38U5fffcz5PTwfGjuVLuI8eBYyNgeHDeYD8xc2w8qi2Xm2oKKkUWWyLMYafvH+CqbYp5rSbU0KzK32Tm0/GCM8RuPTikkJL8u7F3kMP9x4w1jLG+RHnUUWTr1b4uc3PSExLxJLLS6CjpoN13dbl++YxIDIAraq1UijYamrSFJqVNHH11VUMbDAQk05PQkxyDG6Mu1Fk8a5hNsOw8dZGHA8/jjFNxxR67JWXV6BZSRNNTJrIPVcdNR0c6HcA7Xe3x9SzU3Ggv3TtsTwjPPHo/SMcHnhY4ZsYsupn3Q9Hw47iZuRNhTOGQlC0HZOEmY4ZYpJjkCXOKjL7Fp0UjWbbm8GxriP299sv9RhhcWGCZIkl6hvVx+Tmk7ElaAumtpgqV+9jWUh6CyvSjknCWNs4OygOfhMMzUqasDa0lvk8tsa2uP76usLzkVeWOAurr6/G75d+x/hm4+W6OeFx3wOtqrWCuYG5VMcPajgIf936C/MvzsfghoOho5Z/zR/GGG5G3YTHfQ8cfnAYb1PeSj2nCc0mYG23tdBW1Zb6NYQURPCgODQ0FLNnz86uBs0Yy/7PsE6dOli5cmWePsJC6d69O1avXo0zZ85g+PDh2WOkpaVhw4YNAPhGa0JIOWZsDKxbB6xcyZdh79nD20atWcOXXI8aBbi45L8kuxxQUVKBub45HsUXHhQfDD2Im1E3sav3rm/qzcDABgPxo/eP2Bq0Ve6g+NH7R+i6v2v2fsPcPaYBYJHDIiSmJWLDzQ3QVdPFou8W5Xk+KS0JD+IeoH/9/nJfB8CXZtpXt8eVV1ew7+4+/Bv2L5Z1WiZVFqpltZYw1zeHR6hHkUHx1ddX0bp6a4Wq8AJA6xqt8XuH3+H2nxt6WvQsMlvEGMPyq8thYWCBAfUHKDS2PHpa9ISKkgpORJwoG0Fx4v+DYgEyxWImxtuUt1/93c1NzMQYfXI0YpJjcODeAUy2m1zk6hMgp/L0cJvhCs3zS24ObnC/746ZvjPhPcy7WG+SSJY7S6p1K8JE2yR7u0RQdBCamTaTaymwTVUbHAw9KNXqDqG9+vgKIz1H4r+X/6GeQT1sCdqC7vW6o7dVb6nP8eDtA9yNvYu/uv8l9WtEIhHWdVuHVv+0wvKry7Gs87I8z4fHhcPjvgc8Qj3wLOEZ1JTV4GzljF4WvaRqW3Yr6hbW3liLSy8uwb2/O1pWayn13AjJj6BB8cuXLzF69GgkJyfDzs4O9vb2MDIyQlxcHAICAhAcHIyxY8fi33//zbd10pf8/Pzg58eLJMTFxQEAQkJCMHcu30enr6+POXN4lkRbWxtLly7F9OnTMXLkSPTs2RO6urq4ePEinj9/jm7duqFnz55CXi4hpLSoqgJ9+vCPuDjeOmrPHmD6dGDxYiAsLGfJdTlTVFumTxmfMNdvLpqaNJW7yFN5pa6ijjFNxmDDzQ2ISY6R+U3vq4+v4LjPEWImht9IP9TWq/3VMZJem0lpSVh8eTF01HTwc5ufs58PehMEMRPDvrq9opeDdjXaYemVpZh2bho61OqA2W1nS/U6kUgEFxsX/HHljzx7kr/08fNH3I25iwUdFyg8VwD4rcNv8HnqgylnpqBtjbaFLl08/+w8bkffxg7nHaWyn1BPXQ+d6nSCZ4QnVjiuKPFM9ZeEzBQDfK94YUHxxpsb4fvUF6u7rMbagLWY4TMDAeMDilzdEJUUhcS0RIXaMeXHUNMQCzoswEzfmTj35Bx6WhTf+7HYZJ7ZNdYSIFOsZYzY5FhkijNxJ/oOJtpNlOs8klZkoW9Dpbo5IRSP+x744cwPyGJZ2N1nN1xsXGD/jz3GnRqH+1PuS/071P2+O5RFyhjcaLBM47es1hLDbYdj7Y21mGg3EcoiZRwKPQSPUA+ExIRASaSEznU6Y0GHBehXvx8qq0lf92dQw0FwtnTGyBMj0WZnGyzsuBDz2s+DilLF2VJFSpagG202b96MlJQUrFu3Du7u7nB1dcWQIUPg6uoKd3d3rF+/HikpKdiyRbrqp+Hh4fD09ISnpyeuXuX7ol6/fp39mI+PT57jHR0dsX//fjRv3hy+vr44cOAAKlWqhHnz5mHduvyXwRFCyjkjIx4M374NBAbyoLicBsQAYFXFCo/fP0aWOCvf59feWIvXia+xrtu6MrFXsqRNtJuITHEmfrvwG6KToqV+XUxyDDrv64yk9CT4jvAtdAmkkkgJ2523Y1DDQfjl/C/YHpzTWkKSNRIiK9G+VnuImRjKImXs77dfpuBxmM0wiJm40B7CNyJvgIEptJ84NxUlFRzofwCMMYzwHFHg31EAWH51Ocx0zDDCdoQgY8ujn3U/PI5/jLC4sFKbg0RUYhQqKVVSeJ9u7qC4IPdj72OO3xw4WzpjZuuZWNZpGQLfBMLjvkeR588uslUMS5yntpwKCwMLzPKdVaw9e4XOFKdkpCAwKhCpmaly96K3NbYFAJn2gyviw+cPGHZ8GIYdH4YGRg1wd/JdjG4yGqrKqnDv746U9BSMPjFaqr27YiaGx30PdDHvgqpaVWWey/LOy6EkUoL9P/aotb4WZvvNhqqyKjZ034ComVHwHeGLUU1GyRQQS3Ss3RF3J9/F4EaDscB/ATru6YhnCc9kPk9pSUhNwD+3/8HmwJLZa0+KwATUrl075urqWugx06ZNY+3atRNyWIW9fv2aWVpastevX5f2VAghQrl3j7GPH0t7FjLbHrSdwQ3secLzr56LSoxiWn9osf6H+5f8xMqQUZ6jGNzAlBYpMcd9jmzX7V3sQ+qHAo9//+k9s9lsw7T+0GLXX12Xepy0zDTm5O7ERG4i5n7PnTHGWO+DvZnVRiuFr4ExxpLTklnLHS3Z8bDjcr3ebpsds9tmV+Dzv/r9ypQXKbPktGR5p5ivvSF7GdzA/rj8R77P33h9g8ENbM31NYKOK6uoxCgGN7Cl/y0t1XkwxtiI4yNYzXU1FT7P64+vGdzAtgVty/f51IxU1mhzI2b8pzGLTY5ljDGWJc5idtvsWPW11VlKekqh5197fS2DG9jb5LcKzzU/J8JPMLiBbby5sVjOzxhjm25tYnADi06KVvhce+7sYXAD++3CbwxuYOFx4XKdRywWM93luuyH0z8oPKei+D/3ZzXX1WTKi5TZYv/FLCMr46tjNt/azOAGtiFgQ5Hnu/LyCoMb2L6QfXLPaf2N9azxlsZssf9i9vj9Y7nPUxj3e+5Md7ku01mmw/bc2cPEYnGxjKOoT+mf2JHQI6zPwT6s0uJKDG5gcAPzuOdR2lP75gmaZkhISECd3FVj81G3bl0kJCQIOSwhhOT18SPQsSPw44+lPROZ5a5A/aXfLv6GDHEGVjmuKulplSl7+u5B2A9h+K39b3ie8BxjT42F8WpjDDwyEMfDj+Nz5ufsY5PSktDDvQcevX+Ek0NOyrS/VFVZFf9+/y861u6IkZ4jcTLiJC+ypUArpty0VLVwc/xN9KvfT67Xu9i4IDg6GA/fPcz3+auvr6KZabMiC3fJaoTtCAxuOBgL/RciMCrwq+eXX10OAw0DuZeaCsVMxwz21e3hGeFZqvMAeGZX0aXTAF/OK4KowEzxPL95CH0bij1992Rn9ZRESljXbR0iEyOx+vrqQs//IO4BjDSNiq11Um+r3uhUpxMW+i9EQmrxvBeMSY6BCCJB+plLinWdfnQa2qraclecF4lEsDG2KdYK1OlZ6ZjnNw/f7f0OqsqquD7uOn7v+Hu+y4knN5+MXpa9MPv8bIS+DS30vB73PaChoiF1X/T8/Gj/I0Imh+D3jr+jnkE9uc9TGBcbF9ydfBdNTZti9MnRGHR0EN5/yqe7RSnIFGfC54kPRp0Yhaqrq2LQ0UG4FXULri1dcXP8TbSp0QZTzkzByw8vS3uq3zRBg2IDAwM8ffq00GOePXsGfX19IYclhJC8dHWBnTuBP/4o7ZnIrKCg+Hb0bewN2YvpLadLXf2zIqtvVB+Lv1uMx66PETAuAJPsJuHKqysYcGQATFabYNzJcfB96gvng84IfhOMf7//F53rdpZ5HI1KGjg15BTszOww8N+BeA8Io1cAACAASURBVJvyFvbVFN9PLIQhjYZABFG+y2LTMtNwM/KmYEuncxOJRNjitAWm2qYYdnwYktOTs58LfRuKUw9PwbWla5koAtfPuh+Co4Px6uOrUp1HVFJU9tJnRVRSroSqWlXzDYp9nvhg/c31cG3piu71uud5rn2t9hjYYCBWXluZXfQrPw/iHgi+nzg3kUiEtV3XIiE1AYv/W1wsY8Qmx8JIy0iQvaWSJdh3Y+/CztROoS0rNlVtcD/2PhhjCs/rSxHvItB6Z2usuLYC45uNx51Jdwrd4iESibCz907oquvC5ZhLnhuJuWVkZeDIgyPoY92nwOrRZUktvVq4OPIiVnRegZMRJ2G71RZ+z/yQJc4q8Y9McSYCIgMw/dx0VFtbDd3du+NkxEkMbjgYF0ZewOsZr7Gm2xq0rNYS+/vth5iJi9yWQoqXoLvR7e3tcfr0aZw5cwZOTk5fPe/j44MLFy7A2dlZyGEJIeRr/f6ffcvKAry8gL7y3+UuSSbaJtBR1cmT/WOMYYbPDBhqGmJ+h/mlOLuyRyQSoVX1VmhVvRXWdFuDS88vwSPUA/+G/YtdIbsgggju/d3hbCX//zs6ajo4N+wcHPY44P7b+4IU2RKCmY4ZOtXpBPf77nBzcMtTNyM4OhhpWWloV7NdsYytr6GPff32odPeTpjhPQM7eu8AAKy8thJalbTg2tK1WMaVVT/rfpjjNwcnI07CtVXpzSkqMQpd63YV5FxmOmZfBcVxKXEYfXI0Gho1xErHlfm+bpXjKpx6eAq/XvwVe/vu/ep5xhjC4sIErzz9pcYmjTGu6Tj8Hfg3prSYUmj2NTUjFWcen4HHfQ/4PfNDq+qt4NLIBf3r9y+winNsSqwgRbaAvMW65N1PLGFT1QYf0z7ideJrQXvLh8SEoO2uttBQ0YDnYE+pM7pVtapiT5896OnRE79e+BVru6396hifpz54n/oeLo2K7k1cVigrKWNOuznoYt4Fw44PQ5f9XUp1Puoq6nC2dIaLjQt61OsBNRW1r46pq18Xf/f8G6NOjMKqa6swr/08ucc7HHoYE09PRIdaHeDSyAW9rXoLvlooN8YYgt4EweO+B46FH8MPLX7A3HZzi2284iRoUDx16lRcuHABP//8M9zd3dGqVSsYGRnh3bt3uHXrFoKDg6GlpYUpU6YIOSwhhBRs505g0iTgr78AVxneFD97Bri5ASdPAmPGAIsW8Qx0MROJRLwCda62TJ4Rnrj88jK2OG0p8XYe5YmKkgq6mHdBF/Mu2NxzM84+PgvNSproYdFD4XMbaBjgwsgLOP3otEI9f4U2zGYYxp4ai1tRt/Is677y8goAFFtQDAAOtR0wu+1srLy2Ej0teqKJSRMcvH8Q01tNz+79XNosqliggVEDeEZ4llpQnJSWhKT0JIXbMUl8GRQzxjDBawLiU+PhM9ynwHY2dfTrYIb9DKy8thKuLV2/CvIklaeLu48wACzptASHHhzCL+d/wckhJ/M8lynOxMXnF+Fx3wPHw48jKT0JJtom6F+/P66+uoqxp8Ziypkp6GXZCy42Luhp0RPqKurZr5enMn1BjLSMIIIIDEzhoDi72FbsfcGC4k8Zn+ByzAW6aroImhgk82qEHhY94NrSFesC1qF7ve7oap73xo37fXcYaBigW71ugsy3JDUzbYbgicHYeXsnPnz+UCpzqKVXC32t+0pVRGyE7QicfXwWC/wXoIt5F7n+vp1+dBrDPYfD2tAaITEhOP3oNLQqaaGvdV+42LigS90uCrfnk3j47mF2S60n8U+gqqwKJwsnOFuW48Sn0JuU7969y7p3786srKyYlZUVs7a2zv68e/fu7O7du0IPqTAqtEVIBZaZyVjfvoyJRIwdPVr08Z8/MzZlCmMqKoypqzPWowd/rbExY3v3MlYCxTuGHh3Kaq+vzaeT8ZnV3VCXNdzUMN+CKeTb9iH1A1NbosZcz+YtctnLo5dgBcEKk5aZxppta8YMVhqwgUcGskqLK7HXH8vW/6W/XfiNKS9SZu9S3pXK+OFx4QxuYAfuHhDkfBNOTWDGfxpnf70taBuDG9ja62uLfO3Hzx9Z1T+rsna72n1ViMj7sTeDG5j/c39B5lmUZZeXMbiB+T31Y2KxmAW8DmDTz05nxn8aM7iBVV5emY05MYadf3qeZWZlMsZYnuOq/lk1z3F+T/1YZlYmq72+Nht+fLhg8zRaZcTgBoULRH1I/cDgBrb8ynKBZsbY1DNTGdzAfJ/4yn2OT+mfWMNNDZnpalMWlxKX/Xji50SmsVSDTfaaLMRUiRTiP8WzGmtrMIu/LGQukHjx2UWmtkSNNd/enH38/JFlibOY/3N/NvHURKa/Qp/BDcxwlSH74fQP7OrLqyxLnCXz/KISo9ia62uY3TY7BjcwkZuIddrbie28vZMlpCbIfL6yRvBmXra2tjh37hxu376NsLAwJCUlQUdHB/Xr14ednZ3QwxFCSOGUlQEPD8DRERg2DKhaFWifzz7L9HTe/1hVFXj8GJgwAZg/HzAzA4KCgGnTgFGjgB07gL//Bho3LrYpW1axxKHQQ/ic+Rkbb27Es4Rn8BnuQ/0XyVd01XXRy7IXDj84jLXd1kJFSQViJsa1V9cwoP6AYh9f0uKl2bZmOBp2FOOajkP1ytWLfVxZ9LPuhz+u/IHTj04X2ds7S5wF/xf+UBIp4bs63wkyvmQPr5CZ4rcpb5GRlYFnCc8ww2cGHOs64kf7ogsLVlarjCXfLcGk05NwNOwovm/4ffZzD+J4O6bi3FOc24zWM7AteBvGnRoHFSUVPE14CjVltQIzwED+2yXc77vjaNhR7A7ZDRNtE7z79A4mWsJkigG+pSU9Kx3m+orVctBV10Ut3Vq4FytMsa3Tj05jU+AmzLSfiS7m8i8R1qikAff+7mj5T0tM8JqA44OOQyQS4eTDk0jNTMUw22GCzJcULc+2FJ8Z2O68vegXgbcKdD7ojHoG9eA9zDs7M92xdkd0rN0RG3tuhPcTb3jc98DukN3YHLQZtXRrYXDDwVKtLkjPSof3U29cen4pe9XE2q5rMbiRdK8vN4SMsG/dusXCwsKEPGWJoEwxId+Ad+8Ys7JiTE+PsdDQvM+dOMEzwVFR/OvMzK9fn5XF2D//MGZoyDPPxcj9njuDG9jFZxdZ5eWVmZO7k+InXbGCsfr1GUspvCULKX+Ohx1ncAPzfuzNGGPsfux9BjewPXf2lNgcdt7eyYz/NGaP3j0qsTGlJRaLWY21NVifg30KfP5W5C3207mfmMlqk+wMyKH7hxQeOyU9hbXb1Y5VWlyJvUl8o/D5GGNsa+BWBjewp/FPmd02O2aw0oBFJUZJ/frMrExmu8WW1V5fm6VmpGY/PvbEWGa0ykiQOUrLM9yTqSxWyW6tJm+26VP6J/bvg39Z30N9mfpS9ewWakIYc2IMG3J0iCDn6uXRizXa3Ejh88QkxTCjVUbMdost+5zxWYCZMbbm+hoGN7AdwTsYY4x1P9Cd1VxXU66MIlHM3PNzGdwgVbu+uzF3md4KPWa+wVyq3zGJnxPZ/rv7WfcD3ZnyIuXsllBFfdT7qx5beGkhi4iLEOISyyRBg2Jra2u2cOFCIU9ZIigoJuQb8fw5YyYmjFWvztiTJ4y9+f9/IE+fMjZgAH++KO/f57zu0SPGdu/mAbOAgqKCGNzAzDeYM5XFKnL3xszj0CHGAB4ckwrlc8ZnprdCj404PoIxltOD9Gn80xKdR1l+8+x61pWpL1XPsyQxIi6CLbi4gNX7qx6DG5jqElXW/3B/diT0CGu/qz1TWazCTj88LfeYnzM+s677uzKlRUrsSOgRIS6DMcbYqYhTDG5gXfd3lfqN85f8nvoxuIGtuJLz+8D+H3vmsMdBsHlKS+htIWW1Py1jjM3zm8dUFquwtMw0uc8hFotZT/eeTH2pOguNDS36BVLKEmcxx32OTPMPTXbl5RWmvEiZzT0/V7DzE+lJtqVUWVml0BteD989ZFX/rMqqranGnic8l3mclPQUFv8pvsiPhNSEMv3vSiiCtmTS19eHurp60QcSQkhpqF0bOHeO9zG2sADGj+eP160LHD3Kny+KgQFgaso/374dmD4dePdO0GlaVLEAADxNeIopzafA2tBa8ZMOHgw4OQErVgDUK75CUVNRw8D6A+EZ4YlPGZ9w5dUVmGqboo5enRKdhyLtaopbP+t++Jz5GXvv7sXaG2vRfHtzWG+yxpLLS1BLtxZ29t6J2J9jcWzQMXzf8Ht4DfVCY+PGGHBkAC49vyTzeJniTAw9NhS+T32xw3lHnmXKipIsV/R96ovxTcfL1ee6c93OcLZ0xh9X/kBscmx25ekGhiWzdDo3obeF5K7CXtbYGtsiU5yJiHcRcp9jcyAvIrjKcZWgRdGURErY23cv1FXU0XV/V2SxLFo6XUpUlVXh0d8DnzI+YfSJ0RAz8VfHvPzwEo77HMEYg99IP9TWqy3zOJqVNKGvoV/kh566Xpn+dyUUQf8Ha9myJe7cuSPkKQkhRFhNmgCnTvGWTT//rNi5Vq4EAgL4PmXGAG9vQaZYWa0yTLRNoK+uj4UdFyp2suho4PvvgSdPgOXL+Q2BFSsEmScpO1xsXJCcngyvh164+uoq2tdq/028iZFW+1rtYaBhgKlnp2KW76zsfrmRMyPhN9IPY5uOhZ66Xvbxuuq68B7uDXMDc/Q+1Bs3I29KPZaYiTH25Fh4Rnhifbf1GNt0rKDXIgmKLQwssK77OrnPs7rraqRmpuL3S78jMjGyxCpPf8tsqtoA4BWo5REWF4afz/+M7vW6Y1rLaUJODQD/u/WP8z9IzUyFrbEtGlVtJPgYRDpWhlZY120dzj87j79u/pXnuZjkGDjud0RiWiJ8R/gKc+OcCBsU//TTT3j+/DnWr1+PjIwMIU9NCCHCcXAAjh0DvlOwkI6SEtDg/5mVw4eBHj2AWbMA8dd3dWW1ynEVDvQ/oHhrm/v3AX9/QCQCbGyA4cN5e6rISIXnSMqOjrU7oppONay8thKvE1+jXY3ia8VUHqkoqWBzz81Y7LAYD6c9ROCEQMxoPaPQIjGGmoY4P+I8jLWM0cO9h1QFkhhjcD3riv339mPJd0ukKn4lKxNtE7h1dIPnYE9oq2rLfR7LKpaY1mIadt7ZiUOhhwAADY0oKC5OllUsoaqsKlexrbTMNLgcc4G2qjZ299ldbDe9+tXvh409NmJt16/7FpOSNdFuInpb9cYcvznZf2fiU+PRZX8XRCdF49ywc2WqRWB5J2KMMaFONm/ePLx69Qq3b99GlSpVYG1tDSMjo68HFYmwbNkyoYZVWGRkJDp37owLFy6gevWyVTWTEFJOiMXAjBk84Bw6FNi9G1BTK+1ZcWlpOXN58QKwsgJGjuSVtEmF8YvvL1h9YzUA4M6kO/RmSSAvPrxAu13tkCnOxOUxl2FZxbLAY+f5zcOKayswu81srHBcUeaz9QmpCai3sR6S0pKQIc5A3C9xMNQ0LO1pVWhNtjaBmY4Zzg47K9Prfvb9GWturMGpIafgbFWOe8ESmcSlxMF2qy0MNQ1xYeQF9PLohbuxd3HW5Sw61+1c2tOrUAQNiq2tpUvfi0QihIeHCzWswigoJoQIgjHgzz+BOXOAzp2B48eBypVlP8/163xpd69ewK+/yj+f4GCgaVOe0c7tp5+AjRuBBw8AKX9vk7IvJCYETbc1RWW1yoifHQ9lJeXSnlKFEfEuAh12d4C6ijqujr2Kmro1vzpm+ZXl+PXir5hsNxmbnTaX+YBYYuPNjZjuPR1GmkZ4+8vb0p5OhTfCcwQuPb+Elz+9lPrfqN8zP3TZ3wWT7SZjS68txTxDUtZ4P/FGD/ce0FPXQ1JaEo4PPo7eVr1Le1oVjqBBcVRUlNTHVqsmTL8+IVBQTAgR1L59wLhxQKNGwNmzOYW5ihIbywPqvXt5ZvfFC8BEzn6bT5/ygHfhQt5vObe4OMDcHOjShS8jJxUCYwzNtjdDbb3a8BzsWdrTqXBCYkLgsMcBRlpGuDLmCky0c/5tSgLL4bbDsbfv3jJddOxLGVkZaLqtKWrp1cIZlzOlPZ0Kb2vQVkw5MwWm2qYY0mgIhtkMQzPTZgXeRHn/6T1st9pCR1UHtyfdhmYlzRKeMSkLZnjPwIabG3Cg/wG42LiU9nQqJEGD4vKKgmJCiOC8vYGBAwEjI8DHB7AseMklMjOBzZuBBQuAT5+AmTN5IKutDXz+zIPYGjVkG3/UKODIEeDZs/yD8hUrgDdvgHXrAGXKKFYUCakJUFFSgY6aTmlPpUK68foGuuzvgrr6deE/2h8GGgbYE7IHY06OQV/rvvj3+38Fr6ZcEj58/gARRNBV1y3tqVR4YibGsbBjcL/vjrOPzyJDnAHLKpZwaeQCFxuX7O4DAL/R9f2/3+PUw1MIGB+AZqbNSnHmpDQxxhCdHF1oHQSiGEGD4s6dO6NDhw5YuFDBaqkljIJiQkixCAzkbZAklant7L4+5upVYOpU4N49wNGRL2vOvaS5SxceFAcHSx+8RkQADRvyPc6rVwtzLYQQAMCFZxfQ06Mnmpg0wZTmUzDu1Dh0rtMZXkO9oKZSRuoIkHIhITUBx8KPweO+B/xf+IOBoYVZC7jYuGBww8E49+Qcxp0ah5WOKzG77ezSni4hFZqgQXHTpk0xYsQIzJw5U6hTlggKigkhxebJE76Uev9+oGaufYjv3/Ogdf9+ngVeuxYYMIBXic7N15dnknv2lH7MIUOA06eB5895prowly8DKipAmzbSn5+Qb9yph6fQ/3B/ZLEstKnRBr7DfaGlqlXa0yLlWGRiJA6HHob7fXfcibkDJZESlEXKaFuzLfxG+FGNAEKKmaBB8aBBg2BmZob169cLdcoSQUExIaREZGXx9kidOwMfPgC2trxF0m+/AVpSvKH+8AHQ0yv8mHv3gMaN+TmXLi382MxMXona2ho4Q3sJCZHFsbBjOBp+FFuctuTpcUyIosLjwnEw9CCC3gRhW69tqKEr4/YZQojMBA2Kvby8MH/+fBw+fFjqStRlAQXFhJASsWULMHs2EB2ds19YXV261x44AEyfzpdkm5sXfFy/fsClSzxLrK9f9HkfPADq1AE0qXgLIYQQQr5NglaDMDExQevWrTF06FAMGTIENjY2MDQ0zLeiXosWLYQcmhBCyr5x4/j+4NhYHhRLGxADQPv2/M/Bg4Fr1/LvgRwUBJw4ASxeLF1ADPC9xwCQns6XbleqJP2cCCGEEEIqAMH7FItEIkhOWViPPupTTAghMjp5EujbF/jxRyC/bSo9evBM8rNnsvVHfvsWaN2aV72eOlW4+RJCCCGElAOCZoqnTp1abprVE0JIudOnDw+IN2wAHBx4gCzBGP96wADZAmKAF+OqUYNnmEeN4llsQgghhJBvBPUpBmWKCSHlSHo60LYtr2odEgLUqiXMeQMCeLZ48WLg99+FOSchhBBCSDmgVNoTIIQQIgNVVeDQIUAs5q2XMjJ4r+PNm3nALC97e16k688/+b5nQgghhJBvhMJBcWBgIN68eSP18REREThx4oSiwxJCyLfL3BzYsYNnd+fPBw4fBpYv54GyIv74A0hJAZYtE2aehBBCCCHlgMJB8ciRI3H8+PE8j23fvh2tWrXK93g/Pz/MmzdP0WEJIeTbNmgQMHkysGsXsGgRcPOmbNWs81O/PjB6NN+z3LQpL7rl7S3IdAkhhBBCyiqFg+L8tiSnp6cjMTFR0VMTQggpzNq1wJ07gIEBYGYm3DkXLAAMDYF9+wAvL/54ZiYPxM+fF2acojCWdzn4hQvA3bs5XwcGKp4ZJ4QQQgiBwNWnCSGElCANDUDo4oC6uoCbG/88K4svpwaA6GgegEv2G9+9C0yYwItztWnDP2rUkH28Dx94lvvGDb4cPDISeP+ef3TvDpw6xY8bMQJwcuLLxh8+5HugmzThS767deM9lgkhhBBC5EBBMSGEkPwpK+e0d6pRA3j8mGdwASA1lQflO3YAf/3FH6tWLSdIbt2aL8FWU8v/3PPm8Sx0WBg/p5IS0KgRYGkJVKnCP2xtc44/fZq3jgKAevWAPXuAhQt5b+b27fk+6HbtZLu++Hjg4EFg717++fXrQNWqsp2jrImJ4cXYDAxKeyaEEEJIuUFBMSGEEOlJMrL29sB///Hq1/fu8Uzv9ev84+hRfoyaGs8u16/Pg9aTJ3lWGODBW40awODBPIBu2bLw/srNmuV8rqzMM8eDBwM7dwJLlvDAuEcPnjlu2rTg82Rm8n3Se/fyLHR6Og++IyOBkSOBs2d5gF4eXb7Me1lraADnzgGNG5f2jAghhJByoZz+z08IIaRMqFQJsLMDpk0DPDyAFy+AqCgeGLu68qwuwLPINjY8KAWA3bt54Pb774CjY+EBcUFUVYEpU3jP5lWreMDdrBnf+xwRkf9rOnQAnJ0Bf3/ghx940H73Li8u5uMDrF4tz3eh9B0/DnTtChgb85sGkmXnhBBCCCmSIJliEe3lIoQQImFmBgwYwD8kRo3iH8VBUxP45Rdg4kReKGztWkBfH9i2LSfQPXOGB9E//QTMmcOzyqqqOeeYOJEH9D17Fs8ci9PmzfymhL09X5LOGF9+DgAfP/J94oQQQggpkIjlVz5aBtbW1nIFxeHh4YoMK6jIyEh07twZFy5cQHWhi9YQQggpWXFxPDCsWpUvh54/Hzh2DKhTR/pzpKUVvB+6rGCMZ9r/+INnvw8d4jcIJJ4940vTV6wAxowpvXkSQgghZZwgy6cZYzJ9EEIIIcXGyCinYFaPHsDt27IFxBMn8iXYJfX/VUYGL1wm62vGj+cB8fjxfPl07oAYAExNebAsawEyWcTGAtu358zp1q3iG4sQQggpJgovn44oaN8WIYQQUtrk2d5jY8MDSrGY788tDiEhwOvXPGg9fBiYOZPvcf7hB+kqYL97x5eGL1jAW2jld50aGsA///DPGeMVu4cP5/vAFZWQwJelr1/Ps+pdugAbNwJbt/IMtYmJ4mMQQgghJUTh5dMVAS2fJoQQki/GiqcHcpcuwKtXwIMHPJO9ZAlvO6Wmxitrz5zJq3Z/6cMHXpRMSYkHpvr60o3n7w989x3v6Xz0KKCtLd+8U1J4C65Vq/hchgwBFi3irbSionimuF8/+c5NCCGElBKqPk0IIYTk5/JlvvT440dhzicW86ASAPbv5y2tVFR4OyovLyA8nBcjO3AAaNAAcHICLl7MWcb98SPQqhUwezb/WtqAGAAcHHhPaT8/Hhy/fSvb3NPSeCbY3Bz49Vf+fblzh/d5trTkx1SrlhMQJybKdn5CCCGkFFFQTAghhOSnUiXe5mn8eMX3F6ek8H3KffsCWVl8efGXS4ytrXnF7Fev+JLowECgc2feZursWZ4hHjxY/kzs+PHAiRM8O922Lb+2x49zPj5/5sd9+MC/lrTPcnfnge/06XyO167xIL5Jk/zHOX4cqFWLn4MQQggpBygoJoQQQvLTujWwbBlfbrx1q/znefWKZ1Y9PXnhL6Ui/us1MgIWLgRevuRFrD5/5hW1RSJg8WIe0MqrVy+efY6P5y2cLC1zPsLC+DGHDvGv373jX9+/z/c5+/oCly4BbdoUPoa9Pf9zzBh+A4AQQggp4yrcnuJOnTohKioq3+cMDQ1x7dq1rx6nPcWEEELyJRbnBJIBAQVnRwty9SrQvz9ffnzoEA+K5ZkDY8IW/Xr9mi8Pz61HD8DAgGd4b93i89bQ4HNXVZVtb/W+fXwp+Nq1wIwZss1NLM65cRAaCjRqJNvrCSGEEBkpXH26LNLR0cGoUaO+elzzy3YVhBBCSGGUlIC9e3kwPHgwEBQE6OhI99qdO4EpU4DatYFTp/jSY3nnILQaNYBhw/J/zsKCf0jI0695xAieYf/1V743WrLvuCipqYCLC9ChA28xNWUKr9Rtayv7HEj5kJ7Ob7oQQkgpqpBBceXKleHq6lra0yCEEFIRGBkBHh5Ap07AyJHA99/zytBNm/I39EeP8n2/1tZ8P+7ZszxDvGULrzJ9+LBsRbEqApGI749u2BAYPRq4cqXoTHd8PNC7N3D9Oi8GNmgQz1JbWZXIlEkpOHwY+PtvXgBOnpsvhBAiENpTTAghhBSlY0feNunECZ5hPXSIP56Swr/28eFfR0Xxr7dsAX78kQfI31pALGFqyts33bjB+xkX5vVroH17Xlzs0CFe1Etfn/9JwVLFlJQETJvGl8sL0TubEEIUUCEzxenp6Th58iSio6OhoaEBKysrtGjRAspC7scihBDybfn1V2D4cF74ShLoVq4MPHzIs8kAUK8e/1pTE6AaFfwGwb//AvPn873Z+WV9Hzzg/ZOTkgBvb54lzu3kSWDzZuDMGd7CilQMy5bxYm6nT/Of/aZNwJw5wu6dJ4QQKVXI/13i4uIwW9LH8f+qV6+O5cuXo2XLlqU0K0IIIeVezZp5v1ZWzrtfVk1N+v2z3wKRiFfubtgQcHXlFaxzu3KFL5nW0OCFvxo3/vocYjF/3c6dwKRJJTNvUryePOFF2EaO5L23PTyABQv4igxFqqsTQoicKlxQ3L9/f9jZ2cHCwgJaWlp4/fo1Dhw4gCNHjmDChAk4fPgwrAsodrJ+/Xpoa2sDACZOnAgA2L59e/bzDg4OcHBwwJo1a5CUlAQAMDU1xaRJk+Dl5YXg4ODsY2fNmoU3b97g4MGD2Y85OzvDzs4Obm5u2Y9ZWlrCxcUFHh4eePToUfbjbm5uCA4OhpeXV/ZjQ4cOhZmZGdasWZP9mJ2dHZydnbFt2zZER0cD4IXGZs2aBX9/f/j7+2cfS9dE10TXRNdE10TXVOLXdOoUonv1AgwMoLNmTc41bdkCHDsG6OlhoqcnYGSE7bnGz76mp0+RVLMmMHMmTD9/xqQffyz9a6qIP6eSvKbevXlFdUNDOAcHw27oULhdvw6cPw+c8oWJcAAAIABJREFUP18+r6ki/pzomuiaKuA15T5PbhWuJVNBVq5ciV27dsHR0RGbNm3K8xy1ZCKEEEJKAGPAx488w25uzj9OnwaqVCn8dYGBQMuWwG+/AUuXlsxcSfHw9eXL5ZcvB+bO/fp5b2/Azi5nSwIhhJSAb6bQ1pAhQwAAQUFBpTwTQggh5Bs1ahTQvTvfc33hAv8oKiAGgBYteKumNWt4Ua7yJCuL931+/px//i3LyAB++onfDMmvf3VMDNCvH/97IhaX/PwIId+sbyYoNjAwAAB8+vSplGdCCCGEfKOcnXnxLZEIsLHhwbG0li3jmeb584tvfkJjDBg7lu+brVsX0NICGjUC+vcH9uzJOS4+nh9b0W3eDISH8/3E+VUVNzHhNz7OneN/EkJICalwe4oLEhISAgCoUaNGKc+EEEII+UZ9/738r61Vi2cZV67k7a6aNZP+tampPJi2seF9kxMTgdWreZa6ShXA0DDn8ypVeFVxkUj+uUrMnw/s2wfMnAk0aAA8esSrk0dE8ErlAO/FbGQEuLkBv/+u+Jhl2aNHfOm0s3PBx0yZAly6xKu9t2sHtG5dcvMjhHyzKlRQ/PTpU5iamkLzizvPkZGRWLJkCQCgd+/epTE1QgghhChq3jxehXrWLODiRekD18xM3tKpUSP+dXQ035tcUHa2USPAywuoXVv+uW7ezLPbEybwALyguWZm8sypJPi7dAlYsYL3eM6vhVV5tmkTkJ5e+M9NJAJ27ACCg4EhQ4CQEOl7fTMGPH3Kq8SrqgozZ0LIN6FCBcVnz57Frl270KJFC5iZmWVXn/b390daWho6duyIsWPHlvY0CSGEECIPXV2eUd26FXj/nmd4C3PiBNC1K6CjA9y5w1s/ATzYzMgAPnzg53n3jv/5/j0QG8uD0tatgZs3v27DJQ3GAD8/3pt58+bCg0AtLZ75loiN5ePa2PAM8/z5wP87Y5Rb4eE8+LexkS5Y1dMDDh/m7ZnGjAE8PQv/HkZFAfv38yXpDx/yQl0nTwLVqgl2CYSQiq1CVZ++desWDh06hLCwMLx79w6pqanQ0dFB/fr10adPH/Tp0weifH6pUvVpQgghpJzIzOQBkrJywcd8+gRMn86zyitXArNnyzbGgwfA9u3AunWAkpzlVzIzeeAtCcRlERsLzJkD7N0LVK/OM8kDB0qfGX/3ju/L9fUF6tQBpk4FjI1ln4dQ+vblgf6LF/nvJS7IunX8xsCGDfzn+SV/f17F+vx5fiOifXvA0RH4809+I+HECb6fWx7p6fxnqKnJ/w5lZPDq50IsqyeElDkVKiiWFwXFhBBCSDnz8SMQFvb1ntPwcGDQIB7Y/vorzyyrKLAw7tUrICiIF8cqSng4MG0az1qamck/psT16zygDQkBOncGNm4E6tfP/9iYGJ4pPX0auHGDV282NOTZ70qVgOHDeYDZsKHi85JVfDz/WbVrJ9vrGOMB9blz/HthZ8f/rFePB/mHDvG2TqNGASNH8qrWABAaCvTuDbx5w5dhy3rNmZlAhw6AhQX/no4ezfeGDxoE7N4tW4G4iooxnsV/+ZJ/TxTZakBIGfDNVJ8mhBBCSAUydiwPmNLSch7btw9o3pxnWr29+b5hRQJiAFi8GBg/HkhIKPrYN294EP35s2JjSrRpwwPyTZt4cGdry7PeKSm8vdP588Dt2/zY+Hi+51pSVCwwkH8fIiKAceOAgwd5JlWouUkjLY3P08BA9oAY4FnZ3bt5S67MTN7Wql27nMrdAwcCz54BixblBMQA3xMeGAgsWcILnMlKRYW3hnJ25nPYs4dni//9l38Py1tbsOJw/DhfyXDlCmBvz/9OElKOUaYYlCkmhBBCyp2wMB50NW3K35C7uvIAqmNHwMNDmEwtwIPIhw+Bxo1zCnN9uYRWLM5ZZp2RwTOzQouL41lRHx+ekdbU5NlSZ2d+3YzxAmIFXff798Ddu0CnTny+gwfzDKiTk/BzlXBzA06d4oGTlpb852Es53vu5QV8951s+6wfPeKB85YtvLJ4ftLT+ZJ1Jye+BDs/Z84AQ4fy772n57dbGfvDB75iwdSUZ+vv3eM3KAB+E6SwrQ2ElFGUKSaEEEJI+dOgAQ+Iw8J4dnjPHt7SyM9PuIAYANTVeUAM8CrSo0bxwFciPR3o3p1nc4HiCYgB3rZp505+vTo6PPDw88sZVyQq/LqrVOEBMcCXWkdE5GS/k5L4Y0J6+ZJnVy0tFQuIgbw3IZydZS88FhzMq3rHx+f/vCQDvX49cPVqwedxcgICAvj4Dg55e01/S+bMAd6+5VXCLS1zAuIjR3jWODa2dOdHiBwoKCaEEEJI+bVmDS/g5OvLlzoruly6MBkZfL+wszOQnMwzrmPG8GXMOjrFN25uuTOdTZrIt7/VzIxn94YO5V9v3syzfubmwIgR/Os7d/iSZXn98gsPZv/8U/5zCGXoUODxY77vVSzme7QlPD35zZVHj4Bjx3h2uzANGvCiYe3a8Z/9rFk8O/qtuHyZF6GbMYPv8c5NXR2oWpUvlyeknKHl06Dl04QQQki59fAhz4IW1Z5JKLt3897DTZrwysabN/MKyHPnlsz4xSEsDDh7lhexun49J9OnpQW0bMn3NrduDXTrxm86ZGbyCt+SAP38eb7PVtLW6s0bfvNg0SJgwYLSu678/P038NNPPOv//DnvB92iBW8BVaeO9OfJyOCFy44c4UG2qals8xCL+TJkSQB55w7fHz1gAP96wwaezV+4EDAxke3cxeXzZ/73Pi2NFzMrbAXAu3f8GubPl63iOCGlhIJiUFBMCCGEEBmcOQN8/z0vajV1Kq8KXVFa9TDGM+83bvAA+cYNvhdZS4svt1ZS4r2fk5L4cwBfXn7vHv9cVZXfpLCz4wGjPC2pilNSEq/EfeoU//qnn/gyb2n6J+cnNpbv7RaL+dLrdu349+jKFf615EbBl/2wExL4a9LS+NjTp/MbCZIl7ZMm8eXZdeoAFy6UjZ7Lu3bxom0+PvzvgDTH2tnxGw65C6ERUgZRUAwKigkhhBAio+Bg4OJFni2s6IWFUlKAJ09y9lYfO8ZvCAwfzr9+9IgHdoaGPHgu6zcIxGK+F7tuXeEKjf3xB8+KxscD+vp85cDKlfymQJUqOasZJJ9Lvp40iS87fvOGf09zB49XrgA9e/Kg++JFoGZNYeYqL8b4nDp0kO74Eyf4EnOxmK+wkKatGSGlhIJiUFBMCCGEEEIUEB3NM+s9e/JAODmZ3yxRNFMeEMALuenr88BYliXeQhGLeSE2eQrYvXgBDBkC3LoFuLvn7GMnpIyhQluEEEIIIYQowtSU7weWBMHa2sIsHbe358unP37kGdrHjxU/p6y2bgWsrPiKAFnVrs2D+Q4deBG3EycEnx4hQqCgmBBCCCGEkLLKzo63lPr8mQeX4eElO36PHnzvtYWFfK/X1OT9pZs35/2xfXyEnR8hAqCgmBBCCCGEkLKscWPgv//456NG8f29xY0x/lGnDrBkiWJ7xXV0gHPneEurvn2B+/eFmychAqCgmBBCCCGEkLKuQQMeGB88KF+AKmsgfewY0KtXTkVsRenr837is2fzayGkDKGgmBBCCCGEkPLA0pJXqBaLgVmzeAGr/DDG9x/v2wdMnswzzW5uOc/5+vLl2AVJSABcXXmBLR0d4eZvZMT7VysrA5GROa28CCllKqU9AUIIIYQQQogM4uN50SpdXaBlS+DTJyAwMKe39I0bvC8ywI+xt8/ZExwSAnTrxtskjR4NfPjAA2QTk5zzz5kDxMXxntwqxRQuDBvGW1GFhxffGIRIif4GEkIIIYQQUp4YGvJe2bq6/GsbG+DZM/65tTXg7Ay0bg20aQPUrw8o5Voc+r/27j0s6jL///gTDyDgAVIURRPBHcLjZYjnA6KuG266HtrsQKZd1W6rleXXrG2vykOWqX0VWrPMkDQP27rp1zW6lpBdIAVDxcxjgCse8ICiKCIJn98fn9+MTYOutjIDw+txXVzA/bkH7pm3g/Oe+77fd3g4bNkCvXub369aZc4K9+plLpdu1w4+/BCmT4d7762++/Dhh3DxohLiW7F5M3z0ESxe7Przqt2UzilG5xSLiIiISC22bp25zLlPH7jrrtu77eHDsH69WSE6K+t6ca29e83K0c7wwQdmlet27Zzz+2qTigrzzYk9e8yzopOSzDdB5I5SUoySYhERERERTp0y9xtHRDivGFZhoXkOcmAg/Otf0KqVc35vbWAYZlG1wkLIzYXf/hYuX4aNG2HwYFePzq2o0JaIiIiIiJgJaWysc6tDBwaay7mPHYMBA+CPfzT3MhcVOW8MNVFCAjz0EFy7Zj5G/fube8XbtIFf/hI++8zVI3QrSopFRERERMR1+vc3E2E/P3j7bXNvc4sW5v7oSZPMfc91zfnzZkG1H3643nb33ZCeDj17mrPG8fGuG5+bUVIsIiIiIiKuFRVlVtC+cAFSU2HePHNZ9ebNsHLl9X6//715hjKYy4uTk2HXLjh61FxaXNt3hhYWmp+nTYMvvgBvb/vrd91l3udRo8wCaS+/XPvvcw2gcm8iIiIiIlIz+Pqa+2Wte2YNw6xSDeZS4sxM8PeHcePM9uHD7W/v5WXOMjdvbp6LPHAgPPCAc5eE/1wLFsCsWbB9uzne+vWr7uftbS6fnjLFLMTl4eHccbohJcUiIiIiIlIzeXhcP3qqQQPYufP6zKi3N/zzn+b+Y+vH2bPXvz52DN54Axo1MpPMkhLYuhWGDXNeZe1bNXcuvPqquSzaeqb0zTRoAEuXXv9+/36zenfjxj/v95eXg6en+fXSpZCRAYcOmQW+unY1z7QeP/7n//waTkmxiIiIiIjUHtaZUU9PGDTo5n3PnLl+TnNSkpl0pqWZRb2OHTPbf3r6jGGYCXRRkTkb3b272f5//2fOQPfrd+fui2HAa6/B7NlmkbMVK2797Gbr41Baas6Y9+njWICrogKKix3fMCguhuefN/s884z52FjPut6yxTwCKiwMxo4133iYNAn+8AczMX78cXMmv5777MRVUiwiIiIiIu4pIOD616NHwz/+YSaPAAsXwv/+r5n0Nm16PWH8cYErb28z6QTzPOisLHNW9kZLm2+HYcDMmTB/PkyebJ7X/HN+ro+PObvbsaP5/aJF8P775n05f/7Ge45jY80k/5e/NIt4WY+A2rjRPuE1DLPydUKC+RgkJsKMGWZRNDehc4rROcUiIiIiInXOoUPw+efw5ZfmfuXmza/vR/7xx/33m8niuXNmIaxOncyiXs89By++COHht/d7S0vhb3+Djz4yl3P//vdmJek7NfP6ySdmNe+f3o8f37cWLcw3Am7XlSvmY9ali7msevt2M0FevhwsljszfhdQUoySYhERERERuQ1paRATYya4jz1mLoEODr6120ZHm8lwcLBZLOuFF2pvsaykJHjlFbNi+M9JsmsI91kILiIiIiIi4gwDB5p7cJ9/HtasMWdJp069fqTSjyUlQbdu5j5eMAtqpaaaRaxefLH2JsQAv/qVWfysFifEoKRYRERERETk9gUEmPuSv//eLES1dCmEhppnBycmQk6O2c+6XPn0afP76Gi3K1RV2ykSIiIiIiIiP1fbtrBsGRw4AL/5jVmAauJEWL3avB4ZCSkptXrPrbtT9WkREREREZH/VseOZiL8pz+ZS6V793b1iOQWKSkWERERERG5U+65x9UjkNuk5dMiIiIiIiJSZykpFhERERERkTpLSbGIiIiIiIjUWUqKRUREREREpM5SUiwiIiIiIiJ1lpJiERERERERqbOUFIuIiIiIiEidpaRYRERERERE6qwGrh5AdSgsLGTx4sWkpaVRXFxMy5YtGTp0KFOmTKFZs2auHp6IiIiIiIjUEG6XFB89epQJEyZQVFTE0KFDCQkJYc+ePSQmJpKWlsaaNWvw9/d39TBFRERERESkBnC7pPiNN96gqKiIV199ldjYWFv7vHnzSEhI4N1332XWrFkuHKGIiIiIiIjUFG61p/jo0aOkp6cTFBTEI488Yndt6tSp+Pj4sGnTJkpLS100QhEREREREalJ3CopzszMBGDAgAHUq2d/1xo3bsy9997LlStXyMnJccXwREREREREpIZxq+XTeXl5AAQHB1d5vX379qSnp5Ofn0/fvn1t7RUVFYBZoEtERERERETcT2BgIA0aOKbAbpUUX7p0CYAmTZpUed3aXlJSYtd+5swZAIcl1yIiIiIiIuIevvrqK9q2bevQ7lZJ8c/VpUsXVq9eTUBAAPXr13f1cEREREREROQOCwwMrLLdrZLixo0bA44zwVbW9p/OJDdq1IiePXtW7+BERERERESkxnGrQlshISEAHDlypMrr//73vwHo0KGDs4YkIiIiIiIiNZhbJcW9e/cGID09ncrKSrtrly5dYufOnXh7e9O9e3dXDE9ERERERERqGLdaPn333XczYMAA0tPTWb16NbGxsbZrcXFxlJaW8uCDD+Lj4+PCUd66wsJCFi9eTFpaGsXFxbRs2ZKhQ4cyZcoUmjVr5urhua2kpCR27NjB/v37OXDgAJcvX+b+++9nwYIFN7zNzp07Wbp0KTk5OZSVldG+fXvGjRtHbGys9qnfAefPnyc5OZnU1FQOHTrEqVOnaNiwIRaLhbFjxzJu3DiHY9hAcalu77zzDnv37uXIkSOcP3+eRo0a0aZNG4YNG8YjjzyCv7+/w20UE+fbuHEjM2bMAGDOnDk88MADDn22bt3KihUr2LdvH5WVlXTs2JGHH36YMWPGOHu4bik6Oprjx49Xea1FixZkZGQ4tOu54jzbtm1j1apV7N69mwsXLuDn50dYWBiPPfYYgwcPtuuruFSfDRs28PLLL9+0T7169di/f79dm2JS/VJTU0lMTOT777+nuLiYgIAAOnfuzKRJk+jRo4dD/9oYEw/DMAxXD+JOOnr0KBMmTKCoqIihQ4cSGhpKTk4OmZmZBAcHs3bt2ipfqNU0P70fISEh7Nmzh8zMTDp06MCaNWtqxf2ojUaPHs2BAwfw8fEhMDCQvLy8mybFycnJPPvss3h5eXHffffRrFkztm7dSn5+PiNGjGDJkiVOvgfuZ82aNbz++usEBATQu3dv2rRpw9mzZ/nHP/5BSUkJI0aMYPHixXh4eNhuo7hUvy5dutCpUydCQ0Np3rw5V65cYffu3ezdu5eWLVuyfv16WrdubeuvmDjfyZMnuf/++6moqKC0tLTKpHjVqlXMnj0bPz8/YmJiaNiwIV9++SWFhYVMnjyZl156yUWjdx/R0dFcvHiRiRMnOlzz8fHhiSeesGvTc8V55s+fz0cffURgYCCDBg3C39+fc+fO8d1339G3b1/bG0qguFS3/fv3k5ycXOW1b775hu3btxMVFcWyZcts7YpJ9XvnnXdYvnw5fn5+DBs2DH9/f44ePUpKSgrXrl3j7bffZvTo0bb+tTYmhhs6ceKEMXPmTKN///5G586djaioKGPOnDlGcXGxq4d2yyZPnmxYLBYjMTHRrv3NN980LBaL8ac//clFI3N/27ZtM/Lz843Kykpj+/bthsViMV588cUq+5aUlBh9+vQxOnfubOzZs8fWXlZWZjz44IOGxWIxNm/e7Kyhu62vv/7a+Oqrr4yKigq79tOnTxuDBw82LBaLkZSUZGtXXJyjrKysyvZFixYZFovFeO2112xtionzVVZWGhMnTjSGDh1qvPXWW4bFYjHWr19v16egoMDo0qWL0atXL6OgoMDWXlxcbAwbNsywWCzGzp07nT10tzNkyBBjyJAht9RXzxXnWbdunWGxWIyXXnrJuHr1qsP18vJy29eKi2v99re/NSwWi5GcnGxrU0yq3+nTp4177rnH6Nevn3H27Fm7a9u2bTMsFosRHR1ta6vNMXGrPcVWrVu3Zt68eaSnp7N37162bt3KH//4x1qz5Pjo0aOkp6cTFBTkcHby1KlT8fHxYdOmTZSWlrpohO6tT58+BAcH28063khSUhLnzp1j5MiRdO3a1dbu5eXFc889B5iznPLf6du3L9HR0Q5LpAMCApgwYQIAWVlZtnbFxTm8vLyqbL/vvvuA68UNQTFxhcTERLZv3868efNuuG3or3/9K+Xl5TzyyCN25zY2a9aMp59+GoC1a9c6Zbxi0nPFOcrLy3n33Xdp06YNs2bNwtPT06FPw4YNbV8rLq5z8OBBdu/eTatWrYiKirK1KybV78SJE1RWVtKtWzeaN29ud61Pnz74+vpy7tw5W1ttjolbJsW1XWZmJgADBgxwSAIaN27Mvffey5UrV8jJyXHF8ORHtm/fDsDAgQMdrkVGRuLt7c2uXbsoLy939tDqjAYNzNIIP96jori4VkpKCgBhYWG2NsXEuXJzc1m4cCGPPfYYkZGRN+x3s7gMGjTIro/8d8rLy9m4cSPvv/8+K1euZPv27VRUVDj003PFOTIyMjh37hzDhw+nXr16pKam8sEHH7By5Up27drl0F9xcZ3169cDMH78eP1f72Tt27enYcOGfPvtt3bJL8COHTu4fPky/fr1s7XV5pi4VaEtd5GXlwdAcHBwldfbt29Peno6+fn59O3b14kjk5/Kz88Hqo5VgwYNaNu2LYcPH6agoIDQ0FAnj879Xbt2jY0bNwL2f4AVF+f66KOPKC0tpaSkhL1795KdnU1YWBhPPfWUrY9i4jzXrl3jf/7nf2jdujUvvPDCTfveLC4tW7bEx8eHwsJCrly5gre3d3UMt844c+aM3f5UgLZt2zJv3jx69epla9NzxTm+/fZbwJzBGjNmDIcOHbK7HhkZyZIlS7jrrrsAxcVVysrK2LRpE/Xr13eoh6CYVD8/Pz+mT5/OW2+9xciRIxk2bBh+fn62PcX9+/dn1qxZtv61OSZKimugS5cuAdCkSZMqr1vbS0pKnDYmqdp/ilXjxo0BuHjxotPGVJcsXLiQQ4cOMXjwYLukWHFxrhUrVnD27Fnb9wMHDuStt96yvZgExcSZ3nvvPfbv38+nn35Ko0aNbtr3VuJifcNDSfHPN3bsWCIiIvjFL36Br68vBQUFrFq1ivXr1/Pkk0+ybt067rnnHkDPFWcpKioCzDf1QkNDWb16NeHh4Rw7doz58+eTnp7Oc889xyeffAIoLq7yxRdfcPHiRaKiouwKN4Ji4iyPP/44bdu25ZVXXrHN2oM5STdmzBi7ZdW1OSZaPi0itVJiYiIrVqwgJCSE+fPnu3o4dVpGRgYHDx4kIyOD+Ph4CgoK+M1vfsN3333n6qHVOTk5OSxbtuyGx2SIa0yZMoW+ffvSokULvL29sVgszJo1i0mTJlFWVkZcXJyrh1jnGP//8JX69euzdOlSevbsia+vL2FhYcTHxxMYGEhWVlaVS6nFedatWwfAgw8+6OKR1F0ffvghzz77LGPGjCE5OZndu3ezYcMG2rVrx/Tp093mNZiS4hrI+i7KjWaCre03ehdGnOc/xcr6jlnTpk2dNqa6YNWqVcydO5eOHTuSmJiIn5+f3XXFxTVatGjB8OHDWbFiBcXFxXZH+Sgm1e/atWvMmDGD4OBgnn/++Vu6za3GRf/fVA9rocBvvvnG1qbninNY/0136tTJrsgcgLe3NwMGDABgz549gOLiCocPH2bXrl0EBgY6nBcNiokzZGZmsmDBAqKjo3n55Zdp164d3t7edO7cmfj4eFq1asXHH39MQUEBULtjoqS4BgoJCQHgyJEjVV63VnTt0KGDs4YkN2CNQVWxunbtGseOHaNBgwa0a9fOySNzXwkJCcyePRuLxUJiYiIBAQEOfRQX1woKCqJjx44cPnzYVphDMal+paWlHDlyhNzcXLp27UpYWJjtIz4+HoBXX32VsLAw5s6dC9w8LqdPn6a0tJTAwEAtna4m1i0GPz5NQs8V57A+zjd6w8f6ov3q1at2/RUX57HOEv+0wJaVYlL9UlNTAejdu7fDNW9vb7p160ZlZSX79u0DandMlBTXQNZ/eOnp6VRWVtpdu3TpEjt37sTb25vu3bu7YnjyI3369AEgLS3N4dqOHTu4cuUKPXr0qPKoB7l9H3zwAfPmzSM8PJyVK1c6HA9gpbi43unTp4HrVcEVk+rn6enJ+PHjq/zo1KkTABEREYwfP962tPpmcfnXv/5l10fuvN27dwPYvUDUc8U5+vbti4eHB7m5uQ6vtcCcpQRss8iKi3NdvXrVVmBr/PjxVfZRTKqftUr0TytPW1nbrceX1eaYKCmuge6++24GDBjA8ePHWb16td21uLg4SktLGTVq1A3PnRTn+dWvfoW/vz9///vfbZUswfxjvnjxYgAeeughVw3Prbz33nssXLiQzp07k5CQYFfE6acUl+qXn59f5fKoyspK3n33XYqKiujRo4ftfHjFpPo1atSIuXPnVvkRHR0NwJgxY5g7dy4xMTGAWQDK09OT1atXc+zYMdvPunDhAsuWLQOuL/GVnyc3N9duJtjq2LFjzJ49G4BRo0bZ2vVccY6goCCGDBnCiRMnSExMtLuWnp5Oeno6TZs2tRVxVFyc64svvuDChQsMGjTIocCWlWJS/SIiIgDzWKxTp07ZXfvnP//Jzp078fLysr3RWptj4mFYKw1IjXL06FEmTJhAUVERQ4cOJTQ0lJycHDIzMwkODmbt2rX4+/u7ephuKTk5meTkZMA8QiM9PZ127drRs2dPAPz9/e32SiYnJ/Pss8/i5eVFTEwMzZo1IyUlhfz8fEaMGMHixYvx8PBwyX1xF3/729+YOXMm9evX59FHH61yuVtQUBBjx461fa+4VK+EhAQWLVpEREQEbdu2xc/Pj7Nnz7Jjxw4KCgoICAggISGBjh072m6jmLhOXFwc8fHxzJkzx+FYk08++YQ5c+bg5+dHTEwMDRs25Msvv6SwsJDJkyfb/b2T2xcXF8eKFSuIjIykTZs2turTqampXL0hUEbiAAAHT0lEQVR6lcGDBxMfH283c6LninMUFhYyYcIETp48Sd++fQkPD+f48eMkJyfj4eHBokWLGDFihK2/4uI8Dz/8MNnZ2SxdutT2pl5VFJPqVVlZyRNPPMHXX3+Nr68vw4cPp0WLFuTm5pKamophGLzyyitMnDjRdpvaGhMlxTXYyZMnWbJkCWlpaRQXFxMQEMCwYcOYMmWKbfZF7jzri8cbCQoKIiUlxa4tOzub999/n927d3P16lXat2/PuHHjiI2NrXIfjNye/xQTgF69etmOzrBSXKrPoUOHWLt2LdnZ2RQWFtqO7AkODiYqKorY2FiHAmigmLjKzZJigJSUFFasWMF3332HYRiEhoby6KOPMmbMGBeM1r1kZWWxdu1a9u3bx9mzZ7ly5QpNmjQhPDyc0aNHM3r06CpfIOq54hznzp3jvffeIyUlhTNnzuDr60vPnj15+umn6datm0N/xaX65ebmEhMTQ2BgICkpKf/xcVVMqtcPP/zA6tWr2bJlC99//z1lZWU0a9aMbt26ERsbaytK92O1MSZKikVERERERKTO0p5iERERERERqbOUFIuIiIiIiEidpaRYRERERERE6iwlxSIiIiIiIlJnKSkWERERERGROktJsYiIiIiIiNRZSopFRERERESkzlJSLCIiIv+VuLg4wsLCyMzMdPVQREREblsDVw9ARESkrgsLC/uPfRITE+ndu7cTRiMiIlK3KCkWERGpIaZMmXLDa0FBQU4ciYiISN2hpFhERKSGmDp1qquHICIiUucoKRYREall4uLiiI+PJzExkRMnTrBy5Ury8vLw9fUlKiqKF154gYCAAIfbHTlyhD//+c9s27aN8+fP4+fnR79+/XjmmWcIDg526F9RUcH69evZuHEjhw8f5ocffqBVq1b06tWLJ598ssrbJCUlsXz5cg4fPoyXlxf9+/dn5syZtGrVqhoeCRERkf+ekmIREZFaKiEhgYyMDGJiYhg4cCDZ2dls2LCBrKws/vKXv3DXXXfZ+u7Zs4dJkyZx+fJloqOj6dixI3l5eWzatImvvvqKjz/+mG7dutn6l5eX87vf/Y6MjAxat27Nr3/9axo3bszx48dJTk4mIiLCISn+9NNPSUlJITo6msjISPbs2cOWLVs4cOAAGzduxNPT01kPjYiIyC1TUiwiIlJDxMXFVdnu5eXFU0895dCelpbG+vXr6dSpk63tzTffZOXKlSxYsIA333wTAMMweOmll7h06RLvvPMOo0aNsvXfsmUL06ZNY8aMGWzZsoV69cyDKeLj48nIyGDIkCEsWbLELqEtLy/n0qVLVY7ns88+sysc9uKLL7J582aSk5OJiYm5zUdERESk+ikpFhERqSHi4+OrbG/SpEmVSfGoUaPsEmIw9yVv2LCBzZs38/rrr+Pp6cnOnTvJy8ujR48edgkxQExMDKtWrSI7O5vs7GwiIyOpqKjg008/pVGjRrzxxhsOM7yenp52s9BWsbGxDpW0H3jgATZv3sy3336rpFhERGokJcUiIiI1xMGDB2+rf69evRzamjRpQnh4OFlZWeTm5hIeHs6+ffsAbnikU58+fcjOzmbfvn1ERkaSl5dHSUkJ3bt3v629wF27dnVoa926NQAXLly45Z8jIiLiTPVcPQARERH5eZo3b15le4sWLQAoKSmx+9yyZcsq+1uLcln7Xbx4EeC2i2M1adLEoa1+/foAVFZW3tbPEhERcRYlxSIiIrVUUVFRle1nz54Friep1s9nzpypsr+1vXHjxgA0bdoUgFOnTt25wYqIiNRQSopFRERqqaysLIe2kpIS9u/fj5eXF6GhoQCEh4ffsD9AZmYmAJ07dwYgJCSEpk2bcvDgQSXGIiLi9pQUi4iI1FKbNm2y7Re2iouLo6SkhJEjR9oKZEVERNChQweys7NJSkqy65+UlMQ333xDcHAwERERgLnk+eGHH6asrIzXXnuN8vJyu9uUl5dz7ty5arxnIiIizqNCWyIiIjXEjY5kAhg2bJhtxtdq4MCBPPTQQ9x3330EBATYKkgHBQUxffp0Wz8PDw/efvttJk2axLRp09i8eTMhISHk5+eTnJyMr68v8+fPtx3HBPCHP/yBnJwctm7dyogRI4iKisLX15eTJ0+SkZHBjBkzGDt27J1/EERERJxMSbGIiEgNcaMjmQCCgoIckuLHH3+c4cOHs3LlSrZs2YKPjw9jx45l2rRpDkW4unfvzmeffcbSpUvZtm0bW7duxd/fn5EjR/LMM88QEhJi19/T05Ply5ezdu1aPv/8cz7//HMMw6Bly5YMHz7cNqssIiJS23kYhmG4ehAiIiJy6+Li4oiPjycxMfGGxyyJiIjIrdGeYhEREREREamzlBSLiIiIiIhInaWkWEREREREROos7SkWERERERGROkszxSIiIiIiIlJnKSkWERERERGROktJsYiIiIiIiNRZSopFRERERESkzlJSLCIiIiIiInWWkmIRERERERGps/4fFW4w4UoZ1jEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fa8c80860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "\n",
    "gs = gridspec.GridSpec(2,1)\n",
    "gs.update(hspace=0.5)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "fig1 = fig.add_subplot(gs[0,0])\n",
    "fig2 = fig.add_subplot(gs[1,0])\n",
    "fig1.spines['right'].set_visible(False)\n",
    "fig1.spines['top'].set_visible(False)\n",
    "# for item in [fig1.xaxis.label, fig1.yaxis.label,fig2.xaxis.label, fig2.yaxis.label]:\n",
    "#     item.set_fontsize(10)\n",
    "\n",
    "\n",
    "# fig1.plot([i * 0.005 for i in range(1,len(train_data['loss_hist'])+1)],train_data['loss_hist'],color='black')\n",
    "fig1.plot([i * 0.005 for i in range(1,len(train_data['val_loss_hist'])+1)],train_data['val_loss_hist'],color='red')\n",
    "fig1.set(title= 'Loss trajectory of training',ylabel='Loss',xlabel='Iter.(1e4)',ylim=(0,0.4))\n",
    "\n",
    "fig2.plot([100-i for i in train_data['train_acc_hist']], color='red',linestyle='-.',label = 'train')\n",
    "fig2.plot([100-i for i in train_data['val_acc_hist']], color='green',linestyle='-',label='val')\n",
    "fig2.legend(frameon=True)\n",
    "fig2.spines['right'].set_visible(False)\n",
    "fig2.spines['top'].set_visible(False)\n",
    "fig2.axhline(y=[5],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "fig2.axhline(y=[10],alpha=0.5, linestyle='--',color='k',linewidth=1)\n",
    "_=fig2.set(title= 'Top-1 Accuracy of Resnet18',ylim=(0,20),xlabel='Epoch',ylabel='Error(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.cuda.DoubleTensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = torch.cat((out.data,out.data),1)\n",
    "out1.size()\n",
    "# out\n",
    "criterion(out,y.long())\n",
    "type(predicted)\n",
    "type(y.data)\n",
    "#predicted.eq(y.data).cpu().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n"
     ]
    }
   ],
   "source": [
    "net = cnn.plain_cnn(num_classes=2)\n",
    "net.load_state_dict(torch.load('save_cnn_loss20_1.pth'))\n",
    "net.cuda()\n",
    "\n",
    "test = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test)\n",
    "test_X.shape \n",
    "fake_label = np.zeros(len(test_X))\n",
    "\n",
    "test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "prob = [] \n",
    "net.eval()\n",
    "for k, (val_x, val_y) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    x = Variable(val_x)\n",
    "    y = Variable(val_y)\n",
    "    out = net(x)\n",
    "    #prevent overflow\n",
    "    temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "    ans= temp[:,1]/(temp.sum(axis=1))\n",
    "    prob.append(ans)\n",
    "    #print(out.size())\n",
    "    progress_bar(k, len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k =np.stack(result).mean(axis=0)\n",
    "# #sub.shapesub.to_csv('submission2.csv',index=False)\n",
    "# result[1].shape\n",
    "# np.concatenate(prob).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['is_iceberg'] =  np.concatenate(prob)\n",
    "sub.shape\n",
    "sub.to_csv('submissioniu.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg</th>\n",
       "      <th>is_iceberg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg2</th>\n",
       "      <td>0.886197</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_iceberg  is_iceberg2\n",
       "is_iceberg     1.000000     0.886197\n",
       "is_iceberg2    0.886197     1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp= pd.read_csv('submission3.csv') #0.0001 wd one\n",
    "sub['is_iceberg2'] = temp['is_iceberg']\n",
    "sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.607 | Acc: 67.704% (3981/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.527 | Acc: 77.627% (229/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.503 | Acc: 75.884% (4462/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.474 | Acc: 77.966% (230/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.461 | Acc: 78.435% (4612/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.351 | Acc: 85.085% (251/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.450 | Acc: 79.048% (4648/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.332 | Acc: 84.407% (249/295)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.424 | Acc: 80.391% (4727/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.343 | Acc: 82.712% (244/295)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.412 | Acc: 80.527% (4735/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.375 | Acc: 84.746% (250/295)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.404 | Acc: 81.480% (4791/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.341 | Acc: 83.051% (245/295)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.387 | Acc: 81.735% (4806/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.316 | Acc: 85.085% (251/295)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.377 | Acc: 82.432% (4847/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 86.780% (256/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.365 | Acc: 83.180% (4891/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 86.102% (254/295)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.350 | Acc: 83.980% (4938/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.537% (4912/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 90.169% (266/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.344 | Acc: 83.605% (4916/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 90.847% (268/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.339 | Acc: 84.167% (4949/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.334 | Acc: 85.119% (5005/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 87.797% (259/295)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.334 | Acc: 84.150% (4948/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.334 | Acc: 84.133% (4947/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.329 | Acc: 84.558% (4972/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.240 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.323% (5017/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.318 | Acc: 85.034% (5000/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.102% (5004/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.315 | Acc: 82.373% (243/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.300 | Acc: 86.156% (5066/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.309 | Acc: 85.680% (5038/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.298 | Acc: 86.003% (5057/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.296 | Acc: 86.531% (5088/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.292 | Acc: 86.514% (5087/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 87.797% (259/295)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.294 | Acc: 86.207% (5069/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.284 | Acc: 86.582% (5091/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.292 | Acc: 86.667% (5096/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.315 | Acc: 86.102% (254/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.292 | Acc: 87.109% (5122/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.342 | Acc: 84.746% (250/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.280 | Acc: 87.024% (5117/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.284 | Acc: 87.458% (258/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.275 | Acc: 87.398% (5139/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 87.534% (5147/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 87.891% (5168/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.274 | Acc: 87.432% (5141/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.315 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.269 | Acc: 88.452% (5201/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.269 | Acc: 88.129% (5182/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:38\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.242 | Acc: 89.745% (5277/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 91.186% (269/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.226 | Acc: 90.374% (5314/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 91.525% (270/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.220 | Acc: 90.510% (5322/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 90.169% (266/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.217 | Acc: 90.510% (5322/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 91.186% (269/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.214 | Acc: 90.442% (5318/5880)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 91.864% (271/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.212 | Acc: 90.884% (5344/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.216 | Acc: 90.408% (5316/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.209 | Acc: 91.054% (5354/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.186% (269/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.200 | Acc: 91.412% (5375/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.209 | Acc: 91.497% (5380/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 91.525% (270/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.203 | Acc: 91.207% (5363/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.205 | Acc: 91.310% (5369/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.199 | Acc: 91.650% (5389/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.204 | Acc: 91.361% (5372/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 91.186% (269/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.194 | Acc: 91.871% (5402/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 92.203% (272/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.198 | Acc: 91.531% (5382/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.191 | Acc: 91.956% (5407/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.189 | Acc: 91.871% (5402/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.196 | Acc: 91.633% (5388/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 91.973% (5408/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.194 | Acc: 91.735% (5394/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.183 | Acc: 92.381% (5432/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.187 | Acc: 91.956% (5407/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.186 | Acc: 92.245% (5424/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.181 | Acc: 92.551% (5442/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.109% (5416/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.184 | Acc: 92.500% (5439/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.178 | Acc: 92.296% (5427/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.175 | Acc: 92.262% (5425/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.313% (5428/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.058% (5413/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 92.542% (273/295)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.179 | Acc: 92.279% (5426/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.172 | Acc: 92.891% (5462/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.168 | Acc: 93.180% (5479/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 92.881% (274/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.738% (5453/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.166 | Acc: 93.078% (5473/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.156 | Acc: 93.605% (5504/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.401% (5492/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.163 | Acc: 93.197% (5480/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.159 | Acc: 93.401% (5492/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.160 | Acc: 93.503% (5498/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.160 | Acc: 93.214% (5481/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.161 | Acc: 93.571% (5502/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.152 | Acc: 93.656% (5507/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.152 | Acc: 93.622% (5505/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.157 | Acc: 93.163% (5478/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 93.220% (275/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.149 | Acc: 93.724% (5511/5880)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.160 | Acc: 93.265% (5484/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.148 | Acc: 93.912% (5522/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.153 | Acc: 93.503% (5498/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.142 | Acc: 94.031% (5529/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.145 | Acc: 94.048% (5530/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.140 | Acc: 94.456% (5554/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.148 | Acc: 94.048% (5530/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.143 | Acc: 94.133% (5535/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.143 | Acc: 94.065% (5531/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.274 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.138 | Acc: 94.286% (5544/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.309 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:95\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.135 | Acc: 94.864% (5578/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.130 | Acc: 94.745% (5571/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.141 | Acc: 94.184% (5538/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.135 | Acc: 94.881% (5579/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:99\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.132 | Acc: 94.558% (5560/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:100\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.115 | Acc: 95.425% (5611/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:101\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.115 | Acc: 95.442% (5612/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:102\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.110 | Acc: 95.714% (5628/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 93.220% (275/295)\n",
      "\n",
      "This is epoch:103\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.104 | Acc: 95.935% (5641/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.604 | Acc: 67.500% (3969/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.475 | Acc: 78.983% (233/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.508 | Acc: 75.510% (4440/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.427 | Acc: 80.000% (236/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.486 | Acc: 76.463% (4496/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.387 | Acc: 83.051% (245/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.452 | Acc: 78.724% (4629/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.370 | Acc: 82.373% (243/295)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.433 | Acc: 80.425% (4729/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.341 | Acc: 86.441% (255/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.419 | Acc: 80.833% (4753/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.349 | Acc: 85.763% (253/295)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.419 | Acc: 80.731% (4747/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.337 | Acc: 85.424% (252/295)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.396 | Acc: 81.667% (4802/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.321 | Acc: 85.085% (251/295)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.383 | Acc: 82.177% (4832/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 86.780% (256/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.377 | Acc: 82.636% (4859/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.323 | Acc: 85.763% (253/295)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.373 | Acc: 83.027% (4882/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.295 | Acc: 88.475% (261/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.361 | Acc: 83.350% (4901/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 89.153% (263/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.355 | Acc: 83.861% (4931/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.349 | Acc: 84.422% (4964/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 89.492% (264/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.339 | Acc: 84.184% (4950/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 89.831% (265/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.330 | Acc: 85.068% (5002/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.240 | Acc: 90.508% (267/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.333 | Acc: 84.847% (4989/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.381 | Acc: 83.729% (247/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.324 | Acc: 86.122% (5064/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.310 | Acc: 85.935% (5053/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.316 | Acc: 85.782% (5044/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 90.847% (268/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.309 | Acc: 86.173% (5067/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 87.797% (259/295)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.310 | Acc: 86.327% (5076/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.186% (269/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.300 | Acc: 86.224% (5070/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.292 | Acc: 86.837% (5106/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 86.820% (5105/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.294 | Acc: 86.684% (5097/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.344 | Acc: 87.119% (257/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.285 | Acc: 87.296% (5133/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 91.525% (270/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.282 | Acc: 87.160% (5125/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.281 | Acc: 87.313% (5134/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.280 | Acc: 87.721% (5158/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.251 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.278 | Acc: 87.466% (5143/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 93.220% (275/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.284 | Acc: 87.109% (5122/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 89.153% (263/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.007% (5116/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 88.095% (5180/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.274 | Acc: 87.874% (5167/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.263 | Acc: 88.350% (5195/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.207 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.266 | Acc: 88.180% (5185/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 87.119% (257/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.275 | Acc: 88.282% (5191/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 87.619% (5152/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.265 | Acc: 88.503% (5204/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.259 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.263 | Acc: 88.418% (5199/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.946% (5230/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 90.169% (266/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.259 | Acc: 88.537% (5206/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.336 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.247 | Acc: 89.524% (5264/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 3s|Loss: 0.256 | Acc: 88.707% (5216/5880)96)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 3s|Loss: 0.249 | Acc: 88.793% (5221/5880)60)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.299 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 3s|Loss: 0.247 | Acc: 89.320% (5252/5880)28)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 3s|Loss: 0.258 | Acc: 88.827% (5223/5880)56)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:49\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.232 | Acc: 89.966% (5290/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.206 | Acc: 91.412% (5375/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 92.203% (272/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.202 | Acc: 91.412% (5375/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.192 | Acc: 91.854% (5401/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.195 | Acc: 91.973% (5408/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.193 | Acc: 91.769% (5396/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.193 | Acc: 91.565% (5384/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.187 | Acc: 92.211% (5422/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.177 | Acc: 92.228% (5423/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.187 | Acc: 91.837% (5400/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.177 | Acc: 92.415% (5434/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.483% (5438/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.174 | Acc: 92.347% (5430/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.180 | Acc: 92.262% (5425/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.687% (5450/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.166 | Acc: 93.316% (5487/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:65\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.169 | Acc: 92.755% (5454/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.166 | Acc: 92.823% (5458/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 92.203% (272/295)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.156 | Acc: 93.605% (5504/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 92.881% (274/295)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.154 | Acc: 93.435% (5494/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.164 | Acc: 93.367% (5490/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 92.542% (273/295)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.153 | Acc: 93.367% (5490/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.611 | Acc: 67.630% (3980/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.441 | Acc: 82.653% (243/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.515 | Acc: 74.511% (4385/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.395 | Acc: 86.395% (254/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.477 | Acc: 77.264% (4547/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.318 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.455 | Acc: 79.065% (4653/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.373 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.439 | Acc: 78.980% (4648/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.340 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.412 | Acc: 80.527% (4739/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.318 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.401 | Acc: 80.816% (4756/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.288 | Acc: 87.755% (258/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.394 | Acc: 81.393% (4790/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.382 | Acc: 82.073% (4830/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.375 | Acc: 82.192% (4837/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.318 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.361 | Acc: 83.568% (4918/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.352 | Acc: 83.381% (4907/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 88.776% (261/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.349 | Acc: 83.161% (4894/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 90.476% (266/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.347 | Acc: 83.908% (4938/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.339 | Acc: 84.146% (4952/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.330 | Acc: 84.707% (4985/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.327 | Acc: 84.809% (4991/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.323 | Acc: 84.979% (5001/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.314 | Acc: 86.066% (5065/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 91.156% (268/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.318 | Acc: 85.183% (5013/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 92.177% (271/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.306 | Acc: 85.930% (5057/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.306 | Acc: 85.998% (5061/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.306 | Acc: 86.270% (5077/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.194 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.312 | Acc: 85.794% (5049/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.197% (274/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.305 | Acc: 85.336% (5022/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.306 | Acc: 86.389% (5084/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.295 | Acc: 86.593% (5096/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.295 | Acc: 86.525% (5092/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.293 | Acc: 86.219% (5074/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.293 | Acc: 86.542% (5093/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.288 | Acc: 86.559% (5094/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.327 | Acc: 86.054% (253/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.288 | Acc: 87.035% (5122/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.288 | Acc: 87.103% (5126/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.194 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.280 | Acc: 87.477% (5148/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.272 | Acc: 87.477% (5148/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.596% (5155/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.279 | Acc: 87.749% (5164/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.268 | Acc: 87.647% (5158/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.269 | Acc: 88.190% (5190/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.283 | Acc: 87.545% (5152/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 93.537% (275/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.279 | Acc: 87.052% (5123/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.277 | Acc: 87.579% (5154/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.183 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.271 | Acc: 87.732% (5163/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.260 | Acc: 88.513% (5209/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.263 | Acc: 88.088% (5184/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.268 | Acc: 87.816% (5168/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.176 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.268 | Acc: 87.969% (5177/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.262 | Acc: 88.258% (5194/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.310 | Acc: 87.755% (258/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.264 | Acc: 88.037% (5181/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.666% (5218/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.260 | Acc: 88.462% (5206/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.255 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 93.878% (276/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.253 | Acc: 89.074% (5242/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.307 | Acc: 88.776% (261/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.853% (5229/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.257 | Acc: 88.615% (5215/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.252 | Acc: 88.802% (5226/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.252 | Acc: 88.751% (5223/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.251 | Acc: 89.380% (5260/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.250 | Acc: 88.819% (5227/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.247 | Acc: 89.023% (5239/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.254 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.164 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.253 | Acc: 89.363% (5259/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.242 | Acc: 89.159% (5247/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.183 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.243 | Acc: 89.057% (5241/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.243 | Acc: 89.465% (5265/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.232 | Acc: 90.161% (5306/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 90.136% (265/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 89.805% (5285/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.241 | Acc: 89.465% (5265/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:70\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.204 | Acc: 91.538% (5387/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.165 | Acc: 94.558% (278/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.192 | Acc: 92.099% (5420/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.370% (5436/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.159 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.181 | Acc: 92.234% (5428/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.155 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.302% (5432/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.174 | Acc: 92.931% (5469/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.163 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.171 | Acc: 92.829% (5463/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.157 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.170 | Acc: 92.642% (5452/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 93.878% (276/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.339% (5493/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.156 | Acc: 93.407% (5497/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.162 | Acc: 93.203% (5485/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.154 | Acc: 93.322% (5492/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.159 | Acc: 93.441% (5499/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.169 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.151 | Acc: 93.628% (5510/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.149 | Acc: 93.764% (5518/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.145 | Acc: 93.730% (5516/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.141 | Acc: 93.968% (5530/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.141 | Acc: 94.138% (5540/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.149 | Acc: 93.883% (5525/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.140 | Acc: 94.172% (5542/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.176 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.143 | Acc: 93.883% (5525/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.139 | Acc: 93.985% (5531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.142 | Acc: 94.223% (5545/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.130 | Acc: 94.613% (5568/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:95\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.130 | Acc: 94.681% (5572/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.128 | Acc: 94.613% (5568/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.119 | Acc: 95.327% (5610/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.121 | Acc: 95.021% (5592/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.176 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.619 | Acc: 66.338% (3904/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.415 | Acc: 84.694% (249/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.515 | Acc: 75.429% (4439/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.554 | Acc: 70.748% (208/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.496 | Acc: 76.194% (4484/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.347 | Acc: 87.075% (256/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.461 | Acc: 78.641% (4628/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.354 | Acc: 83.673% (246/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.446 | Acc: 78.845% (4640/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.428 | Acc: 79.575% (4683/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.403 | Acc: 82.313% (242/294)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.410 | Acc: 80.952% (4764/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.323 | Acc: 84.694% (249/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.399 | Acc: 81.155% (4776/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.395 | Acc: 81.359% (4788/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.392 | Acc: 81.597% (4802/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.327 | Acc: 86.054% (253/294)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.380 | Acc: 81.784% (4813/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.385 | Acc: 78.231% (230/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.364 | Acc: 82.855% (4876/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.367 | Acc: 82.532% (4857/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 89.456% (263/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.350 | Acc: 83.772% (4930/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.350 | Acc: 83.721% (4927/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.324 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.340 | Acc: 83.670% (4924/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.327 | Acc: 84.843% (4993/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.332 | Acc: 84.673% (4983/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.333 | Acc: 84.656% (4982/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 92.517% (272/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.314 | Acc: 85.692% (5043/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.321 | Acc: 85.302% (5020/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.314 | Acc: 85.624% (5039/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.312 | Acc: 85.981% (5060/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.306 | Acc: 86.168% (5071/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.308 | Acc: 85.879% (5054/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.305 | Acc: 86.134% (5069/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.294 | Acc: 86.780% (5107/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.295 | Acc: 86.610% (5097/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.282 | Acc: 87.375% (5142/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 93.537% (275/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.275 | Acc: 87.664% (5159/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.306 | Acc: 86.729% (5104/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.878% (276/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.290 | Acc: 86.984% (5119/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.596% (5155/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.289 | Acc: 86.780% (5107/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.277 | Acc: 87.630% (5157/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.286 | Acc: 86.882% (5113/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.267 | Acc: 88.139% (5187/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 88.776% (261/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.277 | Acc: 87.715% (5162/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 88.326% (5198/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.268 | Acc: 88.564% (5212/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.270 | Acc: 87.698% (5161/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.274 | Acc: 87.681% (5160/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.256 | Acc: 88.479% (5207/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 94.218% (277/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.257 | Acc: 88.513% (5209/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.207 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.377% (5201/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.479% (5207/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.268 | Acc: 87.415% (257/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.262 | Acc: 88.360% (5200/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.259 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.262 | Acc: 88.122% (5186/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.253 | Acc: 88.870% (5230/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.250 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.261 | Acc: 88.275% (5195/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.255 | Acc: 88.717% (5221/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.254 | Acc: 88.921% (5233/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 88.649% (5217/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.252 | Acc: 88.836% (5228/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.316 | Acc: 86.054% (253/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.257 | Acc: 89.057% (5241/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.260 | Acc: 88.819% (5227/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.255 | Acc: 89.176% (5248/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.243 | Acc: 89.210% (5250/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.336 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.246 | Acc: 89.227% (5251/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.250 | Acc: 89.142% (5246/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.166 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.251 | Acc: 88.904% (5232/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.250 | Acc: 88.734% (5222/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:63\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.212 | Acc: 90.637% (5334/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.193 | Acc: 92.014% (5415/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.190 | Acc: 91.708% (5397/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.169 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.182 | Acc: 92.421% (5439/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.165 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.181 | Acc: 92.184% (5425/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.181 | Acc: 92.268% (5430/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.182 | Acc: 92.099% (5420/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.182 | Acc: 92.116% (5421/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.159 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.184 | Acc: 92.608% (5450/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.166 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.167 | Acc: 92.897% (5467/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 93.537% (275/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.170 | Acc: 92.557% (5447/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.169 | Acc: 92.795% (5461/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 94.558% (278/294)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.165 | Acc: 92.863% (5465/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.165 | Acc: 92.574% (5448/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.898% (279/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 92.897% (5467/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.160 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.161 | Acc: 92.795% (5461/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.339% (5493/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.186% (5484/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.159 | Acc: 93.237% (5487/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.188 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.146 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.156 | Acc: 93.458% (5500/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.560% (5506/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 93.713% (5515/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.183 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.141 | Acc: 94.274% (5548/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 93.764% (5518/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.696% (5514/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.139 | Acc: 94.036% (5534/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.140 | Acc: 94.444% (5558/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.139 | Acc: 93.900% (5526/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.308% (5550/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.139 | Acc: 94.223% (5545/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:95\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.128 | Acc: 95.140% (5599/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.130 | Acc: 94.562% (5565/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.898% (279/294)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.121 | Acc: 95.191% (5602/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.122 | Acc: 94.987% (5590/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.635 | Acc: 64.095% (3772/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.446 | Acc: 81.973% (241/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.533 | Acc: 73.441% (4322/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.434 | Acc: 81.293% (239/294)\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.489 | Acc: 76.398% (4496/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.355 | Acc: 87.075% (256/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.466 | Acc: 78.233% (4604/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.349 | Acc: 83.673% (246/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.447 | Acc: 78.980% (4648/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.318 | Acc: 87.755% (258/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.427 | Acc: 80.051% (4711/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.344 | Acc: 83.333% (245/294)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.401 | Acc: 81.563% (4800/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.420 | Acc: 80.272% (236/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.394 | Acc: 81.546% (4799/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.343 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.393 | Acc: 81.257% (4782/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.386 | Acc: 82.005% (4826/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 88.776% (261/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.372 | Acc: 82.413% (4850/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.364 | Acc: 83.161% (4894/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.289 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.350 | Acc: 83.585% (4919/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.116% (262/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.483% (4913/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.332 | Acc: 84.503% (4973/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.339 | Acc: 83.755% (4929/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 89.456% (263/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.326 | Acc: 85.149% (5011/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 91.837% (270/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.327 | Acc: 84.843% (4993/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.320 | Acc: 84.945% (4999/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.314 | Acc: 85.811% (5050/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 93.197% (274/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 84.928% (4998/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.308 | Acc: 85.607% (5038/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.308 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.303 | Acc: 86.202% (5073/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.304 | Acc: 86.270% (5077/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 87.052% (5123/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.298 | Acc: 86.712% (5103/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.298 | Acc: 86.593% (5096/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.299 | Acc: 86.168% (5071/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.294 | Acc: 86.440% (5087/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.283 | Acc: 86.984% (5119/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 86.661% (5100/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.169 | Acc: 93.537% (275/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.290 | Acc: 86.831% (5110/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.749% (5164/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.284 | Acc: 87.833% (5169/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 93.878% (276/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.647% (5158/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.188 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.681% (5160/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 87.715% (5162/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 87.918% (5174/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 88.037% (5181/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.462% (5206/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.547% (5211/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 89.006% (5238/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.581% (5213/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 88.479% (5207/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.166 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.266 | Acc: 87.850% (5170/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 87.918% (5174/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.870% (5230/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.263 | Acc: 88.343% (5199/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 89.091% (5243/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.164 | Acc: 94.558% (278/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.666% (5218/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.530% (5210/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 89.125% (5245/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.941% (5293/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.162 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.006% (5238/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.164 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.244 | Acc: 89.091% (5243/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.251 | Acc: 88.836% (5228/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.246 | Acc: 89.261% (5253/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.185 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 89.312% (5256/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.165 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.108% (5244/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 88.435% (260/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.254 | Acc: 88.921% (5233/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.207 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 90.025% (5298/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.397% (5261/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.890% (5290/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.233 | Acc: 89.635% (5275/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.907% (5291/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.380% (5260/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.228 | Acc: 89.856% (5288/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.023% (5239/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.245 | Acc: 89.193% (5249/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.108% (5244/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.380% (5260/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.231 | Acc: 89.652% (5276/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.091% (5243/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.091% (5243/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.179 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:76\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.200 | Acc: 91.351% (5376/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.189 | Acc: 92.014% (5415/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.182 | Acc: 92.268% (5430/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.166 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.167 | Acc: 93.152% (5482/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.067% (5477/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.167 | Acc: 92.710% (5456/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.558% (278/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 93.118% (5480/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 93.254% (5488/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.161 | Acc: 93.033% (5475/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.161 | Acc: 93.203% (5485/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 94.019% (5533/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.798% (5520/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.526% (5504/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.356% (5494/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 93.764% (5518/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:92\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.145 | Acc: 94.002% (5532/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 93.832% (5522/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.138 | Acc: 94.444% (5558/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:95\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.133 | Acc: 94.766% (5577/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.138 | Acc: 94.494% (5561/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.511% (5562/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.189% (5543/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:99\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.131 | Acc: 94.494% (5561/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:100\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.129 | Acc: 94.630% (5569/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:101\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.135 | Acc: 94.223% (5545/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.197 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:102\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 94.528% (5563/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:103\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 94.342% (5552/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:104\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 94.342% (5552/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.612 | Acc: 66.321% (3903/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.506 | Acc: 76.871% (226/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.500 | Acc: 76.228% (4486/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.464 | Acc: 79.932% (235/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.474 | Acc: 77.230% (4545/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.422 | Acc: 83.673% (246/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.446 | Acc: 79.388% (4672/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.395 | Acc: 84.354% (248/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.424 | Acc: 80.085% (4713/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.370 | Acc: 83.333% (245/294)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.410 | Acc: 80.918% (4762/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.408 | Acc: 81.293% (239/294)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.396 | Acc: 81.325% (4786/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.341 | Acc: 83.673% (246/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.388 | Acc: 82.345% (4846/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.334 | Acc: 85.034% (250/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.379 | Acc: 82.838% (4875/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.331 | Acc: 83.673% (246/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.365 | Acc: 82.668% (4865/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 87.415% (257/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.348 | Acc: 84.027% (4945/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.352 | Acc: 83.738% (4928/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.343 | Acc: 83.704% (4926/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.335 | Acc: 84.401% (4967/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.339 | Acc: 84.384% (4966/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.330 | Acc: 85.149% (5011/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 88.776% (261/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.322 | Acc: 85.200% (5014/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.339 | Acc: 85.034% (250/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.314 | Acc: 85.556% (5035/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 90.136% (265/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.540% (5034/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.816% (267/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.307 | Acc: 85.947% (5058/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.308 | Acc: 86.151% (5070/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.301 | Acc: 86.287% (5078/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.288 | Acc: 86.967% (5118/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 86.593% (5096/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 86.865% (5112/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.290 | Acc: 87.171% (5130/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.301 | Acc: 86.270% (5077/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 91.837% (270/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.303 | Acc: 85.930% (5057/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.291 | Acc: 86.457% (5088/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 87.075% (256/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 86.950% (5117/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.287 | Acc: 86.831% (5110/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.251 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.286 | Acc: 86.661% (5100/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.279 | Acc: 87.239% (5134/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.281 | Acc: 87.426% (5145/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.280 | Acc: 87.664% (5159/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 87.732% (5163/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 92.177% (271/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.285 | Acc: 87.239% (5134/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 87.935% (5175/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.265 | Acc: 87.901% (5173/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.251 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.207% (5191/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.263 | Acc: 88.190% (5190/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.265 | Acc: 88.037% (5181/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 87.969% (5177/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 89.116% (262/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.088% (5184/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 88.241% (5193/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.240 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.870% (5230/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.273 | Acc: 88.292% (5196/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.785% (5225/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 88.394% (5202/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.564% (5212/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.581% (5213/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.252 | Acc: 88.717% (5221/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.259 | Acc: 88.275% (5195/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 88.717% (5221/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.423 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.266 | Acc: 88.258% (5194/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.853% (5229/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.921% (5233/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 89.796% (264/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.247 | Acc: 89.346% (5258/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.581% (5213/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:60\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.221 | Acc: 90.093% (5302/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 93.197% (274/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.207 | Acc: 91.351% (5376/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.199 | Acc: 91.521% (5386/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.192 | Acc: 92.387% (5437/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 92.857% (273/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.190 | Acc: 91.912% (5409/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.184 | Acc: 92.353% (5435/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.182 | Acc: 92.167% (5424/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.181 | Acc: 92.167% (5424/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.179 | Acc: 92.540% (5446/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.175 | Acc: 92.336% (5434/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.169 | Acc: 92.948% (5470/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.165 | Acc: 92.948% (5470/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.164 | Acc: 92.931% (5469/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 92.778% (5460/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.067% (5477/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.164 | Acc: 93.135% (5481/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.237% (5487/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.275 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.594% (5508/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.156 | Acc: 93.662% (5512/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.407% (5497/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:80\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 93.730% (5516/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 93.764% (5518/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.253 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 93.883% (5525/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 93.900% (5526/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.250 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.607 | Acc: 67.001% (3943/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.509 | Acc: 77.211% (227/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.497 | Acc: 76.551% (4505/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.441 | Acc: 79.252% (233/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.468 | Acc: 78.131% (4598/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.410 | Acc: 82.313% (242/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.442 | Acc: 79.677% (4689/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.425 | Acc: 79.932% (235/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.417 | Acc: 80.306% (4726/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.446 | Acc: 82.993% (244/294)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.404 | Acc: 81.903% (4820/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.338 | Acc: 84.354% (248/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.398 | Acc: 81.682% (4807/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.361 | Acc: 85.714% (252/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.386 | Acc: 82.481% (4854/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.373 | Acc: 82.838% (4875/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.314 | Acc: 86.054% (253/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.367 | Acc: 83.127% (4892/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.337 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.352 | Acc: 83.772% (4930/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.306 | Acc: 87.415% (257/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.344 | Acc: 84.112% (4950/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.339 | Acc: 84.197% (4955/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.270 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.331 | Acc: 84.639% (4981/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 88.776% (261/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.328 | Acc: 84.860% (4994/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.328 | Acc: 85.285% (5019/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.328 | Acc: 85.030% (5004/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 90.816% (267/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.692% (5043/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.303 | Acc: 86.151% (5070/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.318 | Acc: 85.556% (5035/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.274 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.930% (5057/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.506% (5032/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.303 | Acc: 85.964% (5059/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.302 | Acc: 86.542% (5093/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.302 | Acc: 85.811% (5050/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.288 | Acc: 86.950% (5117/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.291 | Acc: 86.780% (5107/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.281 | Acc: 87.222% (5133/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.288 | Acc: 86.950% (5117/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.286 | Acc: 87.324% (5139/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.275 | Acc: 87.901% (5173/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.279 | Acc: 87.782% (5166/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 89.456% (263/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.278 | Acc: 87.986% (5178/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.276 | Acc: 87.426% (5145/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.986% (5178/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.276 | Acc: 87.952% (5176/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 92.177% (271/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.265 | Acc: 88.275% (5195/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.632% (5216/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.266 | Acc: 88.003% (5179/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 89.456% (263/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.265 | Acc: 88.343% (5199/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.683% (5219/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 92.517% (272/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.275% (5195/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.796% (264/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.244 | Acc: 89.040% (5240/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.197 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.836% (5228/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.258% (5194/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.259 | Acc: 88.445% (5205/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.256 | Acc: 89.040% (5240/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.256 | Acc: 88.751% (5223/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.259 | Acc: 88.785% (5225/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 88.020% (5180/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.251 | Acc: 89.142% (5246/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.304 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.581% (5213/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 90.136% (265/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 89.261% (5253/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.241 | Acc: 88.887% (5231/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 89.142% (5246/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.227 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.380% (5260/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.248 | Acc: 89.176% (5248/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.241 | Acc: 89.329% (5257/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 91.497% (269/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:59\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.211 | Acc: 90.739% (5340/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 91.837% (270/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.196 | Acc: 91.810% (5403/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 91.497% (269/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.188 | Acc: 92.319% (5433/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.194 | Acc: 91.572% (5389/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.185 | Acc: 92.523% (5445/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.181 | Acc: 92.319% (5433/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.174 | Acc: 92.574% (5448/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.182 | Acc: 91.963% (5412/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.179 | Acc: 92.829% (5463/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 92.857% (273/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.174 | Acc: 92.523% (5445/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 93.152% (5482/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 93.197% (274/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.168 | Acc: 92.880% (5466/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.166 | Acc: 93.101% (5479/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.157 | Acc: 93.747% (5517/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.166 | Acc: 93.169% (5483/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.560% (5506/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.509% (5503/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.238 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.149 | Acc: 93.747% (5517/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.730% (5516/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 93.815% (5521/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.543% (5505/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.611% (5509/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.240 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.149 | Acc: 94.019% (5533/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.139 | Acc: 94.291% (5549/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.139 | Acc: 94.494% (5561/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 94.121% (5539/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.225 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.460% (5559/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:86\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.132 | Acc: 94.987% (5590/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.128 | Acc: 94.800% (5579/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.230 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 94.800% (5579/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.226 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.122 | Acc: 94.987% (5590/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.610 | Acc: 65.692% (3866/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.473 | Acc: 81.293% (239/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.511 | Acc: 74.902% (4408/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.522 | Acc: 76.190% (224/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.472 | Acc: 77.638% (4569/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.394 | Acc: 84.354% (248/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.456 | Acc: 78.692% (4631/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 85.034% (250/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.432 | Acc: 79.983% (4707/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.340 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.416 | Acc: 81.071% (4771/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.303 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.403 | Acc: 81.172% (4777/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.323 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.381 | Acc: 82.226% (4839/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.389 | Acc: 82.022% (4827/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.365 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.370 | Acc: 83.042% (4887/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.347 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.361 | Acc: 83.415% (4909/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.301 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.352 | Acc: 83.432% (4910/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.352 | Acc: 83.500% (4914/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.342 | Acc: 83.857% (4935/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.316 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.335 | Acc: 84.690% (4984/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.333 | Acc: 84.741% (4987/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 90.136% (265/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.331 | Acc: 84.877% (4995/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.253 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.317 | Acc: 85.523% (5033/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.321 | Acc: 85.506% (5032/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.239 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.318 | Acc: 85.336% (5022/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.306 | Acc: 85.896% (5055/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.156% (268/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.573% (5036/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 86.627% (5098/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.293 | Acc: 86.712% (5103/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 87.755% (258/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.296 | Acc: 86.695% (5102/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 91.497% (269/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.298 | Acc: 86.321% (5080/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.289 | Acc: 87.205% (5132/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 86.916% (5115/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.250 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.279 | Acc: 87.732% (5163/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.291 | Acc: 87.120% (5127/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.275 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.276 | Acc: 87.392% (5143/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.281 | Acc: 87.460% (5147/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.277 | Acc: 87.664% (5159/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 92.177% (271/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.274 | Acc: 87.545% (5152/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.270 | Acc: 87.833% (5169/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.275% (5195/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.289 | Acc: 87.415% (257/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.266 | Acc: 87.884% (5172/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 88.462% (5206/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.666% (5218/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 87.749% (5164/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 89.244% (5252/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.254 | Acc: 88.632% (5216/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 88.768% (5224/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 89.108% (5244/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 89.550% (5270/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 93.197% (274/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.245 | Acc: 89.040% (5240/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.938% (5234/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.197 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.246 | Acc: 88.887% (5231/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 87.755% (258/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.247 | Acc: 89.210% (5250/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.210% (5250/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.397% (5261/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.246 | Acc: 88.989% (5237/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.330 | Acc: 86.054% (253/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 88.462% (5206/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.159% (5247/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.237 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 89.210% (5250/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.235 | Acc: 89.482% (5266/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 91.156% (268/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.246 | Acc: 89.108% (5244/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 90.144% (5305/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.223 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.924% (5292/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.737% (5281/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 93.537% (275/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.244 | Acc: 88.921% (5233/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.187 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.238 | Acc: 89.618% (5274/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.226 | Acc: 90.144% (5305/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.232 | Acc: 90.093% (5302/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.399% (5320/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.225 | Acc: 89.975% (5295/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.235 | Acc: 90.042% (5299/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.221 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.231 | Acc: 90.450% (5323/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.224 | Acc: 90.178% (5307/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.231 | Acc: 89.295% (5255/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 89.992% (5296/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.197 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.223 | Acc: 90.263% (5312/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.941% (5293/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.226 | Acc: 90.399% (5320/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.552% (5329/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.221 | Acc: 90.331% (5316/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:78\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.189 | Acc: 92.065% (5418/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.174 | Acc: 93.033% (5475/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 92.517% (272/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.160 | Acc: 93.543% (5505/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.182 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 93.169% (5483/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 91.497% (269/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.900% (5526/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 94.613% (5568/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.185 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.144 | Acc: 94.002% (5532/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.133 | Acc: 94.545% (5564/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.985% (5531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 92.857% (273/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.140 | Acc: 94.427% (5557/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.135 | Acc: 94.444% (5558/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.183 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.133 | Acc: 94.698% (5573/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.176 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 94.596% (5567/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.176 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.125 | Acc: 95.157% (5600/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.123 | Acc: 94.919% (5586/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.124 | Acc: 95.055% (5594/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:95\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.130 | Acc: 94.545% (5564/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:96\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.117 | Acc: 95.480% (5619/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.115 | Acc: 95.242% (5605/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.194 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.113 | Acc: 95.616% (5627/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:99\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.115 | Acc: 95.327% (5610/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.191 | Acc: 93.878% (276/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:100\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.116 | Acc: 95.361% (5612/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:101\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.101 | Acc: 96.211% (5662/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:102\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.109 | Acc: 95.939% (5646/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:103\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.107 | Acc: 96.007% (5650/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:104\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.109 | Acc: 95.667% (5630/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.207 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:105\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.101 | Acc: 95.905% (5644/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:106\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.101 | Acc: 95.803% (5638/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:107\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.117 | Acc: 95.446% (5617/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:108\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.109 | Acc: 95.667% (5630/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:109\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.106 | Acc: 95.803% (5638/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:110\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.107 | Acc: 95.718% (5633/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:111\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.102 | Acc: 96.024% (5651/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 92.857% (273/294)\n",
      "\n",
      "This is epoch:112\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.110 | Acc: 95.616% (5627/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:113\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.109 | Acc: 95.939% (5646/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:114\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.102 | Acc: 95.905% (5644/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:115\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.106 | Acc: 95.922% (5645/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:116\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.104 | Acc: 95.888% (5643/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.200 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:117\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.105 | Acc: 95.854% (5641/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:118\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.099 | Acc: 96.211% (5662/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:119\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.102 | Acc: 95.922% (5645/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.636 | Acc: 64.197% (3778/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.465 | Acc: 79.592% (234/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.511 | Acc: 74.936% (4410/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.414 | Acc: 81.973% (241/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.471 | Acc: 77.026% (4533/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.363 | Acc: 85.374% (251/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.441 | Acc: 79.388% (4672/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.429 | Acc: 79.490% (4678/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.350 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.406 | Acc: 80.476% (4736/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.312 | Acc: 86.395% (254/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.390 | Acc: 81.699% (4808/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.388 | Acc: 81.529% (4798/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.374 | Acc: 82.243% (4840/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 88.435% (260/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.363 | Acc: 82.906% (4879/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 89.456% (263/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.358 | Acc: 82.719% (4868/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.351 | Acc: 83.297% (4902/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.351 | Acc: 83.517% (4915/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.339 | Acc: 84.758% (4988/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.259 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.331 | Acc: 84.588% (4978/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.796% (264/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.322 | Acc: 84.758% (4988/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.244 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.323 | Acc: 85.489% (5031/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.816% (267/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.311 | Acc: 86.100% (5067/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.243 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.316 | Acc: 85.302% (5020/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.305 | Acc: 85.370% (5024/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.304 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.308 | Acc: 85.981% (5060/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 91.497% (269/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.300 | Acc: 86.372% (5083/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.291 | Acc: 87.001% (5120/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.213 | Acc: 92.857% (273/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 87.239% (5134/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.290 | Acc: 87.426% (5145/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.250 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.291 | Acc: 86.678% (5101/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.285 | Acc: 86.661% (5100/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.224 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.284 | Acc: 87.256% (5135/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.288 | Acc: 86.848% (5111/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.215 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.289 | Acc: 87.341% (5140/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.217 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 87.867% (5171/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.195 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.277 | Acc: 87.460% (5147/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.613% (5156/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.220 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.276 | Acc: 87.358% (5141/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.256 | Acc: 88.700% (5220/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.263 | Acc: 88.292% (5196/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 87.884% (5172/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.257 | Acc: 88.938% (5234/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.270 | Acc: 87.766% (5165/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:40\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.232 | Acc: 89.992% (5296/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.226 | Acc: 90.161% (5306/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.192 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.790% (5343/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.206 | Acc: 91.385% (5378/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.202 | Acc: 91.368% (5377/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.208 | Acc: 91.147% (5364/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.196 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.202 | Acc: 91.164% (5365/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.194 | Acc: 91.861% (5406/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 91.497% (269/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.200 | Acc: 91.640% (5393/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.198 | Acc: 91.657% (5394/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.189 | Acc: 91.980% (5413/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.188 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.191 | Acc: 91.793% (5402/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.185 | Acc: 92.353% (5435/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.190 | Acc: 92.857% (273/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.189 | Acc: 92.251% (5429/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.193 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.185 | Acc: 92.234% (5428/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.185 | Acc: 92.574% (5448/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.186 | Acc: 91.912% (5409/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.201 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.178 | Acc: 92.574% (5448/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.174 | Acc: 92.795% (5461/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.198 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.176 | Acc: 92.642% (5452/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.197 | Acc: 92.517% (272/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.173 | Acc: 92.948% (5470/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.205 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.176 | Acc: 92.880% (5466/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.165 | Acc: 93.356% (5494/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.169 | Acc: 92.574% (5448/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:64\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 94.036% (5534/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.160 | Acc: 93.322% (5492/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.560% (5506/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.206 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.373% (5495/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.747% (5517/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.900% (5526/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.202 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.492% (5502/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.210 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.159 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.203 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.679% (5513/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.609 | Acc: 66.610% (3920/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.478 | Acc: 78.912% (232/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.520 | Acc: 73.985% (4354/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.431 | Acc: 83.673% (246/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.481 | Acc: 76.992% (4531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.399 | Acc: 82.993% (244/294)\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.463 | Acc: 77.859% (4582/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.381 | Acc: 84.694% (249/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.440 | Acc: 79.422% (4674/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.350 | Acc: 86.054% (253/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.427 | Acc: 79.898% (4702/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.310 | Acc: 87.755% (258/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.422 | Acc: 79.847% (4699/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.328 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.409 | Acc: 80.187% (4719/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 89.116% (262/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.385 | Acc: 82.498% (4855/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.309 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.370 | Acc: 82.702% (4867/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.373 | Acc: 82.481% (4854/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.369 | Acc: 82.226% (4839/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.318 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.449% (4911/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.342 | Acc: 83.704% (4926/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.356 | Acc: 82.653% (243/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.344 | Acc: 83.925% (4939/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.337 | Acc: 83.942% (4940/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 90.816% (267/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.329 | Acc: 84.435% (4969/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.259 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.323 | Acc: 84.673% (4983/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.322 | Acc: 85.285% (5019/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.315 | Acc: 85.200% (5014/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.310 | Acc: 85.523% (5033/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.312 | Acc: 85.370% (5024/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.232 | Acc: 91.497% (269/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.306 | Acc: 86.066% (5065/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.299 | Acc: 85.930% (5057/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 86.423% (5086/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.287 | Acc: 86.780% (5107/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.229 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.295 | Acc: 86.406% (5085/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.233 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.283 | Acc: 87.732% (5163/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.228 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.287 | Acc: 86.678% (5101/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.218 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.275 | Acc: 87.596% (5155/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.273 | Acc: 87.562% (5153/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.274 | Acc: 87.918% (5174/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.189 | Acc: 94.218% (277/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 88.037% (5181/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.212 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 88.343% (5199/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 89.796% (264/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 87.935% (5175/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.222 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 88.105% (5185/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.214 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 87.782% (5166/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.216 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 88.173% (5189/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.236 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.343% (5199/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.208 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.122% (5186/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.173% (5189/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.194 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 88.105% (5185/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.264 | Acc: 87.579% (5154/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.209 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.394% (5202/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.234 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.122% (5186/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.199 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.270 | Acc: 88.071% (5183/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.185 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.259 | Acc: 88.377% (5201/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.211 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.247 | Acc: 89.329% (5257/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 89.456% (263/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.887% (5231/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 91.837% (270/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 88.615% (5215/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.204 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:51\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.216 | Acc: 90.654% (5335/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 92.177% (271/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.200 | Acc: 91.674% (5395/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.169 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.194 | Acc: 92.014% (5415/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.174 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.191 | Acc: 91.793% (5402/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.189 | Acc: 91.861% (5406/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.163 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.186 | Acc: 92.133% (5422/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.182 | Acc: 92.082% (5419/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.180 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.179 | Acc: 92.048% (5417/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.162 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.178 | Acc: 92.404% (5438/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.558% (278/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.174 | Acc: 92.625% (5451/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.173 | Acc: 92.523% (5445/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.167 | Acc: 92.931% (5469/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.898% (279/294)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.168 | Acc: 92.863% (5465/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.173 | Acc: 92.676% (5454/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.165 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.162 | Acc: 93.118% (5480/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.166 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.169 | Acc: 92.863% (5465/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.135% (5481/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.161 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.153 | Acc: 93.509% (5503/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 94.898% (279/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.157 | Acc: 93.322% (5492/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.161 | Acc: 94.218% (277/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.985% (5531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.152 | Acc: 94.558% (278/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.149 | Acc: 93.628% (5510/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.165 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.153 | Acc: 93.594% (5508/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.167 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.151 | Acc: 93.628% (5510/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 93.713% (5515/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.168 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 93.798% (5520/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.181 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.291% (5549/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.184 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.138 | Acc: 94.410% (5556/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.146 | Acc: 93.985% (5531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.185 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:79\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.137 | Acc: 94.087% (5537/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.477% (5560/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.131 | Acc: 94.630% (5569/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.131 | Acc: 94.851% (5582/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 95.238% (280/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.136 | Acc: 94.308% (5550/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.124 | Acc: 94.919% (5586/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.130 | Acc: 94.766% (5577/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.135 | Acc: 94.579% (5566/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 94.558% (278/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.124 | Acc: 94.800% (5579/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.127 | Acc: 94.749% (5576/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.173 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.127 | Acc: 94.698% (5573/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.170 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.125 | Acc: 94.987% (5590/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:91\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.132 | Acc: 94.766% (5577/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:92\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.124 | Acc: 95.038% (5593/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:93\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.118 | Acc: 95.412% (5615/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.197% (274/294)\n",
      "\n",
      "This is epoch:94\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.121 | Acc: 94.919% (5586/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.175 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:95\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.126 | Acc: 94.851% (5582/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:96\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.120 | Acc: 95.208% (5603/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:97\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.131 | Acc: 94.325% (5551/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.172 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:98\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.128 | Acc: 94.681% (5572/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:99\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.130 | Acc: 94.291% (5549/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.186 | Acc: 93.537% (275/294)\n",
      "\n",
      "This is epoch:100\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.131 | Acc: 94.494% (5561/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.177 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:101\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.117 | Acc: 95.106% (5597/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.171 | Acc: 94.218% (277/294)\n",
      "\n",
      "This is epoch:102\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.125 | Acc: 94.834% (5581/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.178 | Acc: 93.878% (276/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.670 | Acc: 60.850% (3581/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.591 | Acc: 74.150% (218/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.543 | Acc: 72.218% (4250/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.464 | Acc: 78.231% (230/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.488 | Acc: 76.075% (4477/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.402 | Acc: 81.973% (241/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.463 | Acc: 77.944% (4587/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.413 | Acc: 81.293% (239/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.439 | Acc: 79.575% (4683/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.388 | Acc: 81.973% (241/294)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.426 | Acc: 79.762% (4694/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.375 | Acc: 82.993% (244/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.409 | Acc: 81.427% (4792/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.364 | Acc: 82.993% (244/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.387 | Acc: 81.818% (4815/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.493 | Acc: 77.891% (229/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.382 | Acc: 82.073% (4830/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.403 | Acc: 81.633% (240/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.373 | Acc: 82.787% (4872/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.329 | Acc: 85.374% (251/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.360 | Acc: 82.991% (4884/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.427 | Acc: 80.952% (238/294)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.349 | Acc: 83.314% (4903/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.367 | Acc: 84.014% (247/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.449% (4911/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.301 | Acc: 86.735% (255/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.334 | Acc: 84.979% (5001/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.332 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.332 | Acc: 84.622% (4980/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 87.755% (258/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.324 | Acc: 84.792% (4990/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.313 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.320 | Acc: 84.928% (4998/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.312 | Acc: 85.777% (5048/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.352 | Acc: 84.694% (249/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.312 | Acc: 85.472% (5030/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.314 | Acc: 85.489% (5031/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 90.136% (265/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.307 | Acc: 85.998% (5061/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.421 | Acc: 82.653% (243/294)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.296 | Acc: 86.678% (5101/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.300 | Acc: 86.083% (5066/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.303 | Acc: 87.755% (258/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.301 | Acc: 86.355% (5082/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.289 | Acc: 87.103% (5126/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.403 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.291 | Acc: 86.848% (5111/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.292 | Acc: 86.695% (5102/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.331 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.288 | Acc: 86.984% (5119/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.321 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.282 | Acc: 87.324% (5139/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 87.664% (5159/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.347 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.681% (5160/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.334 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.267 | Acc: 88.020% (5180/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 89.456% (263/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.263 | Acc: 88.190% (5190/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.299 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 88.156% (5188/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.267 | Acc: 87.884% (5172/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.393 | Acc: 83.673% (246/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.273 | Acc: 87.833% (5169/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.261 | Acc: 88.377% (5201/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.311 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.270 | Acc: 88.462% (5206/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.265 | Acc: 88.105% (5185/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.357 | Acc: 82.993% (244/294)\n",
      "\n",
      "This is epoch:40\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.230 | Acc: 89.856% (5288/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.796% (264/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.225 | Acc: 90.569% (5330/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.219 | Acc: 90.892% (5349/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.321 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.217 | Acc: 90.671% (5336/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.203 | Acc: 91.266% (5371/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.206 | Acc: 91.266% (5371/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.207 | Acc: 91.521% (5386/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.136% (265/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.196 | Acc: 91.861% (5406/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 90.476% (266/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.191 | Acc: 92.014% (5415/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.167% (5424/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.194 | Acc: 91.759% (5400/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.387% (5437/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.187 | Acc: 92.116% (5421/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.306 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.421% (5439/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.167% (5424/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.306 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.180 | Acc: 92.387% (5437/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.185 | Acc: 92.387% (5437/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.322 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.179 | Acc: 92.489% (5443/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.308 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.166 | Acc: 92.642% (5452/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 91.156% (268/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.176 | Acc: 92.387% (5437/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.304 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.167 | Acc: 92.846% (5464/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.163 | Acc: 93.356% (5494/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.320 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.167 | Acc: 92.931% (5469/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.394 | Acc: 86.395% (254/294)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.170 | Acc: 92.897% (5467/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.324 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.163 | Acc: 93.186% (5484/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.307 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.154 | Acc: 93.696% (5514/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.162 | Acc: 93.271% (5489/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.360 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.162 | Acc: 93.169% (5483/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.155 | Acc: 93.577% (5507/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.332 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.156 | Acc: 93.594% (5508/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.363 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.153 | Acc: 93.798% (5520/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.303 | Acc: 91.837% (270/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.152 | Acc: 93.713% (5515/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.331 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.356% (5494/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.158 | Acc: 93.543% (5505/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.149 | Acc: 93.934% (5528/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.332 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.150 | Acc: 93.628% (5510/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 91.497% (269/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.147 | Acc: 93.934% (5528/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.366 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.150 | Acc: 93.560% (5506/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.358 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.137 | Acc: 94.308% (5550/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.328 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.139 | Acc: 94.257% (5547/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.284 | Acc: 91.156% (268/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.141 | Acc: 94.291% (5549/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.328 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.144 | Acc: 93.849% (5523/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.342 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.142 | Acc: 94.257% (5547/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.365 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.142 | Acc: 94.206% (5544/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.364 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.127 | Acc: 94.800% (5579/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.333 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.137 | Acc: 94.596% (5567/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.127 | Acc: 94.715% (5574/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.338 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:87\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.119 | Acc: 95.225% (5604/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.329 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:88\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.111 | Acc: 95.259% (5606/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.319 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:89\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.118 | Acc: 95.565% (5624/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.329 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:90\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.114 | Acc: 95.837% (5640/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.337 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.602 | Acc: 67.392% (3966/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.565 | Acc: 76.871% (226/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.499 | Acc: 76.041% (4475/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.442 | Acc: 80.272% (236/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.471 | Acc: 78.131% (4598/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.346 | Acc: 84.354% (248/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.445 | Acc: 78.794% (4637/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.368 | Acc: 81.973% (241/294)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.410 | Acc: 80.102% (4714/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.342 | Acc: 85.714% (252/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.404 | Acc: 81.546% (4799/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.339 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.382 | Acc: 82.328% (4845/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.325 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.388 | Acc: 81.529% (4798/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.367 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.374 | Acc: 82.940% (4881/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.312 | Acc: 87.415% (257/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.356 | Acc: 83.314% (4903/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.386 | Acc: 83.333% (245/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.354 | Acc: 83.670% (4924/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 88.095% (259/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.338 | Acc: 84.435% (4969/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.289 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.341 | Acc: 84.146% (4952/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.335 | Acc: 85.217% (5015/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.351 | Acc: 85.374% (251/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.328 | Acc: 84.826% (4992/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.456% (263/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.318 | Acc: 85.251% (5017/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.307 | Acc: 85.828% (5051/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.320 | Acc: 85.030% (5004/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.346 | Acc: 86.395% (254/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.307 | Acc: 86.151% (5070/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.311 | Acc: 88.435% (260/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.307 | Acc: 85.658% (5041/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.295 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.293 | Acc: 86.831% (5110/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 88.435% (260/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.303 | Acc: 85.760% (5047/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.796% (264/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.303 | Acc: 86.729% (5104/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 90.816% (267/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.283 | Acc: 87.630% (5157/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.816% (5168/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 89.116% (262/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.282 | Acc: 87.137% (5128/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.275 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.279 | Acc: 87.375% (5142/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.301 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.275 | Acc: 87.749% (5164/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.331 | Acc: 86.735% (255/294)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.276 | Acc: 87.341% (5140/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.253 | Acc: 90.816% (267/294)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.277 | Acc: 87.188% (5131/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.271 | Acc: 87.341% (5140/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.295 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.265 | Acc: 87.969% (5177/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.271 | Acc: 88.037% (5181/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.253 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.262 | Acc: 88.122% (5186/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.389 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.259 | Acc: 88.411% (5203/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.422 | Acc: 86.054% (253/294)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 88.003% (5179/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 91.156% (268/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.260 | Acc: 89.057% (5241/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.373 | Acc: 84.694% (249/294)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.256 | Acc: 88.768% (5224/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 89.796% (264/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.262 | Acc: 88.615% (5215/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.264 | Acc: 88.207% (5191/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.392 | Acc: 86.054% (253/294)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.247 | Acc: 89.023% (5239/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.358 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.250 | Acc: 89.023% (5239/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.598% (5214/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.341 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.249 | Acc: 89.567% (5271/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.274 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.252 | Acc: 89.652% (5276/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.370 | Acc: 85.034% (250/294)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.241 | Acc: 89.584% (5272/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.294 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.248 | Acc: 89.040% (5240/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 91.497% (269/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.248 | Acc: 89.142% (5246/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 89.456% (263/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.238 | Acc: 89.686% (5278/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.387 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.241 | Acc: 89.397% (5261/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.302 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.240 | Acc: 89.703% (5279/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.379 | Acc: 87.075% (256/294)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.234 | Acc: 89.431% (5263/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 91.156% (268/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.235 | Acc: 89.839% (5287/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.327 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.230 | Acc: 90.059% (5300/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.310 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.240 | Acc: 89.669% (5277/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.265 | Acc: 90.476% (266/294)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.230 | Acc: 89.431% (5263/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.219 | Acc: 92.177% (271/294)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.228 | Acc: 89.890% (5290/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 87.755% (258/294)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.238 | Acc: 89.414% (5262/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.369 | Acc: 84.354% (248/294)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.232 | Acc: 89.822% (5286/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.237 | Acc: 89.822% (5286/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.355 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.231 | Acc: 90.297% (5314/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.368 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.233 | Acc: 90.229% (5310/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 90.476% (266/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.228 | Acc: 90.195% (5308/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.310 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.222 | Acc: 90.093% (5302/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.432 | Acc: 85.714% (252/294)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.516% (5268/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.225 | Acc: 90.552% (5329/5885)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.289 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.218 | Acc: 90.807% (5344/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 89.116% (262/294)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.225 | Acc: 90.025% (5298/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.334 | Acc: 88.095% (259/294)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.218 | Acc: 90.518% (5327/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.249 | Acc: 90.136% (265/294)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.221 | Acc: 90.297% (5314/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.288 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.218 | Acc: 90.008% (5297/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.223 | Acc: 90.484% (5325/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.218 | Acc: 90.637% (5334/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.320 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.229 | Acc: 90.042% (5299/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.412 | Acc: 84.014% (247/294)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.213 | Acc: 90.841% (5346/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.212 | Acc: 90.994% (5355/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 87.415% (257/294)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.223 | Acc: 90.042% (5299/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.377 | Acc: 84.694% (249/294)\n",
      "\n",
      "This is epoch:78\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.223 | Acc: 90.280% (5313/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.409 | Acc: 85.374% (251/294)\n",
      "\n",
      "This is epoch:79\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.186 | Acc: 92.234% (5428/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.169 | Acc: 93.101% (5479/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.156 | Acc: 93.985% (5531/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.158 | Acc: 93.220% (5486/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.288 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.152 | Acc: 93.696% (5514/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.298 | Acc: 88.776% (261/294)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.152 | Acc: 94.002% (5532/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 89.796% (264/294)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.142 | Acc: 94.342% (5552/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 88.435% (260/294)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.141 | Acc: 94.053% (5535/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 89.116% (262/294)\n",
      "\n",
      "This is epoch:87\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.135 | Acc: 94.613% (5568/5885)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.299 | Acc: 89.456% (263/294)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.597 | Acc: 67.942% (3995/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.498 | Acc: 77.627% (229/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.499 | Acc: 75.578% (4444/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.443 | Acc: 78.305% (231/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.471 | Acc: 77.942% (4583/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.413 | Acc: 82.373% (243/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.433 | Acc: 79.405% (4669/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.382 | Acc: 83.729% (247/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.429 | Acc: 80.051% (4707/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.358 | Acc: 84.746% (250/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 135/184 >......]Step: 0ms| Tot: 2s1ms|Loss: 0.415 | Acc: 80.926% (3496/4320)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6756:\n",
      "Process Process-6754:\n",
      "Process Process-6755:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-03fc44092173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plain_cnn_models/log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-03fc44092173>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, early_stopping)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, dest_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch,early_stopping = None):\n",
    "    global train_data#,out,y,predicted\n",
    "    acc=0\n",
    "    best_acc =0\n",
    "    best_val_loss= 100\n",
    "    loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    train_data={}\n",
    "    train_data['loss_hist'] = loss_hist\n",
    "    train_data['val_loss_hist'] = val_loss_hist\n",
    "    train_data['train_acc_hist'] = train_acc_hist\n",
    "    train_data['val_acc_hist'] =  val_acc_hist\n",
    "    e_s= 0\n",
    "    last_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        print('\\nThis is epoch:{}'.format(i+1))\n",
    "        total= 0\n",
    "        correct=0\n",
    "        loss_avg= 0\n",
    "        #scheduler.step()\n",
    "        scheduler.step(acc)\n",
    "        if optimizer.param_groups[0]['lr'] < last_lr:\n",
    "            print('lr change from %f to %f\\n' %(last_lr,optimizer.param_groups[0]['lr']))\n",
    "            last_lr = optimizer.param_groups[0]['lr']\n",
    "        net.train()\n",
    "        for j,(batch_x, batch_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "            x = Variable(batch_x)\n",
    "            y = Variable(batch_y)\n",
    "            out = net(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y.data).cpu().sum()\n",
    "            progress_bar(j, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "            if j % 5==0:\n",
    "                loss_hist.append(loss_avg/total)\n",
    "            \n",
    "        train_acc_hist.append(100.*correct/total)\n",
    "        e_s+=1\n",
    "        if i %1 == 0:\n",
    "            acc, val_loss = test(val_loader)\n",
    "            val_acc_hist.append(acc)\n",
    "            if acc >best_acc:\n",
    "                best_acc= acc\n",
    "                e_s = 0\n",
    "                print('acc: Save it!')\n",
    "                torch.save(net.state_dict(), 'cnn_acc.pth')\n",
    "            if val_loss <best_val_loss and loss_avg/total <=val_loss :\n",
    "                best_val_loss= val_loss\n",
    "                e_s = 0\n",
    "                acc= best_acc+ 0.01\n",
    "                print('loss: Save it!')\n",
    "                torch.save(net.state_dict(), 'cnn_loss.pth')\n",
    "            if loss_avg/total > val_loss:\n",
    "                e_s = 0\n",
    "#             if best_val_loss >= val_loss:\n",
    "#                 best_val_loss= val_loss\n",
    "#                 torch.save(net.state_dict(), 'resnet34_loss%d.pth'%i)\n",
    "        if early_stopping is not None and e_s >= early_stopping:\n",
    "            return best_val_loss,best_acc,i\n",
    "\n",
    "    return best_val_loss, best_acc,i\n",
    "#         if i%50==0 and save:\n",
    "#             torch.save(net.state_dict(), 'resnet50.pth')\n",
    "        \n",
    "def test(val_load):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_avg= 0\n",
    "    for k, (val_x, val_y) in enumerate(val_load):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss_avg += loss.cpu().data[0] *out.size()[0]\n",
    "        #print(out.size())\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += predicted.eq(y.data).cpu().sum()\n",
    "        total += out.size()[0]\n",
    "        progress_bar(k, len(val_load), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (loss_avg/total, 100.*correct/total, correct, total))\n",
    "    train_data['val_loss_hist'].append(loss_avg/total) #also keep track of loss of val set\n",
    "    acc =  (correct*100.0)/total\n",
    "    return acc,loss_avg/total\n",
    "\n",
    "#Try different transformation\n",
    "\n",
    "for rou in range(4):\n",
    "    ran_num = np.random.randint(20000,30000,size=1)\n",
    "    seed= np.random.RandomState(ran_num)\n",
    "    spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "    for k,(train_index, val_index) in enumerate(spliter.split(train_X_del)):\n",
    "        \n",
    "        train_mean, train_std = transform_compute(train_X_del[train_index])\n",
    "        train_transform = T.Compose([\n",
    "            T.Normalize(train_mean, train_std)\n",
    "        ])\n",
    "        af_train_X, af_train_y = data_aug(train_X_del[train_index], train_y_del[train_index])\n",
    "        \n",
    "        train_dataset = iceberg_dataset(data= af_train_X, label=af_train_y, transform=train_transform)\n",
    "        val_dataset = iceberg_dataset(data= train_X_del[val_index], label=train_y_del[val_index], transform=train_transform, test=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "                                  shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)\n",
    "        \n",
    "        candidate = []\n",
    "        for rep in range(3):\n",
    "            cnn_net = cnn.plain_cnn(num_classes=2)\n",
    "            net= cnn_net\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00175, nesterov= True)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, 'max', patience =15,min_lr= 0.0001)\n",
    "            #5e-3 86\n",
    "            if use_cuda:\n",
    "                criterion.cuda()\n",
    "                net.cuda()\n",
    "\n",
    "            result = train(epoch=250,early_stopping= 20)\n",
    "            candidate.append(result[0])\n",
    "            with open(\"plain_cnn_models/log.txt\", \"a\") as myfile:\n",
    "                msg = 'Phase3, At fold {}, seed {},round {} we find one with acc: {}, loss: {}\\n'.format(\n",
    "                                                            k,ran_num,rep+1, result[1], result[0])\n",
    "                myfile.write(msg)\n",
    "            cmd = 'cp cnn_loss.pth r3_cnn_loss{}.pth'.format(rep)\n",
    "            os.system(cmd)\n",
    "            if len(candidate)==2:\n",
    "                if np.sum(np.array(candidate)<0.18)>=1:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "#         if min(candidate)>0.2:\n",
    "#             with open(\"plain_cnn_models/log.txt\", \"a\") as myfile:\n",
    "#                 msg = 'We are going to give up this round\\n'\n",
    "#                 myfile.write(msg)\n",
    "                \n",
    "#             g= candidate.index(min(candidate))\n",
    "#             cmd = 'cp cnn_loss{}.pth plain_cnn_models_lossbackup/cnn{}_{}{}.pth'.format(g,rou,k,g)\n",
    "#             os.system(cmd)\n",
    "#             continue\n",
    "\n",
    "        #actually an array\n",
    "        #also change here\n",
    "        final_list = np.union1d(np.where(np.array(candidate) <0.18)[0], [candidate.index(min(candidate))])\n",
    "        final_list_v=[i for i in range(3) if i not in final_list]\n",
    "        #final_list = list(range(len(candidate)))\n",
    "        \n",
    "        word= ''\n",
    "        for i in np.array(candidate)[final_list]:\n",
    "            word = word +', '+ str(i)\n",
    "        \n",
    "        \n",
    "        for g in final_list:\n",
    "            with open(\"plain_cnn_models/result.txt\", \"a\") as myfile:\n",
    "                msg = 'Phase3, At fold {}, seed {},round {} we find {} with loss: {}\\n'.format(\n",
    "                                                            k,ran_num,rep+1, len(final_list), word)\n",
    "                myfile.write(msg)\n",
    "            cmd = 'cp r3_cnn_loss{}.pth plain_cnn_models/r4_cnn{}_{}{}[good].pth'.format(g,rou,k,g)\n",
    "            os.system(cmd)\n",
    "        for g in final_list_v:\n",
    "            with open(\"plain_cnn_models/result.txt\", \"a\") as myfile:\n",
    "                msg = 'Phase3, At fold {}, seed {},round {} we find {} with loss: {}\\n'.format(\n",
    "                                                            k,ran_num,rep+1, len(final_list), word)\n",
    "                myfile.write(msg)\n",
    "            cmd = 'cp r3_cnn_loss{}.pth plain_cnn_models/r4_cnn{}_{}{}[bad].pth'.format(g,rou,k,g)\n",
    "            os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.617 | Acc: 65.850% (3872/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.487 | Acc: 78.983% (233/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.511 | Acc: 74.983% (4409/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.437 | Acc: 81.695% (241/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.483 | Acc: 77.092% (4533/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.379 | Acc: 85.424% (252/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.453 | Acc: 78.690% (4627/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.361 | Acc: 83.390% (246/295)\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.423 | Acc: 80.272% (4720/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.338 | Acc: 86.441% (255/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.415 | Acc: 79.745% (4689/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.346 | Acc: 87.119% (257/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.390 | Acc: 81.514% (4793/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.371 | Acc: 84.407% (249/295)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.382 | Acc: 81.582% (4797/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.346 | Acc: 85.085% (251/295)\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.364 | Acc: 82.347% (4842/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.384% (4903/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.307 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.353 | Acc: 83.044% (4883/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.307 | Acc: 87.797% (259/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.333 | Acc: 84.099% (4945/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.324 | Acc: 86.102% (254/295)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.333 | Acc: 83.997% (4939/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 88.136% (260/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.320 | Acc: 85.238% (5012/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.289 | Acc: 89.153% (263/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.324 | Acc: 84.915% (4993/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.313 | Acc: 85.272% (5014/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.315 | Acc: 85.578% (5032/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 90.169% (266/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.302 | Acc: 86.293% (5074/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.294 | Acc: 86.752% (5101/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.297 | Acc: 85.952% (5054/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.296 | Acc: 86.344% (5077/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.285 | Acc: 87.160% (5125/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.346 | Acc: 87.458% (258/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.285 | Acc: 87.007% (5116/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 86.780% (256/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.284 | Acc: 86.973% (5114/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.273 | Acc: 87.364% (5137/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.275 | Acc: 87.636% (5153/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.268 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.503% (5204/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 88.136% (260/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.270 | Acc: 87.993% (5174/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.261 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.269 | Acc: 88.061% (5178/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.336 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s9ms|Loss: 0.263 | Acc: 88.146% (5183/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.308 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.266 | Acc: 87.823% (5164/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 89.831% (265/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.231% (5188/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.279 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.261 | Acc: 88.571% (5208/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.241 | Acc: 91.864% (271/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.254 | Acc: 88.895% (5227/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 88.475% (261/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.252 | Acc: 88.929% (5229/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.325 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.252 | Acc: 88.571% (5208/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.383 | Acc: 83.729% (247/295)\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.256 | Acc: 88.588% (5209/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.253 | Acc: 88.793% (5221/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 90.169% (266/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.238 | Acc: 89.507% (5263/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.247 | Acc: 88.827% (5223/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.297 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.239 | Acc: 89.575% (5267/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.575% (5267/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.268 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.490% (5262/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.299 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.234 | Acc: 89.660% (5272/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.262 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.239 | Acc: 89.728% (5276/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.303% (5251/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.306 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.233 | Acc: 89.626% (5270/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.246 | Acc: 91.864% (271/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.243 | Acc: 89.371% (5255/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.228 | Acc: 90.459% (5319/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.242 | Acc: 89.541% (5265/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.296 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.231 | Acc: 90.136% (5300/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.267 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.236 | Acc: 89.779% (5279/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.368 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.237 | Acc: 89.694% (5274/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.330 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.232 | Acc: 89.847% (5283/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:55\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.201 | Acc: 91.701% (5392/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.257 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.180 | Acc: 92.704% (5451/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.177 | Acc: 92.228% (5423/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.273 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.175 | Acc: 92.619% (5446/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.170 | Acc: 92.874% (5461/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.266 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.172 | Acc: 92.585% (5444/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.154 | Acc: 93.776% (5514/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.333% (5488/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.164 | Acc: 93.214% (5481/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.159 | Acc: 93.401% (5492/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.309 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.150 | Acc: 93.997% (5527/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.284 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.163 | Acc: 93.265% (5484/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.290 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.149 | Acc: 93.878% (5520/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.294 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.157 | Acc: 93.810% (5516/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.155 | Acc: 93.605% (5504/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.143 | Acc: 93.929% (5523/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.284 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.142 | Acc: 94.048% (5530/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.310 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.144 | Acc: 94.031% (5529/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.268 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.135 | Acc: 94.779% (5573/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.288 | Acc: 91.525% (270/295)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.153 | Acc: 93.622% (5505/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.132 | Acc: 94.575% (5561/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:76\n",
      "lr change from 0.001000 to 0.000100\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.133 | Acc: 94.524% (5558/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.292 | Acc: 91.864% (271/295)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.127 | Acc: 95.085% (5591/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.294 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:1\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.594 | Acc: 68.895% (4051/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.512 | Acc: 80.000% (236/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:2\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.493 | Acc: 75.680% (4450/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.428 | Acc: 83.390% (246/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:3\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.470 | Acc: 76.803% (4516/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.449 | Acc: 79.322% (234/295)\n",
      "\n",
      "This is epoch:4\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.458 | Acc: 78.486% (4615/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.381 | Acc: 84.746% (250/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:5\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.438 | Acc: 79.660% (4684/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.386 | Acc: 84.407% (249/295)\n",
      "\n",
      "This is epoch:6\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.425 | Acc: 79.983% (4703/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.350 | Acc: 85.763% (253/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:7\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.410 | Acc: 80.714% (4746/5880)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.358 | Acc: 83.729% (247/295)\n",
      "\n",
      "This is epoch:8\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.387 | Acc: 82.143% (4830/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.294 | Acc: 88.814% (262/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:9\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.373 | Acc: 82.857% (4872/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.319 | Acc: 86.441% (255/295)\n",
      "\n",
      "This is epoch:10\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.364 | Acc: 82.738% (4865/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.305 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:11\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.354 | Acc: 83.027% (4882/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 87.458% (258/295)\n",
      "\n",
      "This is epoch:12\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.351 | Acc: 83.486% (4909/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.314 | Acc: 87.458% (258/295)\n",
      "\n",
      "This is epoch:13\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.344 | Acc: 83.793% (4927/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.314 | Acc: 86.102% (254/295)\n",
      "\n",
      "This is epoch:14\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.334 | Acc: 84.031% (4941/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.308 | Acc: 86.102% (254/295)\n",
      "\n",
      "This is epoch:15\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.331 | Acc: 83.707% (4922/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.287 | Acc: 87.458% (258/295)\n",
      "\n",
      "This is epoch:16\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.319 | Acc: 84.694% (4980/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:17\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.327 | Acc: 84.286% (4956/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:18\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.317 | Acc: 84.898% (4992/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.317 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:19\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.318 | Acc: 85.340% (5018/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:20\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.306 | Acc: 85.680% (5038/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.331 | Acc: 87.458% (258/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:21\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.309 | Acc: 85.527% (5029/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 90.508% (267/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:22\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.294 | Acc: 86.020% (5058/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.254 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:23\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.290 | Acc: 86.684% (5097/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:24\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.285 | Acc: 87.126% (5123/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:25\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.286 | Acc: 87.126% (5123/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:26\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.281 | Acc: 87.398% (5139/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.406 | Acc: 83.051% (245/295)\n",
      "\n",
      "This is epoch:27\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.281 | Acc: 87.092% (5121/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:28\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.276 | Acc: 87.704% (5157/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.312 | Acc: 87.797% (259/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:29\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 87.840% (5165/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 88.814% (262/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:30\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.272 | Acc: 87.925% (5170/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.282 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:31\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.277 | Acc: 86.939% (5112/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:32\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.271 | Acc: 88.350% (5195/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:33\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.263 | Acc: 87.908% (5169/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.295 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:34\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.260 | Acc: 88.844% (5224/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.322 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:35\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.255 | Acc: 89.082% (5238/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.321 | Acc: 90.847% (268/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:36\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.267 | Acc: 88.180% (5185/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 91.186% (269/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:37\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.262 | Acc: 88.061% (5178/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.333 | Acc: 87.119% (257/295)\n",
      "\n",
      "This is epoch:38\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.249 | Acc: 89.150% (5242/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.277 | Acc: 89.831% (265/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:39\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.258 | Acc: 89.065% (5237/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.245 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:40\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.251 | Acc: 89.286% (5250/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.378 | Acc: 84.068% (248/295)\n",
      "\n",
      "This is epoch:41\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.245 | Acc: 89.235% (5247/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.283 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:42\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.248 | Acc: 88.878% (5226/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.333 | Acc: 86.780% (256/295)\n",
      "\n",
      "This is epoch:43\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 88.878% (5226/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.169% (266/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:44\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.250 | Acc: 89.218% (5246/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:45\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.439% (5259/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:46\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.240 | Acc: 89.507% (5263/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:47\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.256 | Acc: 88.316% (5193/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.235 | Acc: 91.525% (270/295)\n",
      "acc: Save it!\n",
      "\n",
      "This is epoch:48\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.235 | Acc: 89.575% (5267/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.258 | Acc: 90.508% (267/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:49\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.230 | Acc: 89.694% (5274/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 90.508% (267/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:50\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.229 | Acc: 89.830% (5282/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.270 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:51\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.229 | Acc: 90.085% (5297/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.313 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:52\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.229 | Acc: 89.983% (5291/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.311 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:53\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.225 | Acc: 90.544% (5324/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:54\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.233 | Acc: 90.017% (5293/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.247 | Acc: 90.847% (268/295)\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:55\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.232 | Acc: 89.762% (5278/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.270 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:56\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.225 | Acc: 90.323% (5311/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.231 | Acc: 91.864% (271/295)\n",
      "acc: Save it!\n",
      "loss: Save it!\n",
      "\n",
      "This is epoch:57\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.223 | Acc: 90.391% (5315/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:58\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.493% (5321/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.285 | Acc: 88.814% (262/295)\n",
      "\n",
      "This is epoch:59\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.220 | Acc: 90.493% (5321/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.264 | Acc: 88.475% (261/295)\n",
      "\n",
      "This is epoch:60\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.217 | Acc: 90.612% (5328/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.260 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:61\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.223 | Acc: 90.748% (5336/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.251 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:62\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.214 | Acc: 90.714% (5334/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.248 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:63\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.223 | Acc: 90.425% (5317/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.269 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:64\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.510% (5322/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.270 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:65\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.215 | Acc: 90.952% (5348/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.252 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:66\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.222 | Acc: 90.799% (5339/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.291 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:67\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.216 | Acc: 90.612% (5328/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:68\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.217 | Acc: 90.731% (5335/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.268 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:69\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.210 | Acc: 91.293% (5368/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.313 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:70\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.217 | Acc: 90.646% (5330/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.304 | Acc: 88.136% (260/295)\n",
      "\n",
      "This is epoch:71\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.217 | Acc: 90.731% (5335/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.281 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:72\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.219 | Acc: 90.663% (5331/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.242 | Acc: 91.186% (269/295)\n",
      "\n",
      "This is epoch:73\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.216 | Acc: 90.714% (5334/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:74\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.215 | Acc: 90.663% (5331/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.256 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:75\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.210 | Acc: 91.310% (5369/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.300 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:76\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.212 | Acc: 91.105% (5357/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 89.153% (263/295)\n",
      "\n",
      "This is epoch:77\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.217 | Acc: 90.884% (5344/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.271 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:78\n",
      "lr change from 0.010000 to 0.001000\n",
      "\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.177 | Acc: 92.653% (5448/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.255 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:79\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.158 | Acc: 93.571% (5502/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.276 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:80\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.161 | Acc: 93.418% (5493/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.272 | Acc: 89.492% (264/295)\n",
      "\n",
      "This is epoch:81\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 94.150% (5536/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.278 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:82\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.147 | Acc: 94.201% (5539/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.263 | Acc: 90.508% (267/295)\n",
      "\n",
      "This is epoch:83\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.142 | Acc: 94.388% (5550/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.274 | Acc: 90.847% (268/295)\n",
      "\n",
      "This is epoch:84\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.134 | Acc: 95.017% (5587/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.280 | Acc: 89.831% (265/295)\n",
      "\n",
      "This is epoch:85\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.138 | Acc: 94.643% (5565/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.286 | Acc: 90.169% (266/295)\n",
      "\n",
      "This is epoch:86\n",
      "[========= 184/184 ======>]Step: 0ms| Tot: 2s8ms|Loss: 0.132 | Acc: 94.762% (5572/5880)\n",
      "[=========   5/  5 ==>....]Step: 0ms| Tot: 0ms|Loss: 0.293 | Acc: 90.847% (268/295)\n"
     ]
    }
   ],
   "source": [
    "ran_num = 6830\n",
    "seed= np.random.RandomState(ran_num)\n",
    "spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "for k,(train_index, val_index) in enumerate(spliter.split(train_X_del)):\n",
    "    if k!=0:\n",
    "        continue\n",
    "    train_mean, train_std = transform_compute(train_X_del[train_index])\n",
    "    train_transform = T.Compose([\n",
    "        T.Normalize(train_mean, train_std)\n",
    "    ])\n",
    "    af_train_X, af_train_y = data_aug(train_X_del[train_index], train_y_del[train_index])\n",
    "\n",
    "    train_dataset = iceberg_dataset(data= af_train_X, label=af_train_y, transform=train_transform)\n",
    "    val_dataset = iceberg_dataset(data= train_X_del[val_index], label=train_y_del[val_index], transform=train_transform, test=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 32, num_workers=3, \n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "    candidate = []\n",
    "    for rep in range(3):\n",
    "        cnn_net = cnn.plain_cnn(num_classes=2)\n",
    "        net= cnn_net\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00175, nesterov= True)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'max', patience =20,min_lr= 0.0001)\n",
    "        #5e-3 86\n",
    "        if use_cuda:\n",
    "            criterion.cuda()\n",
    "            net.cuda()\n",
    "\n",
    "        result = train(epoch=250,early_stopping= 30)\n",
    "        candidate.append(result[0])\n",
    "        with open(\"plain_cnn_models/log.txt\", \"a\") as myfile:\n",
    "            msg = 'Second training, At fold {}, seed {},round {} we find one with acc: {}, loss: {}\\n'.format(\n",
    "                                                        k,ran_num,rep+1, result[1], result[0])\n",
    "            myfile.write(msg)\n",
    "        cmd = 'cp cnn_loss.pth cnn_loss{}.pth'.format(rep)\n",
    "        os.system(cmd)\n",
    "        cmd1= 'cp cnn_acc.pth backup/cnn_acc{}_{}{}.pth'.format(rou,k,rep+1)\n",
    "        os.system(cmd1)\n",
    "        if len(candidate)==2:\n",
    "            if np.sum(np.array(candidate)<0.18)==2:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    if min(candidate)>0.2:\n",
    "        with open(\"plain_cnn_models/log.txt\", \"a\") as myfile:\n",
    "            msg = 'We are going to give up this round\\n'\n",
    "            myfile.write(msg)\n",
    "\n",
    "        g= candidate.index(min(candidate))\n",
    "        cmd = 'cp cnn_loss{}.pth plain_cnn_models_lossbackup/af_cnn{}_{}{}.pth'.format(g,rou,k,g)\n",
    "        os.system(cmd)\n",
    "        continue\n",
    "\n",
    "    #actually an array\n",
    "    final_list = np.union1d(np.where(np.array(candidate) <0.18)[0], [candidate.index(min(candidate))])\n",
    "\n",
    "    word= ''\n",
    "    for i in np.array(candidate)[final_list]:\n",
    "        word = word +', '+ str(i)\n",
    "\n",
    "\n",
    "    for g in final_list:\n",
    "        with open(\"plain_cnn_models/result.txt\", \"a\") as myfile:\n",
    "            msg = 'Second training, At fold {}, seed {},round {} we find {} with loss: {}\\n'.format(\n",
    "                                                        k,ran_num,rep+1, len(final_list), word)\n",
    "            myfile.write(msg)\n",
    "        cmd = 'cp cnn_loss{}.pth plain_cnn_models/cnn{}_{}{}.pth'.format(g,rou,k,g)\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== 132/132 ================>]  Step: 162ms | Tot: 27s494ms\n",
      "[=================== 132/132 ================>]  Step: 160ms | Tot: 27s661ms\n",
      "[=================== 132/132 ================>]  Step: 162ms | Tot: 27s644ms\n",
      "[=================== 132/132 ================>]  Step: 162ms | Tot: 27s598ms\n",
      "[=================== 132/132 ================>]  Step: 161ms | Tot: 27s668ms\n"
     ]
    }
   ],
   "source": [
    "#result_hist\n",
    "\n",
    "temp11 = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    net = resnet.resnet34(num_classes=2)\n",
    "    net.load_state_dict(torch.load('resnet34_acc%d.pth'%i))\n",
    "    net.cuda()\n",
    "\n",
    "    test = pd.read_json(BASE_dir + 'test.json')\n",
    "    test_X = raw_to_numpy(test)\n",
    "    test_X.shape \n",
    "    fake_label = np.zeros(len(test_X))\n",
    "\n",
    "    test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform,test=True)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "    prob = [] \n",
    "    net.eval()\n",
    "    for k, (val_x, val_y) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        #prevent overflow\n",
    "        temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "        ans= temp[:,1]/(temp.sum(axis=1))\n",
    "        prob.append(ans)\n",
    "        #print(out.size())\n",
    "        progress_bar(k, len(test_loader))\n",
    "    msg = 'is_iceberg%d' %i\n",
    "    temp11[msg]= np.concatenate(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['is_iceberg'] = result/5\n",
    "sub.shape\n",
    "sub.to_csv('submissionll.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp11['is_iceberg_max'] = temp11.iloc[:, 0:6].max(axis=1)\n",
    "temp11['is_iceberg_min'] = temp11.iloc[:, 0:6].min(axis=1)\n",
    "temp11['is_iceberg_median'] = temp11.iloc[:, 0:6].median(axis=1)\n",
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2\n",
    "\n",
    "temp11['is_iceberg_base'] = temp11['is_iceberg5']\n",
    "temp11['is_iceberg'] = np.where(np.all(temp11.iloc[:,0:6] > cutoff_lo, axis=1), \n",
    "                                    temp11['is_iceberg_max'], \n",
    "                                    np.where(np.all(temp11.iloc[:,0:6] < cutoff_hi, axis=1),\n",
    "                                             temp11['is_iceberg_min'], \n",
    "                                             temp11['is_iceberg_base']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['is_iceberg'] = temp11['is_iceberg']#temp11.mean(axis=1)#temp11['is_iceberg33']\n",
    "sub.shape\n",
    "sub.to_csv('submissiony.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s2ms\n"
     ]
    }
   ],
   "source": [
    "net = cnn.plain_cnn(num_classes=2)\n",
    "net.load_state_dict(torch.load('plain_cnn_models/cnn_loss2.pth'))\n",
    "net.cuda()\n",
    "\n",
    "test = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test)\n",
    "test_X.shape \n",
    "fake_label = np.zeros(len(test_X))\n",
    "\n",
    "test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform,test=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "temp11=pd.DataFrame()\n",
    "prob = [] \n",
    "net.eval()\n",
    "for k, (val_x, val_y) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    x = Variable(val_x)\n",
    "    y = Variable(val_y)\n",
    "    out = net(x)\n",
    "    #prevent overflow\n",
    "    temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "    ans= temp[:,1]/(temp.sum(axis=1))\n",
    "    prob.append(ans)\n",
    "    #print(out.size())\n",
    "    progress_bar(k, len(test_loader))\n",
    "msg = 'is_iceberg%d' %5\n",
    "temp11[msg]= np.concatenate(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp11.iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg0</th>\n",
       "      <th>is_iceberg1</th>\n",
       "      <th>is_iceberg2</th>\n",
       "      <th>is_iceberg3</th>\n",
       "      <th>is_iceberg4</th>\n",
       "      <th>is_iceberg5</th>\n",
       "      <th>is_iceberg_max</th>\n",
       "      <th>is_iceberg_min</th>\n",
       "      <th>is_iceberg_median</th>\n",
       "      <th>is_iceberg_base</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.822586</td>\n",
       "      <td>0.648968</td>\n",
       "      <td>0.883101</td>\n",
       "      <td>0.905277</td>\n",
       "      <td>0.682861</td>\n",
       "      <td>0.922862</td>\n",
       "      <td>0.942663</td>\n",
       "      <td>0.905277</td>\n",
       "      <td>0.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg1</th>\n",
       "      <td>0.852644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>0.833295</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.821258</td>\n",
       "      <td>0.777728</td>\n",
       "      <td>0.956190</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.816630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg2</th>\n",
       "      <td>0.822586</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771766</td>\n",
       "      <td>0.774018</td>\n",
       "      <td>0.784324</td>\n",
       "      <td>0.847868</td>\n",
       "      <td>0.738630</td>\n",
       "      <td>0.918857</td>\n",
       "      <td>0.784324</td>\n",
       "      <td>0.785453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg3</th>\n",
       "      <td>0.648968</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>0.771766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>0.940914</td>\n",
       "      <td>0.592617</td>\n",
       "      <td>0.749656</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>0.559032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg4</th>\n",
       "      <td>0.883101</td>\n",
       "      <td>0.833295</td>\n",
       "      <td>0.774018</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>0.685683</td>\n",
       "      <td>0.920097</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>0.827514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg5</th>\n",
       "      <td>0.905277</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.784324</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>0.895245</td>\n",
       "      <td>0.896220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg_max</th>\n",
       "      <td>0.682861</td>\n",
       "      <td>0.821258</td>\n",
       "      <td>0.847868</td>\n",
       "      <td>0.940914</td>\n",
       "      <td>0.685683</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583326</td>\n",
       "      <td>0.792055</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>0.655435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg_min</th>\n",
       "      <td>0.922862</td>\n",
       "      <td>0.777728</td>\n",
       "      <td>0.738630</td>\n",
       "      <td>0.592617</td>\n",
       "      <td>0.920097</td>\n",
       "      <td>0.895245</td>\n",
       "      <td>0.583326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875356</td>\n",
       "      <td>0.895245</td>\n",
       "      <td>0.895989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg_median</th>\n",
       "      <td>0.942663</td>\n",
       "      <td>0.956190</td>\n",
       "      <td>0.918857</td>\n",
       "      <td>0.749656</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.896220</td>\n",
       "      <td>0.792055</td>\n",
       "      <td>0.875356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896220</td>\n",
       "      <td>0.897011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg_base</th>\n",
       "      <td>0.905277</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.784324</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>0.895245</td>\n",
       "      <td>0.896220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg</th>\n",
       "      <td>0.905900</td>\n",
       "      <td>0.816630</td>\n",
       "      <td>0.785453</td>\n",
       "      <td>0.559032</td>\n",
       "      <td>0.827514</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.655435</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>0.897011</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   is_iceberg0  is_iceberg1  is_iceberg2  is_iceberg3  \\\n",
       "is_iceberg0           1.000000     0.852644     0.822586     0.648968   \n",
       "is_iceberg1           0.852644     1.000000     0.905401     0.754710   \n",
       "is_iceberg2           0.822586     0.905401     1.000000     0.771766   \n",
       "is_iceberg3           0.648968     0.754710     0.771766     1.000000   \n",
       "is_iceberg4           0.883101     0.833295     0.774018     0.685649   \n",
       "is_iceberg5           0.905277     0.815734     0.784324     0.556919   \n",
       "is_iceberg_max        0.682861     0.821258     0.847868     0.940914   \n",
       "is_iceberg_min        0.922862     0.777728     0.738630     0.592617   \n",
       "is_iceberg_median     0.942663     0.956190     0.918857     0.749656   \n",
       "is_iceberg_base       0.905277     0.815734     0.784324     0.556919   \n",
       "is_iceberg            0.905900     0.816630     0.785453     0.559032   \n",
       "\n",
       "                   is_iceberg4  is_iceberg5  is_iceberg_max  is_iceberg_min  \\\n",
       "is_iceberg0           0.883101     0.905277        0.682861        0.922862   \n",
       "is_iceberg1           0.833295     0.815734        0.821258        0.777728   \n",
       "is_iceberg2           0.774018     0.784324        0.847868        0.738630   \n",
       "is_iceberg3           0.685649     0.556919        0.940914        0.592617   \n",
       "is_iceberg4           1.000000     0.826391        0.685683        0.920097   \n",
       "is_iceberg5           0.826391     1.000000        0.653849        0.895245   \n",
       "is_iceberg_max        0.685683     0.653849        1.000000        0.583326   \n",
       "is_iceberg_min        0.920097     0.895245        0.583326        1.000000   \n",
       "is_iceberg_median     0.909537     0.896220        0.792055        0.875356   \n",
       "is_iceberg_base       0.826391     1.000000        0.653849        0.895245   \n",
       "is_iceberg            0.827514     0.999683        0.655435        0.895989   \n",
       "\n",
       "                   is_iceberg_median  is_iceberg_base  is_iceberg  \n",
       "is_iceberg0                 0.942663         0.905277    0.905900  \n",
       "is_iceberg1                 0.956190         0.815734    0.816630  \n",
       "is_iceberg2                 0.918857         0.784324    0.785453  \n",
       "is_iceberg3                 0.749656         0.556919    0.559032  \n",
       "is_iceberg4                 0.909537         0.826391    0.827514  \n",
       "is_iceberg5                 0.896220         1.000000    0.999683  \n",
       "is_iceberg_max              0.792055         0.653849    0.655435  \n",
       "is_iceberg_min              0.875356         0.895245    0.895989  \n",
       "is_iceberg_median           1.000000         0.896220    0.897011  \n",
       "is_iceberg_base             0.896220         1.000000    0.999683  \n",
       "is_iceberg                  0.897011         0.999683    1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp11.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  2,  5,  6,  7,  8,  9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22,\n",
      "       23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42,\n",
      "       44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62,\n",
      "       63, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 84, 85,\n",
      "       86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99]), array([ 0,  3,  4, 11, 14, 17, 24, 29, 40, 43, 48, 59, 64, 66, 70, 79, 82,\n",
      "       83, 93, 97]))\n"
     ]
    }
   ],
   "source": [
    "seed= np.random.RandomState(67)\n",
    "spliter = KFold(n_splits=5,shuffle =True,random_state = seed)\n",
    "for i in spliter.split(list(range(100))):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plain_cnn_models/r2_cnn0_30.pth', 'plain_cnn_models/r2_cnn0_31.pth', 'plain_cnn_models/r2_cnn0_01.pth', 'plain_cnn_models/r2_cnn0_12.pth', 'plain_cnn_models/r2_cnn0_00.pth', 'plain_cnn_models/r2_cnn0_11.pth', 'plain_cnn_models/r2_cnn0_10.pth', 'plain_cnn_models/r2_cnn0_40.pth', 'plain_cnn_models/r2_cnn0_20.pth', 'plain_cnn_models/r2_cnn0_21.pth', 'plain_cnn_models/r2_cnn0_41.pth']\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3mss\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n",
      "[========= 132/132 ======>]Step: 0ms| Tot: 1s3ms\n"
     ]
    }
   ],
   "source": [
    "temp11 = pd.DataFrame()\n",
    "\n",
    "##test = pd.read_json(BASE_dir + 'test.json')\n",
    "test_X = raw_to_numpy(test)\n",
    "test_X.shape \n",
    "fake_label = np.zeros(len(test_X))\n",
    "\n",
    "test_dataset = iceberg_dataset(data= test_X, label=fake_label, transform=train_transform,test=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, num_workers=3)\n",
    "\n",
    "waiting_list = [os.path.join('plain_cnn_models',i) for i in os.listdir(path='plain_cnn_models') if '.pth' in i and 'r2_' in i]\n",
    "print(waiting_list)\n",
    "for i,pth in enumerate(waiting_list):\n",
    "    net = cnn.plain_cnn(num_classes=2)\n",
    "    net.load_state_dict(torch.load(pth))\n",
    "    net.cuda()\n",
    "    prob = [] \n",
    "    net.eval()\n",
    "    for k, (val_x, val_y) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "        x = Variable(val_x)\n",
    "        y = Variable(val_y)\n",
    "        out = net(x)\n",
    "        #prevent overflow\n",
    "        temp = np.exp(out.cpu().data.numpy()-np.max(out.cpu().data.numpy(),axis=1)[:,np.newaxis])\n",
    "        ans= temp[:,1]/(temp.sum(axis=1))\n",
    "        prob.append(ans)\n",
    "        #print(out.size())\n",
    "        progress_bar(k, len(test_loader))\n",
    "    msg = 'is_iceberg%d' % i\n",
    "    temp11[msg]= np.concatenate(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_cnn_models/cnn1_40.pth\n",
      "plain_cnn_models/cnn3_40.pth\n",
      "plain_cnn_models/cnn2_31.pth\n",
      "plain_cnn_models/cnn5_20.pth\n",
      "plain_cnn_models/cnn7_21.pth\n",
      "plain_cnn_models/cnn7_40.pth\n",
      "plain_cnn_models/cnn2_11.pth\n",
      "plain_cnn_models/cnn6_30.pth\n",
      "plain_cnn_models/cnn3_42.pth\n",
      "plain_cnn_models/cnn5_00.pth\n",
      "plain_cnn_models/cnn0_31.pth\n",
      "plain_cnn_models/cnn9_31.pth\n",
      "plain_cnn_models/cnn4_01.pth\n",
      "plain_cnn_models/cnn3_00.pth\n",
      "plain_cnn_models/cnn2_00.pth\n",
      "plain_cnn_models/cnn_loss0.pth\n",
      "plain_cnn_models/cnn4_20.pth\n",
      "plain_cnn_models/cnn3_31.pth\n",
      "plain_cnn_models/cnn8_20.pth\n",
      "plain_cnn_models/cnn1_31.pth\n",
      "plain_cnn_models/cnn8_01.pth\n",
      "plain_cnn_models/cnn7_11.pth\n",
      "plain_cnn_models/cnn5_40.pth\n",
      "plain_cnn_models/cnn5_30.pth\n",
      "plain_cnn_models/cnn9_40.pth\n",
      "plain_cnn_models/cnn4_40.pth\n",
      "plain_cnn_models/cnn2_01.pth\n",
      "plain_cnn_models/cnn_loss1.pth\n",
      "plain_cnn_models/cnn0_30.pth\n",
      "plain_cnn_models/cnn0_32.pth\n",
      "plain_cnn_models/cnn2_02.pth\n",
      "plain_cnn_models/cnn0_01.pth\n",
      "plain_cnn_models/cnn8_30.pth\n",
      "plain_cnn_models/cnn3_41.pth\n",
      "plain_cnn_models/cnn4_10.pth\n",
      "plain_cnn_models/cnn1_11.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waiting_list = [os.path.join('plain_cnn_models',i) for i in os.listdir(path='plain_cnn_models') if '.pth' in i and 'r2_' not in i]\n",
    "for i in waiting_list:\n",
    "    print(i)\n",
    "len(waiting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['is_iceberg'] = temp11.mean(axis=1)#temp11['is_iceberg']\n",
    "sub.shape\n",
    "sub.to_csv('submissiony.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg0</th>\n",
       "      <th>is_iceberg1</th>\n",
       "      <th>is_iceberg2</th>\n",
       "      <th>is_iceberg3</th>\n",
       "      <th>is_iceberg4</th>\n",
       "      <th>is_iceberg5</th>\n",
       "      <th>is_iceberg6</th>\n",
       "      <th>is_iceberg7</th>\n",
       "      <th>is_iceberg8</th>\n",
       "      <th>is_iceberg9</th>\n",
       "      <th>...</th>\n",
       "      <th>is_iceberg26</th>\n",
       "      <th>is_iceberg27</th>\n",
       "      <th>is_iceberg28</th>\n",
       "      <th>is_iceberg29</th>\n",
       "      <th>is_iceberg30</th>\n",
       "      <th>is_iceberg31</th>\n",
       "      <th>is_iceberg32</th>\n",
       "      <th>is_iceberg33</th>\n",
       "      <th>is_iceberg34</th>\n",
       "      <th>is_iceberg35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886005</td>\n",
       "      <td>0.945239</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.961746</td>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.895530</td>\n",
       "      <td>0.881383</td>\n",
       "      <td>0.867011</td>\n",
       "      <td>0.951947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.088594</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.926176</td>\n",
       "      <td>0.869743</td>\n",
       "      <td>0.922891</td>\n",
       "      <td>0.952035</td>\n",
       "      <td>0.902627</td>\n",
       "      <td>0.951503</td>\n",
       "      <td>0.793508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg1</th>\n",
       "      <td>0.886005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910941</td>\n",
       "      <td>0.894064</td>\n",
       "      <td>0.894448</td>\n",
       "      <td>0.915965</td>\n",
       "      <td>0.929925</td>\n",
       "      <td>0.909491</td>\n",
       "      <td>0.936892</td>\n",
       "      <td>0.907599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909919</td>\n",
       "      <td>0.066279</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.928522</td>\n",
       "      <td>0.873471</td>\n",
       "      <td>0.908133</td>\n",
       "      <td>0.947372</td>\n",
       "      <td>0.902606</td>\n",
       "      <td>0.883981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg2</th>\n",
       "      <td>0.945239</td>\n",
       "      <td>0.910941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920643</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>0.937435</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.911239</td>\n",
       "      <td>0.906097</td>\n",
       "      <td>0.956059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947092</td>\n",
       "      <td>0.087929</td>\n",
       "      <td>0.947277</td>\n",
       "      <td>0.944061</td>\n",
       "      <td>0.904865</td>\n",
       "      <td>0.930772</td>\n",
       "      <td>0.936671</td>\n",
       "      <td>0.924767</td>\n",
       "      <td>0.944818</td>\n",
       "      <td>0.834233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg3</th>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.894064</td>\n",
       "      <td>0.920643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910353</td>\n",
       "      <td>0.942054</td>\n",
       "      <td>0.915012</td>\n",
       "      <td>0.927950</td>\n",
       "      <td>0.911129</td>\n",
       "      <td>0.897441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0.062156</td>\n",
       "      <td>0.926018</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.898069</td>\n",
       "      <td>0.915951</td>\n",
       "      <td>0.883089</td>\n",
       "      <td>0.910914</td>\n",
       "      <td>0.907002</td>\n",
       "      <td>0.875220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg4</th>\n",
       "      <td>0.961746</td>\n",
       "      <td>0.894448</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>0.910353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930269</td>\n",
       "      <td>0.906581</td>\n",
       "      <td>0.892352</td>\n",
       "      <td>0.882816</td>\n",
       "      <td>0.957334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957036</td>\n",
       "      <td>0.094493</td>\n",
       "      <td>0.935350</td>\n",
       "      <td>0.930508</td>\n",
       "      <td>0.890869</td>\n",
       "      <td>0.931706</td>\n",
       "      <td>0.948346</td>\n",
       "      <td>0.913297</td>\n",
       "      <td>0.953171</td>\n",
       "      <td>0.812676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg5</th>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.915965</td>\n",
       "      <td>0.937435</td>\n",
       "      <td>0.942054</td>\n",
       "      <td>0.930269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>0.929974</td>\n",
       "      <td>0.919583</td>\n",
       "      <td>0.927823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932589</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.952359</td>\n",
       "      <td>0.950957</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.915178</td>\n",
       "      <td>0.917951</td>\n",
       "      <td>0.928878</td>\n",
       "      <td>0.931390</td>\n",
       "      <td>0.884461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg6</th>\n",
       "      <td>0.895530</td>\n",
       "      <td>0.929925</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.915012</td>\n",
       "      <td>0.906581</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.925709</td>\n",
       "      <td>0.904934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926457</td>\n",
       "      <td>0.071477</td>\n",
       "      <td>0.933033</td>\n",
       "      <td>0.941807</td>\n",
       "      <td>0.921128</td>\n",
       "      <td>0.894341</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.919089</td>\n",
       "      <td>0.875645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg7</th>\n",
       "      <td>0.881383</td>\n",
       "      <td>0.909491</td>\n",
       "      <td>0.911239</td>\n",
       "      <td>0.927950</td>\n",
       "      <td>0.892352</td>\n",
       "      <td>0.929974</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934032</td>\n",
       "      <td>0.894697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912269</td>\n",
       "      <td>0.070057</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.926375</td>\n",
       "      <td>0.915239</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.892756</td>\n",
       "      <td>0.911654</td>\n",
       "      <td>0.910635</td>\n",
       "      <td>0.902428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg8</th>\n",
       "      <td>0.867011</td>\n",
       "      <td>0.936892</td>\n",
       "      <td>0.906097</td>\n",
       "      <td>0.911129</td>\n",
       "      <td>0.882816</td>\n",
       "      <td>0.919583</td>\n",
       "      <td>0.925709</td>\n",
       "      <td>0.934032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906144</td>\n",
       "      <td>0.064745</td>\n",
       "      <td>0.919891</td>\n",
       "      <td>0.925759</td>\n",
       "      <td>0.924279</td>\n",
       "      <td>0.883315</td>\n",
       "      <td>0.884952</td>\n",
       "      <td>0.930506</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>0.909133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg9</th>\n",
       "      <td>0.951947</td>\n",
       "      <td>0.907599</td>\n",
       "      <td>0.956059</td>\n",
       "      <td>0.897441</td>\n",
       "      <td>0.957334</td>\n",
       "      <td>0.927823</td>\n",
       "      <td>0.904934</td>\n",
       "      <td>0.894697</td>\n",
       "      <td>0.895291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950517</td>\n",
       "      <td>0.088518</td>\n",
       "      <td>0.938949</td>\n",
       "      <td>0.926815</td>\n",
       "      <td>0.898259</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.919939</td>\n",
       "      <td>0.941562</td>\n",
       "      <td>0.828865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg10</th>\n",
       "      <td>0.935544</td>\n",
       "      <td>0.911262</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.914471</td>\n",
       "      <td>0.943653</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.909638</td>\n",
       "      <td>0.903458</td>\n",
       "      <td>0.901941</td>\n",
       "      <td>0.942534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926452</td>\n",
       "      <td>0.081999</td>\n",
       "      <td>0.956006</td>\n",
       "      <td>0.942642</td>\n",
       "      <td>0.907039</td>\n",
       "      <td>0.909060</td>\n",
       "      <td>0.929340</td>\n",
       "      <td>0.919688</td>\n",
       "      <td>0.931074</td>\n",
       "      <td>0.837710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg11</th>\n",
       "      <td>0.928685</td>\n",
       "      <td>0.904451</td>\n",
       "      <td>0.933807</td>\n",
       "      <td>0.898394</td>\n",
       "      <td>0.931139</td>\n",
       "      <td>0.924136</td>\n",
       "      <td>0.908832</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>0.892132</td>\n",
       "      <td>0.915750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923470</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.934992</td>\n",
       "      <td>0.927282</td>\n",
       "      <td>0.889692</td>\n",
       "      <td>0.907828</td>\n",
       "      <td>0.918566</td>\n",
       "      <td>0.921281</td>\n",
       "      <td>0.929350</td>\n",
       "      <td>0.821828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg12</th>\n",
       "      <td>0.891924</td>\n",
       "      <td>0.920565</td>\n",
       "      <td>0.925655</td>\n",
       "      <td>0.936457</td>\n",
       "      <td>0.908818</td>\n",
       "      <td>0.954651</td>\n",
       "      <td>0.934036</td>\n",
       "      <td>0.935581</td>\n",
       "      <td>0.931889</td>\n",
       "      <td>0.914287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919917</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.942806</td>\n",
       "      <td>0.939938</td>\n",
       "      <td>0.933286</td>\n",
       "      <td>0.903499</td>\n",
       "      <td>0.903828</td>\n",
       "      <td>0.928081</td>\n",
       "      <td>0.914106</td>\n",
       "      <td>0.899084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg13</th>\n",
       "      <td>0.921493</td>\n",
       "      <td>0.926653</td>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.922324</td>\n",
       "      <td>0.932829</td>\n",
       "      <td>0.943569</td>\n",
       "      <td>0.950314</td>\n",
       "      <td>0.926211</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.929106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946055</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.941259</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.914126</td>\n",
       "      <td>0.918454</td>\n",
       "      <td>0.921118</td>\n",
       "      <td>0.938024</td>\n",
       "      <td>0.875464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg14</th>\n",
       "      <td>0.915359</td>\n",
       "      <td>0.929844</td>\n",
       "      <td>0.943292</td>\n",
       "      <td>0.923113</td>\n",
       "      <td>0.933339</td>\n",
       "      <td>0.944466</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>0.928226</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>0.930982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945275</td>\n",
       "      <td>0.064281</td>\n",
       "      <td>0.944984</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>0.948133</td>\n",
       "      <td>0.902527</td>\n",
       "      <td>0.922793</td>\n",
       "      <td>0.933184</td>\n",
       "      <td>0.933367</td>\n",
       "      <td>0.871867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg15</th>\n",
       "      <td>0.191458</td>\n",
       "      <td>0.177923</td>\n",
       "      <td>0.197546</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.198923</td>\n",
       "      <td>0.192286</td>\n",
       "      <td>0.178910</td>\n",
       "      <td>0.168759</td>\n",
       "      <td>0.161142</td>\n",
       "      <td>0.196079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177872</td>\n",
       "      <td>0.740287</td>\n",
       "      <td>0.196151</td>\n",
       "      <td>0.185018</td>\n",
       "      <td>0.158335</td>\n",
       "      <td>0.173974</td>\n",
       "      <td>0.198705</td>\n",
       "      <td>0.197217</td>\n",
       "      <td>0.171121</td>\n",
       "      <td>0.135614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg16</th>\n",
       "      <td>0.942723</td>\n",
       "      <td>0.905560</td>\n",
       "      <td>0.945395</td>\n",
       "      <td>0.911697</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>0.928096</td>\n",
       "      <td>0.913310</td>\n",
       "      <td>0.904730</td>\n",
       "      <td>0.896114</td>\n",
       "      <td>0.952341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959708</td>\n",
       "      <td>0.092122</td>\n",
       "      <td>0.929586</td>\n",
       "      <td>0.935153</td>\n",
       "      <td>0.906701</td>\n",
       "      <td>0.922313</td>\n",
       "      <td>0.936941</td>\n",
       "      <td>0.909143</td>\n",
       "      <td>0.947383</td>\n",
       "      <td>0.845734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg17</th>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.926425</td>\n",
       "      <td>0.924865</td>\n",
       "      <td>0.902405</td>\n",
       "      <td>0.914159</td>\n",
       "      <td>0.935391</td>\n",
       "      <td>0.930025</td>\n",
       "      <td>0.919523</td>\n",
       "      <td>0.918289</td>\n",
       "      <td>0.926645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930651</td>\n",
       "      <td>0.068013</td>\n",
       "      <td>0.939379</td>\n",
       "      <td>0.941027</td>\n",
       "      <td>0.911416</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.930441</td>\n",
       "      <td>0.935077</td>\n",
       "      <td>0.923369</td>\n",
       "      <td>0.874275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg18</th>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.908707</td>\n",
       "      <td>0.918197</td>\n",
       "      <td>0.906671</td>\n",
       "      <td>0.905257</td>\n",
       "      <td>0.930768</td>\n",
       "      <td>0.930320</td>\n",
       "      <td>0.914115</td>\n",
       "      <td>0.911474</td>\n",
       "      <td>0.911181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921935</td>\n",
       "      <td>0.066651</td>\n",
       "      <td>0.929794</td>\n",
       "      <td>0.929087</td>\n",
       "      <td>0.910098</td>\n",
       "      <td>0.905948</td>\n",
       "      <td>0.900611</td>\n",
       "      <td>0.918289</td>\n",
       "      <td>0.910266</td>\n",
       "      <td>0.871722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg19</th>\n",
       "      <td>0.928462</td>\n",
       "      <td>0.913579</td>\n",
       "      <td>0.943273</td>\n",
       "      <td>0.906754</td>\n",
       "      <td>0.937448</td>\n",
       "      <td>0.921945</td>\n",
       "      <td>0.929887</td>\n",
       "      <td>0.900722</td>\n",
       "      <td>0.899380</td>\n",
       "      <td>0.921856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937389</td>\n",
       "      <td>0.084151</td>\n",
       "      <td>0.931860</td>\n",
       "      <td>0.944696</td>\n",
       "      <td>0.897822</td>\n",
       "      <td>0.917085</td>\n",
       "      <td>0.925086</td>\n",
       "      <td>0.929153</td>\n",
       "      <td>0.930885</td>\n",
       "      <td>0.827150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg20</th>\n",
       "      <td>0.926795</td>\n",
       "      <td>0.886252</td>\n",
       "      <td>0.935875</td>\n",
       "      <td>0.913590</td>\n",
       "      <td>0.930565</td>\n",
       "      <td>0.914930</td>\n",
       "      <td>0.905828</td>\n",
       "      <td>0.912376</td>\n",
       "      <td>0.898533</td>\n",
       "      <td>0.921786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939984</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>0.905097</td>\n",
       "      <td>0.931990</td>\n",
       "      <td>0.875849</td>\n",
       "      <td>0.932792</td>\n",
       "      <td>0.917954</td>\n",
       "      <td>0.903149</td>\n",
       "      <td>0.942449</td>\n",
       "      <td>0.828441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg21</th>\n",
       "      <td>0.942963</td>\n",
       "      <td>0.923103</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.913526</td>\n",
       "      <td>0.943854</td>\n",
       "      <td>0.941688</td>\n",
       "      <td>0.928771</td>\n",
       "      <td>0.899672</td>\n",
       "      <td>0.897639</td>\n",
       "      <td>0.944616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938097</td>\n",
       "      <td>0.085737</td>\n",
       "      <td>0.951688</td>\n",
       "      <td>0.941592</td>\n",
       "      <td>0.910678</td>\n",
       "      <td>0.904530</td>\n",
       "      <td>0.943474</td>\n",
       "      <td>0.935986</td>\n",
       "      <td>0.929507</td>\n",
       "      <td>0.835784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg22</th>\n",
       "      <td>0.962444</td>\n",
       "      <td>0.896284</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.896769</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.917116</td>\n",
       "      <td>0.895665</td>\n",
       "      <td>0.892160</td>\n",
       "      <td>0.880763</td>\n",
       "      <td>0.952621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948301</td>\n",
       "      <td>0.098416</td>\n",
       "      <td>0.926431</td>\n",
       "      <td>0.928172</td>\n",
       "      <td>0.882041</td>\n",
       "      <td>0.926156</td>\n",
       "      <td>0.955661</td>\n",
       "      <td>0.915942</td>\n",
       "      <td>0.947242</td>\n",
       "      <td>0.797847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg23</th>\n",
       "      <td>0.944624</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.940265</td>\n",
       "      <td>0.892577</td>\n",
       "      <td>0.946739</td>\n",
       "      <td>0.918625</td>\n",
       "      <td>0.910238</td>\n",
       "      <td>0.890747</td>\n",
       "      <td>0.884456</td>\n",
       "      <td>0.937056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938063</td>\n",
       "      <td>0.090263</td>\n",
       "      <td>0.931772</td>\n",
       "      <td>0.929205</td>\n",
       "      <td>0.891914</td>\n",
       "      <td>0.909700</td>\n",
       "      <td>0.942513</td>\n",
       "      <td>0.930015</td>\n",
       "      <td>0.932835</td>\n",
       "      <td>0.813610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg24</th>\n",
       "      <td>0.945266</td>\n",
       "      <td>0.881141</td>\n",
       "      <td>0.945334</td>\n",
       "      <td>0.900634</td>\n",
       "      <td>0.939727</td>\n",
       "      <td>0.906986</td>\n",
       "      <td>0.887938</td>\n",
       "      <td>0.892230</td>\n",
       "      <td>0.875402</td>\n",
       "      <td>0.930464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933188</td>\n",
       "      <td>0.089334</td>\n",
       "      <td>0.916477</td>\n",
       "      <td>0.927141</td>\n",
       "      <td>0.860627</td>\n",
       "      <td>0.928308</td>\n",
       "      <td>0.924065</td>\n",
       "      <td>0.908934</td>\n",
       "      <td>0.938328</td>\n",
       "      <td>0.801613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg25</th>\n",
       "      <td>0.936910</td>\n",
       "      <td>0.913118</td>\n",
       "      <td>0.953011</td>\n",
       "      <td>0.941938</td>\n",
       "      <td>0.953236</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>0.934689</td>\n",
       "      <td>0.915149</td>\n",
       "      <td>0.942753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.077750</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.921757</td>\n",
       "      <td>0.938836</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>0.928816</td>\n",
       "      <td>0.942454</td>\n",
       "      <td>0.871154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg26</th>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.909919</td>\n",
       "      <td>0.947092</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0.957036</td>\n",
       "      <td>0.932589</td>\n",
       "      <td>0.926457</td>\n",
       "      <td>0.912269</td>\n",
       "      <td>0.906144</td>\n",
       "      <td>0.950517</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>0.932780</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.917770</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.942016</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.844448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg27</th>\n",
       "      <td>0.088594</td>\n",
       "      <td>0.066279</td>\n",
       "      <td>0.087929</td>\n",
       "      <td>0.062156</td>\n",
       "      <td>0.094493</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.071477</td>\n",
       "      <td>0.070057</td>\n",
       "      <td>0.064745</td>\n",
       "      <td>0.088518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>0.085074</td>\n",
       "      <td>0.079385</td>\n",
       "      <td>0.083264</td>\n",
       "      <td>0.038075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg28</th>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>0.947277</td>\n",
       "      <td>0.926018</td>\n",
       "      <td>0.935350</td>\n",
       "      <td>0.952359</td>\n",
       "      <td>0.933033</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.919891</td>\n",
       "      <td>0.938949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932780</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952496</td>\n",
       "      <td>0.930042</td>\n",
       "      <td>0.910887</td>\n",
       "      <td>0.924481</td>\n",
       "      <td>0.942131</td>\n",
       "      <td>0.931641</td>\n",
       "      <td>0.868692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg29</th>\n",
       "      <td>0.926176</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.944061</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.930508</td>\n",
       "      <td>0.950957</td>\n",
       "      <td>0.941807</td>\n",
       "      <td>0.926375</td>\n",
       "      <td>0.925759</td>\n",
       "      <td>0.926815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.952496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919828</td>\n",
       "      <td>0.912110</td>\n",
       "      <td>0.920245</td>\n",
       "      <td>0.933280</td>\n",
       "      <td>0.935788</td>\n",
       "      <td>0.873284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg30</th>\n",
       "      <td>0.869743</td>\n",
       "      <td>0.928522</td>\n",
       "      <td>0.904865</td>\n",
       "      <td>0.898069</td>\n",
       "      <td>0.890869</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.921128</td>\n",
       "      <td>0.915239</td>\n",
       "      <td>0.924279</td>\n",
       "      <td>0.898259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917770</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.930042</td>\n",
       "      <td>0.919828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866449</td>\n",
       "      <td>0.887004</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.902745</td>\n",
       "      <td>0.904976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg31</th>\n",
       "      <td>0.922891</td>\n",
       "      <td>0.873471</td>\n",
       "      <td>0.930772</td>\n",
       "      <td>0.915951</td>\n",
       "      <td>0.931706</td>\n",
       "      <td>0.915178</td>\n",
       "      <td>0.894341</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.883315</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>0.910887</td>\n",
       "      <td>0.912110</td>\n",
       "      <td>0.866449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919369</td>\n",
       "      <td>0.901564</td>\n",
       "      <td>0.933263</td>\n",
       "      <td>0.829924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg32</th>\n",
       "      <td>0.952035</td>\n",
       "      <td>0.908133</td>\n",
       "      <td>0.936671</td>\n",
       "      <td>0.883089</td>\n",
       "      <td>0.948346</td>\n",
       "      <td>0.917951</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.892756</td>\n",
       "      <td>0.884952</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942016</td>\n",
       "      <td>0.085074</td>\n",
       "      <td>0.924481</td>\n",
       "      <td>0.920245</td>\n",
       "      <td>0.887004</td>\n",
       "      <td>0.919369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922719</td>\n",
       "      <td>0.940614</td>\n",
       "      <td>0.814280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg33</th>\n",
       "      <td>0.902627</td>\n",
       "      <td>0.947372</td>\n",
       "      <td>0.924767</td>\n",
       "      <td>0.910914</td>\n",
       "      <td>0.913297</td>\n",
       "      <td>0.928878</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.911654</td>\n",
       "      <td>0.930506</td>\n",
       "      <td>0.919939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.079385</td>\n",
       "      <td>0.942131</td>\n",
       "      <td>0.933280</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.901564</td>\n",
       "      <td>0.922719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914009</td>\n",
       "      <td>0.858465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg34</th>\n",
       "      <td>0.951503</td>\n",
       "      <td>0.902606</td>\n",
       "      <td>0.944818</td>\n",
       "      <td>0.907002</td>\n",
       "      <td>0.953171</td>\n",
       "      <td>0.931390</td>\n",
       "      <td>0.919089</td>\n",
       "      <td>0.910635</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>0.941562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.083264</td>\n",
       "      <td>0.931641</td>\n",
       "      <td>0.935788</td>\n",
       "      <td>0.902745</td>\n",
       "      <td>0.933263</td>\n",
       "      <td>0.940614</td>\n",
       "      <td>0.914009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg35</th>\n",
       "      <td>0.793508</td>\n",
       "      <td>0.883981</td>\n",
       "      <td>0.834233</td>\n",
       "      <td>0.875220</td>\n",
       "      <td>0.812676</td>\n",
       "      <td>0.884461</td>\n",
       "      <td>0.875645</td>\n",
       "      <td>0.902428</td>\n",
       "      <td>0.909133</td>\n",
       "      <td>0.828865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844448</td>\n",
       "      <td>0.038075</td>\n",
       "      <td>0.868692</td>\n",
       "      <td>0.873284</td>\n",
       "      <td>0.904976</td>\n",
       "      <td>0.829924</td>\n",
       "      <td>0.814280</td>\n",
       "      <td>0.858465</td>\n",
       "      <td>0.847099</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_iceberg0  is_iceberg1  is_iceberg2  is_iceberg3  is_iceberg4  \\\n",
       "is_iceberg0      1.000000     0.886005     0.945239     0.891328     0.961746   \n",
       "is_iceberg1      0.886005     1.000000     0.910941     0.894064     0.894448   \n",
       "is_iceberg2      0.945239     0.910941     1.000000     0.920643     0.957490   \n",
       "is_iceberg3      0.891328     0.894064     0.920643     1.000000     0.910353   \n",
       "is_iceberg4      0.961746     0.894448     0.957490     0.910353     1.000000   \n",
       "is_iceberg5      0.917887     0.915965     0.937435     0.942054     0.930269   \n",
       "is_iceberg6      0.895530     0.929925     0.917559     0.915012     0.906581   \n",
       "is_iceberg7      0.881383     0.909491     0.911239     0.927950     0.892352   \n",
       "is_iceberg8      0.867011     0.936892     0.906097     0.911129     0.882816   \n",
       "is_iceberg9      0.951947     0.907599     0.956059     0.897441     0.957334   \n",
       "is_iceberg10     0.935544     0.911262     0.950311     0.914471     0.943653   \n",
       "is_iceberg11     0.928685     0.904451     0.933807     0.898394     0.931139   \n",
       "is_iceberg12     0.891924     0.920565     0.925655     0.936457     0.908818   \n",
       "is_iceberg13     0.921493     0.926653     0.942906     0.922324     0.932829   \n",
       "is_iceberg14     0.915359     0.929844     0.943292     0.923113     0.933339   \n",
       "is_iceberg15     0.191458     0.177923     0.197546     0.167203     0.198923   \n",
       "is_iceberg16     0.942723     0.905560     0.945395     0.911697     0.956543   \n",
       "is_iceberg17     0.917266     0.926425     0.924865     0.902405     0.914159   \n",
       "is_iceberg18     0.897565     0.908707     0.918197     0.906671     0.905257   \n",
       "is_iceberg19     0.928462     0.913579     0.943273     0.906754     0.937448   \n",
       "is_iceberg20     0.926795     0.886252     0.935875     0.913590     0.930565   \n",
       "is_iceberg21     0.942963     0.923103     0.949392     0.913526     0.943854   \n",
       "is_iceberg22     0.962444     0.896284     0.956000     0.896769     0.964528   \n",
       "is_iceberg23     0.944624     0.911717     0.940265     0.892577     0.946739   \n",
       "is_iceberg24     0.945266     0.881141     0.945334     0.900634     0.939727   \n",
       "is_iceberg25     0.936910     0.913118     0.953011     0.941938     0.953236   \n",
       "is_iceberg26     0.946088     0.909919     0.947092     0.914600     0.957036   \n",
       "is_iceberg27     0.088594     0.066279     0.087929     0.062156     0.094493   \n",
       "is_iceberg28     0.927444     0.933108     0.947277     0.926018     0.935350   \n",
       "is_iceberg29     0.926176     0.926675     0.944061     0.934498     0.930508   \n",
       "is_iceberg30     0.869743     0.928522     0.904865     0.898069     0.890869   \n",
       "is_iceberg31     0.922891     0.873471     0.930772     0.915951     0.931706   \n",
       "is_iceberg32     0.952035     0.908133     0.936671     0.883089     0.948346   \n",
       "is_iceberg33     0.902627     0.947372     0.924767     0.910914     0.913297   \n",
       "is_iceberg34     0.951503     0.902606     0.944818     0.907002     0.953171   \n",
       "is_iceberg35     0.793508     0.883981     0.834233     0.875220     0.812676   \n",
       "\n",
       "              is_iceberg5  is_iceberg6  is_iceberg7  is_iceberg8  is_iceberg9  \\\n",
       "is_iceberg0      0.917887     0.895530     0.881383     0.867011     0.951947   \n",
       "is_iceberg1      0.915965     0.929925     0.909491     0.936892     0.907599   \n",
       "is_iceberg2      0.937435     0.917559     0.911239     0.906097     0.956059   \n",
       "is_iceberg3      0.942054     0.915012     0.927950     0.911129     0.897441   \n",
       "is_iceberg4      0.930269     0.906581     0.892352     0.882816     0.957334   \n",
       "is_iceberg5      1.000000     0.937750     0.929974     0.919583     0.927823   \n",
       "is_iceberg6      0.937750     1.000000     0.916932     0.925709     0.904934   \n",
       "is_iceberg7      0.929974     0.916932     1.000000     0.934032     0.894697   \n",
       "is_iceberg8      0.919583     0.925709     0.934032     1.000000     0.895291   \n",
       "is_iceberg9      0.927823     0.904934     0.894697     0.895291     1.000000   \n",
       "is_iceberg10     0.935407     0.909638     0.903458     0.901941     0.942534   \n",
       "is_iceberg11     0.924136     0.908832     0.891572     0.892132     0.915750   \n",
       "is_iceberg12     0.954651     0.934036     0.935581     0.931889     0.914287   \n",
       "is_iceberg13     0.943569     0.950314     0.926211     0.919322     0.929106   \n",
       "is_iceberg14     0.944466     0.930517     0.928226     0.926899     0.930982   \n",
       "is_iceberg15     0.192286     0.178910     0.168759     0.161142     0.196079   \n",
       "is_iceberg16     0.928096     0.913310     0.904730     0.896114     0.952341   \n",
       "is_iceberg17     0.935391     0.930025     0.919523     0.918289     0.926645   \n",
       "is_iceberg18     0.930768     0.930320     0.914115     0.911474     0.911181   \n",
       "is_iceberg19     0.921945     0.929887     0.900722     0.899380     0.921856   \n",
       "is_iceberg20     0.914930     0.905828     0.912376     0.898533     0.921786   \n",
       "is_iceberg21     0.941688     0.928771     0.899672     0.897639     0.944616   \n",
       "is_iceberg22     0.917116     0.895665     0.892160     0.880763     0.952621   \n",
       "is_iceberg23     0.918625     0.910238     0.890747     0.884456     0.937056   \n",
       "is_iceberg24     0.906986     0.887938     0.892230     0.875402     0.930464   \n",
       "is_iceberg25     0.954645     0.931580     0.934689     0.915149     0.942753   \n",
       "is_iceberg26     0.932589     0.926457     0.912269     0.906144     0.950517   \n",
       "is_iceberg27     0.079600     0.071477     0.070057     0.064745     0.088518   \n",
       "is_iceberg28     0.952359     0.933033     0.915333     0.919891     0.938949   \n",
       "is_iceberg29     0.950957     0.941807     0.926375     0.925759     0.926815   \n",
       "is_iceberg30     0.928696     0.921128     0.915239     0.924279     0.898259   \n",
       "is_iceberg31     0.915178     0.894341     0.903366     0.883315     0.920568   \n",
       "is_iceberg32     0.917951     0.899761     0.892756     0.884952     0.958667   \n",
       "is_iceberg33     0.928878     0.925592     0.911654     0.930506     0.919939   \n",
       "is_iceberg34     0.931390     0.919089     0.910635     0.900361     0.941562   \n",
       "is_iceberg35     0.884461     0.875645     0.902428     0.909133     0.828865   \n",
       "\n",
       "                  ...       is_iceberg26  is_iceberg27  is_iceberg28  \\\n",
       "is_iceberg0       ...           0.946088      0.088594      0.927444   \n",
       "is_iceberg1       ...           0.909919      0.066279      0.933108   \n",
       "is_iceberg2       ...           0.947092      0.087929      0.947277   \n",
       "is_iceberg3       ...           0.914600      0.062156      0.926018   \n",
       "is_iceberg4       ...           0.957036      0.094493      0.935350   \n",
       "is_iceberg5       ...           0.932589      0.079600      0.952359   \n",
       "is_iceberg6       ...           0.926457      0.071477      0.933033   \n",
       "is_iceberg7       ...           0.912269      0.070057      0.915333   \n",
       "is_iceberg8       ...           0.906144      0.064745      0.919891   \n",
       "is_iceberg9       ...           0.950517      0.088518      0.938949   \n",
       "is_iceberg10      ...           0.926452      0.081999      0.956006   \n",
       "is_iceberg11      ...           0.923470      0.092945      0.934992   \n",
       "is_iceberg12      ...           0.919917      0.052174      0.942806   \n",
       "is_iceberg13      ...           0.946055      0.071454      0.941259   \n",
       "is_iceberg14      ...           0.945275      0.064281      0.944984   \n",
       "is_iceberg15      ...           0.177872      0.740287      0.196151   \n",
       "is_iceberg16      ...           0.959708      0.092122      0.929586   \n",
       "is_iceberg17      ...           0.930651      0.068013      0.939379   \n",
       "is_iceberg18      ...           0.921935      0.066651      0.929794   \n",
       "is_iceberg19      ...           0.937389      0.084151      0.931860   \n",
       "is_iceberg20      ...           0.939984      0.081265      0.905097   \n",
       "is_iceberg21      ...           0.938097      0.085737      0.951688   \n",
       "is_iceberg22      ...           0.948301      0.098416      0.926431   \n",
       "is_iceberg23      ...           0.938063      0.090263      0.931772   \n",
       "is_iceberg24      ...           0.933188      0.089334      0.916477   \n",
       "is_iceberg25      ...           0.954716      0.077750      0.949534   \n",
       "is_iceberg26      ...           1.000000      0.082424      0.932780   \n",
       "is_iceberg27      ...           0.082424      1.000000      0.083250   \n",
       "is_iceberg28      ...           0.932780      0.083250      1.000000   \n",
       "is_iceberg29      ...           0.942802      0.078732      0.952496   \n",
       "is_iceberg30      ...           0.917770      0.052278      0.930042   \n",
       "is_iceberg31      ...           0.931100      0.077990      0.910887   \n",
       "is_iceberg32      ...           0.942016      0.085074      0.924481   \n",
       "is_iceberg33      ...           0.918424      0.079385      0.942131   \n",
       "is_iceberg34      ...           0.951909      0.083264      0.931641   \n",
       "is_iceberg35      ...           0.844448      0.038075      0.868692   \n",
       "\n",
       "              is_iceberg29  is_iceberg30  is_iceberg31  is_iceberg32  \\\n",
       "is_iceberg0       0.926176      0.869743      0.922891      0.952035   \n",
       "is_iceberg1       0.926675      0.928522      0.873471      0.908133   \n",
       "is_iceberg2       0.944061      0.904865      0.930772      0.936671   \n",
       "is_iceberg3       0.934498      0.898069      0.915951      0.883089   \n",
       "is_iceberg4       0.930508      0.890869      0.931706      0.948346   \n",
       "is_iceberg5       0.950957      0.928696      0.915178      0.917951   \n",
       "is_iceberg6       0.941807      0.921128      0.894341      0.899761   \n",
       "is_iceberg7       0.926375      0.915239      0.903366      0.892756   \n",
       "is_iceberg8       0.925759      0.924279      0.883315      0.884952   \n",
       "is_iceberg9       0.926815      0.898259      0.920568      0.958667   \n",
       "is_iceberg10      0.942642      0.907039      0.909060      0.929340   \n",
       "is_iceberg11      0.927282      0.889692      0.907828      0.918566   \n",
       "is_iceberg12      0.939938      0.933286      0.903499      0.903828   \n",
       "is_iceberg13      0.954248      0.932008      0.914126      0.918454   \n",
       "is_iceberg14      0.940661      0.948133      0.902527      0.922793   \n",
       "is_iceberg15      0.185018      0.158335      0.173974      0.198705   \n",
       "is_iceberg16      0.935153      0.906701      0.922313      0.936941   \n",
       "is_iceberg17      0.941027      0.911416      0.904234      0.930441   \n",
       "is_iceberg18      0.929087      0.910098      0.905948      0.900611   \n",
       "is_iceberg19      0.944696      0.897822      0.917085      0.925086   \n",
       "is_iceberg20      0.931990      0.875849      0.932792      0.917954   \n",
       "is_iceberg21      0.941592      0.910678      0.904530      0.943474   \n",
       "is_iceberg22      0.928172      0.882041      0.926156      0.955661   \n",
       "is_iceberg23      0.929205      0.891914      0.909700      0.942513   \n",
       "is_iceberg24      0.927141      0.860627      0.928308      0.924065   \n",
       "is_iceberg25      0.949337      0.921757      0.938836      0.929772   \n",
       "is_iceberg26      0.942802      0.917770      0.931100      0.942016   \n",
       "is_iceberg27      0.078732      0.052278      0.077990      0.085074   \n",
       "is_iceberg28      0.952496      0.930042      0.910887      0.924481   \n",
       "is_iceberg29      1.000000      0.919828      0.912110      0.920245   \n",
       "is_iceberg30      0.919828      1.000000      0.866449      0.887004   \n",
       "is_iceberg31      0.912110      0.866449      1.000000      0.919369   \n",
       "is_iceberg32      0.920245      0.887004      0.919369      1.000000   \n",
       "is_iceberg33      0.933280      0.910535      0.901564      0.922719   \n",
       "is_iceberg34      0.935788      0.902745      0.933263      0.940614   \n",
       "is_iceberg35      0.873284      0.904976      0.829924      0.814280   \n",
       "\n",
       "              is_iceberg33  is_iceberg34  is_iceberg35  \n",
       "is_iceberg0       0.902627      0.951503      0.793508  \n",
       "is_iceberg1       0.947372      0.902606      0.883981  \n",
       "is_iceberg2       0.924767      0.944818      0.834233  \n",
       "is_iceberg3       0.910914      0.907002      0.875220  \n",
       "is_iceberg4       0.913297      0.953171      0.812676  \n",
       "is_iceberg5       0.928878      0.931390      0.884461  \n",
       "is_iceberg6       0.925592      0.919089      0.875645  \n",
       "is_iceberg7       0.911654      0.910635      0.902428  \n",
       "is_iceberg8       0.930506      0.900361      0.909133  \n",
       "is_iceberg9       0.919939      0.941562      0.828865  \n",
       "is_iceberg10      0.919688      0.931074      0.837710  \n",
       "is_iceberg11      0.921281      0.929350      0.821828  \n",
       "is_iceberg12      0.928081      0.914106      0.899084  \n",
       "is_iceberg13      0.921118      0.938024      0.875464  \n",
       "is_iceberg14      0.933184      0.933367      0.871867  \n",
       "is_iceberg15      0.197217      0.171121      0.135614  \n",
       "is_iceberg16      0.909143      0.947383      0.845734  \n",
       "is_iceberg17      0.935077      0.923369      0.874275  \n",
       "is_iceberg18      0.918289      0.910266      0.871722  \n",
       "is_iceberg19      0.929153      0.930885      0.827150  \n",
       "is_iceberg20      0.903149      0.942449      0.828441  \n",
       "is_iceberg21      0.935986      0.929507      0.835784  \n",
       "is_iceberg22      0.915942      0.947242      0.797847  \n",
       "is_iceberg23      0.930015      0.932835      0.813610  \n",
       "is_iceberg24      0.908934      0.938328      0.801613  \n",
       "is_iceberg25      0.928816      0.942454      0.871154  \n",
       "is_iceberg26      0.918424      0.951909      0.844448  \n",
       "is_iceberg27      0.079385      0.083264      0.038075  \n",
       "is_iceberg28      0.942131      0.931641      0.868692  \n",
       "is_iceberg29      0.933280      0.935788      0.873284  \n",
       "is_iceberg30      0.910535      0.902745      0.904976  \n",
       "is_iceberg31      0.901564      0.933263      0.829924  \n",
       "is_iceberg32      0.922719      0.940614      0.814280  \n",
       "is_iceberg33      1.000000      0.914009      0.858465  \n",
       "is_iceberg34      0.914009      1.000000      0.847099  \n",
       "is_iceberg35      0.858465      0.847099      1.000000  \n",
       "\n",
       "[36 rows x 36 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = temp11.mean(1)\n",
    "# temp11.head()\n",
    "temp11.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp11['is_iceberg_max'] = temp11.iloc[:, :36].max(axis=1)\n",
    "temp11['is_iceberg_min'] = temp11.iloc[:, :36].min(axis=1)\n",
    "temp11['is_iceberg_median'] = temp11.iloc[:, :36].median(axis=1)\n",
    "temp11['is_iceberg_mean'] = temp11.iloc[:, :36].mean(axis=1)\n",
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.80\n",
    "cutoff_hi = 0.20\n",
    "\n",
    "#temp11['is_iceberg_base'] = temp11['is_iceberg3']\n",
    "temp11['is_iceberg'] = np.where(np.all(temp11.iloc[:,0:36] > cutoff_lo, axis=1), \n",
    "                                    temp11['is_iceberg_max'], \n",
    "                                    np.where(np.all(temp11.iloc[:,0:36] < cutoff_hi, axis=1),\n",
    "                                             temp11['is_iceberg_min'], \n",
    "                                             temp11['is_iceberg_median']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp11 =pd.read_csv('36_plain_cnn.csv')\n",
    "temp11.columns\n",
    "temp11.to_csv('r2_11_plain_cnn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp11.to_csv('36_plain_cnn.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
