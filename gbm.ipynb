{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x7f247307fc18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\", line 368, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/train.json\n",
      "data/processed/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:00<00:00, 937261.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 247)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8424/8424 [00:00<00:00, 1154290.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 247)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import datetime as dt\n",
    "#\n",
    "from collections import OrderedDict\n",
    "from random import choice, sample, shuffle, uniform, seed\n",
    "from math import exp, expm1, log1p, log10, log2, sqrt, ceil, floor, isfinite, isnan\n",
    "from itertools import combinations\n",
    "#import for image processing\n",
    "#import cv2\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.ndimage import laplace, sobel\n",
    "#evaluation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "###############################################################################\n",
    "def read_jason(file='', loc='../input/'):\n",
    "    print('{}{}'.format(loc, file))\n",
    "    df = pd.read_json('{}{}'.format(loc, file))\n",
    "    df['inc_angle'] = df['inc_angle'].replace('na', -1).astype(float)\n",
    "    #print(df['inc_angle'].value_counts())\n",
    "    \n",
    "    band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n",
    "    band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n",
    "    df = df.drop(['band_1', 'band_2'], axis=1)\n",
    "    \n",
    "    bands = np.stack((band1, band2,  0.5 * (band1 + band2)), axis=-1)  # -1 means add to the last dimension\n",
    "    del band1, band2\n",
    "    \n",
    "    return df, bands\n",
    "\n",
    "###############################################################################\n",
    "#forked from\n",
    "#https://www.kaggle.com/the1owl/planet-understanding-the-amazon-from-space/natural-growth-patterns-fractals-of-nature/notebook\n",
    "def img_to_stats(paths):\n",
    "    \n",
    "    img_id, img = paths[0], paths[1]\n",
    "    \n",
    "    #ignored error    \n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    bins = 20\n",
    "    scl_min, scl_max = -50, 50\n",
    "    opt_poly = True\n",
    "    #opt_poly = False\n",
    "    \n",
    "    try:\n",
    "        st = []\n",
    "        st_interv = []\n",
    "        hist_interv = []\n",
    "        for i in range(img.shape[2]):\n",
    "            img_sub = np.squeeze(img[:, :, i])\n",
    "            \n",
    "            #median, max and min\n",
    "            sub_st = []\n",
    "            sub_st += [np.mean(img_sub), np.std(img_sub), np.max(img_sub), np.median(img_sub), np.min(img_sub)]\n",
    "            sub_st += [(sub_st[2] - sub_st[3]), (sub_st[2] - sub_st[4]), (sub_st[3] - sub_st[4])] \n",
    "            sub_st += [(sub_st[-3] / sub_st[1]), (sub_st[-2] / sub_st[1]), (sub_st[-1] / sub_st[1])] #normalized by stdev\n",
    "            st += sub_st\n",
    "            #Laplacian, Sobel, kurtosis and skewness\n",
    "            st_trans = []\n",
    "            st_trans += [laplace(img_sub, mode='reflect', cval=0.0).ravel().var()] #blurr\n",
    "            sobel0 = sobel(img_sub, axis=0, mode='reflect', cval=0.0).ravel().var()\n",
    "            sobel1 = sobel(img_sub, axis=1, mode='reflect', cval=0.0).ravel().var()\n",
    "            st_trans += [sobel0, sobel1]\n",
    "            st_trans += [kurtosis(img_sub.ravel()), skew(img_sub.ravel())]\n",
    "            \n",
    "            if opt_poly:\n",
    "                st_interv.append(sub_st)\n",
    "                #\n",
    "                st += [x * y for x, y in combinations(st_trans, 2)]\n",
    "                st += [x + y for x, y in combinations(st_trans, 2)]\n",
    "                st += [x - y for x, y in combinations(st_trans, 2)]                \n",
    " \n",
    "            #hist\n",
    "            #hist = list(cv2.calcHist([img], [i], None, [bins], [0., 1.]).flatten())\n",
    "            hist = list(np.histogram(img_sub, bins=bins, range=(scl_min, scl_max))[0])\n",
    "            hist_interv.append(hist)\n",
    "            st += hist\n",
    "            st += [hist.index(max(hist))] #only the smallest index w/ max value would be incl\n",
    "            st += [np.std(hist), np.max(hist), np.median(hist), (np.max(hist) - np.median(hist))]\n",
    "\n",
    "        if opt_poly:\n",
    "            for x, y in combinations(st_interv, 2):\n",
    "                st += [float(x[j]) * float(y[j]) for j in range(len(st_interv[0]))]\n",
    "\n",
    "            for x, y in combinations(hist_interv, 2):\n",
    "                hist_diff = [x[j] * y[j] for j in range(len(hist_interv[0]))]\n",
    "                st += [hist_diff.index(max(hist_diff))] #only the smallest index w/ max value would be incl\n",
    "                st += [np.std(hist_diff), np.max(hist_diff), np.median(hist_diff), (np.max(hist_diff) - np.median(hist_diff))]\n",
    "                \n",
    "        #correction\n",
    "        nan = -999\n",
    "        for i in range(len(st)):\n",
    "            if isnan(st[i]) == True:\n",
    "                st[i] = nan\n",
    "                \n",
    "    except:\n",
    "        print('except: ')\n",
    "    \n",
    "    return [img_id, st]\n",
    "\n",
    "\n",
    "def extract_img_stats(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(8) #(cpu_count())\n",
    "    ret = p.map(img_to_stats, paths)   # list of pair of (id, bands) bands is np.array shape (75, 75, 3)\n",
    "    for i in tqdm(range(len(ret)), miniters=100):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "\n",
    "    ret = []\n",
    "    fdata = [imf_d[i] for i, j in paths]\n",
    "    return np.array(fdata, dtype=np.float32)\n",
    "\n",
    "\n",
    "def process(df, bands):\n",
    "\n",
    "    data = extract_img_stats([(k, v) for k, v in zip(df['id'].tolist(), bands)]); gc.collect() #(N, 246)\n",
    "    data = np.concatenate([data, df['inc_angle'].values[:, np.newaxis]], axis=-1); gc.collect() #(N, 247)\n",
    "\n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "###############################################################################\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    np.random.seed(1017)\n",
    "    target = 'is_iceberg'\n",
    "    def iso(arr):\n",
    "        p = np.reshape(np.array(arr), [75,75]) >(np.mean(np.array(arr))+2*np.std(np.array(arr)))\n",
    "        return p * np.reshape(np.array(arr), [75,75])\n",
    "    def size(arr):     \n",
    "        return float(np.sum(arr<-5))/(75*75)\n",
    "    #Load data\n",
    "    train, train_bands = read_jason(file='train.json', loc='data/processed/')\n",
    "    test, test_bands = read_jason(file='test.json', loc='data/processed/')\n",
    "\n",
    "    train_X_full = process(df=train, bands=train_bands)\n",
    "    train_y_full = train[target].values    \n",
    "    test_X = process(df=test, bands=test_bands)\n",
    "    \n",
    "    data = pd.read_json('data/processed/train.json')\n",
    "    test = pd.read_json('data/processed/test.json')\n",
    "\n",
    "    data['iso1'] = data.iloc[:, 0].apply(iso)\n",
    "    data['iso2'] = data.iloc[:, 1].apply(iso)\n",
    "    test['iso1'] = test.iloc[:, 0].apply(iso)\n",
    "    test['iso2'] = test.iloc[:, 1].apply(iso)\n",
    "    # Feature engineering s1 s2 and size.\n",
    "    data['s1'] = data.iloc[:,5].apply(size)\n",
    "    data['s2'] = data.iloc[:,6].apply(size)\n",
    "    test['s1'] = test['iso1'].apply(size)\n",
    "    test['s2'] = test['iso2'].apply(size)\n",
    "    train_X_full= np.concatenate([train_X_full, data.iloc[:,7:]],axis=1)\n",
    "    test_X = np.concatenate([test_X, test.iloc[:,6:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X= train_X_full[train_X_full[:,-1]!=-1] #train_X[:,-1]==-1\n",
    "# train_y= train_y_full[train_X_full[:,-1]!=-1]\n",
    "\n",
    "train_X= train_X_full\n",
    "train_y= train_y_full\n",
    "\n",
    "# train_X = np.delete(train_X_full,249,1)\n",
    "# test_X = np.delete(test_X,249,1)\n",
    "# print(train_X.shape, train_y.shape)\n",
    "# train_X[:,246]\n",
    "\n",
    "# def iso(arr):\n",
    "#     p = np.reshape(np.array(arr), [75,75]) >(np.mean(np.array(arr))+2*np.std(np.array(arr)))\n",
    "#     return p * np.reshape(np.array(arr), [75,75])\n",
    "# def size(arr):     \n",
    "#     return float(np.sum(arr<-5))/(75*75)\n",
    "# # data = pd.read_json('data/processed/train.json')\n",
    "\n",
    "# data['iso1'] = data.iloc[:, 0].apply(iso)\n",
    "# data['iso2'] = data.iloc[:, 1].apply(iso)\n",
    "# test['iso1'] = test.iloc[:, 0].apply(iso)\n",
    "# test['iso2'] = test.iloc[:, 1].apply(iso)\n",
    "# # Feature engineering s1 s2 and size.\n",
    "# data['s1'] = data.iloc[:,5].apply(size)\n",
    "# data['s2'] = data.iloc[:,6].apply(size)\n",
    "# test['s1'] = test['iso1'].apply(size)\n",
    "# test['s2'] = test['iso2'].apply(size)\n",
    "# train_X_full= np.concatenate([train_X_full, data.iloc[:,7:]],axis=1)\n",
    "# test_X = np.concatenate([test_X, test.iloc[:,7:]],axis=1)\n",
    "# # data['iso1'] = data.iloc[:, 0].apply(iso)\n",
    "# # data['iso2'] = data.iloc[:, 1].apply(iso)\n",
    "# # # Feature engineering s1 s2 and size.\n",
    "# # data['s1'] = data.iloc[:,5].apply(size)\n",
    "# # data['s2'] = data.iloc[:,6].apply(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "      <th>iso1</th>\n",
       "      <th>iso2</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.016356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -19.411043, -0.0, -0.0, -2...</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>0.008533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-20.769371, -20.769434, -25.906025, -25.90602...</td>\n",
       "      <td>[-29.288746, -29.712593, -28.884804, -28.88480...</td>\n",
       "      <td>b51d18b5</td>\n",
       "      <td>36.9034</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-26.673811, -23.666162, -27.622442, -28.31768...</td>\n",
       "      <td>[-24.557735, -26.97868, -27.622442, -29.073456...</td>\n",
       "      <td>31da1a04</td>\n",
       "      <td>34.4751</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -21.9427...</td>\n",
       "      <td>0.023644</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-24.989119, -27.755224, -25.817074, -24.98927...</td>\n",
       "      <td>[-27.755173, -26.732174, -28.124943, -31.83772...</td>\n",
       "      <td>56929c16</td>\n",
       "      <td>41.1769</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-17.146641, -17.146572, -17.994583, -19.44553...</td>\n",
       "      <td>[-25.733608, -24.472507, -24.710424, -22.77215...</td>\n",
       "      <td>525ab75c</td>\n",
       "      <td>35.7829</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.020622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-24.020853, -23.551275, -27.18819, -29.126434...</td>\n",
       "      <td>[-28.702518, -33.563324, -29.571918, -29.12643...</td>\n",
       "      <td>192f56eb</td>\n",
       "      <td>43.3007</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.011556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.624</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.011556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-22.020813, -22.020864, -20.345379, -18.07829...</td>\n",
       "      <td>[-29.018383, -26.519661, -26.214916, -27.16346...</td>\n",
       "      <td>161a6860</td>\n",
       "      <td>39.5067</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -18.078295, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.012089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-21.112206, -21.638832, -25.436468, -23.22255...</td>\n",
       "      <td>[-27.30481, -28.415202999999998, -24.634125, -...</td>\n",
       "      <td>3c794f0c</td>\n",
       "      <td>41.8544</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.033244</td>\n",
       "      <td>0.046222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-23.864258, -27.755791, -26.047226, -24.62014...</td>\n",
       "      <td>[-23.626272, -24.620068, -28.546, -26.363146, ...</td>\n",
       "      <td>86730f0d</td>\n",
       "      <td>45.2909</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.011022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-20.558899, -21.328135, -19.585205, -19.71788...</td>\n",
       "      <td>[-29.127485, -30.40094, -28.741528, -24.380484...</td>\n",
       "      <td>e356f7a3</td>\n",
       "      <td>34.7715</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-28.282215, -27.896156, -25.882795, -25.88279...</td>\n",
       "      <td>[-31.608845, -29.110111, -32.851887, -32.85188...</td>\n",
       "      <td>87592c38</td>\n",
       "      <td>43.782</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-21.345695, -21.345734, -21.166676, -20.65056...</td>\n",
       "      <td>[-26.343246, -25.143326, -23.374924, -22.92943...</td>\n",
       "      <td>1c18a39e</td>\n",
       "      <td>45.3568</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.008711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-19.261189, -19.812914, -23.263891, -25.41662...</td>\n",
       "      <td>[-25.149176, -26.271551, -27.560766, -27.91539...</td>\n",
       "      <td>a210f335</td>\n",
       "      <td>38.7812</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-25.950783, -26.571512, -22.943153, -21.94372...</td>\n",
       "      <td>[-29.623671, -30.093336, -27.594606, -29.17827...</td>\n",
       "      <td>958d155f</td>\n",
       "      <td>42.5145</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.012622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-21.557806, -22.084446, -19.187838, -16.91901...</td>\n",
       "      <td>[-22.084385, -24.583221, -30.13426, -26.461437...</td>\n",
       "      <td>6d81d201</td>\n",
       "      <td>37.2802</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.012444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[-27.674824, -26.335936, -26.979677, -31.19679...</td>\n",
       "      <td>[-28.044491, -27.67487, -29.704073, -31.196793...</td>\n",
       "      <td>75126706</td>\n",
       "      <td>41.7973</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>0.009067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-26.345797, -26.05139, -26.650714999999998, -...</td>\n",
       "      <td>[-30.488308, -26.05139, -22.924503, -22.924503...</td>\n",
       "      <td>112a6cfa</td>\n",
       "      <td>38.0669</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-15.745731, -14.04358, -14.653421, -16.111671...</td>\n",
       "      <td>[-26.538006, -27.522421, -29.906204, -27.52253...</td>\n",
       "      <td>a29662a4</td>\n",
       "      <td>39.6636</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-14.6148, -14.6148, -16.136662, -15.342532, -...</td>\n",
       "      <td>[-26.656, -26.656, -22.534969, -25.496277, -26...</td>\n",
       "      <td>bd1a1bdf</td>\n",
       "      <td>37.6866</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.019733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-16.015327, -16.015327, -14.87892, -16.899502...</td>\n",
       "      <td>[-23.789312, -23.789312, -24.021, -23.78941499...</td>\n",
       "      <td>31e37d93</td>\n",
       "      <td>40.296</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-19.261448, -19.671938, -20.712574, -20.10284...</td>\n",
       "      <td>[-27.220249, -28.671318, -30.910847, -25.69265...</td>\n",
       "      <td>76b8d446</td>\n",
       "      <td>39.234</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.017956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[-10.99748, -11.994458, -11.209444, -11.209444...</td>\n",
       "      <td>[-12.792967, -18.622711, -13.816119, -13.81611...</td>\n",
       "      <td>958d42a8</td>\n",
       "      <td>40.3904</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -7.268992, -3.272221...</td>\n",
       "      <td>[[-12.792967, -0.0, -13.816119, -13.816119, -1...</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.064533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-31.042643, -31.60326, -32.202568, -30.51619,...</td>\n",
       "      <td>[-34.297188, -32.846218, -30.019676, -29.10457...</td>\n",
       "      <td>70830858</td>\n",
       "      <td>43.7895</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-27.995171, -23.865738, -22.165567, -22.76487...</td>\n",
       "      <td>[-28.785341, -30.620794, -27.625595, -25.40263...</td>\n",
       "      <td>faf2c49e</td>\n",
       "      <td>42.5891</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-26.390104, -28.888929, -28.888929, -27.72913...</td>\n",
       "      <td>[-25.230265, -26.706038, -26.706038, -24.45200...</td>\n",
       "      <td>02314c59</td>\n",
       "      <td>41.0303</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>[-21.309566, -20.840015, -22.515629, -21.15040...</td>\n",
       "      <td>[-26.709482, -26.709555, -27.998783, -29.51327...</td>\n",
       "      <td>84fe7f94</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.012444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>[-20.215452, -19.626303, -18.941971, -19.07453...</td>\n",
       "      <td>[-22.867964, -23.2917, -23.737179, -23.511507,...</td>\n",
       "      <td>04e6f331</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.018133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>[-23.334843, -25.328943, -26.213058, -25.90830...</td>\n",
       "      <td>[-31.073734, -29.581106, -33.572594, -32.87739...</td>\n",
       "      <td>92c90853</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.017422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>[-25.666952, -25.942781, -24.64403, -24.174473...</td>\n",
       "      <td>[-25.666952, -25.667017, -25.942844, -27.81134...</td>\n",
       "      <td>660a98a7</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>[-19.281799, -17.870247, -18.202303, -18.78553...</td>\n",
       "      <td>[-23.890778, -26.988886, -30.357046, -27.63272...</td>\n",
       "      <td>89670962</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>0.012978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>[-18.215658, -17.459957, -17.564053, -19.68742...</td>\n",
       "      <td>[-25.064114, -26.697582, -27.986814, -27.64621...</td>\n",
       "      <td>9d586019</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.012089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>[-17.248318, -16.214254, -15.532733, -15.95249...</td>\n",
       "      <td>[-21.718636, -24.217484, -24.443178, -25.15756...</td>\n",
       "      <td>5f49ea3b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.012622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>[-24.588913, -24.588951, -24.85627, -23.363632...</td>\n",
       "      <td>[-29.853745, -28.110779, -23.363598, -23.83325...</td>\n",
       "      <td>968e1414</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>0.015289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>[-24.811455, -25.078775, -24.055771, -20.69634...</td>\n",
       "      <td>[-29.161131, -27.222977, -28.737434, -30.07641...</td>\n",
       "      <td>389d7eaf</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>[-19.654991, -24.04619, -21.321854, -18.991802...</td>\n",
       "      <td>[-26.099377, -25.814627, -29.197536, -32.12015...</td>\n",
       "      <td>65ca9e76</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.018311</td>\n",
       "      <td>0.017778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>[-19.815434, -20.994926, -19.954279, -17.52577...</td>\n",
       "      <td>[-23.761044, -23.760979, -22.737862, -24.92068...</td>\n",
       "      <td>a09cae27</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>[-18.443468, -17.668488, -21.296959, -21.79350...</td>\n",
       "      <td>[-24.349022, -24.12347, -23.689157, -27.645437...</td>\n",
       "      <td>00c5b3e0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.012267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>[-21.710968, -21.162241, -24.336622, -22.92503...</td>\n",
       "      <td>[-21.710968, -23.840113, -26.023041, -23.60220...</td>\n",
       "      <td>7f9df2b0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-21.710968, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>[-20.982038, -17.765095, -17.460377, -17.36119...</td>\n",
       "      <td>[-28.291798, -27.30752, -22.995605, -25.124796...</td>\n",
       "      <td>a2303efc</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>[-13.383982, -12.767777, -14.186477, -17.88528...</td>\n",
       "      <td>[-24.233467, -24.233543, -23.185856, -23.38561...</td>\n",
       "      <td>cb62e5cb</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.011733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>[-22.688837, -21.349943, -22.898233, -22.89827...</td>\n",
       "      <td>[-30.048372, -31.63204, -34.326054, -32.231392...</td>\n",
       "      <td>9ff1e0f0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>0.023467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>[-22.613323, -20.475389, -19.295786, -19.15894...</td>\n",
       "      <td>[-24.401331, -23.91861, -23.461304, -26.983082...</td>\n",
       "      <td>39fd995a</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.012089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>[-16.95768, -21.794147, -24.581587, -24.819641...</td>\n",
       "      <td>[-23.27611, -29.501163, -35.945621, -29.501307...</td>\n",
       "      <td>544d0681</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>0.008533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>[-5.64585, -7.455446, -8.050229, -8.050307, -8...</td>\n",
       "      <td>[-14.208546, -13.801398, -14.709263, -15.80631...</td>\n",
       "      <td>cb0319fc</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-5.64585, -7.455446, -8.050229, -8.050307, -...</td>\n",
       "      <td>[[-14.208546, -13.801398, -14.709263, -15.8063...</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.016356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>[-28.554342, -26.37149, -25.17157, -25.171608,...</td>\n",
       "      <td>[-26.055567, -27.394543, -28.55442, -30.389864...</td>\n",
       "      <td>d86deb2b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>[-25.950792, -26.255636, -23.834808, -25.09588...</td>\n",
       "      <td>[-30.093304, -28.75441, -27.240044, -29.178288...</td>\n",
       "      <td>cdee905a</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.017422</td>\n",
       "      <td>0.034844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>[-25.31617, -25.895485, -24.773212, -23.779497...</td>\n",
       "      <td>[-26.516129, -29.122847, -29.568417, -30.53455...</td>\n",
       "      <td>2539742b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.027733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>[-14.463013, -15.378237, -14.535848, -14.83290...</td>\n",
       "      <td>[-25.165276, -24.682676, -25.41721, -30.026262...</td>\n",
       "      <td>2ea3c9f1</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>[-19.997332, -18.115284, -15.673027, -14.26133...</td>\n",
       "      <td>[-20.727669, -23.175728, -20.576469, -20.28193...</td>\n",
       "      <td>9cadda28</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>[-14.200315, -15.292111, -15.60808, -18.324097...</td>\n",
       "      <td>[-24.02071, -24.455181, -24.020878, -23.607269...</td>\n",
       "      <td>8376a077</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.014222</td>\n",
       "      <td>0.017244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>[-30.999878, -29.976866, -28.233906, -29.50732...</td>\n",
       "      <td>[-27.847719, -28.233864, -24.712077999999998, ...</td>\n",
       "      <td>04e11240</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -24.452822, -0.0, -0.0, -0...</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.014222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>[-25.31155, -26.511555, -28.694487, -27.180115...</td>\n",
       "      <td>[-29.563713, -28.290375, -26.839405, -28.29046...</td>\n",
       "      <td>c7d6f6f8</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>0.020978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>[-18.141895, -18.141844, -19.01737, -19.701599...</td>\n",
       "      <td>[-25.305355, -29.387701, -28.963863, -26.16023...</td>\n",
       "      <td>bba1a0f1</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -10.697523, -9...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.014222</td>\n",
       "      <td>0.012089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>[-22.455633, -25.794661, -26.954567, -22.83354...</td>\n",
       "      <td>[-26.070356, -22.093737, -21.577662, -24.53376...</td>\n",
       "      <td>7f66bb44</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>[-19.909191, -20.678406, -20.208834, -18.42441...</td>\n",
       "      <td>[-24.44487, -24.956001, -27.722103, -26.078417...</td>\n",
       "      <td>9d8f326c</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.011378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1     [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2     [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3     [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4     [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "5     [-20.769371, -20.769434, -25.906025, -25.90602...   \n",
       "6     [-26.673811, -23.666162, -27.622442, -28.31768...   \n",
       "7     [-24.989119, -27.755224, -25.817074, -24.98927...   \n",
       "8     [-17.146641, -17.146572, -17.994583, -19.44553...   \n",
       "9     [-24.020853, -23.551275, -27.18819, -29.126434...   \n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "11    [-22.020813, -22.020864, -20.345379, -18.07829...   \n",
       "12    [-21.112206, -21.638832, -25.436468, -23.22255...   \n",
       "13    [-23.864258, -27.755791, -26.047226, -24.62014...   \n",
       "14    [-20.558899, -21.328135, -19.585205, -19.71788...   \n",
       "15    [-28.282215, -27.896156, -25.882795, -25.88279...   \n",
       "16    [-21.345695, -21.345734, -21.166676, -20.65056...   \n",
       "17    [-19.261189, -19.812914, -23.263891, -25.41662...   \n",
       "18    [-25.950783, -26.571512, -22.943153, -21.94372...   \n",
       "19    [-21.557806, -22.084446, -19.187838, -16.91901...   \n",
       "20    [-27.674824, -26.335936, -26.979677, -31.19679...   \n",
       "21    [-26.345797, -26.05139, -26.650714999999998, -...   \n",
       "22    [-15.745731, -14.04358, -14.653421, -16.111671...   \n",
       "23    [-14.6148, -14.6148, -16.136662, -15.342532, -...   \n",
       "24    [-16.015327, -16.015327, -14.87892, -16.899502...   \n",
       "25    [-19.261448, -19.671938, -20.712574, -20.10284...   \n",
       "26    [-10.99748, -11.994458, -11.209444, -11.209444...   \n",
       "27    [-31.042643, -31.60326, -32.202568, -30.51619,...   \n",
       "28    [-27.995171, -23.865738, -22.165567, -22.76487...   \n",
       "29    [-26.390104, -28.888929, -28.888929, -27.72913...   \n",
       "...                                                 ...   \n",
       "1574  [-21.309566, -20.840015, -22.515629, -21.15040...   \n",
       "1575  [-20.215452, -19.626303, -18.941971, -19.07453...   \n",
       "1576  [-23.334843, -25.328943, -26.213058, -25.90830...   \n",
       "1577  [-25.666952, -25.942781, -24.64403, -24.174473...   \n",
       "1578  [-19.281799, -17.870247, -18.202303, -18.78553...   \n",
       "1579  [-18.215658, -17.459957, -17.564053, -19.68742...   \n",
       "1580  [-17.248318, -16.214254, -15.532733, -15.95249...   \n",
       "1581  [-24.588913, -24.588951, -24.85627, -23.363632...   \n",
       "1582  [-24.811455, -25.078775, -24.055771, -20.69634...   \n",
       "1583  [-19.654991, -24.04619, -21.321854, -18.991802...   \n",
       "1584  [-19.815434, -20.994926, -19.954279, -17.52577...   \n",
       "1585  [-18.443468, -17.668488, -21.296959, -21.79350...   \n",
       "1586  [-21.710968, -21.162241, -24.336622, -22.92503...   \n",
       "1587  [-20.982038, -17.765095, -17.460377, -17.36119...   \n",
       "1588  [-13.383982, -12.767777, -14.186477, -17.88528...   \n",
       "1589  [-22.688837, -21.349943, -22.898233, -22.89827...   \n",
       "1590  [-22.613323, -20.475389, -19.295786, -19.15894...   \n",
       "1591  [-16.95768, -21.794147, -24.581587, -24.819641...   \n",
       "1592  [-5.64585, -7.455446, -8.050229, -8.050307, -8...   \n",
       "1593  [-28.554342, -26.37149, -25.17157, -25.171608,...   \n",
       "1594  [-25.950792, -26.255636, -23.834808, -25.09588...   \n",
       "1595  [-25.31617, -25.895485, -24.773212, -23.779497...   \n",
       "1596  [-14.463013, -15.378237, -14.535848, -14.83290...   \n",
       "1597  [-19.997332, -18.115284, -15.673027, -14.26133...   \n",
       "1598  [-14.200315, -15.292111, -15.60808, -18.324097...   \n",
       "1599  [-30.999878, -29.976866, -28.233906, -29.50732...   \n",
       "1600  [-25.31155, -26.511555, -28.694487, -27.180115...   \n",
       "1601  [-18.141895, -18.141844, -19.01737, -19.701599...   \n",
       "1602  [-22.455633, -25.794661, -26.954567, -22.83354...   \n",
       "1603  [-19.909191, -20.678406, -20.208834, -18.42441...   \n",
       "\n",
       "                                                 band_2        id inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2     [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3     [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4     [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "5     [-29.288746, -29.712593, -28.884804, -28.88480...  b51d18b5   36.9034   \n",
       "6     [-24.557735, -26.97868, -27.622442, -29.073456...  31da1a04   34.4751   \n",
       "7     [-27.755173, -26.732174, -28.124943, -31.83772...  56929c16   41.1769   \n",
       "8     [-25.733608, -24.472507, -24.710424, -22.77215...  525ab75c   35.7829   \n",
       "9     [-28.702518, -33.563324, -29.571918, -29.12643...  192f56eb   43.3007   \n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.624   \n",
       "11    [-29.018383, -26.519661, -26.214916, -27.16346...  161a6860   39.5067   \n",
       "12    [-27.30481, -28.415202999999998, -24.634125, -...  3c794f0c   41.8544   \n",
       "13    [-23.626272, -24.620068, -28.546, -26.363146, ...  86730f0d   45.2909   \n",
       "14    [-29.127485, -30.40094, -28.741528, -24.380484...  e356f7a3   34.7715   \n",
       "15    [-31.608845, -29.110111, -32.851887, -32.85188...  87592c38    43.782   \n",
       "16    [-26.343246, -25.143326, -23.374924, -22.92943...  1c18a39e   45.3568   \n",
       "17    [-25.149176, -26.271551, -27.560766, -27.91539...  a210f335   38.7812   \n",
       "18    [-29.623671, -30.093336, -27.594606, -29.17827...  958d155f   42.5145   \n",
       "19    [-22.084385, -24.583221, -30.13426, -26.461437...  6d81d201   37.2802   \n",
       "20    [-28.044491, -27.67487, -29.704073, -31.196793...  75126706   41.7973   \n",
       "21    [-30.488308, -26.05139, -22.924503, -22.924503...  112a6cfa   38.0669   \n",
       "22    [-26.538006, -27.522421, -29.906204, -27.52253...  a29662a4   39.6636   \n",
       "23    [-26.656, -26.656, -22.534969, -25.496277, -26...  bd1a1bdf   37.6866   \n",
       "24    [-23.789312, -23.789312, -24.021, -23.78941499...  31e37d93    40.296   \n",
       "25    [-27.220249, -28.671318, -30.910847, -25.69265...  76b8d446    39.234   \n",
       "26    [-12.792967, -18.622711, -13.816119, -13.81611...  958d42a8   40.3904   \n",
       "27    [-34.297188, -32.846218, -30.019676, -29.10457...  70830858   43.7895   \n",
       "28    [-28.785341, -30.620794, -27.625595, -25.40263...  faf2c49e   42.5891   \n",
       "29    [-25.230265, -26.706038, -26.706038, -24.45200...  02314c59   41.0303   \n",
       "...                                                 ...       ...       ...   \n",
       "1574  [-26.709482, -26.709555, -27.998783, -29.51327...  84fe7f94        na   \n",
       "1575  [-22.867964, -23.2917, -23.737179, -23.511507,...  04e6f331        na   \n",
       "1576  [-31.073734, -29.581106, -33.572594, -32.87739...  92c90853        na   \n",
       "1577  [-25.666952, -25.667017, -25.942844, -27.81134...  660a98a7        na   \n",
       "1578  [-23.890778, -26.988886, -30.357046, -27.63272...  89670962        na   \n",
       "1579  [-25.064114, -26.697582, -27.986814, -27.64621...  9d586019        na   \n",
       "1580  [-21.718636, -24.217484, -24.443178, -25.15756...  5f49ea3b        na   \n",
       "1581  [-29.853745, -28.110779, -23.363598, -23.83325...  968e1414        na   \n",
       "1582  [-29.161131, -27.222977, -28.737434, -30.07641...  389d7eaf        na   \n",
       "1583  [-26.099377, -25.814627, -29.197536, -32.12015...  65ca9e76        na   \n",
       "1584  [-23.761044, -23.760979, -22.737862, -24.92068...  a09cae27        na   \n",
       "1585  [-24.349022, -24.12347, -23.689157, -27.645437...  00c5b3e0        na   \n",
       "1586  [-21.710968, -23.840113, -26.023041, -23.60220...  7f9df2b0        na   \n",
       "1587  [-28.291798, -27.30752, -22.995605, -25.124796...  a2303efc        na   \n",
       "1588  [-24.233467, -24.233543, -23.185856, -23.38561...  cb62e5cb        na   \n",
       "1589  [-30.048372, -31.63204, -34.326054, -32.231392...  9ff1e0f0        na   \n",
       "1590  [-24.401331, -23.91861, -23.461304, -26.983082...  39fd995a        na   \n",
       "1591  [-23.27611, -29.501163, -35.945621, -29.501307...  544d0681        na   \n",
       "1592  [-14.208546, -13.801398, -14.709263, -15.80631...  cb0319fc        na   \n",
       "1593  [-26.055567, -27.394543, -28.55442, -30.389864...  d86deb2b        na   \n",
       "1594  [-30.093304, -28.75441, -27.240044, -29.178288...  cdee905a        na   \n",
       "1595  [-26.516129, -29.122847, -29.568417, -30.53455...  2539742b        na   \n",
       "1596  [-25.165276, -24.682676, -25.41721, -30.026262...  2ea3c9f1        na   \n",
       "1597  [-20.727669, -23.175728, -20.576469, -20.28193...  9cadda28        na   \n",
       "1598  [-24.02071, -24.455181, -24.020878, -23.607269...  8376a077        na   \n",
       "1599  [-27.847719, -28.233864, -24.712077999999998, ...  04e11240        na   \n",
       "1600  [-29.563713, -28.290375, -26.839405, -28.29046...  c7d6f6f8        na   \n",
       "1601  [-25.305355, -29.387701, -28.963863, -26.16023...  bba1a0f1        na   \n",
       "1602  [-26.070356, -22.093737, -21.577662, -24.53376...  7f66bb44        na   \n",
       "1603  [-24.44487, -24.956001, -27.722103, -26.078417...  9d8f326c        na   \n",
       "\n",
       "      is_iceberg                                               iso1  \\\n",
       "0              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "2              1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "3              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "4              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "5              1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "6              1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "7              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "8              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "9              0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "10             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "11             0  [[-0.0, -0.0, -0.0, -18.078295, -0.0, -0.0, -0...   \n",
       "12             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "13             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "14             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "15             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "16             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "17             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "18             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "19             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "20             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "21             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "22             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "23             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "24             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "25             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "26             1  [[-0.0, -0.0, -0.0, -0.0, -7.268992, -3.272221...   \n",
       "27             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "28             1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "29             0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "...          ...                                                ...   \n",
       "1574           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1575           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1576           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1577           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1578           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1579           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1580           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1581           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1582           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1583           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1584           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1585           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1586           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1587           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1588           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1589           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1590           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1591           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1592           0  [[-5.64585, -7.455446, -8.050229, -8.050307, -...   \n",
       "1593           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1594           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1595           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1596           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1597           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1598           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1599           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1600           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1601           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -10.697523, -9...   \n",
       "1602           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1603           0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "\n",
       "                                                   iso2        s1        s2  \n",
       "0     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011378  0.010133  \n",
       "1     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.003022  0.016356  \n",
       "2     [[-0.0, -0.0, -0.0, -19.411043, -0.0, -0.0, -2...  0.016178  0.010667  \n",
       "3     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.009244  0.008533  \n",
       "4     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.012089  0.007822  \n",
       "5     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.021333  0.027200  \n",
       "6     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -21.9427...  0.023644  0.013156  \n",
       "7     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.019733  0.009422  \n",
       "8     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.001422  0.020622  \n",
       "9     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.010667  0.011556  \n",
       "10    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.019556  0.011556  \n",
       "11    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011911  0.012089  \n",
       "12    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.033244  0.046222  \n",
       "13    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.010311  0.011022  \n",
       "14    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.019200  0.014756  \n",
       "15    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.012978  0.009956  \n",
       "16    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.017244  0.008711  \n",
       "17    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.007467  0.014756  \n",
       "18    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.010489  0.012622  \n",
       "19    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.013689  0.012444  \n",
       "20    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.016356  0.009067  \n",
       "21    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.013511  0.010133  \n",
       "22    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.006756  0.028800  \n",
       "23    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.016889  0.019733  \n",
       "24    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.005867  0.026667  \n",
       "25    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.016533  0.017956  \n",
       "26    [[-12.792967, -0.0, -13.816119, -13.816119, -1...  0.029333  0.064533  \n",
       "27    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011378  0.010133  \n",
       "28    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.013867  0.014400  \n",
       "29    [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011022  0.009600  \n",
       "...                                                 ...       ...       ...  \n",
       "1574  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.009422  0.012444  \n",
       "1575  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.013867  0.018133  \n",
       "1576  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.022933  0.017422  \n",
       "1577  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.016000  0.014400  \n",
       "1578  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.020622  0.012978  \n",
       "1579  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.017956  0.012089  \n",
       "1580  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.019733  0.012622  \n",
       "1581  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.012978  0.015289  \n",
       "1582  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.012444  0.013333  \n",
       "1583  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.018311  0.017778  \n",
       "1584  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.008000  0.015822  \n",
       "1585  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.016889  0.012267  \n",
       "1586  [[-21.710968, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.013511  0.010667  \n",
       "1587  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011378  0.009956  \n",
       "1588  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.017956  0.011733  \n",
       "1589  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.023111  0.023467  \n",
       "1590  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.015822  0.012089  \n",
       "1591  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.012978  0.008533  \n",
       "1592  [[-14.208546, -13.801398, -14.709263, -15.8063...  0.007822  0.016356  \n",
       "1593  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.011556  0.008356  \n",
       "1594  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.017422  0.034844  \n",
       "1595  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.026311  0.027733  \n",
       "1596  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.020800  0.013156  \n",
       "1597  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.000000  0.024889  \n",
       "1598  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.014222  0.017244  \n",
       "1599  [[-0.0, -0.0, -0.0, -24.452822, -0.0, -0.0, -0...  0.019556  0.014222  \n",
       "1600  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.025067  0.020978  \n",
       "1601  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.014222  0.012089  \n",
       "1602  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.009778  0.007822  \n",
       "1603  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...  0.010311  0.011378  \n",
       "\n",
       "[1604 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fft(dt):\n",
    "    result =pd.DataFrame()\n",
    "    for j in range(0,dt.shape[0]):            \n",
    "        for band in ['band_1', 'band_2']:\n",
    "            x = np.array(dt.iloc[j,:][band])\n",
    "            multiplier = 1.1\n",
    "            threshold_h = 45.0\n",
    "            threshold_v = 45.0\n",
    "            mean_value = {}\n",
    "\n",
    "\n",
    "            mean_value['h'] = []\n",
    "            xx = []\n",
    "            sph = None\n",
    "            for i in range(75):\n",
    "                th = np.reshape(x,(75,75))[i,:]\n",
    "                sph = np.fft.fft(th)\n",
    "                mnh = np.mean(abs(sph))     \n",
    "                sph[abs(sph)<mnh*multiplier] = 0.0\n",
    "                xx.append(abs(np.fft.ifft(sph)))\n",
    "                mean_value['h'].append(mnh)\n",
    "            mxh = np.max(mean_value['h'])\n",
    "            mih = np.min(mean_value['h'])\n",
    "            mnh = np.mean(mean_value['h'])\n",
    "\n",
    "\n",
    "            mean_value['v']=[]\n",
    "            yy = []\n",
    "            spv = None\n",
    "            for i in range(75):\n",
    "                tv = np.reshape(x,(75,75))[:,i]\n",
    "                spv = np.fft.fft(tv)\n",
    "                mnv = np.mean(abs(spv))\n",
    "                spv[abs(spv)<mnv*multiplier] = 0.0\n",
    "                yy.append(abs(np.fft.ifft(spv)))\n",
    "                mean_value['v'].append(mnv)\n",
    "\n",
    "            mxv = np.max(mean_value['v'])\n",
    "            miv = np.min(mean_value['v'])                \n",
    "            mnv = np.mean(mean_value['v'])\n",
    "\n",
    "            estimate_size = sum(mean_value['v'] > mnv*multiplier)*sum(mean_value['h'] > mnh*multiplier)\n",
    "\n",
    "            yy = np.transpose(yy)\n",
    "            if band == 'band_1':\n",
    "#             fft_data = {'band':band, 'id':dt.iloc[j,:].id, 'inc_angle':dt.iloc[j,:].inc_angle, 'is_iceberg':dt.iloc[j,:].is_iceberg, 'mxv':mxv,'miv':miv,'mnv':mnv,'mean_value_v':mean_value['v'], 'size_v': sum(mean_value['v'] > mnv*multiplier)\n",
    "#                         ,'mxh':mxh,'mih':mih,'mnh':mnh,'mean_value_h':mean_value['h'], 'size_h': sum(mean_value['h'] > mnh*multiplier) }\n",
    "                fft_data = (('id',[dt.iloc[j,:].id]), ('mxv',mxv),('miv',miv),('mnv',mnv), ('size_v',sum(mean_value['v'] > mnv*multiplier)),\n",
    "                ('mxh',mxh),('mih',mih),('mnh',mnh), ('size_h', sum(mean_value['h'] > mnh*multiplier)))\n",
    "            if band == 'band_2':\n",
    "                fft_data += (('mxv2',mxv),('miv2',miv),('mnv2',mnv), ('size_v2',sum(mean_value['v'] > mnv*multiplier)),\n",
    "                ('mxh2',mxh),('mih2',mih),('mnh2',mnh), ('size_h2', sum(mean_value['h'] > mnh*multiplier)))\n",
    "#             print(len(mean_value['v']))\n",
    "        temp = pd.DataFrame.from_dict(OrderedDict(fft_data))\n",
    "        result = pd.concat([result,temp])\n",
    "        \n",
    "    return result\n",
    "                    \n",
    "                    \n",
    "\n",
    "a = gen_fft(data)\n",
    "b = gen_fft(test)\n",
    "# train_X_full = np.concatenate((train_X_full, a.drop(['id']).values),axis=1)\n",
    "# test_X = np.concatenate((test_X, b.drop(['id']).values),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.delete(train_X_full,249,1)[1,:]\n",
    "# train_X_full[1,:]\n",
    "# a.drop(['id'],axis=1)\n",
    "train_X_full = np.concatenate((train_X_full, a.drop(['id'],axis=1).values),axis=1)\n",
    "test_X = np.concatenate((test_X, b.drop(['id'],axis=1).values),axis=1)\n",
    "# test_X = np.concatenate([test_X, test.iloc[:,6:]],axis=1)\n",
    "# test_X = np.concatenate((test_X, b.drop(['id'],axis=1).values),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 265)\n",
      "(8424, 265)\n"
     ]
    }
   ],
   "source": [
    "# test_X = test_X[:,:246]\n",
    "# test_X.shape\n",
    "print(train_X_full.shape)\n",
    "print(test_X.shape)\n",
    "#246+17+2\n",
    "# test.iloc[:,6:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       dfd5f913\n",
       "1       e25388fd\n",
       "2       58b2aaa0\n",
       "3       4cfc3a18\n",
       "4       271f93f4\n",
       "5       b51d18b5\n",
       "6       31da1a04\n",
       "7       56929c16\n",
       "8       525ab75c\n",
       "9       192f56eb\n",
       "10      3aac67cd\n",
       "11      161a6860\n",
       "12      3c794f0c\n",
       "13      86730f0d\n",
       "14      e356f7a3\n",
       "15      87592c38\n",
       "16      1c18a39e\n",
       "17      a210f335\n",
       "18      958d155f\n",
       "19      6d81d201\n",
       "20      75126706\n",
       "21      112a6cfa\n",
       "22      a29662a4\n",
       "23      bd1a1bdf\n",
       "24      31e37d93\n",
       "25      76b8d446\n",
       "26      958d42a8\n",
       "27      70830858\n",
       "28      faf2c49e\n",
       "29      02314c59\n",
       "          ...   \n",
       "1574    84fe7f94\n",
       "1575    04e6f331\n",
       "1576    92c90853\n",
       "1577    660a98a7\n",
       "1578    89670962\n",
       "1579    9d586019\n",
       "1580    5f49ea3b\n",
       "1581    968e1414\n",
       "1582    389d7eaf\n",
       "1583    65ca9e76\n",
       "1584    a09cae27\n",
       "1585    00c5b3e0\n",
       "1586    7f9df2b0\n",
       "1587    a2303efc\n",
       "1588    cb62e5cb\n",
       "1589    9ff1e0f0\n",
       "1590    39fd995a\n",
       "1591    544d0681\n",
       "1592    cb0319fc\n",
       "1593    d86deb2b\n",
       "1594    cdee905a\n",
       "1595    2539742b\n",
       "1596    2ea3c9f1\n",
       "1597    9cadda28\n",
       "1598    8376a077\n",
       "1599    04e11240\n",
       "1600    c7d6f6f8\n",
       "1601    bba1a0f1\n",
       "1602    7f66bb44\n",
       "1603    9d8f326c\n",
       "Name: id, Length: 1604, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed we are using is: 58828\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f2684696168>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.676031\tvalid-logloss:0.676764\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.305669\tvalid-logloss:0.352983\n",
      "[100]\ttrain-logloss:0.197015\tvalid-logloss:0.27242\n",
      "[150]\ttrain-logloss:0.140457\tvalid-logloss:0.242431\n",
      "[200]\ttrain-logloss:0.105486\tvalid-logloss:0.223807\n",
      "[250]\ttrain-logloss:0.080958\tvalid-logloss:0.213532\n",
      "[300]\ttrain-logloss:0.063245\tvalid-logloss:0.206793\n",
      "[350]\ttrain-logloss:0.05009\tvalid-logloss:0.20169\n",
      "[400]\ttrain-logloss:0.040743\tvalid-logloss:0.197232\n",
      "[450]\ttrain-logloss:0.033358\tvalid-logloss:0.195457\n",
      "[500]\ttrain-logloss:0.027726\tvalid-logloss:0.194399\n",
      "[550]\ttrain-logloss:0.023321\tvalid-logloss:0.194148\n",
      "[600]\ttrain-logloss:0.019943\tvalid-logloss:0.19502\n",
      "Stopping. Best iteration:\n",
      "[545]\ttrain-logloss:0.023796\tvalid-logloss:0.193273\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.349675\n",
      "[100]\tvalid_0's binary_logloss: 0.270843\n",
      "[150]\tvalid_0's binary_logloss: 0.241822\n",
      "[200]\tvalid_0's binary_logloss: 0.225776\n",
      "[250]\tvalid_0's binary_logloss: 0.215406\n",
      "[300]\tvalid_0's binary_logloss: 0.207625\n",
      "[350]\tvalid_0's binary_logloss: 0.203852\n",
      "[400]\tvalid_0's binary_logloss: 0.19941\n",
      "[450]\tvalid_0's binary_logloss: 0.200161\n",
      "[500]\tvalid_0's binary_logloss: 0.201765\n",
      "Early stopping, best iteration is:\n",
      "[402]\tvalid_0's binary_logloss: 0.199363\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.370978\n",
      "[100]\tvalid_0's binary_logloss: 0.323254\n",
      "[150]\tvalid_0's binary_logloss: 0.288585\n",
      "[200]\tvalid_0's binary_logloss: 0.266688\n",
      "[250]\tvalid_0's binary_logloss: 0.262477\n",
      "[300]\tvalid_0's binary_logloss: 0.247321\n",
      "[350]\tvalid_0's binary_logloss: 0.239819\n",
      "[400]\tvalid_0's binary_logloss: 0.236263\n",
      "[450]\tvalid_0's binary_logloss: 0.232008\n",
      "[500]\tvalid_0's binary_logloss: 0.223613\n",
      "[550]\tvalid_0's binary_logloss: 0.220567\n",
      "[600]\tvalid_0's binary_logloss: 0.215699\n",
      "[650]\tvalid_0's binary_logloss: 0.214996\n",
      "[700]\tvalid_0's binary_logloss: 0.21336\n",
      "[750]\tvalid_0's binary_logloss: 0.213544\n",
      "[800]\tvalid_0's binary_logloss: 0.208666\n",
      "[850]\tvalid_0's binary_logloss: 0.207535\n",
      "[900]\tvalid_0's binary_logloss: 0.209349\n",
      "Early stopping, best iteration is:\n",
      "[838]\tvalid_0's binary_logloss: 0.206677\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f2684696168>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.677222\tvalid-logloss:0.678546\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.315558\tvalid-logloss:0.350806\n",
      "[100]\ttrain-logloss:0.204172\tvalid-logloss:0.260145\n",
      "[150]\ttrain-logloss:0.145393\tvalid-logloss:0.220304\n",
      "[200]\ttrain-logloss:0.110267\tvalid-logloss:0.198963\n",
      "[250]\ttrain-logloss:0.084644\tvalid-logloss:0.187762\n",
      "[300]\ttrain-logloss:0.066745\tvalid-logloss:0.181519\n",
      "[350]\ttrain-logloss:0.052783\tvalid-logloss:0.178876\n",
      "[400]\ttrain-logloss:0.042692\tvalid-logloss:0.178438\n",
      "[450]\ttrain-logloss:0.034897\tvalid-logloss:0.177229\n",
      "[500]\ttrain-logloss:0.028817\tvalid-logloss:0.174186\n",
      "[550]\ttrain-logloss:0.023997\tvalid-logloss:0.172724\n",
      "[600]\ttrain-logloss:0.020486\tvalid-logloss:0.172004\n",
      "[650]\ttrain-logloss:0.01755\tvalid-logloss:0.171806\n",
      "[700]\ttrain-logloss:0.01537\tvalid-logloss:0.173179\n",
      "Stopping. Best iteration:\n",
      "[606]\ttrain-logloss:0.020078\tvalid-logloss:0.171507\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.341777\n",
      "[100]\tvalid_0's binary_logloss: 0.248179\n",
      "[150]\tvalid_0's binary_logloss: 0.214705\n",
      "[200]\tvalid_0's binary_logloss: 0.200391\n",
      "[250]\tvalid_0's binary_logloss: 0.189737\n",
      "[300]\tvalid_0's binary_logloss: 0.181808\n",
      "[350]\tvalid_0's binary_logloss: 0.179246\n",
      "[400]\tvalid_0's binary_logloss: 0.17764\n",
      "[450]\tvalid_0's binary_logloss: 0.174738\n",
      "[500]\tvalid_0's binary_logloss: 0.174972\n",
      "[550]\tvalid_0's binary_logloss: 0.174522\n",
      "[600]\tvalid_0's binary_logloss: 0.175973\n",
      "Early stopping, best iteration is:\n",
      "[543]\tvalid_0's binary_logloss: 0.173279\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.424309\n",
      "[100]\tvalid_0's binary_logloss: 0.345238\n",
      "[150]\tvalid_0's binary_logloss: 0.293364\n",
      "[200]\tvalid_0's binary_logloss: 0.268466\n",
      "[250]\tvalid_0's binary_logloss: 0.25827\n",
      "[300]\tvalid_0's binary_logloss: 0.245662\n",
      "[350]\tvalid_0's binary_logloss: 0.223476\n",
      "[400]\tvalid_0's binary_logloss: 0.212324\n",
      "[450]\tvalid_0's binary_logloss: 0.20016\n",
      "[500]\tvalid_0's binary_logloss: 0.19612\n",
      "[550]\tvalid_0's binary_logloss: 0.19368\n",
      "[600]\tvalid_0's binary_logloss: 0.19132\n",
      "[650]\tvalid_0's binary_logloss: 0.188845\n",
      "[700]\tvalid_0's binary_logloss: 0.186939\n",
      "[750]\tvalid_0's binary_logloss: 0.185921\n",
      "[800]\tvalid_0's binary_logloss: 0.186813\n",
      "[850]\tvalid_0's binary_logloss: 0.184844\n",
      "[900]\tvalid_0's binary_logloss: 0.184138\n",
      "[950]\tvalid_0's binary_logloss: 0.184398\n",
      "[1000]\tvalid_0's binary_logloss: 0.185551\n",
      "Early stopping, best iteration is:\n",
      "[912]\tvalid_0's binary_logloss: 0.182963\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f2684696168>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.676482\tvalid-logloss:0.678248\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.305266\tvalid-logloss:0.388567\n",
      "[100]\ttrain-logloss:0.192092\tvalid-logloss:0.319038\n",
      "[150]\ttrain-logloss:0.135436\tvalid-logloss:0.291603\n",
      "[200]\ttrain-logloss:0.101305\tvalid-logloss:0.274942\n",
      "[250]\ttrain-logloss:0.077203\tvalid-logloss:0.264611\n",
      "[300]\ttrain-logloss:0.059965\tvalid-logloss:0.259877\n",
      "[350]\ttrain-logloss:0.048082\tvalid-logloss:0.255979\n",
      "[400]\ttrain-logloss:0.039129\tvalid-logloss:0.255305\n",
      "[450]\ttrain-logloss:0.032126\tvalid-logloss:0.254586\n",
      "[500]\ttrain-logloss:0.026623\tvalid-logloss:0.253054\n",
      "[550]\ttrain-logloss:0.022547\tvalid-logloss:0.252625\n",
      "[600]\ttrain-logloss:0.019221\tvalid-logloss:0.25291\n",
      "Stopping. Best iteration:\n",
      "[512]\ttrain-logloss:0.025569\tvalid-logloss:0.251902\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.372326\n",
      "[100]\tvalid_0's binary_logloss: 0.310518\n",
      "[150]\tvalid_0's binary_logloss: 0.287211\n",
      "[200]\tvalid_0's binary_logloss: 0.274464\n",
      "[250]\tvalid_0's binary_logloss: 0.268765\n",
      "[300]\tvalid_0's binary_logloss: 0.267041\n",
      "[350]\tvalid_0's binary_logloss: 0.264539\n",
      "[400]\tvalid_0's binary_logloss: 0.264355\n",
      "[450]\tvalid_0's binary_logloss: 0.2634\n",
      "[500]\tvalid_0's binary_logloss: 0.265406\n",
      "Early stopping, best iteration is:\n",
      "[410]\tvalid_0's binary_logloss: 0.262957\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.437794\n",
      "[100]\tvalid_0's binary_logloss: 0.358569\n",
      "[150]\tvalid_0's binary_logloss: 0.353072\n",
      "[200]\tvalid_0's binary_logloss: 0.329839\n",
      "[250]\tvalid_0's binary_logloss: 0.306262\n",
      "[300]\tvalid_0's binary_logloss: 0.298196\n",
      "[350]\tvalid_0's binary_logloss: 0.277561\n",
      "[400]\tvalid_0's binary_logloss: 0.276303\n",
      "[450]\tvalid_0's binary_logloss: 0.274883\n",
      "[500]\tvalid_0's binary_logloss: 0.271084\n",
      "[550]\tvalid_0's binary_logloss: 0.264094\n",
      "[600]\tvalid_0's binary_logloss: 0.262831\n",
      "[650]\tvalid_0's binary_logloss: 0.264144\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's binary_logloss: 0.262723\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f2684696168>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.677363\tvalid-logloss:0.679671\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.309242\tvalid-logloss:0.359182\n",
      "[100]\ttrain-logloss:0.198476\tvalid-logloss:0.273385\n",
      "[150]\ttrain-logloss:0.142401\tvalid-logloss:0.244075\n",
      "[200]\ttrain-logloss:0.107864\tvalid-logloss:0.224311\n",
      "[250]\ttrain-logloss:0.083206\tvalid-logloss:0.214634\n",
      "[300]\ttrain-logloss:0.06443\tvalid-logloss:0.20903\n",
      "[350]\ttrain-logloss:0.051097\tvalid-logloss:0.206284\n",
      "[400]\ttrain-logloss:0.041789\tvalid-logloss:0.205972\n",
      "[450]\ttrain-logloss:0.034291\tvalid-logloss:0.206209\n",
      "[500]\ttrain-logloss:0.028484\tvalid-logloss:0.205902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[422]\ttrain-logloss:0.038409\tvalid-logloss:0.204492\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.349948\n",
      "[100]\tvalid_0's binary_logloss: 0.271037\n",
      "[150]\tvalid_0's binary_logloss: 0.239794\n",
      "[200]\tvalid_0's binary_logloss: 0.227625\n",
      "[250]\tvalid_0's binary_logloss: 0.219024\n",
      "[300]\tvalid_0's binary_logloss: 0.214025\n",
      "[350]\tvalid_0's binary_logloss: 0.214819\n",
      "[400]\tvalid_0's binary_logloss: 0.212579\n",
      "[450]\tvalid_0's binary_logloss: 0.212799\n",
      "[500]\tvalid_0's binary_logloss: 0.211184\n",
      "[550]\tvalid_0's binary_logloss: 0.213168\n",
      "[600]\tvalid_0's binary_logloss: 0.213657\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's binary_logloss: 0.211184\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.444292\n",
      "[100]\tvalid_0's binary_logloss: 0.355852\n",
      "[150]\tvalid_0's binary_logloss: 0.32824\n",
      "[200]\tvalid_0's binary_logloss: 0.286147\n",
      "[250]\tvalid_0's binary_logloss: 0.27299\n",
      "[300]\tvalid_0's binary_logloss: 0.262011\n",
      "[350]\tvalid_0's binary_logloss: 0.25128\n",
      "[400]\tvalid_0's binary_logloss: 0.241011\n",
      "[450]\tvalid_0's binary_logloss: 0.233763\n",
      "[500]\tvalid_0's binary_logloss: 0.223807\n",
      "[550]\tvalid_0's binary_logloss: 0.224043\n",
      "[600]\tvalid_0's binary_logloss: 0.222019\n",
      "[650]\tvalid_0's binary_logloss: 0.219484\n",
      "[700]\tvalid_0's binary_logloss: 0.220247\n",
      "[750]\tvalid_0's binary_logloss: 0.218303\n",
      "[800]\tvalid_0's binary_logloss: 0.216953\n",
      "[850]\tvalid_0's binary_logloss: 0.212592\n",
      "[900]\tvalid_0's binary_logloss: 0.213225\n",
      "[950]\tvalid_0's binary_logloss: 0.214341\n",
      "Early stopping, best iteration is:\n",
      "[879]\tvalid_0's binary_logloss: 0.211444\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f2684696168>\n",
      "splitted: (1284, 265), (320, 265)\n",
      "[0]\ttrain-logloss:0.675098\tvalid-logloss:0.68039\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.304746\tvalid-logloss:0.391271\n",
      "[100]\ttrain-logloss:0.196824\tvalid-logloss:0.297295\n",
      "[150]\ttrain-logloss:0.140138\tvalid-logloss:0.256978\n",
      "[200]\ttrain-logloss:0.106042\tvalid-logloss:0.242286\n",
      "[250]\ttrain-logloss:0.081437\tvalid-logloss:0.229366\n",
      "[300]\ttrain-logloss:0.064842\tvalid-logloss:0.218683\n",
      "[350]\ttrain-logloss:0.052546\tvalid-logloss:0.216131\n",
      "[400]\ttrain-logloss:0.042428\tvalid-logloss:0.213944\n",
      "[450]\ttrain-logloss:0.035034\tvalid-logloss:0.21122\n",
      "[500]\ttrain-logloss:0.02916\tvalid-logloss:0.209786\n",
      "[550]\ttrain-logloss:0.024513\tvalid-logloss:0.210814\n",
      "Stopping. Best iteration:\n",
      "[481]\ttrain-logloss:0.031271\tvalid-logloss:0.209578\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.393465\n",
      "[100]\tvalid_0's binary_logloss: 0.279678\n",
      "[150]\tvalid_0's binary_logloss: 0.237887\n",
      "[200]\tvalid_0's binary_logloss: 0.216067\n",
      "[250]\tvalid_0's binary_logloss: 0.204365\n",
      "[300]\tvalid_0's binary_logloss: 0.198313\n",
      "[350]\tvalid_0's binary_logloss: 0.192645\n",
      "[400]\tvalid_0's binary_logloss: 0.189572\n",
      "[450]\tvalid_0's binary_logloss: 0.192416\n",
      "[500]\tvalid_0's binary_logloss: 0.194376\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's binary_logloss: 0.188083\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.447473\n",
      "[100]\tvalid_0's binary_logloss: 0.382741\n",
      "[150]\tvalid_0's binary_logloss: 0.337567\n",
      "[200]\tvalid_0's binary_logloss: 0.300476\n",
      "[250]\tvalid_0's binary_logloss: 0.271755\n",
      "[300]\tvalid_0's binary_logloss: 0.253998\n",
      "[350]\tvalid_0's binary_logloss: 0.244071\n",
      "[400]\tvalid_0's binary_logloss: 0.231432\n",
      "[450]\tvalid_0's binary_logloss: 0.219401\n",
      "[500]\tvalid_0's binary_logloss: 0.213589\n",
      "[550]\tvalid_0's binary_logloss: 0.215048\n",
      "[600]\tvalid_0's binary_logloss: 0.206773\n",
      "[650]\tvalid_0's binary_logloss: 0.207468\n",
      "[700]\tvalid_0's binary_logloss: 0.200879\n",
      "[750]\tvalid_0's binary_logloss: 0.198749\n",
      "[800]\tvalid_0's binary_logloss: 0.197033\n",
      "[850]\tvalid_0's binary_logloss: 0.197296\n",
      "Early stopping, best iteration is:\n",
      "[773]\tvalid_0's binary_logloss: 0.195831\n",
      "\n",
      "Blending...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'.//gbm/subm_2018-01-16-00-41_lgb_gbdt_02.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-eb04cd7bd4ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m#blending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0msave_blend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-eb04cd7bd4ab>\u001b[0m in \u001b[0;36msave_blend\u001b[0;34m(preds, loc)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mblend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/{1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load: {0}, w={1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'.//gbm/subm_2018-01-16-00-41_lgb_gbdt_02.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# This will be the version changed based on my own understanding\n",
    "def save_blend(preds={}, loc='./'):\n",
    "    target = 'is_iceberg'\n",
    "    \n",
    "    w_total = 0.0\n",
    "    blend = None\n",
    "    df_corr = None\n",
    "    print('\\nBlending...')\n",
    "    for k, v in preds.items():\n",
    "        if blend is None:\n",
    "            blend = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            \n",
    "            df_corr = pd.DataFrame({'id': blend['id'].tolist()})\n",
    "            df_corr[k[16:-4]] = blend[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] = blend[target] * v\n",
    "                \n",
    "        else:\n",
    "            preds_tmp = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            df_corr[k[16:-4]] = preds_tmp[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] += preds_tmp[target] * v\n",
    "            del preds_tmp\n",
    "            \n",
    "    print('\\n{}'.format(df_corr.corr()), flush=True)\n",
    "    #write submission\n",
    "    blend[target] = blend[target] / w_total\n",
    "    print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "    blend.to_csv('{}subm_blend{:03d}_{}.csv'.format(loc, len(preds), tmp), index=False, float_format='%.6f')\n",
    "\n",
    "def run_lgb(params={}, lgb_train=None, lgb_valid=None, lgb_test=None, test_ids=None, nr_round=2000, min_round=100, file=''):\n",
    "\n",
    "    print('\\nLightGBM: {}'.format(params['boosting'])) \n",
    "    model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "    \n",
    "    pred = model2.predict(lgb_test, num_iteration=model2.best_iteration)\n",
    "    #\n",
    "    subm = pd.DataFrame({'id': test_ids, 'is_iceberg': pred})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    #   \n",
    "    df = pd.DataFrame({'feature':model2.feature_name(), 'importances': model2.feature_importance()})\n",
    "    \n",
    "    return pred, df\n",
    "\n",
    "\n",
    "#results\n",
    "freq = pd.DataFrame()\n",
    "subms = []\n",
    "\n",
    "#training\n",
    "# test_ratio = 0.2\n",
    "# nr_runs = 3\n",
    "# split_seed = 25\n",
    "# kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "seed_list=[]\n",
    "# final_dict ={}\n",
    "# final_dict['xgb_re'] = []\n",
    "# final_dict['lgb_re'] = []\n",
    "# final_dict['lgb_dart_re'] =[]\n",
    "for rep in range(1):\n",
    "    ran_num =  np.random.randint(50000,60000,size=1)[0]\n",
    "    seed_list.append(ran_num)\n",
    "    split_seed= np.random.RandomState(ran_num)\n",
    "    print('The seed we are using is: %d' % ran_num)\n",
    "    nr_runs = 5\n",
    "    kf = KFold(n_splits=nr_runs, random_state=split_seed)\n",
    "    tree_lim =0\n",
    "    xgb_re = []\n",
    "    lgb_re =[]\n",
    "    lgb_dart_re= []\n",
    "    for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "        print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "        tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "        x1, x2 = train_X[train_index], train_X[test_index]\n",
    "        y1, y2 = train_y[train_index], train_y[test_index]\n",
    "        #x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=test_ratio, random_state=split_seed + r)\n",
    "        print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "        test_X_dup = test_X.copy()\n",
    "\n",
    "        #XGB\n",
    "        xgb_train = xgb.DMatrix(x1, y1)\n",
    "        xgb_valid = xgb.DMatrix(x2, y2)\n",
    "        #\n",
    "        watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "        params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "        params['eta'] = 0.03\n",
    "        params['max_depth'] = 4\n",
    "        params['subsample'] = 0.9\n",
    "        params['eval_metric'] = 'logloss'\n",
    "        params['colsample_bytree'] = 0.8\n",
    "        params['colsample_bylevel'] = 0.8\n",
    "        params['max_delta_step'] = 3\n",
    "        #params['gamma'] = 5.0\n",
    "        #params['labmda'] = 1\n",
    "        params['scale_pos_weight'] = 1.0\n",
    "        params['seed'] = ran_num + r\n",
    "        nr_round = 2000\n",
    "        min_round = 100\n",
    "\n",
    "        model1 = xgb.train(params, \n",
    "                           xgb_train, \n",
    "                           nr_round,  \n",
    "                           watchlist, \n",
    "                           verbose_eval=50, \n",
    "                           early_stopping_rounds=min_round)\n",
    "\n",
    "        pred_xgb = model1.predict(xgb.DMatrix(test_X_dup), ntree_limit=model1.best_ntree_limit+tree_lim)\n",
    "\n",
    "        #\n",
    "        file = 'gbm/subm_{}_xgb_{:02d}.csv'.format(tmp, r+1)\n",
    "        subm = pd.DataFrame({'id': test['id'].values, target: pred_xgb})\n",
    "        subm.to_csv(file, index=False, float_format='%.6f')\n",
    "        subms.append(file)    \n",
    "\n",
    "        ##LightGBM\n",
    "        lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "        lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "        #gbdt\n",
    "        params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "        params['boosting'] = 'gbdt'\n",
    "        params['metric'] = 'binary_logloss'\n",
    "        params['learning_rate'] = 0.03\n",
    "        params['max_depth'] = 5\n",
    "        params['num_leaves'] = 9 # higher number of leaves\n",
    "        params['feature_fraction'] = 0.8 # Controls overfit\n",
    "        params['bagging_fraction'] = 0.9    \n",
    "        params['bagging_freq'] = 3\n",
    "        params['seed'] = ran_num + r\n",
    "        #\n",
    "        params['verbose'] = -1\n",
    "\n",
    "        file = 'gbm/subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "        subms.append(file)\n",
    "        \n",
    "        model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "\n",
    "        ##LightGBM\n",
    "        #dart\n",
    "        params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "        params['boosting'] = 'dart'\n",
    "        params['metric'] = 'binary_logloss'\n",
    "        params['learning_rate'] = 0.04\n",
    "        params['max_depth'] = 5\n",
    "        params['num_leaves'] = 16 # higher number of leaves\n",
    "        params['feature_fraction'] = 0.8 # Controls overfit\n",
    "        params['bagging_fraction'] = 0.9    \n",
    "        params['bagging_freq'] = 3\n",
    "        params['seed'] = ran_num + r\n",
    "        #dart\n",
    "        params['drop_rate'] = 0.1\n",
    "        params['skip_drop'] = 0.5\n",
    "        params['max_drop'] = 10\n",
    "        params['verbose'] = -1 \n",
    "\n",
    "        file = 'gbm/subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "        subms.append(file)\n",
    "\n",
    "        model3 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "        \n",
    "        \n",
    "        xgb_re.append(model1.best_score)\n",
    "        lgb_re.append(model2.best_score['valid_0']['binary_logloss'])\n",
    "        lgb_dart_re.append(model3.best_score['valid_0']['binary_logloss'])\n",
    "    \n",
    "#     final_dict['xgb_re'].append(np.mean(xgb_re))\n",
    "#     final_dict['lgb_re'].append(np.mean(lgb_re))\n",
    "#     final_dict['lgb_dart_re'].append(np.mean(lgb_dart_re))\n",
    "    \n",
    "    #blending\n",
    "    preds = {k: 1.0 for k in subms}\n",
    "    save_blend(preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21012963979079585, 0.20862186577636441, 0.20983491831459072, 0.205572354848373, 0.20768137792375349, 0.21065259329173974, 0.21025686751234796, 0.2092285317725569, 0.20937734740484334, 0.20710388216406561]\n",
      "[0.21192038774617994, 0.21510278865547719, 0.21349441290720278, 0.21314132306764719, 0.21106262003875184, 0.21150269654329173, 0.20970752255349692, 0.21026733285106491, 0.21018590252162195, 0.21561990540992712]\n",
      "[0.20853060000000001, 0.20904379999999997, 0.20738019999999996, 0.20734639999999999, 0.207984, 0.20712419999999998, 0.20816319999999999, 0.20811739999999998, 0.20851959999999997, 0.20861739999999998]\n"
     ]
    }
   ],
   "source": [
    "for i,v in final_dict.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will be the version changed based on my own understanding\n",
    "def save_blend(preds={}, loc='./'):\n",
    "    target = 'is_iceberg'\n",
    "    \n",
    "    w_total = 0.0\n",
    "    blend = None\n",
    "    df_corr = None\n",
    "    print('\\nBlending...')\n",
    "    for k, v in preds.items():\n",
    "        if blend is None:\n",
    "            blend = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            \n",
    "            df_corr = pd.DataFrame({'id': blend['id'].tolist()})\n",
    "            df_corr[k[16:-4]] = blend[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] = blend[target] * v\n",
    "                \n",
    "        else:\n",
    "            preds_tmp = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            df_corr[k[16:-4]] = preds_tmp[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] += preds_tmp[target] * v\n",
    "            del preds_tmp\n",
    "            \n",
    "    print('\\n{}'.format(df_corr.corr()), flush=True)\n",
    "    #write submission\n",
    "    blend[target] = blend[target] / w_total\n",
    "    print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "    blend.to_csv('{}subm_blend{:03d}_{}.csv'.format(loc, len(preds), tmp), index=False, float_format='%.6f')\n",
    "\n",
    "def run_lgb(params={}, lgb_train=None, lgb_valid=None, lgb_test=None, test_ids=None, nr_round=2000, min_round=100, file=''):\n",
    "\n",
    "    print('\\nLightGBM: {}'.format(params['boosting'])) \n",
    "    model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "    \n",
    "    pred = model2.predict(lgb_test, num_iteration=model2.best_iteration)\n",
    "    #\n",
    "    subm = pd.DataFrame({'id': test_ids, 'is_iceberg': pred})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    #   \n",
    "    df = pd.DataFrame({'feature':model2.feature_name(), 'importances': model2.feature_importance()})\n",
    "    \n",
    "    return pred, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed we are using is: 56491\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.666214\tvalid-logloss:0.668001\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.23468\tvalid-logloss:0.302959\n",
      "[100]\ttrain-logloss:0.1385\tvalid-logloss:0.240614\n",
      "[150]\ttrain-logloss:0.090079\tvalid-logloss:0.213791\n",
      "[200]\ttrain-logloss:0.061226\tvalid-logloss:0.201662\n",
      "[250]\ttrain-logloss:0.043525\tvalid-logloss:0.195157\n",
      "[300]\ttrain-logloss:0.032578\tvalid-logloss:0.194752\n",
      "[350]\ttrain-logloss:0.024474\tvalid-logloss:0.193095\n",
      "Stopping. Best iteration:\n",
      "[280]\ttrain-logloss:0.036201\tvalid-logloss:0.192763\n",
      "\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.666596\tvalid-logloss:0.668727\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.240889\tvalid-logloss:0.283905\n",
      "[100]\ttrain-logloss:0.142967\tvalid-logloss:0.21845\n",
      "[150]\ttrain-logloss:0.093978\tvalid-logloss:0.19393\n",
      "[200]\ttrain-logloss:0.063425\tvalid-logloss:0.181622\n",
      "[250]\ttrain-logloss:0.045308\tvalid-logloss:0.176367\n",
      "[300]\ttrain-logloss:0.033076\tvalid-logloss:0.173846\n",
      "[350]\ttrain-logloss:0.024893\tvalid-logloss:0.170745\n",
      "[400]\ttrain-logloss:0.019392\tvalid-logloss:0.171306\n",
      "[450]\ttrain-logloss:0.01579\tvalid-logloss:0.17114\n",
      "[500]\ttrain-logloss:0.013128\tvalid-logloss:0.172019\n",
      "Stopping. Best iteration:\n",
      "[417]\ttrain-logloss:0.018\tvalid-logloss:0.170298\n",
      "\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.666402\tvalid-logloss:0.670054\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.22897\tvalid-logloss:0.340124\n",
      "[100]\ttrain-logloss:0.129845\tvalid-logloss:0.283948\n",
      "[150]\ttrain-logloss:0.082976\tvalid-logloss:0.270349\n",
      "[200]\ttrain-logloss:0.057181\tvalid-logloss:0.261868\n",
      "[250]\ttrain-logloss:0.040632\tvalid-logloss:0.259427\n",
      "[300]\ttrain-logloss:0.029976\tvalid-logloss:0.257781\n",
      "[350]\ttrain-logloss:0.022812\tvalid-logloss:0.260664\n",
      "[400]\ttrain-logloss:0.017932\tvalid-logloss:0.258241\n",
      "Stopping. Best iteration:\n",
      "[300]\ttrain-logloss:0.029976\tvalid-logloss:0.257781\n",
      "\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.665853\tvalid-logloss:0.668345\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.233797\tvalid-logloss:0.30071\n",
      "[100]\ttrain-logloss:0.133867\tvalid-logloss:0.244239\n",
      "[150]\ttrain-logloss:0.089286\tvalid-logloss:0.227799\n",
      "[200]\ttrain-logloss:0.061123\tvalid-logloss:0.221956\n",
      "[250]\ttrain-logloss:0.043382\tvalid-logloss:0.218026\n",
      "[300]\ttrain-logloss:0.031582\tvalid-logloss:0.215482\n",
      "[350]\ttrain-logloss:0.023975\tvalid-logloss:0.216334\n",
      "Stopping. Best iteration:\n",
      "[293]\ttrain-logloss:0.033125\tvalid-logloss:0.214801\n",
      "\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1284, 247), (320, 247)\n",
      "[0]\ttrain-logloss:0.664521\tvalid-logloss:0.6706\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.2349\tvalid-logloss:0.324698\n",
      "[100]\ttrain-logloss:0.138843\tvalid-logloss:0.240784\n",
      "[150]\ttrain-logloss:0.09166\tvalid-logloss:0.216414\n",
      "[200]\ttrain-logloss:0.062603\tvalid-logloss:0.206853\n",
      "[250]\ttrain-logloss:0.044424\tvalid-logloss:0.202808\n",
      "[300]\ttrain-logloss:0.032655\tvalid-logloss:0.201506\n",
      "[350]\ttrain-logloss:0.024519\tvalid-logloss:0.203313\n",
      "[400]\ttrain-logloss:0.01912\tvalid-logloss:0.203144\n",
      "Stopping. Best iteration:\n",
      "[302]\ttrain-logloss:0.032328\tvalid-logloss:0.200549\n",
      "\n",
      "All your scores are: \n",
      "[0.192763, 0.170298, 0.257781, 0.214801, 0.200549]\n",
      "The average of your score\n",
      "0.2072384\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.666067\tvalid-logloss:0.667713\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.229277\tvalid-logloss:0.298399\n",
      "[100]\ttrain-logloss:0.131136\tvalid-logloss:0.240229\n",
      "[150]\ttrain-logloss:0.083456\tvalid-logloss:0.216576\n",
      "[200]\ttrain-logloss:0.056792\tvalid-logloss:0.207917\n",
      "[250]\ttrain-logloss:0.040131\tvalid-logloss:0.203977\n",
      "[300]\ttrain-logloss:0.029615\tvalid-logloss:0.200053\n",
      "[350]\ttrain-logloss:0.02202\tvalid-logloss:0.200564\n",
      "[400]\ttrain-logloss:0.017469\tvalid-logloss:0.203603\n",
      "Stopping. Best iteration:\n",
      "[310]\ttrain-logloss:0.027817\tvalid-logloss:0.198184\n",
      "\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.666406\tvalid-logloss:0.668471\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.236529\tvalid-logloss:0.279748\n",
      "[100]\ttrain-logloss:0.13858\tvalid-logloss:0.212694\n",
      "[150]\ttrain-logloss:0.089556\tvalid-logloss:0.191619\n",
      "[200]\ttrain-logloss:0.059304\tvalid-logloss:0.184286\n",
      "[250]\ttrain-logloss:0.041874\tvalid-logloss:0.176309\n",
      "[300]\ttrain-logloss:0.030082\tvalid-logloss:0.175199\n",
      "[350]\ttrain-logloss:0.023085\tvalid-logloss:0.173952\n",
      "[400]\ttrain-logloss:0.01806\tvalid-logloss:0.17464\n",
      "Stopping. Best iteration:\n",
      "[342]\ttrain-logloss:0.024072\tvalid-logloss:0.173422\n",
      "\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.664991\tvalid-logloss:0.669403\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.224803\tvalid-logloss:0.335545\n",
      "[100]\ttrain-logloss:0.125837\tvalid-logloss:0.282081\n",
      "[150]\ttrain-logloss:0.079213\tvalid-logloss:0.260596\n",
      "[200]\ttrain-logloss:0.053171\tvalid-logloss:0.250554\n",
      "[250]\ttrain-logloss:0.037226\tvalid-logloss:0.244185\n",
      "[300]\ttrain-logloss:0.026989\tvalid-logloss:0.243244\n",
      "[350]\ttrain-logloss:0.020739\tvalid-logloss:0.244094\n",
      "Stopping. Best iteration:\n",
      "[256]\ttrain-logloss:0.035641\tvalid-logloss:0.242851\n",
      "\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n",
      "[0]\ttrain-logloss:0.665549\tvalid-logloss:0.667739\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.232222\tvalid-logloss:0.30225\n",
      "[100]\ttrain-logloss:0.131846\tvalid-logloss:0.24812\n",
      "[150]\ttrain-logloss:0.088866\tvalid-logloss:0.234397\n",
      "[200]\ttrain-logloss:0.059061\tvalid-logloss:0.226135\n",
      "[250]\ttrain-logloss:0.041048\tvalid-logloss:0.21854\n",
      "[300]\ttrain-logloss:0.030266\tvalid-logloss:0.221084\n",
      "[350]\ttrain-logloss:0.023087\tvalid-logloss:0.221248\n",
      "Stopping. Best iteration:\n",
      "[261]\ttrain-logloss:0.038608\tvalid-logloss:0.217011\n",
      "\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1284, 247), (320, 247)\n",
      "[0]\ttrain-logloss:0.664159\tvalid-logloss:0.671323\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.228229\tvalid-logloss:0.320427\n",
      "[100]\ttrain-logloss:0.131681\tvalid-logloss:0.248603\n",
      "[150]\ttrain-logloss:0.085522\tvalid-logloss:0.224335\n",
      "[200]\ttrain-logloss:0.058631\tvalid-logloss:0.21777\n",
      "[250]\ttrain-logloss:0.04085\tvalid-logloss:0.214886\n",
      "[300]\ttrain-logloss:0.029499\tvalid-logloss:0.212339\n",
      "[350]\ttrain-logloss:0.022363\tvalid-logloss:0.212458\n",
      "[400]\ttrain-logloss:0.017329\tvalid-logloss:0.214893\n",
      "Stopping. Best iteration:\n",
      "[321]\ttrain-logloss:0.026112\tvalid-logloss:0.210235\n",
      "\n",
      "All your scores are: \n",
      "[0.198184, 0.173422, 0.242851, 0.217011, 0.210235]\n",
      "The average of your score\n",
      "0.2083406\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f4f99a3e4c8>\n",
      "splitted: (1283, 247), (321, 247)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "b'value 1.2 for Parameter colsample_bylevel exceed bound [0,1]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-3db9a2d649de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                                \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                                early_stopping_rounds=min_round)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X_dup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'value 1.2 for Parameter colsample_bylevel exceed bound [0,1]'"
     ]
    }
   ],
   "source": [
    "#results\n",
    "freq = pd.DataFrame()\n",
    "\n",
    "avg_result = []\n",
    "#training\n",
    "# test_ratio = 0.2\n",
    "# nr_runs = 3\n",
    "# split_seed = 25\n",
    "# kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "\n",
    "ran_num = 463465 #463465#56491\n",
    "for ran_num in [56491,463465]:\n",
    "    split_seed= np.random.RandomState(ran_num)\n",
    "    print('The seed we are using is: %d' % ran_num)\n",
    "    nr_runs = 5\n",
    "    kf = KFold(n_splits=nr_runs, random_state=split_seed)\n",
    "\n",
    "    for param in [0.5,0.8,1.2,1.5]:\n",
    "        result = []\n",
    "        for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "            print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "            tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "            x1, x2 = train_X[train_index], train_X[test_index]\n",
    "            y1, y2 = train_y[train_index], train_y[test_index]\n",
    "            #x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=test_ratio, random_state=split_seed + r)\n",
    "            print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "            test_X_dup = test_X.copy()\n",
    "\n",
    "            #XGB\n",
    "            xgb_train = xgb.DMatrix(x1, y1)\n",
    "            xgb_valid = xgb.DMatrix(x2, y2)\n",
    "            #\n",
    "            watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "            params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "            params['eta'] = 0.05\n",
    "            params['max_depth'] = 4\n",
    "            params['subsample'] = 0.9\n",
    "            params['eval_metric'] = 'logloss'\n",
    "            params['colsample_bytree'] = 0.8\n",
    "            params['colsample_bylevel'] = param\n",
    "            params['max_delta_step'] = 3\n",
    "            #params['gamma'] = 5.0\n",
    "            params['labmda'] = param\n",
    "            params['scale_pos_weight'] = 1.0\n",
    "            params['seed'] = ran_num + r\n",
    "            nr_round = 2000\n",
    "            min_round = 100\n",
    "\n",
    "            model1 = xgb.train(params, \n",
    "                               xgb_train, \n",
    "                               nr_round,  \n",
    "                               watchlist, \n",
    "                               verbose_eval=50, \n",
    "                               early_stopping_rounds=min_round)\n",
    "\n",
    "            pred_xgb = model1.predict(xgb.DMatrix(test_X_dup), ntree_limit=model1.best_ntree_limit)\n",
    "\n",
    "            #\n",
    "            msg= 'xgbfold%d'%r\n",
    "            freq[msg] = pred_xgb\n",
    "            result.append(model1.best_score)\n",
    "        print('All your scores are: ')\n",
    "        print(result)\n",
    "        print('The average of your score')\n",
    "        print(np.mean(result))\n",
    "        avg_result.append(np.mean(result))\n",
    "print(avg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#model1.best_score\n",
    "\n",
    "nta = [0.01,0.015,0.02,0.025,0.03]\n",
    "[0.20835880000000001, 0.20946060000000002, 0.2080698, 0.20710020000000001, 0.20994420000000003]\n",
    "#change to different split.\n",
    "[0.2067958, 0.20759760000000002, 0.20812819999999999, 0.20848559999999999, 0.20875680000000002]\n",
    "\n",
    "then we want to see tree depth sensitivity.\n",
    "[2,3,4,5]\n",
    "[0.2127414, 0.20789479999999999, 0.2080698, 0.20814539999999998\n",
    " \n",
    "subsample 0.5,0.6,0.7,0.8,0.85,0.9,0.95 #maybe because data points are limited?\n",
    "[0.21047080000000001, 0.20971980000000001, 0.2092918, 0.2080698,0.20451239, 0.2070148,0.20853039999999998]\n",
    "\n",
    "change to other data split! consistent here!\n",
    "[0.21159359999999999, 0.21181939999999999, 0.20943299999999998, 0.2081281,0.2075963 0.207232,0.20908] \n",
    "\n",
    " \n",
    "#### colsample_bytree 0.6,0.7,0.8,0.9\n",
    "[0.2066904, 0.20730179999999998, 0.2070148, 0.21193840000000003]\n",
    "[0.2090204, 0.20862359999999999, 0.207232, 0.20750860000000002]\n",
    "\n",
    "#### max_delta: Maximum delta step we allow each tree’s weight estimation to be.\n",
    "[0.20828599999999997, 0.2070148, 0.2070148, 0.2070148]\n",
    "[0.20910699999999999, 0.207232, 0.207232, 0.207232]\n",
    "\n",
    "  [0.6,0.7,0.8,0.9]\n",
    "0.20991120000000002, 0.2083854, 0.20834060000000001, 0.20772740000000001, \n",
    "0.20727820000000002, 0.20918019999999998, 0.21255940000000001, 0.2111894\n",
    "\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed we are using is: 2312\n",
      "\n",
      "round 0001 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.343065\n",
      "[100]\tvalid_0's binary_logloss: 0.254834\n",
      "[150]\tvalid_0's binary_logloss: 0.220965\n",
      "[200]\tvalid_0's binary_logloss: 0.201352\n",
      "[250]\tvalid_0's binary_logloss: 0.19127\n",
      "[300]\tvalid_0's binary_logloss: 0.184706\n",
      "[350]\tvalid_0's binary_logloss: 0.181717\n",
      "[400]\tvalid_0's binary_logloss: 0.180455\n",
      "[450]\tvalid_0's binary_logloss: 0.180666\n",
      "[500]\tvalid_0's binary_logloss: 0.173666\n",
      "[550]\tvalid_0's binary_logloss: 0.170401\n",
      "[600]\tvalid_0's binary_logloss: 0.16884\n",
      "[650]\tvalid_0's binary_logloss: 0.173522\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's binary_logloss: 0.167662\n",
      "\n",
      "round 0002 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.378399\n",
      "[100]\tvalid_0's binary_logloss: 0.301905\n",
      "[150]\tvalid_0's binary_logloss: 0.275759\n",
      "[200]\tvalid_0's binary_logloss: 0.26219\n",
      "[250]\tvalid_0's binary_logloss: 0.254096\n",
      "[300]\tvalid_0's binary_logloss: 0.249903\n",
      "[350]\tvalid_0's binary_logloss: 0.249095\n",
      "[400]\tvalid_0's binary_logloss: 0.250474\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's binary_logloss: 0.247819\n",
      "\n",
      "round 0003 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.352476\n",
      "[100]\tvalid_0's binary_logloss: 0.263543\n",
      "[150]\tvalid_0's binary_logloss: 0.225651\n",
      "[200]\tvalid_0's binary_logloss: 0.206268\n",
      "[250]\tvalid_0's binary_logloss: 0.193059\n",
      "[300]\tvalid_0's binary_logloss: 0.1842\n",
      "[350]\tvalid_0's binary_logloss: 0.178217\n",
      "[400]\tvalid_0's binary_logloss: 0.177505\n",
      "[450]\tvalid_0's binary_logloss: 0.177303\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's binary_logloss: 0.175978\n",
      "\n",
      "round 0004 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.323545\n",
      "[100]\tvalid_0's binary_logloss: 0.232212\n",
      "[150]\tvalid_0's binary_logloss: 0.196828\n",
      "[200]\tvalid_0's binary_logloss: 0.18134\n",
      "[250]\tvalid_0's binary_logloss: 0.174004\n",
      "[300]\tvalid_0's binary_logloss: 0.163071\n",
      "[350]\tvalid_0's binary_logloss: 0.155409\n",
      "[400]\tvalid_0's binary_logloss: 0.152922\n",
      "[450]\tvalid_0's binary_logloss: 0.151813\n",
      "[500]\tvalid_0's binary_logloss: 0.149686\n",
      "[550]\tvalid_0's binary_logloss: 0.148294\n",
      "[600]\tvalid_0's binary_logloss: 0.149283\n",
      "Early stopping, best iteration is:\n",
      "[516]\tvalid_0's binary_logloss: 0.147147\n",
      "\n",
      "round 0005 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.386534\n",
      "[100]\tvalid_0's binary_logloss: 0.327918\n",
      "[150]\tvalid_0's binary_logloss: 0.302457\n",
      "[200]\tvalid_0's binary_logloss: 0.292179\n",
      "[250]\tvalid_0's binary_logloss: 0.287759\n",
      "[300]\tvalid_0's binary_logloss: 0.281532\n",
      "[350]\tvalid_0's binary_logloss: 0.28261\n",
      "[400]\tvalid_0's binary_logloss: 0.282431\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's binary_logloss: 0.280413\n",
      "\n",
      "round 0006 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.355316\n",
      "[100]\tvalid_0's binary_logloss: 0.279425\n",
      "[150]\tvalid_0's binary_logloss: 0.252668\n",
      "[200]\tvalid_0's binary_logloss: 0.240048\n",
      "[250]\tvalid_0's binary_logloss: 0.232272\n",
      "[300]\tvalid_0's binary_logloss: 0.233465\n",
      "[350]\tvalid_0's binary_logloss: 0.232947\n",
      "[400]\tvalid_0's binary_logloss: 0.231259\n",
      "[450]\tvalid_0's binary_logloss: 0.231899\n",
      "[500]\tvalid_0's binary_logloss: 0.239039\n",
      "Early stopping, best iteration is:\n",
      "[437]\tvalid_0's binary_logloss: 0.230192\n",
      "\n",
      "round 0007 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.347871\n",
      "[100]\tvalid_0's binary_logloss: 0.261602\n",
      "[150]\tvalid_0's binary_logloss: 0.230592\n",
      "[200]\tvalid_0's binary_logloss: 0.215199\n",
      "[250]\tvalid_0's binary_logloss: 0.208754\n",
      "[300]\tvalid_0's binary_logloss: 0.20301\n",
      "[350]\tvalid_0's binary_logloss: 0.199178\n",
      "[400]\tvalid_0's binary_logloss: 0.199207\n",
      "[450]\tvalid_0's binary_logloss: 0.195146\n",
      "[500]\tvalid_0's binary_logloss: 0.192931\n",
      "[550]\tvalid_0's binary_logloss: 0.194517\n",
      "Early stopping, best iteration is:\n",
      "[498]\tvalid_0's binary_logloss: 0.192308\n",
      "\n",
      "round 0008 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.348908\n",
      "[100]\tvalid_0's binary_logloss: 0.264972\n",
      "[150]\tvalid_0's binary_logloss: 0.237004\n",
      "[200]\tvalid_0's binary_logloss: 0.227609\n",
      "[250]\tvalid_0's binary_logloss: 0.221746\n",
      "[300]\tvalid_0's binary_logloss: 0.21689\n",
      "[350]\tvalid_0's binary_logloss: 0.216858\n",
      "[400]\tvalid_0's binary_logloss: 0.215505\n",
      "[450]\tvalid_0's binary_logloss: 0.2112\n",
      "[500]\tvalid_0's binary_logloss: 0.212341\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's binary_logloss: 0.209964\n",
      "\n",
      "round 0009 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.384627\n",
      "[100]\tvalid_0's binary_logloss: 0.309719\n",
      "[150]\tvalid_0's binary_logloss: 0.282605\n",
      "[200]\tvalid_0's binary_logloss: 0.273071\n",
      "[250]\tvalid_0's binary_logloss: 0.265858\n",
      "[300]\tvalid_0's binary_logloss: 0.264536\n",
      "[350]\tvalid_0's binary_logloss: 0.262968\n",
      "[400]\tvalid_0's binary_logloss: 0.262747\n",
      "[450]\tvalid_0's binary_logloss: 0.260736\n",
      "[500]\tvalid_0's binary_logloss: 0.263533\n",
      "Early stopping, best iteration is:\n",
      "[449]\tvalid_0's binary_logloss: 0.260729\n",
      "\n",
      "round 0010 of 0010, seed=<mtrand.RandomState object at 0x7f51feb63678>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.384283\n",
      "[100]\tvalid_0's binary_logloss: 0.246884\n",
      "[150]\tvalid_0's binary_logloss: 0.178272\n",
      "[200]\tvalid_0's binary_logloss: 0.167528\n",
      "[250]\tvalid_0's binary_logloss: 0.159191\n",
      "[300]\tvalid_0's binary_logloss: 0.151512\n",
      "[350]\tvalid_0's binary_logloss: 0.149079\n",
      "[400]\tvalid_0's binary_logloss: 0.143607\n",
      "[450]\tvalid_0's binary_logloss: 0.141985\n",
      "[500]\tvalid_0's binary_logloss: 0.136619\n",
      "[550]\tvalid_0's binary_logloss: 0.1396\n",
      "[600]\tvalid_0's binary_logloss: 0.141824\n",
      "Early stopping, best iteration is:\n",
      "[501]\tvalid_0's binary_logloss: 0.136564\n",
      "All your scores are: \n",
      "[0.16766203979307295, 0.24781945842830488, 0.17597810792745913, 0.14714716525164626, 0.28041251884171059, 0.23019167342826558, 0.19230755956374987, 0.20996438579061122, 0.26072931253513709, 0.13656441932182722]\n",
      "The average of your score\n",
      "0.204877664088\n",
      "The seed we are using is: 56491\n",
      "\n",
      "round 0001 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.342415\n",
      "[100]\tvalid_0's binary_logloss: 0.257943\n",
      "[150]\tvalid_0's binary_logloss: 0.226912\n",
      "[200]\tvalid_0's binary_logloss: 0.206617\n",
      "[250]\tvalid_0's binary_logloss: 0.197054\n",
      "[300]\tvalid_0's binary_logloss: 0.184139\n",
      "[350]\tvalid_0's binary_logloss: 0.180141\n",
      "[400]\tvalid_0's binary_logloss: 0.176099\n",
      "[450]\tvalid_0's binary_logloss: 0.173831\n",
      "[500]\tvalid_0's binary_logloss: 0.17183\n",
      "[550]\tvalid_0's binary_logloss: 0.172316\n",
      "[600]\tvalid_0's binary_logloss: 0.172587\n",
      "Early stopping, best iteration is:\n",
      "[536]\tvalid_0's binary_logloss: 0.171277\n",
      "\n",
      "round 0002 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.370054\n",
      "[100]\tvalid_0's binary_logloss: 0.297253\n",
      "[150]\tvalid_0's binary_logloss: 0.27445\n",
      "[200]\tvalid_0's binary_logloss: 0.270926\n",
      "[250]\tvalid_0's binary_logloss: 0.260392\n",
      "[300]\tvalid_0's binary_logloss: 0.259999\n",
      "[350]\tvalid_0's binary_logloss: 0.25992\n",
      "[400]\tvalid_0's binary_logloss: 0.259338\n",
      "[450]\tvalid_0's binary_logloss: 0.25827\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's binary_logloss: 0.255886\n",
      "\n",
      "round 0003 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.352356\n",
      "[100]\tvalid_0's binary_logloss: 0.257801\n",
      "[150]\tvalid_0's binary_logloss: 0.221578\n",
      "[200]\tvalid_0's binary_logloss: 0.20616\n",
      "[250]\tvalid_0's binary_logloss: 0.200948\n",
      "[300]\tvalid_0's binary_logloss: 0.197356\n",
      "[350]\tvalid_0's binary_logloss: 0.194827\n",
      "[400]\tvalid_0's binary_logloss: 0.193151\n",
      "[450]\tvalid_0's binary_logloss: 0.191603\n",
      "[500]\tvalid_0's binary_logloss: 0.189083\n",
      "[550]\tvalid_0's binary_logloss: 0.192485\n",
      "Early stopping, best iteration is:\n",
      "[486]\tvalid_0's binary_logloss: 0.187184\n",
      "\n",
      "round 0004 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.323819\n",
      "[100]\tvalid_0's binary_logloss: 0.233011\n",
      "[150]\tvalid_0's binary_logloss: 0.198224\n",
      "[200]\tvalid_0's binary_logloss: 0.181314\n",
      "[250]\tvalid_0's binary_logloss: 0.173802\n",
      "[300]\tvalid_0's binary_logloss: 0.16524\n",
      "[350]\tvalid_0's binary_logloss: 0.162879\n",
      "[400]\tvalid_0's binary_logloss: 0.156504\n",
      "[450]\tvalid_0's binary_logloss: 0.155874\n",
      "[500]\tvalid_0's binary_logloss: 0.157055\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid_0's binary_logloss: 0.153709\n",
      "\n",
      "round 0005 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.388992\n",
      "[100]\tvalid_0's binary_logloss: 0.324831\n",
      "[150]\tvalid_0's binary_logloss: 0.303491\n",
      "[200]\tvalid_0's binary_logloss: 0.298675\n",
      "[250]\tvalid_0's binary_logloss: 0.293249\n",
      "[300]\tvalid_0's binary_logloss: 0.289354\n",
      "[350]\tvalid_0's binary_logloss: 0.284245\n",
      "[400]\tvalid_0's binary_logloss: 0.28455\n",
      "[450]\tvalid_0's binary_logloss: 0.28875\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's binary_logloss: 0.281474\n",
      "\n",
      "round 0006 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.350433\n",
      "[100]\tvalid_0's binary_logloss: 0.282475\n",
      "[150]\tvalid_0's binary_logloss: 0.248346\n",
      "[200]\tvalid_0's binary_logloss: 0.238705\n",
      "[250]\tvalid_0's binary_logloss: 0.232583\n",
      "[300]\tvalid_0's binary_logloss: 0.235831\n",
      "[350]\tvalid_0's binary_logloss: 0.234231\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's binary_logloss: 0.232583\n",
      "\n",
      "round 0007 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.351792\n",
      "[100]\tvalid_0's binary_logloss: 0.266013\n",
      "[150]\tvalid_0's binary_logloss: 0.233622\n",
      "[200]\tvalid_0's binary_logloss: 0.217553\n",
      "[250]\tvalid_0's binary_logloss: 0.208796\n",
      "[300]\tvalid_0's binary_logloss: 0.202339\n",
      "[350]\tvalid_0's binary_logloss: 0.199592\n",
      "[400]\tvalid_0's binary_logloss: 0.19723\n",
      "[450]\tvalid_0's binary_logloss: 0.196566\n",
      "[500]\tvalid_0's binary_logloss: 0.197307\n",
      "[550]\tvalid_0's binary_logloss: 0.198344\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's binary_logloss: 0.194365\n",
      "\n",
      "round 0008 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.352769\n",
      "[100]\tvalid_0's binary_logloss: 0.266078\n",
      "[150]\tvalid_0's binary_logloss: 0.243016\n",
      "[200]\tvalid_0's binary_logloss: 0.232529\n",
      "[250]\tvalid_0's binary_logloss: 0.22473\n",
      "[300]\tvalid_0's binary_logloss: 0.21956\n",
      "[350]\tvalid_0's binary_logloss: 0.218208\n",
      "[400]\tvalid_0's binary_logloss: 0.217412\n",
      "[450]\tvalid_0's binary_logloss: 0.218236\n",
      "[500]\tvalid_0's binary_logloss: 0.217159\n",
      "[550]\tvalid_0's binary_logloss: 0.21898\n",
      "Early stopping, best iteration is:\n",
      "[471]\tvalid_0's binary_logloss: 0.21588\n",
      "\n",
      "round 0009 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.374515\n",
      "[100]\tvalid_0's binary_logloss: 0.306602\n",
      "[150]\tvalid_0's binary_logloss: 0.279471\n",
      "[200]\tvalid_0's binary_logloss: 0.270429\n",
      "[250]\tvalid_0's binary_logloss: 0.267821\n",
      "[300]\tvalid_0's binary_logloss: 0.263429\n",
      "[350]\tvalid_0's binary_logloss: 0.261928\n",
      "[400]\tvalid_0's binary_logloss: 0.262698\n",
      "[450]\tvalid_0's binary_logloss: 0.262332\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's binary_logloss: 0.260245\n",
      "\n",
      "round 0010 of 0010, seed=<mtrand.RandomState object at 0x7f4fb93e6510>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.382525\n",
      "[100]\tvalid_0's binary_logloss: 0.236069\n",
      "[150]\tvalid_0's binary_logloss: 0.195879\n",
      "[200]\tvalid_0's binary_logloss: 0.162833\n",
      "[250]\tvalid_0's binary_logloss: 0.149167\n",
      "[300]\tvalid_0's binary_logloss: 0.140531\n",
      "[350]\tvalid_0's binary_logloss: 0.134423\n",
      "[400]\tvalid_0's binary_logloss: 0.133763\n",
      "[450]\tvalid_0's binary_logloss: 0.133491\n",
      "Early stopping, best iteration is:\n",
      "[366]\tvalid_0's binary_logloss: 0.130646\n",
      "All your scores are: \n",
      "[0.17127714600499575, 0.2558864838359558, 0.18718406238095384, 0.15370905426002621, 0.28147403208340138, 0.23258291615675358, 0.19436524792680296, 0.21588014866552802, 0.26024495885195353, 0.13064635819260975]\n",
      "The average of your score\n",
      "0.208325040836\n",
      "The seed we are using is: 463465\n",
      "\n",
      "round 0001 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.339401\n",
      "[100]\tvalid_0's binary_logloss: 0.251923\n",
      "[150]\tvalid_0's binary_logloss: 0.219397\n",
      "[200]\tvalid_0's binary_logloss: 0.201087\n",
      "[250]\tvalid_0's binary_logloss: 0.187081\n",
      "[300]\tvalid_0's binary_logloss: 0.180402\n",
      "[350]\tvalid_0's binary_logloss: 0.170254\n",
      "[400]\tvalid_0's binary_logloss: 0.167898\n",
      "[450]\tvalid_0's binary_logloss: 0.168567\n",
      "[500]\tvalid_0's binary_logloss: 0.165864\n",
      "[550]\tvalid_0's binary_logloss: 0.16355\n",
      "[600]\tvalid_0's binary_logloss: 0.164249\n",
      "[650]\tvalid_0's binary_logloss: 0.162444\n",
      "[700]\tvalid_0's binary_logloss: 0.166442\n",
      "Early stopping, best iteration is:\n",
      "[639]\tvalid_0's binary_logloss: 0.162068\n",
      "\n",
      "round 0002 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.382481\n",
      "[100]\tvalid_0's binary_logloss: 0.308136\n",
      "[150]\tvalid_0's binary_logloss: 0.281027\n",
      "[200]\tvalid_0's binary_logloss: 0.275576\n",
      "[250]\tvalid_0's binary_logloss: 0.270076\n",
      "[300]\tvalid_0's binary_logloss: 0.2678\n",
      "[350]\tvalid_0's binary_logloss: 0.261893\n",
      "[400]\tvalid_0's binary_logloss: 0.254526\n",
      "[450]\tvalid_0's binary_logloss: 0.253004\n",
      "[500]\tvalid_0's binary_logloss: 0.253072\n",
      "[550]\tvalid_0's binary_logloss: 0.258015\n",
      "Early stopping, best iteration is:\n",
      "[498]\tvalid_0's binary_logloss: 0.252584\n",
      "\n",
      "round 0003 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.34883\n",
      "[100]\tvalid_0's binary_logloss: 0.265694\n",
      "[150]\tvalid_0's binary_logloss: 0.223505\n",
      "[200]\tvalid_0's binary_logloss: 0.201956\n",
      "[250]\tvalid_0's binary_logloss: 0.194837\n",
      "[300]\tvalid_0's binary_logloss: 0.188817\n",
      "[350]\tvalid_0's binary_logloss: 0.188726\n",
      "[400]\tvalid_0's binary_logloss: 0.183111\n",
      "[450]\tvalid_0's binary_logloss: 0.183917\n",
      "[500]\tvalid_0's binary_logloss: 0.186481\n",
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's binary_logloss: 0.182853\n",
      "\n",
      "round 0004 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.326257\n",
      "[100]\tvalid_0's binary_logloss: 0.232288\n",
      "[150]\tvalid_0's binary_logloss: 0.193779\n",
      "[200]\tvalid_0's binary_logloss: 0.17886\n",
      "[250]\tvalid_0's binary_logloss: 0.166543\n",
      "[300]\tvalid_0's binary_logloss: 0.160134\n",
      "[350]\tvalid_0's binary_logloss: 0.153545\n",
      "[400]\tvalid_0's binary_logloss: 0.148944\n",
      "[450]\tvalid_0's binary_logloss: 0.145929\n",
      "[500]\tvalid_0's binary_logloss: 0.144604\n",
      "[550]\tvalid_0's binary_logloss: 0.146811\n",
      "[600]\tvalid_0's binary_logloss: 0.1438\n",
      "[650]\tvalid_0's binary_logloss: 0.145102\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's binary_logloss: 0.142645\n",
      "\n",
      "round 0005 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.381385\n",
      "[100]\tvalid_0's binary_logloss: 0.318433\n",
      "[150]\tvalid_0's binary_logloss: 0.297672\n",
      "[200]\tvalid_0's binary_logloss: 0.288309\n",
      "[250]\tvalid_0's binary_logloss: 0.286265\n",
      "[300]\tvalid_0's binary_logloss: 0.281654\n",
      "[350]\tvalid_0's binary_logloss: 0.279748\n",
      "[400]\tvalid_0's binary_logloss: 0.278049\n",
      "[450]\tvalid_0's binary_logloss: 0.280082\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's binary_logloss: 0.277211\n",
      "\n",
      "round 0006 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.358168\n",
      "[100]\tvalid_0's binary_logloss: 0.278698\n",
      "[150]\tvalid_0's binary_logloss: 0.249987\n",
      "[200]\tvalid_0's binary_logloss: 0.243479\n",
      "[250]\tvalid_0's binary_logloss: 0.227212\n",
      "[300]\tvalid_0's binary_logloss: 0.223046\n",
      "[350]\tvalid_0's binary_logloss: 0.220706\n",
      "[400]\tvalid_0's binary_logloss: 0.221034\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's binary_logloss: 0.218621\n",
      "\n",
      "round 0007 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.355334\n",
      "[100]\tvalid_0's binary_logloss: 0.261883\n",
      "[150]\tvalid_0's binary_logloss: 0.23218\n",
      "[200]\tvalid_0's binary_logloss: 0.216746\n",
      "[250]\tvalid_0's binary_logloss: 0.211628\n",
      "[300]\tvalid_0's binary_logloss: 0.207755\n",
      "[350]\tvalid_0's binary_logloss: 0.209932\n",
      "[400]\tvalid_0's binary_logloss: 0.206766\n",
      "[450]\tvalid_0's binary_logloss: 0.206726\n",
      "[500]\tvalid_0's binary_logloss: 0.208441\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's binary_logloss: 0.205294\n",
      "\n",
      "round 0008 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.34195\n",
      "[100]\tvalid_0's binary_logloss: 0.26116\n",
      "[150]\tvalid_0's binary_logloss: 0.237969\n",
      "[200]\tvalid_0's binary_logloss: 0.22491\n",
      "[250]\tvalid_0's binary_logloss: 0.218191\n",
      "[300]\tvalid_0's binary_logloss: 0.213657\n",
      "[350]\tvalid_0's binary_logloss: 0.210099\n",
      "[400]\tvalid_0's binary_logloss: 0.208881\n",
      "[450]\tvalid_0's binary_logloss: 0.206886\n",
      "[500]\tvalid_0's binary_logloss: 0.20517\n",
      "[550]\tvalid_0's binary_logloss: 0.208037\n",
      "[600]\tvalid_0's binary_logloss: 0.210094\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's binary_logloss: 0.204743\n",
      "\n",
      "round 0009 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.384795\n",
      "[100]\tvalid_0's binary_logloss: 0.314923\n",
      "[150]\tvalid_0's binary_logloss: 0.290858\n",
      "[200]\tvalid_0's binary_logloss: 0.283134\n",
      "[250]\tvalid_0's binary_logloss: 0.274896\n",
      "[300]\tvalid_0's binary_logloss: 0.270816\n",
      "[350]\tvalid_0's binary_logloss: 0.27285\n",
      "[400]\tvalid_0's binary_logloss: 0.270707\n",
      "[450]\tvalid_0's binary_logloss: 0.271154\n",
      "Early stopping, best iteration is:\n",
      "[375]\tvalid_0's binary_logloss: 0.27044\n",
      "\n",
      "round 0010 of 0010, seed=<mtrand.RandomState object at 0x7f4f99ab5798>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.381943\n",
      "[100]\tvalid_0's binary_logloss: 0.25221\n",
      "[150]\tvalid_0's binary_logloss: 0.183778\n",
      "[200]\tvalid_0's binary_logloss: 0.157321\n",
      "[250]\tvalid_0's binary_logloss: 0.139619\n",
      "[300]\tvalid_0's binary_logloss: 0.136058\n",
      "[350]\tvalid_0's binary_logloss: 0.132374\n",
      "[400]\tvalid_0's binary_logloss: 0.129537\n",
      "[450]\tvalid_0's binary_logloss: 0.129944\n",
      "[500]\tvalid_0's binary_logloss: 0.125338\n",
      "[550]\tvalid_0's binary_logloss: 0.124152\n",
      "[600]\tvalid_0's binary_logloss: 0.122914\n",
      "[650]\tvalid_0's binary_logloss: 0.125373\n",
      "Early stopping, best iteration is:\n",
      "[590]\tvalid_0's binary_logloss: 0.122105\n",
      "All your scores are: \n",
      "[0.162068135951978, 0.25258433717276435, 0.18285266671468731, 0.14264462649805276, 0.27721112069343029, 0.21862131396048956, 0.20529405563858591, 0.2047427224203246, 0.2704399217641173, 0.1221054911261283]\n",
      "The average of your score\n",
      "0.203856439194\n",
      "[0.20487766408817848, 0.20832504083589809, 0.20385643919405583]\n"
     ]
    }
   ],
   "source": [
    "avg_result = []\n",
    "#training\n",
    "# test_ratio = 0.2\n",
    "# nr_runs = 3\n",
    "# split_seed = 25\n",
    "# kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "\n",
    "ran_num = 463465 #463465#56491\n",
    "for ran_num in [2312, 56491,463465]:\n",
    "    split_seed= np.random.RandomState(ran_num)\n",
    "    print('The seed we are using is: %d' % ran_num)\n",
    "    nr_runs = 10\n",
    "    kf = KFold(n_splits=nr_runs, random_state=split_seed)\n",
    "\n",
    "    for param in [0.8]:\n",
    "        result = []\n",
    "        for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "            print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "            tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "            x1, x2 = train_X[train_index], train_X[test_index]\n",
    "            y1, y2 = train_y[train_index], train_y[test_index] \n",
    "\n",
    "            ##LightGBM\n",
    "            lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "            #gbdt\n",
    "            params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "            params['boosting'] = 'gbdt'\n",
    "            params['metric'] = 'binary_logloss'\n",
    "            params['learning_rate'] = 0.03\n",
    "            params['max_depth'] = 5\n",
    "            params['num_leaves'] = 9 # higher number of leaves\n",
    "            params['feature_fraction'] = param # Controls overfit\n",
    "            params['bagging_fraction'] = 0.9    \n",
    "            params['bagging_freq'] = 3\n",
    "            params['seed'] = ran_num + r\n",
    "            #\n",
    "            params['verbose'] = -1\n",
    "\n",
    "            file = 'gbm/subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "            subms.append(file)\n",
    "\n",
    "            model2 = lgb.train(params, \n",
    "                           lgb_train, \n",
    "                           nr_round, \n",
    "                           lgb_valid, \n",
    "                           verbose_eval=50, early_stopping_rounds=min_round)\n",
    "            result.append(model2.best_score['valid_0']['binary_logloss'])\n",
    "            \n",
    "        print('All your scores are: ')\n",
    "        print(result)\n",
    "        print('The average of your score')\n",
    "        print(np.mean(result))\n",
    "        avg_result.append(np.mean(result))\n",
    "print(avg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.20997504631763109\n",
    "\n",
    "num_leaves  [6,8,9,10,12,14,16,20]\n",
    "\n",
    "2312:0.20693540784004155, 0.20807777115480661,0.208204, 0.2101704305882699, 0.20958977185302161, 0.2097247594090052, 0.21252432775232091, 0.21097843374429764\n",
    "     0.21085407105688136, 0.20972141239725756,0.20768 , 0.20802226387790204, 0.21319986508838254, 0.2114961113773989, 0.20997504631763109, 0.21187703738304534, \n",
    "     0.21143941426691132, 0.20521332038873236,0.206531, 0.20727516177890259, 0.20963941105802347, 0.20857695536404003, 0.21374484604203184, 0.21189068566992506\n",
    "\n",
    "try another one [6,7,8,9]\n",
    "[0.21142256014136723, 0.20535415309766486, 0.20584818981873357, 0.20905026043297328]\n",
    "\n",
    "## change num_leaf to 9\n",
    "\n",
    "0.20826665232053476, 0.20893920897305204, 0.20820437367235373, 0.20789867033173567,\n",
    "0.21021699406462796, 0.20997471390055775, 0.20768137792375355, 0.20762240986338024,\n",
    "0.20571142430466466, 0.20512413321541617, 0.2065318518352405, 0.21059664548852566]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21655854539955169"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_score['valid_0']['binary_logloss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed we are using is: 1123\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.441487\n",
      "[100]\tvalid_0's binary_logloss: 0.374806\n",
      "[150]\tvalid_0's binary_logloss: 0.343087\n",
      "[200]\tvalid_0's binary_logloss: 0.319263\n",
      "[250]\tvalid_0's binary_logloss: 0.295517\n",
      "[300]\tvalid_0's binary_logloss: 0.286817\n",
      "[350]\tvalid_0's binary_logloss: 0.283165\n",
      "[400]\tvalid_0's binary_logloss: 0.26954\n",
      "[450]\tvalid_0's binary_logloss: 0.259985\n",
      "[500]\tvalid_0's binary_logloss: 0.252553\n",
      "[550]\tvalid_0's binary_logloss: 0.246402\n",
      "[600]\tvalid_0's binary_logloss: 0.245004\n",
      "[650]\tvalid_0's binary_logloss: 0.23783\n",
      "[700]\tvalid_0's binary_logloss: 0.234628\n",
      "[750]\tvalid_0's binary_logloss: 0.229842\n",
      "[800]\tvalid_0's binary_logloss: 0.230116\n",
      "[850]\tvalid_0's binary_logloss: 0.231584\n",
      "[900]\tvalid_0's binary_logloss: 0.227668\n",
      "[950]\tvalid_0's binary_logloss: 0.223863\n",
      "[1000]\tvalid_0's binary_logloss: 0.222578\n",
      "[1050]\tvalid_0's binary_logloss: 0.219807\n",
      "[1100]\tvalid_0's binary_logloss: 0.217183\n",
      "[1150]\tvalid_0's binary_logloss: 0.217314\n",
      "[1200]\tvalid_0's binary_logloss: 0.215629\n",
      "[1250]\tvalid_0's binary_logloss: 0.21425\n",
      "[1300]\tvalid_0's binary_logloss: 0.211693\n",
      "[1350]\tvalid_0's binary_logloss: 0.211452\n",
      "[1400]\tvalid_0's binary_logloss: 0.208178\n",
      "[1450]\tvalid_0's binary_logloss: 0.20962\n",
      "[1500]\tvalid_0's binary_logloss: 0.20669\n",
      "[1550]\tvalid_0's binary_logloss: 0.207179\n",
      "Early stopping, best iteration is:\n",
      "[1499]\tvalid_0's binary_logloss: 0.206645\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.418628\n",
      "[100]\tvalid_0's binary_logloss: 0.357022\n",
      "[150]\tvalid_0's binary_logloss: 0.313951\n",
      "[200]\tvalid_0's binary_logloss: 0.288177\n",
      "[250]\tvalid_0's binary_logloss: 0.269095\n",
      "[300]\tvalid_0's binary_logloss: 0.25844\n",
      "[350]\tvalid_0's binary_logloss: 0.2422\n",
      "[400]\tvalid_0's binary_logloss: 0.241669\n",
      "[450]\tvalid_0's binary_logloss: 0.226882\n",
      "[500]\tvalid_0's binary_logloss: 0.222321\n",
      "[550]\tvalid_0's binary_logloss: 0.217163\n",
      "[600]\tvalid_0's binary_logloss: 0.213146\n",
      "[650]\tvalid_0's binary_logloss: 0.209275\n",
      "[700]\tvalid_0's binary_logloss: 0.205905\n",
      "[750]\tvalid_0's binary_logloss: 0.201924\n",
      "[800]\tvalid_0's binary_logloss: 0.201068\n",
      "[850]\tvalid_0's binary_logloss: 0.1963\n",
      "[900]\tvalid_0's binary_logloss: 0.197644\n",
      "[950]\tvalid_0's binary_logloss: 0.194938\n",
      "[1000]\tvalid_0's binary_logloss: 0.193677\n",
      "[1050]\tvalid_0's binary_logloss: 0.193512\n",
      "[1100]\tvalid_0's binary_logloss: 0.190458\n",
      "[1150]\tvalid_0's binary_logloss: 0.187543\n",
      "[1200]\tvalid_0's binary_logloss: 0.183127\n",
      "[1250]\tvalid_0's binary_logloss: 0.182529\n",
      "[1300]\tvalid_0's binary_logloss: 0.183008\n",
      "Early stopping, best iteration is:\n",
      "[1226]\tvalid_0's binary_logloss: 0.18191\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.479453\n",
      "[100]\tvalid_0's binary_logloss: 0.41201\n",
      "[150]\tvalid_0's binary_logloss: 0.378803\n",
      "[200]\tvalid_0's binary_logloss: 0.343231\n",
      "[250]\tvalid_0's binary_logloss: 0.32832\n",
      "[300]\tvalid_0's binary_logloss: 0.324389\n",
      "[350]\tvalid_0's binary_logloss: 0.302422\n",
      "[400]\tvalid_0's binary_logloss: 0.302984\n",
      "[450]\tvalid_0's binary_logloss: 0.294697\n",
      "[500]\tvalid_0's binary_logloss: 0.292758\n",
      "[550]\tvalid_0's binary_logloss: 0.287975\n",
      "[600]\tvalid_0's binary_logloss: 0.283496\n",
      "[650]\tvalid_0's binary_logloss: 0.281915\n",
      "[700]\tvalid_0's binary_logloss: 0.278361\n",
      "[750]\tvalid_0's binary_logloss: 0.27464\n",
      "[800]\tvalid_0's binary_logloss: 0.269995\n",
      "[850]\tvalid_0's binary_logloss: 0.268728\n",
      "[900]\tvalid_0's binary_logloss: 0.268132\n",
      "[950]\tvalid_0's binary_logloss: 0.263617\n",
      "[1000]\tvalid_0's binary_logloss: 0.263638\n",
      "[1050]\tvalid_0's binary_logloss: 0.260588\n",
      "[1100]\tvalid_0's binary_logloss: 0.261433\n",
      "[1150]\tvalid_0's binary_logloss: 0.25909\n",
      "[1200]\tvalid_0's binary_logloss: 0.259165\n",
      "[1250]\tvalid_0's binary_logloss: 0.25859\n",
      "Early stopping, best iteration is:\n",
      "[1178]\tvalid_0's binary_logloss: 0.2571\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.446769\n",
      "[100]\tvalid_0's binary_logloss: 0.378879\n",
      "[150]\tvalid_0's binary_logloss: 0.335189\n",
      "[200]\tvalid_0's binary_logloss: 0.328854\n",
      "[250]\tvalid_0's binary_logloss: 0.297984\n",
      "[300]\tvalid_0's binary_logloss: 0.284013\n",
      "[350]\tvalid_0's binary_logloss: 0.273794\n",
      "[400]\tvalid_0's binary_logloss: 0.260616\n",
      "[450]\tvalid_0's binary_logloss: 0.254193\n",
      "[500]\tvalid_0's binary_logloss: 0.251788\n",
      "[550]\tvalid_0's binary_logloss: 0.247103\n",
      "[600]\tvalid_0's binary_logloss: 0.245382\n",
      "[650]\tvalid_0's binary_logloss: 0.238838\n",
      "[700]\tvalid_0's binary_logloss: 0.236937\n",
      "[750]\tvalid_0's binary_logloss: 0.235205\n",
      "[800]\tvalid_0's binary_logloss: 0.23266\n",
      "[850]\tvalid_0's binary_logloss: 0.229601\n",
      "[900]\tvalid_0's binary_logloss: 0.228033\n",
      "[950]\tvalid_0's binary_logloss: 0.227468\n",
      "[1000]\tvalid_0's binary_logloss: 0.226258\n",
      "[1050]\tvalid_0's binary_logloss: 0.223059\n",
      "[1100]\tvalid_0's binary_logloss: 0.219208\n",
      "[1150]\tvalid_0's binary_logloss: 0.220202\n",
      "[1200]\tvalid_0's binary_logloss: 0.216059\n",
      "[1250]\tvalid_0's binary_logloss: 0.215619\n",
      "[1300]\tvalid_0's binary_logloss: 0.214983\n",
      "[1350]\tvalid_0's binary_logloss: 0.215233\n",
      "[1400]\tvalid_0's binary_logloss: 0.214666\n",
      "[1450]\tvalid_0's binary_logloss: 0.212278\n",
      "[1500]\tvalid_0's binary_logloss: 0.21233\n",
      "[1550]\tvalid_0's binary_logloss: 0.212409\n",
      "[1600]\tvalid_0's binary_logloss: 0.212755\n",
      "[1650]\tvalid_0's binary_logloss: 0.212366\n",
      "[1700]\tvalid_0's binary_logloss: 0.212046\n",
      "[1750]\tvalid_0's binary_logloss: 0.210282\n",
      "[1800]\tvalid_0's binary_logloss: 0.209245\n",
      "[1850]\tvalid_0's binary_logloss: 0.20845\n",
      "[1900]\tvalid_0's binary_logloss: 0.209267\n",
      "Early stopping, best iteration is:\n",
      "[1810]\tvalid_0's binary_logloss: 0.20816\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.448116\n",
      "[100]\tvalid_0's binary_logloss: 0.415097\n",
      "[150]\tvalid_0's binary_logloss: 0.36604\n",
      "[200]\tvalid_0's binary_logloss: 0.348059\n",
      "[250]\tvalid_0's binary_logloss: 0.335008\n",
      "[300]\tvalid_0's binary_logloss: 0.306537\n",
      "[350]\tvalid_0's binary_logloss: 0.281468\n",
      "[400]\tvalid_0's binary_logloss: 0.270712\n",
      "[450]\tvalid_0's binary_logloss: 0.262911\n",
      "[500]\tvalid_0's binary_logloss: 0.254003\n",
      "[550]\tvalid_0's binary_logloss: 0.245989\n",
      "[600]\tvalid_0's binary_logloss: 0.23635\n",
      "[650]\tvalid_0's binary_logloss: 0.236333\n",
      "[700]\tvalid_0's binary_logloss: 0.22827\n",
      "[750]\tvalid_0's binary_logloss: 0.220674\n",
      "[800]\tvalid_0's binary_logloss: 0.216503\n",
      "[850]\tvalid_0's binary_logloss: 0.217092\n",
      "[900]\tvalid_0's binary_logloss: 0.211883\n",
      "[950]\tvalid_0's binary_logloss: 0.211876\n",
      "[1000]\tvalid_0's binary_logloss: 0.208001\n",
      "[1050]\tvalid_0's binary_logloss: 0.20858\n",
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's binary_logloss: 0.206674\n",
      "All your scores are: \n",
      "[0.20664494472778835, 0.18191023938874346, 0.25710006961824122, 0.20816025311300423, 0.20667377715030963]\n",
      "The average of your score\n",
      "0.2120978568\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.431204\n",
      "[100]\tvalid_0's binary_logloss: 0.364447\n",
      "[150]\tvalid_0's binary_logloss: 0.332576\n",
      "[200]\tvalid_0's binary_logloss: 0.306931\n",
      "[250]\tvalid_0's binary_logloss: 0.285271\n",
      "[300]\tvalid_0's binary_logloss: 0.275084\n",
      "[350]\tvalid_0's binary_logloss: 0.271297\n",
      "[400]\tvalid_0's binary_logloss: 0.256797\n",
      "[450]\tvalid_0's binary_logloss: 0.249549\n",
      "[500]\tvalid_0's binary_logloss: 0.242669\n",
      "[550]\tvalid_0's binary_logloss: 0.236791\n",
      "[600]\tvalid_0's binary_logloss: 0.234883\n",
      "[650]\tvalid_0's binary_logloss: 0.23068\n",
      "[700]\tvalid_0's binary_logloss: 0.228349\n",
      "[750]\tvalid_0's binary_logloss: 0.224617\n",
      "[800]\tvalid_0's binary_logloss: 0.225876\n",
      "[850]\tvalid_0's binary_logloss: 0.224644\n",
      "[900]\tvalid_0's binary_logloss: 0.22336\n",
      "[950]\tvalid_0's binary_logloss: 0.222144\n",
      "[1000]\tvalid_0's binary_logloss: 0.221732\n",
      "[1050]\tvalid_0's binary_logloss: 0.217413\n",
      "[1100]\tvalid_0's binary_logloss: 0.215975\n",
      "[1150]\tvalid_0's binary_logloss: 0.213368\n",
      "[1200]\tvalid_0's binary_logloss: 0.213285\n",
      "[1250]\tvalid_0's binary_logloss: 0.214301\n",
      "Early stopping, best iteration is:\n",
      "[1186]\tvalid_0's binary_logloss: 0.210968\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.405814\n",
      "[100]\tvalid_0's binary_logloss: 0.341539\n",
      "[150]\tvalid_0's binary_logloss: 0.300143\n",
      "[200]\tvalid_0's binary_logloss: 0.273013\n",
      "[250]\tvalid_0's binary_logloss: 0.253096\n",
      "[300]\tvalid_0's binary_logloss: 0.243682\n",
      "[350]\tvalid_0's binary_logloss: 0.226306\n",
      "[400]\tvalid_0's binary_logloss: 0.226077\n",
      "[450]\tvalid_0's binary_logloss: 0.21135\n",
      "[500]\tvalid_0's binary_logloss: 0.209386\n",
      "[550]\tvalid_0's binary_logloss: 0.204842\n",
      "[600]\tvalid_0's binary_logloss: 0.200552\n",
      "[650]\tvalid_0's binary_logloss: 0.196731\n",
      "[700]\tvalid_0's binary_logloss: 0.194661\n",
      "[750]\tvalid_0's binary_logloss: 0.189943\n",
      "[800]\tvalid_0's binary_logloss: 0.189661\n",
      "[850]\tvalid_0's binary_logloss: 0.185628\n",
      "[900]\tvalid_0's binary_logloss: 0.187222\n",
      "[950]\tvalid_0's binary_logloss: 0.185584\n",
      "[1000]\tvalid_0's binary_logloss: 0.185861\n",
      "[1050]\tvalid_0's binary_logloss: 0.183517\n",
      "[1100]\tvalid_0's binary_logloss: 0.181724\n",
      "[1150]\tvalid_0's binary_logloss: 0.179621\n",
      "[1200]\tvalid_0's binary_logloss: 0.176714\n",
      "[1250]\tvalid_0's binary_logloss: 0.177599\n",
      "[1300]\tvalid_0's binary_logloss: 0.179735\n",
      "Early stopping, best iteration is:\n",
      "[1203]\tvalid_0's binary_logloss: 0.176107\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.472487\n",
      "[100]\tvalid_0's binary_logloss: 0.398366\n",
      "[150]\tvalid_0's binary_logloss: 0.363583\n",
      "[200]\tvalid_0's binary_logloss: 0.334778\n",
      "[250]\tvalid_0's binary_logloss: 0.316207\n",
      "[300]\tvalid_0's binary_logloss: 0.311305\n",
      "[350]\tvalid_0's binary_logloss: 0.289267\n",
      "[400]\tvalid_0's binary_logloss: 0.288565\n",
      "[450]\tvalid_0's binary_logloss: 0.27907\n",
      "[500]\tvalid_0's binary_logloss: 0.277822\n",
      "[550]\tvalid_0's binary_logloss: 0.276383\n",
      "[600]\tvalid_0's binary_logloss: 0.270919\n",
      "[650]\tvalid_0's binary_logloss: 0.26697\n",
      "[700]\tvalid_0's binary_logloss: 0.262485\n",
      "[750]\tvalid_0's binary_logloss: 0.260644\n",
      "[800]\tvalid_0's binary_logloss: 0.256299\n",
      "[850]\tvalid_0's binary_logloss: 0.256854\n",
      "[900]\tvalid_0's binary_logloss: 0.257581\n",
      "Early stopping, best iteration is:\n",
      "[804]\tvalid_0's binary_logloss: 0.255427\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.431898\n",
      "[100]\tvalid_0's binary_logloss: 0.363897\n",
      "[150]\tvalid_0's binary_logloss: 0.319025\n",
      "[200]\tvalid_0's binary_logloss: 0.312834\n",
      "[250]\tvalid_0's binary_logloss: 0.280829\n",
      "[300]\tvalid_0's binary_logloss: 0.26894\n",
      "[350]\tvalid_0's binary_logloss: 0.259701\n",
      "[400]\tvalid_0's binary_logloss: 0.248996\n",
      "[450]\tvalid_0's binary_logloss: 0.243508\n",
      "[500]\tvalid_0's binary_logloss: 0.242164\n",
      "[550]\tvalid_0's binary_logloss: 0.234807\n",
      "[600]\tvalid_0's binary_logloss: 0.233072\n",
      "[650]\tvalid_0's binary_logloss: 0.225301\n",
      "[700]\tvalid_0's binary_logloss: 0.225868\n",
      "[750]\tvalid_0's binary_logloss: 0.224649\n",
      "[800]\tvalid_0's binary_logloss: 0.22176\n",
      "[850]\tvalid_0's binary_logloss: 0.219072\n",
      "[900]\tvalid_0's binary_logloss: 0.218327\n",
      "[950]\tvalid_0's binary_logloss: 0.219554\n",
      "[1000]\tvalid_0's binary_logloss: 0.217967\n",
      "[1050]\tvalid_0's binary_logloss: 0.219069\n",
      "[1100]\tvalid_0's binary_logloss: 0.216008\n",
      "[1150]\tvalid_0's binary_logloss: 0.21687\n",
      "[1200]\tvalid_0's binary_logloss: 0.214742\n",
      "[1250]\tvalid_0's binary_logloss: 0.213913\n",
      "[1300]\tvalid_0's binary_logloss: 0.214062\n",
      "[1350]\tvalid_0's binary_logloss: 0.213359\n",
      "[1400]\tvalid_0's binary_logloss: 0.21371\n",
      "Early stopping, best iteration is:\n",
      "[1324]\tvalid_0's binary_logloss: 0.211785\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.438697\n",
      "[100]\tvalid_0's binary_logloss: 0.40349\n",
      "[150]\tvalid_0's binary_logloss: 0.353803\n",
      "[200]\tvalid_0's binary_logloss: 0.327247\n",
      "[250]\tvalid_0's binary_logloss: 0.31395\n",
      "[300]\tvalid_0's binary_logloss: 0.289017\n",
      "[350]\tvalid_0's binary_logloss: 0.264344\n",
      "[400]\tvalid_0's binary_logloss: 0.254269\n",
      "[450]\tvalid_0's binary_logloss: 0.250917\n",
      "[500]\tvalid_0's binary_logloss: 0.237423\n",
      "[550]\tvalid_0's binary_logloss: 0.228991\n",
      "[600]\tvalid_0's binary_logloss: 0.2221\n",
      "[650]\tvalid_0's binary_logloss: 0.218985\n",
      "[700]\tvalid_0's binary_logloss: 0.214354\n",
      "[750]\tvalid_0's binary_logloss: 0.205061\n",
      "[800]\tvalid_0's binary_logloss: 0.203568\n",
      "[850]\tvalid_0's binary_logloss: 0.205398\n",
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's binary_logloss: 0.202916\n",
      "All your scores are: \n",
      "[0.21096832673645344, 0.1761068155588679, 0.25542745788483906, 0.21178459601471045, 0.20291553781604468]\n",
      "The average of your score\n",
      "0.211440546802\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.424046\n",
      "[100]\tvalid_0's binary_logloss: 0.357367\n",
      "[150]\tvalid_0's binary_logloss: 0.328692\n",
      "[200]\tvalid_0's binary_logloss: 0.301965\n",
      "[250]\tvalid_0's binary_logloss: 0.277428\n",
      "[300]\tvalid_0's binary_logloss: 0.264961\n",
      "[350]\tvalid_0's binary_logloss: 0.26129\n",
      "[400]\tvalid_0's binary_logloss: 0.246395\n",
      "[450]\tvalid_0's binary_logloss: 0.241128\n",
      "[500]\tvalid_0's binary_logloss: 0.235357\n",
      "[550]\tvalid_0's binary_logloss: 0.232014\n",
      "[600]\tvalid_0's binary_logloss: 0.22639\n",
      "[650]\tvalid_0's binary_logloss: 0.221348\n",
      "[700]\tvalid_0's binary_logloss: 0.222019\n",
      "[750]\tvalid_0's binary_logloss: 0.216844\n",
      "[800]\tvalid_0's binary_logloss: 0.218832\n",
      "[850]\tvalid_0's binary_logloss: 0.220156\n",
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.216844\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.402719\n",
      "[100]\tvalid_0's binary_logloss: 0.337505\n",
      "[150]\tvalid_0's binary_logloss: 0.294713\n",
      "[200]\tvalid_0's binary_logloss: 0.265873\n",
      "[250]\tvalid_0's binary_logloss: 0.244668\n",
      "[300]\tvalid_0's binary_logloss: 0.233386\n",
      "[350]\tvalid_0's binary_logloss: 0.218664\n",
      "[400]\tvalid_0's binary_logloss: 0.216614\n",
      "[450]\tvalid_0's binary_logloss: 0.201691\n",
      "[500]\tvalid_0's binary_logloss: 0.198383\n",
      "[550]\tvalid_0's binary_logloss: 0.193977\n",
      "[600]\tvalid_0's binary_logloss: 0.191777\n",
      "[650]\tvalid_0's binary_logloss: 0.186817\n",
      "[700]\tvalid_0's binary_logloss: 0.184415\n",
      "[750]\tvalid_0's binary_logloss: 0.18061\n",
      "[800]\tvalid_0's binary_logloss: 0.178419\n",
      "[850]\tvalid_0's binary_logloss: 0.174933\n",
      "[900]\tvalid_0's binary_logloss: 0.175935\n",
      "[950]\tvalid_0's binary_logloss: 0.176257\n",
      "[1000]\tvalid_0's binary_logloss: 0.17771\n",
      "Early stopping, best iteration is:\n",
      "[927]\tvalid_0's binary_logloss: 0.173923\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.465414\n",
      "[100]\tvalid_0's binary_logloss: 0.392887\n",
      "[150]\tvalid_0's binary_logloss: 0.357021\n",
      "[200]\tvalid_0's binary_logloss: 0.321977\n",
      "[250]\tvalid_0's binary_logloss: 0.306445\n",
      "[300]\tvalid_0's binary_logloss: 0.302856\n",
      "[350]\tvalid_0's binary_logloss: 0.28247\n",
      "[400]\tvalid_0's binary_logloss: 0.281767\n",
      "[450]\tvalid_0's binary_logloss: 0.27563\n",
      "[500]\tvalid_0's binary_logloss: 0.272345\n",
      "[550]\tvalid_0's binary_logloss: 0.270814\n",
      "[600]\tvalid_0's binary_logloss: 0.266359\n",
      "[650]\tvalid_0's binary_logloss: 0.264435\n",
      "[700]\tvalid_0's binary_logloss: 0.2625\n",
      "[750]\tvalid_0's binary_logloss: 0.263122\n",
      "[800]\tvalid_0's binary_logloss: 0.257981\n",
      "[850]\tvalid_0's binary_logloss: 0.256171\n",
      "[900]\tvalid_0's binary_logloss: 0.254117\n",
      "[950]\tvalid_0's binary_logloss: 0.251888\n",
      "[1000]\tvalid_0's binary_logloss: 0.252521\n",
      "[1050]\tvalid_0's binary_logloss: 0.252596\n",
      "Early stopping, best iteration is:\n",
      "[976]\tvalid_0's binary_logloss: 0.248964\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.428882\n",
      "[100]\tvalid_0's binary_logloss: 0.356576\n",
      "[150]\tvalid_0's binary_logloss: 0.310381\n",
      "[200]\tvalid_0's binary_logloss: 0.301793\n",
      "[250]\tvalid_0's binary_logloss: 0.271509\n",
      "[300]\tvalid_0's binary_logloss: 0.261387\n",
      "[350]\tvalid_0's binary_logloss: 0.25137\n",
      "[400]\tvalid_0's binary_logloss: 0.240104\n",
      "[450]\tvalid_0's binary_logloss: 0.233954\n",
      "[500]\tvalid_0's binary_logloss: 0.231878\n",
      "[550]\tvalid_0's binary_logloss: 0.225871\n",
      "[600]\tvalid_0's binary_logloss: 0.223918\n",
      "[650]\tvalid_0's binary_logloss: 0.219983\n",
      "[700]\tvalid_0's binary_logloss: 0.219146\n",
      "[750]\tvalid_0's binary_logloss: 0.219527\n",
      "[800]\tvalid_0's binary_logloss: 0.216357\n",
      "[850]\tvalid_0's binary_logloss: 0.214872\n",
      "[900]\tvalid_0's binary_logloss: 0.214897\n",
      "[950]\tvalid_0's binary_logloss: 0.214093\n",
      "[1000]\tvalid_0's binary_logloss: 0.213342\n",
      "[1050]\tvalid_0's binary_logloss: 0.213104\n",
      "[1100]\tvalid_0's binary_logloss: 0.2125\n",
      "Early stopping, best iteration is:\n",
      "[1036]\tvalid_0's binary_logloss: 0.211922\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.43424\n",
      "[100]\tvalid_0's binary_logloss: 0.393704\n",
      "[150]\tvalid_0's binary_logloss: 0.341988\n",
      "[200]\tvalid_0's binary_logloss: 0.320549\n",
      "[250]\tvalid_0's binary_logloss: 0.302033\n",
      "[300]\tvalid_0's binary_logloss: 0.282979\n",
      "[350]\tvalid_0's binary_logloss: 0.256518\n",
      "[400]\tvalid_0's binary_logloss: 0.241435\n",
      "[450]\tvalid_0's binary_logloss: 0.242719\n",
      "[500]\tvalid_0's binary_logloss: 0.227369\n",
      "[550]\tvalid_0's binary_logloss: 0.22192\n",
      "[600]\tvalid_0's binary_logloss: 0.213329\n",
      "[650]\tvalid_0's binary_logloss: 0.211867\n",
      "[700]\tvalid_0's binary_logloss: 0.205251\n",
      "[750]\tvalid_0's binary_logloss: 0.199974\n",
      "[800]\tvalid_0's binary_logloss: 0.198451\n",
      "[850]\tvalid_0's binary_logloss: 0.199235\n",
      "[900]\tvalid_0's binary_logloss: 0.194408\n",
      "[950]\tvalid_0's binary_logloss: 0.193398\n",
      "[1000]\tvalid_0's binary_logloss: 0.191387\n",
      "[1050]\tvalid_0's binary_logloss: 0.189693\n",
      "[1100]\tvalid_0's binary_logloss: 0.190829\n",
      "[1150]\tvalid_0's binary_logloss: 0.193182\n",
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.189693\n",
      "All your scores are: \n",
      "[0.21684361453066239, 0.1739227861934064, 0.24896428182710714, 0.21192163618045901, 0.18969335546713967]\n",
      "The average of your score\n",
      "0.20826913484\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.421644\n",
      "[100]\tvalid_0's binary_logloss: 0.352906\n",
      "[150]\tvalid_0's binary_logloss: 0.326391\n",
      "[200]\tvalid_0's binary_logloss: 0.295514\n",
      "[250]\tvalid_0's binary_logloss: 0.275128\n",
      "[300]\tvalid_0's binary_logloss: 0.261375\n",
      "[350]\tvalid_0's binary_logloss: 0.257925\n",
      "[400]\tvalid_0's binary_logloss: 0.242377\n",
      "[450]\tvalid_0's binary_logloss: 0.234396\n",
      "[500]\tvalid_0's binary_logloss: 0.228372\n",
      "[550]\tvalid_0's binary_logloss: 0.22651\n",
      "[600]\tvalid_0's binary_logloss: 0.220711\n",
      "[650]\tvalid_0's binary_logloss: 0.21816\n",
      "[700]\tvalid_0's binary_logloss: 0.217801\n",
      "[750]\tvalid_0's binary_logloss: 0.214536\n",
      "[800]\tvalid_0's binary_logloss: 0.216475\n",
      "[850]\tvalid_0's binary_logloss: 0.215544\n",
      "[900]\tvalid_0's binary_logloss: 0.214363\n",
      "[950]\tvalid_0's binary_logloss: 0.214783\n",
      "[1000]\tvalid_0's binary_logloss: 0.213389\n",
      "[1050]\tvalid_0's binary_logloss: 0.210144\n",
      "[1100]\tvalid_0's binary_logloss: 0.209286\n",
      "[1150]\tvalid_0's binary_logloss: 0.207005\n",
      "[1200]\tvalid_0's binary_logloss: 0.207515\n",
      "[1250]\tvalid_0's binary_logloss: 0.212668\n",
      "Early stopping, best iteration is:\n",
      "[1169]\tvalid_0's binary_logloss: 0.205474\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.397026\n",
      "[100]\tvalid_0's binary_logloss: 0.332292\n",
      "[150]\tvalid_0's binary_logloss: 0.28913\n",
      "[200]\tvalid_0's binary_logloss: 0.261875\n",
      "[250]\tvalid_0's binary_logloss: 0.243797\n",
      "[300]\tvalid_0's binary_logloss: 0.233558\n",
      "[350]\tvalid_0's binary_logloss: 0.218615\n",
      "[400]\tvalid_0's binary_logloss: 0.217742\n",
      "[450]\tvalid_0's binary_logloss: 0.202463\n",
      "[500]\tvalid_0's binary_logloss: 0.198333\n",
      "[550]\tvalid_0's binary_logloss: 0.193672\n",
      "[600]\tvalid_0's binary_logloss: 0.189488\n",
      "[650]\tvalid_0's binary_logloss: 0.187067\n",
      "[700]\tvalid_0's binary_logloss: 0.185187\n",
      "[750]\tvalid_0's binary_logloss: 0.184435\n",
      "[800]\tvalid_0's binary_logloss: 0.183934\n",
      "[850]\tvalid_0's binary_logloss: 0.179475\n",
      "[900]\tvalid_0's binary_logloss: 0.180084\n",
      "[950]\tvalid_0's binary_logloss: 0.179912\n",
      "[1000]\tvalid_0's binary_logloss: 0.178994\n",
      "[1050]\tvalid_0's binary_logloss: 0.176945\n",
      "[1100]\tvalid_0's binary_logloss: 0.176788\n",
      "Early stopping, best iteration is:\n",
      "[1025]\tvalid_0's binary_logloss: 0.175665\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.46161\n",
      "[100]\tvalid_0's binary_logloss: 0.38695\n",
      "[150]\tvalid_0's binary_logloss: 0.35293\n",
      "[200]\tvalid_0's binary_logloss: 0.317976\n",
      "[250]\tvalid_0's binary_logloss: 0.301984\n",
      "[300]\tvalid_0's binary_logloss: 0.296665\n",
      "[350]\tvalid_0's binary_logloss: 0.276657\n",
      "[400]\tvalid_0's binary_logloss: 0.277587\n",
      "[450]\tvalid_0's binary_logloss: 0.268489\n",
      "[500]\tvalid_0's binary_logloss: 0.267552\n",
      "[550]\tvalid_0's binary_logloss: 0.266899\n",
      "Early stopping, best iteration is:\n",
      "[480]\tvalid_0's binary_logloss: 0.264468\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.426206\n",
      "[100]\tvalid_0's binary_logloss: 0.353411\n",
      "[150]\tvalid_0's binary_logloss: 0.305766\n",
      "[200]\tvalid_0's binary_logloss: 0.299216\n",
      "[250]\tvalid_0's binary_logloss: 0.268911\n",
      "[300]\tvalid_0's binary_logloss: 0.25742\n",
      "[350]\tvalid_0's binary_logloss: 0.247524\n",
      "[400]\tvalid_0's binary_logloss: 0.237207\n",
      "[450]\tvalid_0's binary_logloss: 0.232861\n",
      "[500]\tvalid_0's binary_logloss: 0.231598\n",
      "[550]\tvalid_0's binary_logloss: 0.223865\n",
      "[600]\tvalid_0's binary_logloss: 0.221133\n",
      "[650]\tvalid_0's binary_logloss: 0.21798\n",
      "[700]\tvalid_0's binary_logloss: 0.214592\n",
      "[750]\tvalid_0's binary_logloss: 0.214067\n",
      "[800]\tvalid_0's binary_logloss: 0.214189\n",
      "[850]\tvalid_0's binary_logloss: 0.21353\n",
      "[900]\tvalid_0's binary_logloss: 0.213299\n",
      "Early stopping, best iteration is:\n",
      "[825]\tvalid_0's binary_logloss: 0.212217\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.424215\n",
      "[100]\tvalid_0's binary_logloss: 0.392273\n",
      "[150]\tvalid_0's binary_logloss: 0.334913\n",
      "[200]\tvalid_0's binary_logloss: 0.319367\n",
      "[250]\tvalid_0's binary_logloss: 0.303154\n",
      "[300]\tvalid_0's binary_logloss: 0.283315\n",
      "[350]\tvalid_0's binary_logloss: 0.254022\n",
      "[400]\tvalid_0's binary_logloss: 0.244863\n",
      "[450]\tvalid_0's binary_logloss: 0.24338\n",
      "[500]\tvalid_0's binary_logloss: 0.227133\n",
      "[550]\tvalid_0's binary_logloss: 0.221173\n",
      "[600]\tvalid_0's binary_logloss: 0.212189\n",
      "[650]\tvalid_0's binary_logloss: 0.213561\n",
      "[700]\tvalid_0's binary_logloss: 0.208793\n",
      "[750]\tvalid_0's binary_logloss: 0.203408\n",
      "[800]\tvalid_0's binary_logloss: 0.201763\n",
      "[850]\tvalid_0's binary_logloss: 0.201632\n",
      "[900]\tvalid_0's binary_logloss: 0.198063\n",
      "[950]\tvalid_0's binary_logloss: 0.194046\n",
      "[1000]\tvalid_0's binary_logloss: 0.193511\n",
      "[1050]\tvalid_0's binary_logloss: 0.191623\n",
      "[1100]\tvalid_0's binary_logloss: 0.190071\n",
      "[1150]\tvalid_0's binary_logloss: 0.190645\n",
      "Early stopping, best iteration is:\n",
      "[1062]\tvalid_0's binary_logloss: 0.189546\n",
      "All your scores are: \n",
      "[0.20547409174702191, 0.1756646504842734, 0.26446796667862538, 0.21221705372483182, 0.1895464014332317]\n",
      "The average of your score\n",
      "0.209474032814\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.421252\n",
      "[100]\tvalid_0's binary_logloss: 0.353359\n",
      "[150]\tvalid_0's binary_logloss: 0.32438\n",
      "[200]\tvalid_0's binary_logloss: 0.297834\n",
      "[250]\tvalid_0's binary_logloss: 0.272392\n",
      "[300]\tvalid_0's binary_logloss: 0.262287\n",
      "[350]\tvalid_0's binary_logloss: 0.257848\n",
      "[400]\tvalid_0's binary_logloss: 0.242724\n",
      "[450]\tvalid_0's binary_logloss: 0.234969\n",
      "[500]\tvalid_0's binary_logloss: 0.230905\n",
      "[550]\tvalid_0's binary_logloss: 0.224957\n",
      "[600]\tvalid_0's binary_logloss: 0.219888\n",
      "[650]\tvalid_0's binary_logloss: 0.217437\n",
      "[700]\tvalid_0's binary_logloss: 0.217247\n",
      "[750]\tvalid_0's binary_logloss: 0.213794\n",
      "[800]\tvalid_0's binary_logloss: 0.212549\n",
      "[850]\tvalid_0's binary_logloss: 0.213124\n",
      "[900]\tvalid_0's binary_logloss: 0.212205\n",
      "[950]\tvalid_0's binary_logloss: 0.212428\n",
      "[1000]\tvalid_0's binary_logloss: 0.21229\n",
      "Early stopping, best iteration is:\n",
      "[937]\tvalid_0's binary_logloss: 0.210506\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.396444\n",
      "[100]\tvalid_0's binary_logloss: 0.331035\n",
      "[150]\tvalid_0's binary_logloss: 0.288231\n",
      "[200]\tvalid_0's binary_logloss: 0.258972\n",
      "[250]\tvalid_0's binary_logloss: 0.238894\n",
      "[300]\tvalid_0's binary_logloss: 0.229056\n",
      "[350]\tvalid_0's binary_logloss: 0.215164\n",
      "[400]\tvalid_0's binary_logloss: 0.21422\n",
      "[450]\tvalid_0's binary_logloss: 0.201387\n",
      "[500]\tvalid_0's binary_logloss: 0.197004\n",
      "[550]\tvalid_0's binary_logloss: 0.19315\n",
      "[600]\tvalid_0's binary_logloss: 0.188502\n",
      "[650]\tvalid_0's binary_logloss: 0.182941\n",
      "[700]\tvalid_0's binary_logloss: 0.18202\n",
      "[750]\tvalid_0's binary_logloss: 0.180166\n",
      "[800]\tvalid_0's binary_logloss: 0.178821\n",
      "[850]\tvalid_0's binary_logloss: 0.176018\n",
      "[900]\tvalid_0's binary_logloss: 0.177709\n",
      "[950]\tvalid_0's binary_logloss: 0.178825\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid_0's binary_logloss: 0.176018\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.461299\n",
      "[100]\tvalid_0's binary_logloss: 0.386482\n",
      "[150]\tvalid_0's binary_logloss: 0.349782\n",
      "[200]\tvalid_0's binary_logloss: 0.314008\n",
      "[250]\tvalid_0's binary_logloss: 0.297867\n",
      "[300]\tvalid_0's binary_logloss: 0.291855\n",
      "[350]\tvalid_0's binary_logloss: 0.27386\n",
      "[400]\tvalid_0's binary_logloss: 0.27567\n",
      "[450]\tvalid_0's binary_logloss: 0.267961\n",
      "[500]\tvalid_0's binary_logloss: 0.2671\n",
      "[550]\tvalid_0's binary_logloss: 0.265527\n",
      "[600]\tvalid_0's binary_logloss: 0.260072\n",
      "[650]\tvalid_0's binary_logloss: 0.25848\n",
      "[700]\tvalid_0's binary_logloss: 0.256798\n",
      "[750]\tvalid_0's binary_logloss: 0.255234\n",
      "[800]\tvalid_0's binary_logloss: 0.2512\n",
      "[850]\tvalid_0's binary_logloss: 0.250034\n",
      "[900]\tvalid_0's binary_logloss: 0.250161\n",
      "Early stopping, best iteration is:\n",
      "[837]\tvalid_0's binary_logloss: 0.248604\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.427123\n",
      "[100]\tvalid_0's binary_logloss: 0.352955\n",
      "[150]\tvalid_0's binary_logloss: 0.308544\n",
      "[200]\tvalid_0's binary_logloss: 0.301736\n",
      "[250]\tvalid_0's binary_logloss: 0.268156\n",
      "[300]\tvalid_0's binary_logloss: 0.256557\n",
      "[350]\tvalid_0's binary_logloss: 0.246798\n",
      "[400]\tvalid_0's binary_logloss: 0.236104\n",
      "[450]\tvalid_0's binary_logloss: 0.233418\n",
      "[500]\tvalid_0's binary_logloss: 0.231244\n",
      "[550]\tvalid_0's binary_logloss: 0.225176\n",
      "[600]\tvalid_0's binary_logloss: 0.225792\n",
      "[650]\tvalid_0's binary_logloss: 0.221789\n",
      "[700]\tvalid_0's binary_logloss: 0.221054\n",
      "[750]\tvalid_0's binary_logloss: 0.22084\n",
      "[800]\tvalid_0's binary_logloss: 0.219864\n",
      "[850]\tvalid_0's binary_logloss: 0.217767\n",
      "[900]\tvalid_0's binary_logloss: 0.215058\n",
      "[950]\tvalid_0's binary_logloss: 0.214288\n",
      "[1000]\tvalid_0's binary_logloss: 0.215083\n",
      "[1050]\tvalid_0's binary_logloss: 0.213969\n",
      "[1100]\tvalid_0's binary_logloss: 0.210816\n",
      "[1150]\tvalid_0's binary_logloss: 0.211978\n",
      "[1200]\tvalid_0's binary_logloss: 0.210279\n",
      "[1250]\tvalid_0's binary_logloss: 0.209069\n",
      "[1300]\tvalid_0's binary_logloss: 0.209641\n",
      "[1350]\tvalid_0's binary_logloss: 0.208507\n",
      "[1400]\tvalid_0's binary_logloss: 0.210458\n",
      "Early stopping, best iteration is:\n",
      "[1347]\tvalid_0's binary_logloss: 0.208246\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.426522\n",
      "[100]\tvalid_0's binary_logloss: 0.388837\n",
      "[150]\tvalid_0's binary_logloss: 0.33694\n",
      "[200]\tvalid_0's binary_logloss: 0.320416\n",
      "[250]\tvalid_0's binary_logloss: 0.303754\n",
      "[300]\tvalid_0's binary_logloss: 0.279582\n",
      "[350]\tvalid_0's binary_logloss: 0.252986\n",
      "[400]\tvalid_0's binary_logloss: 0.240333\n",
      "[450]\tvalid_0's binary_logloss: 0.240241\n",
      "[500]\tvalid_0's binary_logloss: 0.232998\n",
      "[550]\tvalid_0's binary_logloss: 0.227234\n",
      "[600]\tvalid_0's binary_logloss: 0.21841\n",
      "[650]\tvalid_0's binary_logloss: 0.218179\n",
      "[700]\tvalid_0's binary_logloss: 0.211289\n",
      "[750]\tvalid_0's binary_logloss: 0.204276\n",
      "[800]\tvalid_0's binary_logloss: 0.20377\n",
      "[850]\tvalid_0's binary_logloss: 0.201892\n",
      "[900]\tvalid_0's binary_logloss: 0.196874\n",
      "[950]\tvalid_0's binary_logloss: 0.19888\n",
      "[1000]\tvalid_0's binary_logloss: 0.195837\n",
      "[1050]\tvalid_0's binary_logloss: 0.19355\n",
      "[1100]\tvalid_0's binary_logloss: 0.194981\n",
      "[1150]\tvalid_0's binary_logloss: 0.195457\n",
      "Early stopping, best iteration is:\n",
      "[1060]\tvalid_0's binary_logloss: 0.193423\n",
      "All your scores are: \n",
      "[0.21050591665111695, 0.17601801884876639, 0.24860390225965898, 0.20824568391896797, 0.19342322729562325]\n",
      "The average of your score\n",
      "0.207359349795\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.420195\n",
      "[100]\tvalid_0's binary_logloss: 0.35166\n",
      "[150]\tvalid_0's binary_logloss: 0.323902\n",
      "[200]\tvalid_0's binary_logloss: 0.295814\n",
      "[250]\tvalid_0's binary_logloss: 0.271702\n",
      "[300]\tvalid_0's binary_logloss: 0.256976\n",
      "[350]\tvalid_0's binary_logloss: 0.252397\n",
      "[400]\tvalid_0's binary_logloss: 0.238673\n",
      "[450]\tvalid_0's binary_logloss: 0.234256\n",
      "[500]\tvalid_0's binary_logloss: 0.230789\n",
      "[550]\tvalid_0's binary_logloss: 0.22889\n",
      "[600]\tvalid_0's binary_logloss: 0.223461\n",
      "[650]\tvalid_0's binary_logloss: 0.21998\n",
      "[700]\tvalid_0's binary_logloss: 0.220241\n",
      "[750]\tvalid_0's binary_logloss: 0.220694\n",
      "Early stopping, best iteration is:\n",
      "[681]\tvalid_0's binary_logloss: 0.219548\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.395267\n",
      "[100]\tvalid_0's binary_logloss: 0.330525\n",
      "[150]\tvalid_0's binary_logloss: 0.288293\n",
      "[200]\tvalid_0's binary_logloss: 0.264626\n",
      "[250]\tvalid_0's binary_logloss: 0.245153\n",
      "[300]\tvalid_0's binary_logloss: 0.234248\n",
      "[350]\tvalid_0's binary_logloss: 0.216925\n",
      "[400]\tvalid_0's binary_logloss: 0.213558\n",
      "[450]\tvalid_0's binary_logloss: 0.200109\n",
      "[500]\tvalid_0's binary_logloss: 0.198288\n",
      "[550]\tvalid_0's binary_logloss: 0.194135\n",
      "[600]\tvalid_0's binary_logloss: 0.190393\n",
      "[650]\tvalid_0's binary_logloss: 0.185307\n",
      "[700]\tvalid_0's binary_logloss: 0.184091\n",
      "[750]\tvalid_0's binary_logloss: 0.183263\n",
      "[800]\tvalid_0's binary_logloss: 0.183482\n",
      "[850]\tvalid_0's binary_logloss: 0.180019\n",
      "[900]\tvalid_0's binary_logloss: 0.18151\n",
      "[950]\tvalid_0's binary_logloss: 0.181423\n",
      "[1000]\tvalid_0's binary_logloss: 0.177592\n",
      "[1050]\tvalid_0's binary_logloss: 0.17606\n",
      "[1100]\tvalid_0's binary_logloss: 0.176341\n",
      "[1150]\tvalid_0's binary_logloss: 0.175049\n",
      "[1200]\tvalid_0's binary_logloss: 0.176218\n",
      "[1250]\tvalid_0's binary_logloss: 0.181562\n",
      "Early stopping, best iteration is:\n",
      "[1159]\tvalid_0's binary_logloss: 0.174229\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.460985\n",
      "[100]\tvalid_0's binary_logloss: 0.387618\n",
      "[150]\tvalid_0's binary_logloss: 0.351342\n",
      "[200]\tvalid_0's binary_logloss: 0.315199\n",
      "[250]\tvalid_0's binary_logloss: 0.301991\n",
      "[300]\tvalid_0's binary_logloss: 0.297125\n",
      "[350]\tvalid_0's binary_logloss: 0.277065\n",
      "[400]\tvalid_0's binary_logloss: 0.276879\n",
      "[450]\tvalid_0's binary_logloss: 0.269955\n",
      "[500]\tvalid_0's binary_logloss: 0.266715\n",
      "[550]\tvalid_0's binary_logloss: 0.264546\n",
      "[600]\tvalid_0's binary_logloss: 0.260795\n",
      "[650]\tvalid_0's binary_logloss: 0.257714\n",
      "[700]\tvalid_0's binary_logloss: 0.256476\n",
      "[750]\tvalid_0's binary_logloss: 0.254658\n",
      "[800]\tvalid_0's binary_logloss: 0.250581\n",
      "[850]\tvalid_0's binary_logloss: 0.250266\n",
      "[900]\tvalid_0's binary_logloss: 0.249056\n",
      "[950]\tvalid_0's binary_logloss: 0.247123\n",
      "[1000]\tvalid_0's binary_logloss: 0.247406\n",
      "[1050]\tvalid_0's binary_logloss: 0.247868\n",
      "Early stopping, best iteration is:\n",
      "[979]\tvalid_0's binary_logloss: 0.243336\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.425379\n",
      "[100]\tvalid_0's binary_logloss: 0.354151\n",
      "[150]\tvalid_0's binary_logloss: 0.310424\n",
      "[200]\tvalid_0's binary_logloss: 0.303577\n",
      "[250]\tvalid_0's binary_logloss: 0.268955\n",
      "[300]\tvalid_0's binary_logloss: 0.25585\n",
      "[350]\tvalid_0's binary_logloss: 0.24389\n",
      "[400]\tvalid_0's binary_logloss: 0.236166\n",
      "[450]\tvalid_0's binary_logloss: 0.233092\n",
      "[500]\tvalid_0's binary_logloss: 0.230918\n",
      "[550]\tvalid_0's binary_logloss: 0.225965\n",
      "[600]\tvalid_0's binary_logloss: 0.225467\n",
      "[650]\tvalid_0's binary_logloss: 0.219441\n",
      "[700]\tvalid_0's binary_logloss: 0.218535\n",
      "[750]\tvalid_0's binary_logloss: 0.21987\n",
      "[800]\tvalid_0's binary_logloss: 0.21624\n",
      "[850]\tvalid_0's binary_logloss: 0.213056\n",
      "[900]\tvalid_0's binary_logloss: 0.213679\n",
      "[950]\tvalid_0's binary_logloss: 0.21241\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's binary_logloss: 0.211803\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.428919\n",
      "[100]\tvalid_0's binary_logloss: 0.388512\n",
      "[150]\tvalid_0's binary_logloss: 0.335773\n",
      "[200]\tvalid_0's binary_logloss: 0.313826\n",
      "[250]\tvalid_0's binary_logloss: 0.302852\n",
      "[300]\tvalid_0's binary_logloss: 0.282864\n",
      "[350]\tvalid_0's binary_logloss: 0.25462\n",
      "[400]\tvalid_0's binary_logloss: 0.245657\n",
      "[450]\tvalid_0's binary_logloss: 0.238479\n",
      "[500]\tvalid_0's binary_logloss: 0.230097\n",
      "[550]\tvalid_0's binary_logloss: 0.220942\n",
      "[600]\tvalid_0's binary_logloss: 0.215389\n",
      "[650]\tvalid_0's binary_logloss: 0.212132\n",
      "[700]\tvalid_0's binary_logloss: 0.208203\n",
      "[750]\tvalid_0's binary_logloss: 0.19933\n",
      "[800]\tvalid_0's binary_logloss: 0.196444\n",
      "[850]\tvalid_0's binary_logloss: 0.198174\n",
      "[900]\tvalid_0's binary_logloss: 0.194017\n",
      "[950]\tvalid_0's binary_logloss: 0.194688\n",
      "Early stopping, best iteration is:\n",
      "[882]\tvalid_0's binary_logloss: 0.192617\n",
      "All your scores are: \n",
      "[0.21954798262556718, 0.17422882416928084, 0.24333613061954548, 0.2118034694403042, 0.19261659010368443]\n",
      "The average of your score\n",
      "0.208306599392\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.420199\n",
      "[100]\tvalid_0's binary_logloss: 0.351648\n",
      "[150]\tvalid_0's binary_logloss: 0.324113\n",
      "[200]\tvalid_0's binary_logloss: 0.299382\n",
      "[250]\tvalid_0's binary_logloss: 0.275523\n",
      "[300]\tvalid_0's binary_logloss: 0.262938\n",
      "[350]\tvalid_0's binary_logloss: 0.256989\n",
      "[400]\tvalid_0's binary_logloss: 0.239398\n",
      "[450]\tvalid_0's binary_logloss: 0.23339\n",
      "[500]\tvalid_0's binary_logloss: 0.226349\n",
      "[550]\tvalid_0's binary_logloss: 0.224096\n",
      "[600]\tvalid_0's binary_logloss: 0.219769\n",
      "[650]\tvalid_0's binary_logloss: 0.216947\n",
      "[700]\tvalid_0's binary_logloss: 0.218525\n",
      "[750]\tvalid_0's binary_logloss: 0.21436\n",
      "[800]\tvalid_0's binary_logloss: 0.213387\n",
      "[850]\tvalid_0's binary_logloss: 0.214897\n",
      "[900]\tvalid_0's binary_logloss: 0.211914\n",
      "[950]\tvalid_0's binary_logloss: 0.211237\n",
      "[1000]\tvalid_0's binary_logloss: 0.210301\n",
      "[1050]\tvalid_0's binary_logloss: 0.209858\n",
      "[1100]\tvalid_0's binary_logloss: 0.208643\n",
      "[1150]\tvalid_0's binary_logloss: 0.205903\n",
      "[1200]\tvalid_0's binary_logloss: 0.20837\n",
      "[1250]\tvalid_0's binary_logloss: 0.21126\n",
      "Early stopping, best iteration is:\n",
      "[1168]\tvalid_0's binary_logloss: 0.204832\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.395119\n",
      "[100]\tvalid_0's binary_logloss: 0.330331\n",
      "[150]\tvalid_0's binary_logloss: 0.289272\n",
      "[200]\tvalid_0's binary_logloss: 0.262137\n",
      "[250]\tvalid_0's binary_logloss: 0.240759\n",
      "[300]\tvalid_0's binary_logloss: 0.232567\n",
      "[350]\tvalid_0's binary_logloss: 0.214961\n",
      "[400]\tvalid_0's binary_logloss: 0.213568\n",
      "[450]\tvalid_0's binary_logloss: 0.200654\n",
      "[500]\tvalid_0's binary_logloss: 0.197684\n",
      "[550]\tvalid_0's binary_logloss: 0.192529\n",
      "[600]\tvalid_0's binary_logloss: 0.189077\n",
      "[650]\tvalid_0's binary_logloss: 0.183441\n",
      "[700]\tvalid_0's binary_logloss: 0.183991\n",
      "[750]\tvalid_0's binary_logloss: 0.180333\n",
      "[800]\tvalid_0's binary_logloss: 0.179453\n",
      "[850]\tvalid_0's binary_logloss: 0.175844\n",
      "[900]\tvalid_0's binary_logloss: 0.177867\n",
      "[950]\tvalid_0's binary_logloss: 0.180713\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's binary_logloss: 0.175558\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.460944\n",
      "[100]\tvalid_0's binary_logloss: 0.389491\n",
      "[150]\tvalid_0's binary_logloss: 0.351268\n",
      "[200]\tvalid_0's binary_logloss: 0.316705\n",
      "[250]\tvalid_0's binary_logloss: 0.298082\n",
      "[300]\tvalid_0's binary_logloss: 0.292738\n",
      "[350]\tvalid_0's binary_logloss: 0.272471\n",
      "[400]\tvalid_0's binary_logloss: 0.272139\n",
      "[450]\tvalid_0's binary_logloss: 0.262963\n",
      "[500]\tvalid_0's binary_logloss: 0.260697\n",
      "[550]\tvalid_0's binary_logloss: 0.259499\n",
      "[600]\tvalid_0's binary_logloss: 0.257718\n",
      "[650]\tvalid_0's binary_logloss: 0.254986\n",
      "[700]\tvalid_0's binary_logloss: 0.249758\n",
      "[750]\tvalid_0's binary_logloss: 0.248901\n",
      "[800]\tvalid_0's binary_logloss: 0.245091\n",
      "[850]\tvalid_0's binary_logloss: 0.245594\n",
      "[900]\tvalid_0's binary_logloss: 0.245877\n",
      "[950]\tvalid_0's binary_logloss: 0.245342\n",
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's binary_logloss: 0.243297\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.424583\n",
      "[100]\tvalid_0's binary_logloss: 0.354416\n",
      "[150]\tvalid_0's binary_logloss: 0.307727\n",
      "[200]\tvalid_0's binary_logloss: 0.300723\n",
      "[250]\tvalid_0's binary_logloss: 0.269041\n",
      "[300]\tvalid_0's binary_logloss: 0.25525\n",
      "[350]\tvalid_0's binary_logloss: 0.245634\n",
      "[400]\tvalid_0's binary_logloss: 0.237088\n",
      "[450]\tvalid_0's binary_logloss: 0.229073\n",
      "[500]\tvalid_0's binary_logloss: 0.22698\n",
      "[550]\tvalid_0's binary_logloss: 0.222791\n",
      "[600]\tvalid_0's binary_logloss: 0.221684\n",
      "[650]\tvalid_0's binary_logloss: 0.219215\n",
      "[700]\tvalid_0's binary_logloss: 0.216787\n",
      "[750]\tvalid_0's binary_logloss: 0.217349\n",
      "[800]\tvalid_0's binary_logloss: 0.216086\n",
      "[850]\tvalid_0's binary_logloss: 0.212667\n",
      "[900]\tvalid_0's binary_logloss: 0.213005\n",
      "[950]\tvalid_0's binary_logloss: 0.211101\n",
      "[1000]\tvalid_0's binary_logloss: 0.21073\n",
      "[1050]\tvalid_0's binary_logloss: 0.209926\n",
      "[1100]\tvalid_0's binary_logloss: 0.210586\n",
      "Early stopping, best iteration is:\n",
      "[1043]\tvalid_0's binary_logloss: 0.209695\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.426548\n",
      "[100]\tvalid_0's binary_logloss: 0.389624\n",
      "[150]\tvalid_0's binary_logloss: 0.336667\n",
      "[200]\tvalid_0's binary_logloss: 0.319688\n",
      "[250]\tvalid_0's binary_logloss: 0.30358\n",
      "[300]\tvalid_0's binary_logloss: 0.281776\n",
      "[350]\tvalid_0's binary_logloss: 0.251454\n",
      "[400]\tvalid_0's binary_logloss: 0.242945\n",
      "[450]\tvalid_0's binary_logloss: 0.242929\n",
      "[500]\tvalid_0's binary_logloss: 0.232807\n",
      "[550]\tvalid_0's binary_logloss: 0.223847\n",
      "[600]\tvalid_0's binary_logloss: 0.213014\n",
      "[650]\tvalid_0's binary_logloss: 0.212648\n",
      "[700]\tvalid_0's binary_logloss: 0.209878\n",
      "[750]\tvalid_0's binary_logloss: 0.204857\n",
      "[800]\tvalid_0's binary_logloss: 0.206067\n",
      "[850]\tvalid_0's binary_logloss: 0.206544\n",
      "Early stopping, best iteration is:\n",
      "[759]\tvalid_0's binary_logloss: 0.203477\n",
      "All your scores are: \n",
      "[0.20483152228148749, 0.17555775424764453, 0.24329678995740317, 0.20969491786704861, 0.20347712034797766]\n",
      "The average of your score\n",
      "0.20737162094\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.420198\n",
      "[100]\tvalid_0's binary_logloss: 0.351648\n",
      "[150]\tvalid_0's binary_logloss: 0.324113\n",
      "[200]\tvalid_0's binary_logloss: 0.299384\n",
      "[250]\tvalid_0's binary_logloss: 0.275539\n",
      "[300]\tvalid_0's binary_logloss: 0.26405\n",
      "[350]\tvalid_0's binary_logloss: 0.258042\n",
      "[400]\tvalid_0's binary_logloss: 0.242015\n",
      "[450]\tvalid_0's binary_logloss: 0.235959\n",
      "[500]\tvalid_0's binary_logloss: 0.232663\n",
      "[550]\tvalid_0's binary_logloss: 0.229539\n",
      "[600]\tvalid_0's binary_logloss: 0.224521\n",
      "[650]\tvalid_0's binary_logloss: 0.220405\n",
      "[700]\tvalid_0's binary_logloss: 0.219059\n",
      "[750]\tvalid_0's binary_logloss: 0.217036\n",
      "[800]\tvalid_0's binary_logloss: 0.217287\n",
      "[850]\tvalid_0's binary_logloss: 0.216027\n",
      "[900]\tvalid_0's binary_logloss: 0.216397\n",
      "[950]\tvalid_0's binary_logloss: 0.21585\n",
      "Early stopping, best iteration is:\n",
      "[875]\tvalid_0's binary_logloss: 0.215014\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.395102\n",
      "[100]\tvalid_0's binary_logloss: 0.330301\n",
      "[150]\tvalid_0's binary_logloss: 0.289258\n",
      "[200]\tvalid_0's binary_logloss: 0.26211\n",
      "[250]\tvalid_0's binary_logloss: 0.240822\n",
      "[300]\tvalid_0's binary_logloss: 0.231459\n",
      "[350]\tvalid_0's binary_logloss: 0.21614\n",
      "[400]\tvalid_0's binary_logloss: 0.212908\n",
      "[450]\tvalid_0's binary_logloss: 0.201423\n",
      "[500]\tvalid_0's binary_logloss: 0.198666\n",
      "[550]\tvalid_0's binary_logloss: 0.192186\n",
      "[600]\tvalid_0's binary_logloss: 0.18916\n",
      "[650]\tvalid_0's binary_logloss: 0.185912\n",
      "[700]\tvalid_0's binary_logloss: 0.185694\n",
      "[750]\tvalid_0's binary_logloss: 0.183733\n",
      "[800]\tvalid_0's binary_logloss: 0.182485\n",
      "[850]\tvalid_0's binary_logloss: 0.177929\n",
      "[900]\tvalid_0's binary_logloss: 0.179302\n",
      "[950]\tvalid_0's binary_logloss: 0.181669\n",
      "Early stopping, best iteration is:\n",
      "[882]\tvalid_0's binary_logloss: 0.177813\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.460945\n",
      "[100]\tvalid_0's binary_logloss: 0.389506\n",
      "[150]\tvalid_0's binary_logloss: 0.35133\n",
      "[200]\tvalid_0's binary_logloss: 0.316848\n",
      "[250]\tvalid_0's binary_logloss: 0.301102\n",
      "[300]\tvalid_0's binary_logloss: 0.294077\n",
      "[350]\tvalid_0's binary_logloss: 0.272562\n",
      "[400]\tvalid_0's binary_logloss: 0.271692\n",
      "[450]\tvalid_0's binary_logloss: 0.26558\n",
      "[500]\tvalid_0's binary_logloss: 0.2633\n",
      "[550]\tvalid_0's binary_logloss: 0.26403\n",
      "[600]\tvalid_0's binary_logloss: 0.260205\n",
      "[650]\tvalid_0's binary_logloss: 0.258323\n",
      "[700]\tvalid_0's binary_logloss: 0.255559\n",
      "[750]\tvalid_0's binary_logloss: 0.254365\n",
      "[800]\tvalid_0's binary_logloss: 0.250244\n",
      "[850]\tvalid_0's binary_logloss: 0.24872\n",
      "[900]\tvalid_0's binary_logloss: 0.248063\n",
      "Early stopping, best iteration is:\n",
      "[821]\tvalid_0's binary_logloss: 0.247535\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.424582\n",
      "[100]\tvalid_0's binary_logloss: 0.354417\n",
      "[150]\tvalid_0's binary_logloss: 0.30773\n",
      "[200]\tvalid_0's binary_logloss: 0.30071\n",
      "[250]\tvalid_0's binary_logloss: 0.269005\n",
      "[300]\tvalid_0's binary_logloss: 0.255227\n",
      "[350]\tvalid_0's binary_logloss: 0.245102\n",
      "[400]\tvalid_0's binary_logloss: 0.235208\n",
      "[450]\tvalid_0's binary_logloss: 0.230138\n",
      "[500]\tvalid_0's binary_logloss: 0.227296\n",
      "[550]\tvalid_0's binary_logloss: 0.222215\n",
      "[600]\tvalid_0's binary_logloss: 0.224318\n",
      "[650]\tvalid_0's binary_logloss: 0.218416\n",
      "[700]\tvalid_0's binary_logloss: 0.21544\n",
      "[750]\tvalid_0's binary_logloss: 0.215789\n",
      "[800]\tvalid_0's binary_logloss: 0.217145\n",
      "[850]\tvalid_0's binary_logloss: 0.215059\n",
      "[900]\tvalid_0's binary_logloss: 0.214135\n",
      "[950]\tvalid_0's binary_logloss: 0.214612\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's binary_logloss: 0.213065\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0ca8>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.426548\n",
      "[100]\tvalid_0's binary_logloss: 0.389624\n",
      "[150]\tvalid_0's binary_logloss: 0.336641\n",
      "[200]\tvalid_0's binary_logloss: 0.319146\n",
      "[250]\tvalid_0's binary_logloss: 0.302823\n",
      "[300]\tvalid_0's binary_logloss: 0.275615\n",
      "[350]\tvalid_0's binary_logloss: 0.249572\n",
      "[400]\tvalid_0's binary_logloss: 0.241022\n",
      "[450]\tvalid_0's binary_logloss: 0.238942\n",
      "[500]\tvalid_0's binary_logloss: 0.224537\n",
      "[550]\tvalid_0's binary_logloss: 0.220253\n",
      "[600]\tvalid_0's binary_logloss: 0.212257\n",
      "[650]\tvalid_0's binary_logloss: 0.209568\n",
      "[700]\tvalid_0's binary_logloss: 0.207635\n",
      "[750]\tvalid_0's binary_logloss: 0.198458\n",
      "[800]\tvalid_0's binary_logloss: 0.198084\n",
      "[850]\tvalid_0's binary_logloss: 0.200043\n",
      "[900]\tvalid_0's binary_logloss: 0.197637\n",
      "[950]\tvalid_0's binary_logloss: 0.194982\n",
      "[1000]\tvalid_0's binary_logloss: 0.196358\n",
      "[1050]\tvalid_0's binary_logloss: 0.196384\n",
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's binary_logloss: 0.194247\n",
      "All your scores are: \n",
      "[0.2150140066280645, 0.17781284428485339, 0.24753506159262287, 0.21306518080219425, 0.19424678776600993]\n",
      "The average of your score\n",
      "0.209534776215\n",
      "The seed we are using is: 463465\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.434\n",
      "[100]\tvalid_0's binary_logloss: 0.368643\n",
      "[150]\tvalid_0's binary_logloss: 0.35226\n",
      "[200]\tvalid_0's binary_logloss: 0.318677\n",
      "[250]\tvalid_0's binary_logloss: 0.306333\n",
      "[300]\tvalid_0's binary_logloss: 0.2998\n",
      "[350]\tvalid_0's binary_logloss: 0.294917\n",
      "[400]\tvalid_0's binary_logloss: 0.27858\n",
      "[450]\tvalid_0's binary_logloss: 0.281138\n",
      "[500]\tvalid_0's binary_logloss: 0.274553\n",
      "[550]\tvalid_0's binary_logloss: 0.265845\n",
      "[600]\tvalid_0's binary_logloss: 0.25671\n",
      "[650]\tvalid_0's binary_logloss: 0.251065\n",
      "[700]\tvalid_0's binary_logloss: 0.24816\n",
      "[750]\tvalid_0's binary_logloss: 0.243801\n",
      "[800]\tvalid_0's binary_logloss: 0.241403\n",
      "[850]\tvalid_0's binary_logloss: 0.238865\n",
      "[900]\tvalid_0's binary_logloss: 0.236196\n",
      "[950]\tvalid_0's binary_logloss: 0.233834\n",
      "[1000]\tvalid_0's binary_logloss: 0.233329\n",
      "[1050]\tvalid_0's binary_logloss: 0.230389\n",
      "[1100]\tvalid_0's binary_logloss: 0.230899\n",
      "[1150]\tvalid_0's binary_logloss: 0.226832\n",
      "[1200]\tvalid_0's binary_logloss: 0.225321\n",
      "[1250]\tvalid_0's binary_logloss: 0.224163\n",
      "[1300]\tvalid_0's binary_logloss: 0.220251\n",
      "[1350]\tvalid_0's binary_logloss: 0.218603\n",
      "[1400]\tvalid_0's binary_logloss: 0.219423\n",
      "[1450]\tvalid_0's binary_logloss: 0.21751\n",
      "[1500]\tvalid_0's binary_logloss: 0.217255\n",
      "Early stopping, best iteration is:\n",
      "[1423]\tvalid_0's binary_logloss: 0.216028\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.428391\n",
      "[100]\tvalid_0's binary_logloss: 0.358722\n",
      "[150]\tvalid_0's binary_logloss: 0.324345\n",
      "[200]\tvalid_0's binary_logloss: 0.298415\n",
      "[250]\tvalid_0's binary_logloss: 0.268996\n",
      "[300]\tvalid_0's binary_logloss: 0.254435\n",
      "[350]\tvalid_0's binary_logloss: 0.247936\n",
      "[400]\tvalid_0's binary_logloss: 0.234304\n",
      "[450]\tvalid_0's binary_logloss: 0.226276\n",
      "[500]\tvalid_0's binary_logloss: 0.219186\n",
      "[550]\tvalid_0's binary_logloss: 0.216318\n",
      "[600]\tvalid_0's binary_logloss: 0.215225\n",
      "[650]\tvalid_0's binary_logloss: 0.211039\n",
      "[700]\tvalid_0's binary_logloss: 0.203755\n",
      "[750]\tvalid_0's binary_logloss: 0.199904\n",
      "[800]\tvalid_0's binary_logloss: 0.196939\n",
      "[850]\tvalid_0's binary_logloss: 0.195692\n",
      "[900]\tvalid_0's binary_logloss: 0.194185\n",
      "[950]\tvalid_0's binary_logloss: 0.193281\n",
      "[1000]\tvalid_0's binary_logloss: 0.190315\n",
      "[1050]\tvalid_0's binary_logloss: 0.187185\n",
      "[1100]\tvalid_0's binary_logloss: 0.186013\n",
      "[1150]\tvalid_0's binary_logloss: 0.189078\n",
      "[1200]\tvalid_0's binary_logloss: 0.188305\n",
      "Early stopping, best iteration is:\n",
      "[1108]\tvalid_0's binary_logloss: 0.185942\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.476334\n",
      "[100]\tvalid_0's binary_logloss: 0.383416\n",
      "[150]\tvalid_0's binary_logloss: 0.35922\n",
      "[200]\tvalid_0's binary_logloss: 0.339694\n",
      "[250]\tvalid_0's binary_logloss: 0.322887\n",
      "[300]\tvalid_0's binary_logloss: 0.304891\n",
      "[350]\tvalid_0's binary_logloss: 0.299829\n",
      "[400]\tvalid_0's binary_logloss: 0.292908\n",
      "[450]\tvalid_0's binary_logloss: 0.288937\n",
      "[500]\tvalid_0's binary_logloss: 0.28547\n",
      "[550]\tvalid_0's binary_logloss: 0.281057\n",
      "[600]\tvalid_0's binary_logloss: 0.274254\n",
      "[650]\tvalid_0's binary_logloss: 0.273081\n",
      "[700]\tvalid_0's binary_logloss: 0.272789\n",
      "[750]\tvalid_0's binary_logloss: 0.271982\n",
      "[800]\tvalid_0's binary_logloss: 0.268399\n",
      "[850]\tvalid_0's binary_logloss: 0.264071\n",
      "[900]\tvalid_0's binary_logloss: 0.267236\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's binary_logloss: 0.263775\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.426937\n",
      "[100]\tvalid_0's binary_logloss: 0.365363\n",
      "[150]\tvalid_0's binary_logloss: 0.343777\n",
      "[200]\tvalid_0's binary_logloss: 0.316668\n",
      "[250]\tvalid_0's binary_logloss: 0.293696\n",
      "[300]\tvalid_0's binary_logloss: 0.286944\n",
      "[350]\tvalid_0's binary_logloss: 0.276427\n",
      "[400]\tvalid_0's binary_logloss: 0.269732\n",
      "[450]\tvalid_0's binary_logloss: 0.266759\n",
      "[500]\tvalid_0's binary_logloss: 0.264169\n",
      "[550]\tvalid_0's binary_logloss: 0.259334\n",
      "[600]\tvalid_0's binary_logloss: 0.257209\n",
      "[650]\tvalid_0's binary_logloss: 0.248994\n",
      "[700]\tvalid_0's binary_logloss: 0.2426\n",
      "[750]\tvalid_0's binary_logloss: 0.239415\n",
      "[800]\tvalid_0's binary_logloss: 0.236835\n",
      "[850]\tvalid_0's binary_logloss: 0.235439\n",
      "[900]\tvalid_0's binary_logloss: 0.231838\n",
      "[950]\tvalid_0's binary_logloss: 0.232372\n",
      "[1000]\tvalid_0's binary_logloss: 0.229348\n",
      "[1050]\tvalid_0's binary_logloss: 0.228295\n",
      "[1100]\tvalid_0's binary_logloss: 0.229309\n",
      "[1150]\tvalid_0's binary_logloss: 0.228657\n",
      "Early stopping, best iteration is:\n",
      "[1052]\tvalid_0's binary_logloss: 0.227707\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.486118\n",
      "[100]\tvalid_0's binary_logloss: 0.413862\n",
      "[150]\tvalid_0's binary_logloss: 0.387838\n",
      "[200]\tvalid_0's binary_logloss: 0.34969\n",
      "[250]\tvalid_0's binary_logloss: 0.322992\n",
      "[300]\tvalid_0's binary_logloss: 0.305567\n",
      "[350]\tvalid_0's binary_logloss: 0.287513\n",
      "[400]\tvalid_0's binary_logloss: 0.258782\n",
      "[450]\tvalid_0's binary_logloss: 0.251469\n",
      "[500]\tvalid_0's binary_logloss: 0.240704\n",
      "[550]\tvalid_0's binary_logloss: 0.23525\n",
      "[600]\tvalid_0's binary_logloss: 0.230187\n",
      "[650]\tvalid_0's binary_logloss: 0.229639\n",
      "[700]\tvalid_0's binary_logloss: 0.228261\n",
      "[750]\tvalid_0's binary_logloss: 0.228861\n",
      "[800]\tvalid_0's binary_logloss: 0.227139\n",
      "[850]\tvalid_0's binary_logloss: 0.223505\n",
      "[900]\tvalid_0's binary_logloss: 0.218948\n",
      "[950]\tvalid_0's binary_logloss: 0.213406\n",
      "[1000]\tvalid_0's binary_logloss: 0.214807\n",
      "[1050]\tvalid_0's binary_logloss: 0.216767\n",
      "Early stopping, best iteration is:\n",
      "[958]\tvalid_0's binary_logloss: 0.212503\n",
      "All your scores are: \n",
      "[0.21602771997171688, 0.18594187497323708, 0.26377509705850294, 0.22770712650648575, 0.21250284959853244]\n",
      "The average of your score\n",
      "0.221190933622\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.421828\n",
      "[100]\tvalid_0's binary_logloss: 0.355316\n",
      "[150]\tvalid_0's binary_logloss: 0.339261\n",
      "[200]\tvalid_0's binary_logloss: 0.307199\n",
      "[250]\tvalid_0's binary_logloss: 0.290087\n",
      "[300]\tvalid_0's binary_logloss: 0.286215\n",
      "[350]\tvalid_0's binary_logloss: 0.278423\n",
      "[400]\tvalid_0's binary_logloss: 0.263726\n",
      "[450]\tvalid_0's binary_logloss: 0.265698\n",
      "[500]\tvalid_0's binary_logloss: 0.260147\n",
      "[550]\tvalid_0's binary_logloss: 0.251402\n",
      "[600]\tvalid_0's binary_logloss: 0.24306\n",
      "[650]\tvalid_0's binary_logloss: 0.237684\n",
      "[700]\tvalid_0's binary_logloss: 0.234802\n",
      "[750]\tvalid_0's binary_logloss: 0.230055\n",
      "[800]\tvalid_0's binary_logloss: 0.228975\n",
      "[850]\tvalid_0's binary_logloss: 0.227037\n",
      "[900]\tvalid_0's binary_logloss: 0.226163\n",
      "[950]\tvalid_0's binary_logloss: 0.222667\n",
      "[1000]\tvalid_0's binary_logloss: 0.223482\n",
      "[1050]\tvalid_0's binary_logloss: 0.221128\n",
      "[1100]\tvalid_0's binary_logloss: 0.220674\n",
      "[1150]\tvalid_0's binary_logloss: 0.21862\n",
      "[1200]\tvalid_0's binary_logloss: 0.217997\n",
      "[1250]\tvalid_0's binary_logloss: 0.215361\n",
      "[1300]\tvalid_0's binary_logloss: 0.213482\n",
      "[1350]\tvalid_0's binary_logloss: 0.211018\n",
      "[1400]\tvalid_0's binary_logloss: 0.210716\n",
      "[1450]\tvalid_0's binary_logloss: 0.210338\n",
      "[1500]\tvalid_0's binary_logloss: 0.210347\n",
      "Early stopping, best iteration is:\n",
      "[1423]\tvalid_0's binary_logloss: 0.209197\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.418498\n",
      "[100]\tvalid_0's binary_logloss: 0.345914\n",
      "[150]\tvalid_0's binary_logloss: 0.311623\n",
      "[200]\tvalid_0's binary_logloss: 0.28366\n",
      "[250]\tvalid_0's binary_logloss: 0.253896\n",
      "[300]\tvalid_0's binary_logloss: 0.236523\n",
      "[350]\tvalid_0's binary_logloss: 0.230447\n",
      "[400]\tvalid_0's binary_logloss: 0.22069\n",
      "[450]\tvalid_0's binary_logloss: 0.213625\n",
      "[500]\tvalid_0's binary_logloss: 0.207168\n",
      "[550]\tvalid_0's binary_logloss: 0.204919\n",
      "[600]\tvalid_0's binary_logloss: 0.202907\n",
      "[650]\tvalid_0's binary_logloss: 0.19916\n",
      "[700]\tvalid_0's binary_logloss: 0.194256\n",
      "[750]\tvalid_0's binary_logloss: 0.192345\n",
      "[800]\tvalid_0's binary_logloss: 0.190356\n",
      "[850]\tvalid_0's binary_logloss: 0.189859\n",
      "[900]\tvalid_0's binary_logloss: 0.189097\n",
      "[950]\tvalid_0's binary_logloss: 0.18531\n",
      "[1000]\tvalid_0's binary_logloss: 0.183712\n",
      "[1050]\tvalid_0's binary_logloss: 0.181729\n",
      "[1100]\tvalid_0's binary_logloss: 0.181689\n",
      "Early stopping, best iteration is:\n",
      "[1019]\tvalid_0's binary_logloss: 0.180382\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.467273\n",
      "[100]\tvalid_0's binary_logloss: 0.37104\n",
      "[150]\tvalid_0's binary_logloss: 0.343629\n",
      "[200]\tvalid_0's binary_logloss: 0.322995\n",
      "[250]\tvalid_0's binary_logloss: 0.309231\n",
      "[300]\tvalid_0's binary_logloss: 0.290361\n",
      "[350]\tvalid_0's binary_logloss: 0.288009\n",
      "[400]\tvalid_0's binary_logloss: 0.283181\n",
      "[450]\tvalid_0's binary_logloss: 0.278636\n",
      "[500]\tvalid_0's binary_logloss: 0.272718\n",
      "[550]\tvalid_0's binary_logloss: 0.270037\n",
      "[600]\tvalid_0's binary_logloss: 0.2671\n",
      "[650]\tvalid_0's binary_logloss: 0.263594\n",
      "[700]\tvalid_0's binary_logloss: 0.264378\n",
      "Early stopping, best iteration is:\n",
      "[648]\tvalid_0's binary_logloss: 0.263573\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.414458\n",
      "[100]\tvalid_0's binary_logloss: 0.352412\n",
      "[150]\tvalid_0's binary_logloss: 0.327992\n",
      "[200]\tvalid_0's binary_logloss: 0.302059\n",
      "[250]\tvalid_0's binary_logloss: 0.27956\n",
      "[300]\tvalid_0's binary_logloss: 0.275657\n",
      "[350]\tvalid_0's binary_logloss: 0.266647\n",
      "[400]\tvalid_0's binary_logloss: 0.257575\n",
      "[450]\tvalid_0's binary_logloss: 0.254842\n",
      "[500]\tvalid_0's binary_logloss: 0.251639\n",
      "[550]\tvalid_0's binary_logloss: 0.245673\n",
      "[600]\tvalid_0's binary_logloss: 0.243842\n",
      "[650]\tvalid_0's binary_logloss: 0.235262\n",
      "[700]\tvalid_0's binary_logloss: 0.230681\n",
      "[750]\tvalid_0's binary_logloss: 0.227664\n",
      "[800]\tvalid_0's binary_logloss: 0.226301\n",
      "[850]\tvalid_0's binary_logloss: 0.225535\n",
      "[900]\tvalid_0's binary_logloss: 0.223415\n",
      "[950]\tvalid_0's binary_logloss: 0.225438\n",
      "[1000]\tvalid_0's binary_logloss: 0.222854\n",
      "[1050]\tvalid_0's binary_logloss: 0.222433\n",
      "[1100]\tvalid_0's binary_logloss: 0.222449\n",
      "[1150]\tvalid_0's binary_logloss: 0.22128\n",
      "[1200]\tvalid_0's binary_logloss: 0.220046\n",
      "[1250]\tvalid_0's binary_logloss: 0.218026\n",
      "[1300]\tvalid_0's binary_logloss: 0.217138\n",
      "[1350]\tvalid_0's binary_logloss: 0.217123\n",
      "[1400]\tvalid_0's binary_logloss: 0.215292\n",
      "[1450]\tvalid_0's binary_logloss: 0.214605\n",
      "[1500]\tvalid_0's binary_logloss: 0.212335\n",
      "[1550]\tvalid_0's binary_logloss: 0.212722\n",
      "[1600]\tvalid_0's binary_logloss: 0.21225\n",
      "[1650]\tvalid_0's binary_logloss: 0.210768\n",
      "[1700]\tvalid_0's binary_logloss: 0.210987\n",
      "[1750]\tvalid_0's binary_logloss: 0.21025\n",
      "[1800]\tvalid_0's binary_logloss: 0.208267\n",
      "[1850]\tvalid_0's binary_logloss: 0.208085\n",
      "[1900]\tvalid_0's binary_logloss: 0.209129\n",
      "Early stopping, best iteration is:\n",
      "[1822]\tvalid_0's binary_logloss: 0.206977\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.484963\n",
      "[100]\tvalid_0's binary_logloss: 0.404509\n",
      "[150]\tvalid_0's binary_logloss: 0.370664\n",
      "[200]\tvalid_0's binary_logloss: 0.336382\n",
      "[250]\tvalid_0's binary_logloss: 0.308777\n",
      "[300]\tvalid_0's binary_logloss: 0.284973\n",
      "[350]\tvalid_0's binary_logloss: 0.265861\n",
      "[400]\tvalid_0's binary_logloss: 0.241717\n",
      "[450]\tvalid_0's binary_logloss: 0.238567\n",
      "[500]\tvalid_0's binary_logloss: 0.230533\n",
      "[550]\tvalid_0's binary_logloss: 0.223302\n",
      "[600]\tvalid_0's binary_logloss: 0.217261\n",
      "[650]\tvalid_0's binary_logloss: 0.218026\n",
      "[700]\tvalid_0's binary_logloss: 0.21531\n",
      "[750]\tvalid_0's binary_logloss: 0.217631\n",
      "[800]\tvalid_0's binary_logloss: 0.213986\n",
      "[850]\tvalid_0's binary_logloss: 0.212422\n",
      "[900]\tvalid_0's binary_logloss: 0.207707\n",
      "[950]\tvalid_0's binary_logloss: 0.204305\n",
      "[1000]\tvalid_0's binary_logloss: 0.203649\n",
      "[1050]\tvalid_0's binary_logloss: 0.20559\n",
      "Early stopping, best iteration is:\n",
      "[956]\tvalid_0's binary_logloss: 0.2021\n",
      "All your scores are: \n",
      "[0.20919736018729551, 0.18038195343033397, 0.26357304353235805, 0.20697742359039806, 0.20209958183294524]\n",
      "The average of your score\n",
      "0.212445872515\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.414525\n",
      "[100]\tvalid_0's binary_logloss: 0.348877\n",
      "[150]\tvalid_0's binary_logloss: 0.331085\n",
      "[200]\tvalid_0's binary_logloss: 0.299948\n",
      "[250]\tvalid_0's binary_logloss: 0.283868\n",
      "[300]\tvalid_0's binary_logloss: 0.276551\n",
      "[350]\tvalid_0's binary_logloss: 0.270954\n",
      "[400]\tvalid_0's binary_logloss: 0.251837\n",
      "[450]\tvalid_0's binary_logloss: 0.253091\n",
      "[500]\tvalid_0's binary_logloss: 0.249757\n",
      "[550]\tvalid_0's binary_logloss: 0.242095\n",
      "[600]\tvalid_0's binary_logloss: 0.236637\n",
      "[650]\tvalid_0's binary_logloss: 0.231876\n",
      "[700]\tvalid_0's binary_logloss: 0.22895\n",
      "[750]\tvalid_0's binary_logloss: 0.225878\n",
      "[800]\tvalid_0's binary_logloss: 0.223809\n",
      "[850]\tvalid_0's binary_logloss: 0.222648\n",
      "[900]\tvalid_0's binary_logloss: 0.22133\n",
      "[950]\tvalid_0's binary_logloss: 0.218605\n",
      "[1000]\tvalid_0's binary_logloss: 0.218667\n",
      "[1050]\tvalid_0's binary_logloss: 0.215107\n",
      "[1100]\tvalid_0's binary_logloss: 0.214972\n",
      "[1150]\tvalid_0's binary_logloss: 0.214162\n",
      "[1200]\tvalid_0's binary_logloss: 0.213469\n",
      "[1250]\tvalid_0's binary_logloss: 0.212257\n",
      "[1300]\tvalid_0's binary_logloss: 0.210467\n",
      "[1350]\tvalid_0's binary_logloss: 0.211281\n",
      "Early stopping, best iteration is:\n",
      "[1293]\tvalid_0's binary_logloss: 0.210199\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.411617\n",
      "[100]\tvalid_0's binary_logloss: 0.339078\n",
      "[150]\tvalid_0's binary_logloss: 0.302555\n",
      "[200]\tvalid_0's binary_logloss: 0.272875\n",
      "[250]\tvalid_0's binary_logloss: 0.243852\n",
      "[300]\tvalid_0's binary_logloss: 0.227997\n",
      "[350]\tvalid_0's binary_logloss: 0.222914\n",
      "[400]\tvalid_0's binary_logloss: 0.212315\n",
      "[450]\tvalid_0's binary_logloss: 0.206563\n",
      "[500]\tvalid_0's binary_logloss: 0.19757\n",
      "[550]\tvalid_0's binary_logloss: 0.19598\n",
      "[600]\tvalid_0's binary_logloss: 0.194996\n",
      "[650]\tvalid_0's binary_logloss: 0.194253\n",
      "[700]\tvalid_0's binary_logloss: 0.190513\n",
      "[750]\tvalid_0's binary_logloss: 0.18734\n",
      "[800]\tvalid_0's binary_logloss: 0.184743\n",
      "[850]\tvalid_0's binary_logloss: 0.185756\n",
      "[900]\tvalid_0's binary_logloss: 0.18533\n",
      "Early stopping, best iteration is:\n",
      "[822]\tvalid_0's binary_logloss: 0.182905\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.463377\n",
      "[100]\tvalid_0's binary_logloss: 0.36432\n",
      "[150]\tvalid_0's binary_logloss: 0.333496\n",
      "[200]\tvalid_0's binary_logloss: 0.317535\n",
      "[250]\tvalid_0's binary_logloss: 0.300602\n",
      "[300]\tvalid_0's binary_logloss: 0.284204\n",
      "[350]\tvalid_0's binary_logloss: 0.281962\n",
      "[400]\tvalid_0's binary_logloss: 0.277401\n",
      "[450]\tvalid_0's binary_logloss: 0.271183\n",
      "[500]\tvalid_0's binary_logloss: 0.266841\n",
      "[550]\tvalid_0's binary_logloss: 0.265267\n",
      "[600]\tvalid_0's binary_logloss: 0.25881\n",
      "[650]\tvalid_0's binary_logloss: 0.260338\n",
      "[700]\tvalid_0's binary_logloss: 0.260315\n",
      "Early stopping, best iteration is:\n",
      "[602]\tvalid_0's binary_logloss: 0.258128\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.407631\n",
      "[100]\tvalid_0's binary_logloss: 0.343849\n",
      "[150]\tvalid_0's binary_logloss: 0.318482\n",
      "[200]\tvalid_0's binary_logloss: 0.29469\n",
      "[250]\tvalid_0's binary_logloss: 0.269374\n",
      "[300]\tvalid_0's binary_logloss: 0.26385\n",
      "[350]\tvalid_0's binary_logloss: 0.254355\n",
      "[400]\tvalid_0's binary_logloss: 0.247119\n",
      "[450]\tvalid_0's binary_logloss: 0.244643\n",
      "[500]\tvalid_0's binary_logloss: 0.241662\n",
      "[550]\tvalid_0's binary_logloss: 0.236673\n",
      "[600]\tvalid_0's binary_logloss: 0.239176\n",
      "[650]\tvalid_0's binary_logloss: 0.228137\n",
      "[700]\tvalid_0's binary_logloss: 0.225866\n",
      "[750]\tvalid_0's binary_logloss: 0.224205\n",
      "[800]\tvalid_0's binary_logloss: 0.223879\n",
      "[850]\tvalid_0's binary_logloss: 0.223872\n",
      "[900]\tvalid_0's binary_logloss: 0.220748\n",
      "[950]\tvalid_0's binary_logloss: 0.220301\n",
      "[1000]\tvalid_0's binary_logloss: 0.216638\n",
      "[1050]\tvalid_0's binary_logloss: 0.215874\n",
      "[1100]\tvalid_0's binary_logloss: 0.21679\n",
      "Early stopping, best iteration is:\n",
      "[1039]\tvalid_0's binary_logloss: 0.214799\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.471817\n",
      "[100]\tvalid_0's binary_logloss: 0.396241\n",
      "[150]\tvalid_0's binary_logloss: 0.356876\n",
      "[200]\tvalid_0's binary_logloss: 0.326076\n",
      "[250]\tvalid_0's binary_logloss: 0.295191\n",
      "[300]\tvalid_0's binary_logloss: 0.276671\n",
      "[350]\tvalid_0's binary_logloss: 0.255903\n",
      "[400]\tvalid_0's binary_logloss: 0.237925\n",
      "[450]\tvalid_0's binary_logloss: 0.22781\n",
      "[500]\tvalid_0's binary_logloss: 0.21924\n",
      "[550]\tvalid_0's binary_logloss: 0.216576\n",
      "[600]\tvalid_0's binary_logloss: 0.212892\n",
      "[650]\tvalid_0's binary_logloss: 0.212558\n",
      "[700]\tvalid_0's binary_logloss: 0.21022\n",
      "[750]\tvalid_0's binary_logloss: 0.211473\n",
      "Early stopping, best iteration is:\n",
      "[666]\tvalid_0's binary_logloss: 0.209508\n",
      "All your scores are: \n",
      "[0.2101991680679075, 0.1829050396017885, 0.25812838909412322, 0.21479882534202216, 0.20950764865321747]\n",
      "The average of your score\n",
      "0.215107814152\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.410045\n",
      "[100]\tvalid_0's binary_logloss: 0.344742\n",
      "[150]\tvalid_0's binary_logloss: 0.327866\n",
      "[200]\tvalid_0's binary_logloss: 0.295958\n",
      "[250]\tvalid_0's binary_logloss: 0.280491\n",
      "[300]\tvalid_0's binary_logloss: 0.274793\n",
      "[350]\tvalid_0's binary_logloss: 0.267706\n",
      "[400]\tvalid_0's binary_logloss: 0.249843\n",
      "[450]\tvalid_0's binary_logloss: 0.250953\n",
      "[500]\tvalid_0's binary_logloss: 0.245571\n",
      "[550]\tvalid_0's binary_logloss: 0.237148\n",
      "[600]\tvalid_0's binary_logloss: 0.2293\n",
      "[650]\tvalid_0's binary_logloss: 0.225703\n",
      "[700]\tvalid_0's binary_logloss: 0.222191\n",
      "[750]\tvalid_0's binary_logloss: 0.220287\n",
      "[800]\tvalid_0's binary_logloss: 0.219064\n",
      "[850]\tvalid_0's binary_logloss: 0.217701\n",
      "Early stopping, best iteration is:\n",
      "[789]\tvalid_0's binary_logloss: 0.217001\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.410654\n",
      "[100]\tvalid_0's binary_logloss: 0.3381\n",
      "[150]\tvalid_0's binary_logloss: 0.302417\n",
      "[200]\tvalid_0's binary_logloss: 0.272371\n",
      "[250]\tvalid_0's binary_logloss: 0.239379\n",
      "[300]\tvalid_0's binary_logloss: 0.223842\n",
      "[350]\tvalid_0's binary_logloss: 0.218082\n",
      "[400]\tvalid_0's binary_logloss: 0.207698\n",
      "[450]\tvalid_0's binary_logloss: 0.20202\n",
      "[500]\tvalid_0's binary_logloss: 0.196412\n",
      "[550]\tvalid_0's binary_logloss: 0.193317\n",
      "[600]\tvalid_0's binary_logloss: 0.192078\n",
      "[650]\tvalid_0's binary_logloss: 0.189588\n",
      "[700]\tvalid_0's binary_logloss: 0.183664\n",
      "[750]\tvalid_0's binary_logloss: 0.181804\n",
      "[800]\tvalid_0's binary_logloss: 0.182526\n",
      "[850]\tvalid_0's binary_logloss: 0.184882\n",
      "Early stopping, best iteration is:\n",
      "[765]\tvalid_0's binary_logloss: 0.180045\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.4612\n",
      "[100]\tvalid_0's binary_logloss: 0.362715\n",
      "[150]\tvalid_0's binary_logloss: 0.332301\n",
      "[200]\tvalid_0's binary_logloss: 0.316891\n",
      "[250]\tvalid_0's binary_logloss: 0.299698\n",
      "[300]\tvalid_0's binary_logloss: 0.280841\n",
      "[350]\tvalid_0's binary_logloss: 0.278167\n",
      "[400]\tvalid_0's binary_logloss: 0.270086\n",
      "[450]\tvalid_0's binary_logloss: 0.264941\n",
      "[500]\tvalid_0's binary_logloss: 0.263268\n",
      "[550]\tvalid_0's binary_logloss: 0.261241\n",
      "[600]\tvalid_0's binary_logloss: 0.255399\n",
      "[650]\tvalid_0's binary_logloss: 0.257857\n",
      "[700]\tvalid_0's binary_logloss: 0.258103\n",
      "Early stopping, best iteration is:\n",
      "[604]\tvalid_0's binary_logloss: 0.254582\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.404837\n",
      "[100]\tvalid_0's binary_logloss: 0.342075\n",
      "[150]\tvalid_0's binary_logloss: 0.315259\n",
      "[200]\tvalid_0's binary_logloss: 0.292715\n",
      "[250]\tvalid_0's binary_logloss: 0.267874\n",
      "[300]\tvalid_0's binary_logloss: 0.260641\n",
      "[350]\tvalid_0's binary_logloss: 0.249964\n",
      "[400]\tvalid_0's binary_logloss: 0.241841\n",
      "[450]\tvalid_0's binary_logloss: 0.240815\n",
      "[500]\tvalid_0's binary_logloss: 0.237377\n",
      "[550]\tvalid_0's binary_logloss: 0.233327\n",
      "[600]\tvalid_0's binary_logloss: 0.23646\n",
      "[650]\tvalid_0's binary_logloss: 0.224068\n",
      "[700]\tvalid_0's binary_logloss: 0.219922\n",
      "[750]\tvalid_0's binary_logloss: 0.2174\n",
      "[800]\tvalid_0's binary_logloss: 0.216931\n",
      "[850]\tvalid_0's binary_logloss: 0.217661\n",
      "[900]\tvalid_0's binary_logloss: 0.217297\n",
      "[950]\tvalid_0's binary_logloss: 0.216292\n",
      "[1000]\tvalid_0's binary_logloss: 0.21237\n",
      "[1050]\tvalid_0's binary_logloss: 0.212562\n",
      "[1100]\tvalid_0's binary_logloss: 0.212217\n",
      "Early stopping, best iteration is:\n",
      "[1007]\tvalid_0's binary_logloss: 0.211571\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.469858\n",
      "[100]\tvalid_0's binary_logloss: 0.392005\n",
      "[150]\tvalid_0's binary_logloss: 0.353068\n",
      "[200]\tvalid_0's binary_logloss: 0.321732\n",
      "[250]\tvalid_0's binary_logloss: 0.294593\n",
      "[300]\tvalid_0's binary_logloss: 0.273859\n",
      "[350]\tvalid_0's binary_logloss: 0.252808\n",
      "[400]\tvalid_0's binary_logloss: 0.233652\n",
      "[450]\tvalid_0's binary_logloss: 0.230732\n",
      "[500]\tvalid_0's binary_logloss: 0.224097\n",
      "[550]\tvalid_0's binary_logloss: 0.216497\n",
      "[600]\tvalid_0's binary_logloss: 0.211511\n",
      "[650]\tvalid_0's binary_logloss: 0.210131\n",
      "[700]\tvalid_0's binary_logloss: 0.205231\n",
      "[750]\tvalid_0's binary_logloss: 0.206027\n",
      "[800]\tvalid_0's binary_logloss: 0.20225\n",
      "[850]\tvalid_0's binary_logloss: 0.20116\n",
      "[900]\tvalid_0's binary_logloss: 0.201068\n",
      "[950]\tvalid_0's binary_logloss: 0.197311\n",
      "[1000]\tvalid_0's binary_logloss: 0.199576\n",
      "Early stopping, best iteration is:\n",
      "[947]\tvalid_0's binary_logloss: 0.197145\n",
      "All your scores are: \n",
      "[0.21700128458827658, 0.18004498973260236, 0.25458231285652377, 0.21157060188635443, 0.19714460922974225]\n",
      "The average of your score\n",
      "0.212068759659\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.411748\n",
      "[100]\tvalid_0's binary_logloss: 0.342962\n",
      "[150]\tvalid_0's binary_logloss: 0.327246\n",
      "[200]\tvalid_0's binary_logloss: 0.292426\n",
      "[250]\tvalid_0's binary_logloss: 0.278679\n",
      "[300]\tvalid_0's binary_logloss: 0.27404\n",
      "[350]\tvalid_0's binary_logloss: 0.267648\n",
      "[400]\tvalid_0's binary_logloss: 0.248244\n",
      "[450]\tvalid_0's binary_logloss: 0.249266\n",
      "[500]\tvalid_0's binary_logloss: 0.2436\n",
      "[550]\tvalid_0's binary_logloss: 0.233485\n",
      "[600]\tvalid_0's binary_logloss: 0.228363\n",
      "[650]\tvalid_0's binary_logloss: 0.223343\n",
      "[700]\tvalid_0's binary_logloss: 0.224711\n",
      "[750]\tvalid_0's binary_logloss: 0.222725\n",
      "[800]\tvalid_0's binary_logloss: 0.221218\n",
      "[850]\tvalid_0's binary_logloss: 0.222015\n",
      "Early stopping, best iteration is:\n",
      "[789]\tvalid_0's binary_logloss: 0.2209\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.410008\n",
      "[100]\tvalid_0's binary_logloss: 0.337979\n",
      "[150]\tvalid_0's binary_logloss: 0.301724\n",
      "[200]\tvalid_0's binary_logloss: 0.270945\n",
      "[250]\tvalid_0's binary_logloss: 0.240218\n",
      "[300]\tvalid_0's binary_logloss: 0.228265\n",
      "[350]\tvalid_0's binary_logloss: 0.221877\n",
      "[400]\tvalid_0's binary_logloss: 0.208856\n",
      "[450]\tvalid_0's binary_logloss: 0.203927\n",
      "[500]\tvalid_0's binary_logloss: 0.197359\n",
      "[550]\tvalid_0's binary_logloss: 0.194293\n",
      "[600]\tvalid_0's binary_logloss: 0.19335\n",
      "[650]\tvalid_0's binary_logloss: 0.190987\n",
      "[700]\tvalid_0's binary_logloss: 0.184675\n",
      "[750]\tvalid_0's binary_logloss: 0.182459\n",
      "[800]\tvalid_0's binary_logloss: 0.180668\n",
      "[850]\tvalid_0's binary_logloss: 0.183177\n",
      "[900]\tvalid_0's binary_logloss: 0.184591\n",
      "Early stopping, best iteration is:\n",
      "[814]\tvalid_0's binary_logloss: 0.179916\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.457918\n",
      "[100]\tvalid_0's binary_logloss: 0.36117\n",
      "[150]\tvalid_0's binary_logloss: 0.331717\n",
      "[200]\tvalid_0's binary_logloss: 0.314084\n",
      "[250]\tvalid_0's binary_logloss: 0.298829\n",
      "[300]\tvalid_0's binary_logloss: 0.28283\n",
      "[350]\tvalid_0's binary_logloss: 0.278922\n",
      "[400]\tvalid_0's binary_logloss: 0.270413\n",
      "[450]\tvalid_0's binary_logloss: 0.266487\n",
      "[500]\tvalid_0's binary_logloss: 0.263051\n",
      "[550]\tvalid_0's binary_logloss: 0.258183\n",
      "[600]\tvalid_0's binary_logloss: 0.25478\n",
      "[650]\tvalid_0's binary_logloss: 0.254792\n",
      "[700]\tvalid_0's binary_logloss: 0.255365\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's binary_logloss: 0.253419\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.401543\n",
      "[100]\tvalid_0's binary_logloss: 0.339221\n",
      "[150]\tvalid_0's binary_logloss: 0.314432\n",
      "[200]\tvalid_0's binary_logloss: 0.28971\n",
      "[250]\tvalid_0's binary_logloss: 0.263253\n",
      "[300]\tvalid_0's binary_logloss: 0.258095\n",
      "[350]\tvalid_0's binary_logloss: 0.249442\n",
      "[400]\tvalid_0's binary_logloss: 0.243771\n",
      "[450]\tvalid_0's binary_logloss: 0.239597\n",
      "[500]\tvalid_0's binary_logloss: 0.234979\n",
      "[550]\tvalid_0's binary_logloss: 0.231948\n",
      "[600]\tvalid_0's binary_logloss: 0.234461\n",
      "[650]\tvalid_0's binary_logloss: 0.224366\n",
      "[700]\tvalid_0's binary_logloss: 0.219839\n",
      "[750]\tvalid_0's binary_logloss: 0.214734\n",
      "[800]\tvalid_0's binary_logloss: 0.214148\n",
      "[850]\tvalid_0's binary_logloss: 0.213785\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's binary_logloss: 0.212951\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.465054\n",
      "[100]\tvalid_0's binary_logloss: 0.387665\n",
      "[150]\tvalid_0's binary_logloss: 0.349008\n",
      "[200]\tvalid_0's binary_logloss: 0.317558\n",
      "[250]\tvalid_0's binary_logloss: 0.290506\n",
      "[300]\tvalid_0's binary_logloss: 0.268837\n",
      "[350]\tvalid_0's binary_logloss: 0.255314\n",
      "[400]\tvalid_0's binary_logloss: 0.238168\n",
      "[450]\tvalid_0's binary_logloss: 0.229172\n",
      "[500]\tvalid_0's binary_logloss: 0.216501\n",
      "[550]\tvalid_0's binary_logloss: 0.21397\n",
      "[600]\tvalid_0's binary_logloss: 0.211915\n",
      "[650]\tvalid_0's binary_logloss: 0.209604\n",
      "[700]\tvalid_0's binary_logloss: 0.202332\n",
      "[750]\tvalid_0's binary_logloss: 0.203639\n",
      "[800]\tvalid_0's binary_logloss: 0.202175\n",
      "[850]\tvalid_0's binary_logloss: 0.19781\n",
      "[900]\tvalid_0's binary_logloss: 0.194764\n",
      "[950]\tvalid_0's binary_logloss: 0.195908\n",
      "Early stopping, best iteration is:\n",
      "[888]\tvalid_0's binary_logloss: 0.194151\n",
      "All your scores are: \n",
      "[0.22089986975186288, 0.17991594259982829, 0.25341883632348505, 0.21295056991661751, 0.19415070812952401]\n",
      "The average of your score\n",
      "0.212267185344\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.41005\n",
      "[100]\tvalid_0's binary_logloss: 0.340543\n",
      "[150]\tvalid_0's binary_logloss: 0.32425\n",
      "[200]\tvalid_0's binary_logloss: 0.289815\n",
      "[250]\tvalid_0's binary_logloss: 0.273744\n",
      "[300]\tvalid_0's binary_logloss: 0.268755\n",
      "[350]\tvalid_0's binary_logloss: 0.26321\n",
      "[400]\tvalid_0's binary_logloss: 0.24575\n",
      "[450]\tvalid_0's binary_logloss: 0.248153\n",
      "[500]\tvalid_0's binary_logloss: 0.241735\n",
      "[550]\tvalid_0's binary_logloss: 0.233415\n",
      "[600]\tvalid_0's binary_logloss: 0.227206\n",
      "[650]\tvalid_0's binary_logloss: 0.222496\n",
      "[700]\tvalid_0's binary_logloss: 0.220895\n",
      "[750]\tvalid_0's binary_logloss: 0.21906\n",
      "[800]\tvalid_0's binary_logloss: 0.21795\n",
      "[850]\tvalid_0's binary_logloss: 0.217124\n",
      "[900]\tvalid_0's binary_logloss: 0.216725\n",
      "[950]\tvalid_0's binary_logloss: 0.21402\n",
      "[1000]\tvalid_0's binary_logloss: 0.214596\n",
      "[1050]\tvalid_0's binary_logloss: 0.213396\n",
      "[1100]\tvalid_0's binary_logloss: 0.214956\n",
      "Early stopping, best iteration is:\n",
      "[1040]\tvalid_0's binary_logloss: 0.212982\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.409415\n",
      "[100]\tvalid_0's binary_logloss: 0.338619\n",
      "[150]\tvalid_0's binary_logloss: 0.301922\n",
      "[200]\tvalid_0's binary_logloss: 0.276083\n",
      "[250]\tvalid_0's binary_logloss: 0.24298\n",
      "[300]\tvalid_0's binary_logloss: 0.228584\n",
      "[350]\tvalid_0's binary_logloss: 0.220243\n",
      "[400]\tvalid_0's binary_logloss: 0.211016\n",
      "[450]\tvalid_0's binary_logloss: 0.20401\n",
      "[500]\tvalid_0's binary_logloss: 0.1984\n",
      "[550]\tvalid_0's binary_logloss: 0.195132\n",
      "[600]\tvalid_0's binary_logloss: 0.193281\n",
      "[650]\tvalid_0's binary_logloss: 0.190982\n",
      "[700]\tvalid_0's binary_logloss: 0.188522\n",
      "[750]\tvalid_0's binary_logloss: 0.18499\n",
      "[800]\tvalid_0's binary_logloss: 0.181884\n",
      "[850]\tvalid_0's binary_logloss: 0.181744\n",
      "[900]\tvalid_0's binary_logloss: 0.179739\n",
      "[950]\tvalid_0's binary_logloss: 0.178864\n",
      "[1000]\tvalid_0's binary_logloss: 0.178855\n",
      "[1050]\tvalid_0's binary_logloss: 0.176574\n",
      "[1100]\tvalid_0's binary_logloss: 0.176152\n",
      "[1150]\tvalid_0's binary_logloss: 0.177589\n",
      "[1200]\tvalid_0's binary_logloss: 0.175458\n",
      "[1250]\tvalid_0's binary_logloss: 0.175999\n",
      "[1300]\tvalid_0's binary_logloss: 0.177261\n",
      "Early stopping, best iteration is:\n",
      "[1229]\tvalid_0's binary_logloss: 0.17534\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.460566\n",
      "[100]\tvalid_0's binary_logloss: 0.360393\n",
      "[150]\tvalid_0's binary_logloss: 0.330018\n",
      "[200]\tvalid_0's binary_logloss: 0.312121\n",
      "[250]\tvalid_0's binary_logloss: 0.296363\n",
      "[300]\tvalid_0's binary_logloss: 0.279756\n",
      "[350]\tvalid_0's binary_logloss: 0.277078\n",
      "[400]\tvalid_0's binary_logloss: 0.270457\n",
      "[450]\tvalid_0's binary_logloss: 0.269353\n",
      "[500]\tvalid_0's binary_logloss: 0.265439\n",
      "[550]\tvalid_0's binary_logloss: 0.264161\n",
      "[600]\tvalid_0's binary_logloss: 0.259922\n",
      "[650]\tvalid_0's binary_logloss: 0.261657\n",
      "[700]\tvalid_0's binary_logloss: 0.262494\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's binary_logloss: 0.259922\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.401555\n",
      "[100]\tvalid_0's binary_logloss: 0.340279\n",
      "[150]\tvalid_0's binary_logloss: 0.313948\n",
      "[200]\tvalid_0's binary_logloss: 0.290281\n",
      "[250]\tvalid_0's binary_logloss: 0.262585\n",
      "[300]\tvalid_0's binary_logloss: 0.257359\n",
      "[350]\tvalid_0's binary_logloss: 0.247321\n",
      "[400]\tvalid_0's binary_logloss: 0.242706\n",
      "[450]\tvalid_0's binary_logloss: 0.236188\n",
      "[500]\tvalid_0's binary_logloss: 0.235175\n",
      "[550]\tvalid_0's binary_logloss: 0.231286\n",
      "[600]\tvalid_0's binary_logloss: 0.234701\n",
      "[650]\tvalid_0's binary_logloss: 0.225975\n",
      "[700]\tvalid_0's binary_logloss: 0.218742\n",
      "[750]\tvalid_0's binary_logloss: 0.217648\n",
      "[800]\tvalid_0's binary_logloss: 0.215624\n",
      "[850]\tvalid_0's binary_logloss: 0.21666\n",
      "[900]\tvalid_0's binary_logloss: 0.217861\n",
      "Early stopping, best iteration is:\n",
      "[831]\tvalid_0's binary_logloss: 0.215293\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.466959\n",
      "[100]\tvalid_0's binary_logloss: 0.390719\n",
      "[150]\tvalid_0's binary_logloss: 0.349518\n",
      "[200]\tvalid_0's binary_logloss: 0.319496\n",
      "[250]\tvalid_0's binary_logloss: 0.293268\n",
      "[300]\tvalid_0's binary_logloss: 0.273647\n",
      "[350]\tvalid_0's binary_logloss: 0.254781\n",
      "[400]\tvalid_0's binary_logloss: 0.236746\n",
      "[450]\tvalid_0's binary_logloss: 0.23071\n",
      "[500]\tvalid_0's binary_logloss: 0.220797\n",
      "[550]\tvalid_0's binary_logloss: 0.216484\n",
      "[600]\tvalid_0's binary_logloss: 0.214526\n",
      "[650]\tvalid_0's binary_logloss: 0.212228\n",
      "[700]\tvalid_0's binary_logloss: 0.209542\n",
      "[750]\tvalid_0's binary_logloss: 0.209379\n",
      "Early stopping, best iteration is:\n",
      "[681]\tvalid_0's binary_logloss: 0.207825\n",
      "All your scores are: \n",
      "[0.21298215836723777, 0.1753398677136144, 0.25992184260255335, 0.21529333800403638, 0.20782547359462861]\n",
      "The average of your score\n",
      "0.214272536056\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.410126\n",
      "[100]\tvalid_0's binary_logloss: 0.341765\n",
      "[150]\tvalid_0's binary_logloss: 0.326415\n",
      "[200]\tvalid_0's binary_logloss: 0.29445\n",
      "[250]\tvalid_0's binary_logloss: 0.279163\n",
      "[300]\tvalid_0's binary_logloss: 0.274075\n",
      "[350]\tvalid_0's binary_logloss: 0.267299\n",
      "[400]\tvalid_0's binary_logloss: 0.250678\n",
      "[450]\tvalid_0's binary_logloss: 0.253029\n",
      "[500]\tvalid_0's binary_logloss: 0.247362\n",
      "[550]\tvalid_0's binary_logloss: 0.239965\n",
      "[600]\tvalid_0's binary_logloss: 0.233138\n",
      "[650]\tvalid_0's binary_logloss: 0.22941\n",
      "[700]\tvalid_0's binary_logloss: 0.225929\n",
      "[750]\tvalid_0's binary_logloss: 0.223437\n",
      "[800]\tvalid_0's binary_logloss: 0.22411\n",
      "[850]\tvalid_0's binary_logloss: 0.223683\n",
      "[900]\tvalid_0's binary_logloss: 0.222028\n",
      "[950]\tvalid_0's binary_logloss: 0.218326\n",
      "[1000]\tvalid_0's binary_logloss: 0.218132\n",
      "[1050]\tvalid_0's binary_logloss: 0.217807\n",
      "[1100]\tvalid_0's binary_logloss: 0.215851\n",
      "[1150]\tvalid_0's binary_logloss: 0.217775\n",
      "[1200]\tvalid_0's binary_logloss: 0.217723\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's binary_logloss: 0.215587\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.409409\n",
      "[100]\tvalid_0's binary_logloss: 0.338374\n",
      "[150]\tvalid_0's binary_logloss: 0.301521\n",
      "[200]\tvalid_0's binary_logloss: 0.271596\n",
      "[250]\tvalid_0's binary_logloss: 0.24248\n",
      "[300]\tvalid_0's binary_logloss: 0.229592\n",
      "[350]\tvalid_0's binary_logloss: 0.222942\n",
      "[400]\tvalid_0's binary_logloss: 0.21027\n",
      "[450]\tvalid_0's binary_logloss: 0.203629\n",
      "[500]\tvalid_0's binary_logloss: 0.193829\n",
      "[550]\tvalid_0's binary_logloss: 0.190823\n",
      "[600]\tvalid_0's binary_logloss: 0.19136\n",
      "[650]\tvalid_0's binary_logloss: 0.189836\n",
      "[700]\tvalid_0's binary_logloss: 0.184758\n",
      "[750]\tvalid_0's binary_logloss: 0.181587\n",
      "[800]\tvalid_0's binary_logloss: 0.180541\n",
      "[850]\tvalid_0's binary_logloss: 0.183138\n",
      "Early stopping, best iteration is:\n",
      "[765]\tvalid_0's binary_logloss: 0.179122\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.46061\n",
      "[100]\tvalid_0's binary_logloss: 0.360369\n",
      "[150]\tvalid_0's binary_logloss: 0.330048\n",
      "[200]\tvalid_0's binary_logloss: 0.312761\n",
      "[250]\tvalid_0's binary_logloss: 0.297123\n",
      "[300]\tvalid_0's binary_logloss: 0.28109\n",
      "[350]\tvalid_0's binary_logloss: 0.278501\n",
      "[400]\tvalid_0's binary_logloss: 0.272263\n",
      "[450]\tvalid_0's binary_logloss: 0.266375\n",
      "[500]\tvalid_0's binary_logloss: 0.266909\n",
      "[550]\tvalid_0's binary_logloss: 0.263951\n",
      "[600]\tvalid_0's binary_logloss: 0.259137\n",
      "[650]\tvalid_0's binary_logloss: 0.262994\n",
      "[700]\tvalid_0's binary_logloss: 0.261624\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's binary_logloss: 0.259137\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.401543\n",
      "[100]\tvalid_0's binary_logloss: 0.339971\n",
      "[150]\tvalid_0's binary_logloss: 0.31506\n",
      "[200]\tvalid_0's binary_logloss: 0.294607\n",
      "[250]\tvalid_0's binary_logloss: 0.266017\n",
      "[300]\tvalid_0's binary_logloss: 0.260583\n",
      "[350]\tvalid_0's binary_logloss: 0.251308\n",
      "[400]\tvalid_0's binary_logloss: 0.240067\n",
      "[450]\tvalid_0's binary_logloss: 0.2368\n",
      "[500]\tvalid_0's binary_logloss: 0.232692\n",
      "[550]\tvalid_0's binary_logloss: 0.231355\n",
      "[600]\tvalid_0's binary_logloss: 0.232989\n",
      "Early stopping, best iteration is:\n",
      "[515]\tvalid_0's binary_logloss: 0.230905\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.467537\n",
      "[100]\tvalid_0's binary_logloss: 0.389742\n",
      "[150]\tvalid_0's binary_logloss: 0.350571\n",
      "[200]\tvalid_0's binary_logloss: 0.322558\n",
      "[250]\tvalid_0's binary_logloss: 0.294444\n",
      "[300]\tvalid_0's binary_logloss: 0.271155\n",
      "[350]\tvalid_0's binary_logloss: 0.253208\n",
      "[400]\tvalid_0's binary_logloss: 0.234709\n",
      "[450]\tvalid_0's binary_logloss: 0.225673\n",
      "[500]\tvalid_0's binary_logloss: 0.217558\n",
      "[550]\tvalid_0's binary_logloss: 0.214723\n",
      "[600]\tvalid_0's binary_logloss: 0.209264\n",
      "[650]\tvalid_0's binary_logloss: 0.208359\n",
      "[700]\tvalid_0's binary_logloss: 0.205503\n",
      "[750]\tvalid_0's binary_logloss: 0.207298\n",
      "Early stopping, best iteration is:\n",
      "[666]\tvalid_0's binary_logloss: 0.205117\n",
      "All your scores are: \n",
      "[0.21558668134309361, 0.17912243795258762, 0.25913703081926864, 0.23090523325649484, 0.20511653454280868]\n",
      "The average of your score\n",
      "0.217973583583\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.41014\n",
      "[100]\tvalid_0's binary_logloss: 0.341368\n",
      "[150]\tvalid_0's binary_logloss: 0.324883\n",
      "[200]\tvalid_0's binary_logloss: 0.292909\n",
      "[250]\tvalid_0's binary_logloss: 0.276087\n",
      "[300]\tvalid_0's binary_logloss: 0.27236\n",
      "[350]\tvalid_0's binary_logloss: 0.263738\n",
      "[400]\tvalid_0's binary_logloss: 0.247866\n",
      "[450]\tvalid_0's binary_logloss: 0.250517\n",
      "[500]\tvalid_0's binary_logloss: 0.244974\n",
      "[550]\tvalid_0's binary_logloss: 0.236937\n",
      "[600]\tvalid_0's binary_logloss: 0.233212\n",
      "[650]\tvalid_0's binary_logloss: 0.230533\n",
      "[700]\tvalid_0's binary_logloss: 0.227494\n",
      "[750]\tvalid_0's binary_logloss: 0.224384\n",
      "[800]\tvalid_0's binary_logloss: 0.220665\n",
      "[850]\tvalid_0's binary_logloss: 0.221983\n",
      "Early stopping, best iteration is:\n",
      "[796]\tvalid_0's binary_logloss: 0.220403\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.409409\n",
      "[100]\tvalid_0's binary_logloss: 0.338374\n",
      "[150]\tvalid_0's binary_logloss: 0.301523\n",
      "[200]\tvalid_0's binary_logloss: 0.271596\n",
      "[250]\tvalid_0's binary_logloss: 0.242521\n",
      "[300]\tvalid_0's binary_logloss: 0.228017\n",
      "[350]\tvalid_0's binary_logloss: 0.221772\n",
      "[400]\tvalid_0's binary_logloss: 0.211973\n",
      "[450]\tvalid_0's binary_logloss: 0.205316\n",
      "[500]\tvalid_0's binary_logloss: 0.19748\n",
      "[550]\tvalid_0's binary_logloss: 0.191674\n",
      "[600]\tvalid_0's binary_logloss: 0.191587\n",
      "[650]\tvalid_0's binary_logloss: 0.192522\n",
      "[700]\tvalid_0's binary_logloss: 0.187203\n",
      "[750]\tvalid_0's binary_logloss: 0.184727\n",
      "[800]\tvalid_0's binary_logloss: 0.184117\n",
      "[850]\tvalid_0's binary_logloss: 0.183868\n",
      "[900]\tvalid_0's binary_logloss: 0.184953\n",
      "Early stopping, best iteration is:\n",
      "[813]\tvalid_0's binary_logloss: 0.18249\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.46061\n",
      "[100]\tvalid_0's binary_logloss: 0.360371\n",
      "[150]\tvalid_0's binary_logloss: 0.330016\n",
      "[200]\tvalid_0's binary_logloss: 0.312727\n",
      "[250]\tvalid_0's binary_logloss: 0.297096\n",
      "[300]\tvalid_0's binary_logloss: 0.279164\n",
      "[350]\tvalid_0's binary_logloss: 0.277096\n",
      "[400]\tvalid_0's binary_logloss: 0.271383\n",
      "[450]\tvalid_0's binary_logloss: 0.267474\n",
      "[500]\tvalid_0's binary_logloss: 0.26508\n",
      "[550]\tvalid_0's binary_logloss: 0.264833\n",
      "[600]\tvalid_0's binary_logloss: 0.256285\n",
      "[650]\tvalid_0's binary_logloss: 0.257346\n",
      "[700]\tvalid_0's binary_logloss: 0.258143\n",
      "Early stopping, best iteration is:\n",
      "[626]\tvalid_0's binary_logloss: 0.254988\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.401543\n",
      "[100]\tvalid_0's binary_logloss: 0.33997\n",
      "[150]\tvalid_0's binary_logloss: 0.31506\n",
      "[200]\tvalid_0's binary_logloss: 0.294607\n",
      "[250]\tvalid_0's binary_logloss: 0.266009\n",
      "[300]\tvalid_0's binary_logloss: 0.260576\n",
      "[350]\tvalid_0's binary_logloss: 0.251312\n",
      "[400]\tvalid_0's binary_logloss: 0.240569\n",
      "[450]\tvalid_0's binary_logloss: 0.237834\n",
      "[500]\tvalid_0's binary_logloss: 0.234831\n",
      "[550]\tvalid_0's binary_logloss: 0.232196\n",
      "[600]\tvalid_0's binary_logloss: 0.232334\n",
      "[650]\tvalid_0's binary_logloss: 0.226493\n",
      "[700]\tvalid_0's binary_logloss: 0.223008\n",
      "[750]\tvalid_0's binary_logloss: 0.220222\n",
      "[800]\tvalid_0's binary_logloss: 0.217411\n",
      "[850]\tvalid_0's binary_logloss: 0.217608\n",
      "[900]\tvalid_0's binary_logloss: 0.220413\n",
      "Early stopping, best iteration is:\n",
      "[815]\tvalid_0's binary_logloss: 0.216612\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f3d962d0e58>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.467536\n",
      "[100]\tvalid_0's binary_logloss: 0.389741\n",
      "[150]\tvalid_0's binary_logloss: 0.349556\n",
      "[200]\tvalid_0's binary_logloss: 0.317241\n",
      "[250]\tvalid_0's binary_logloss: 0.289701\n",
      "[300]\tvalid_0's binary_logloss: 0.26971\n",
      "[350]\tvalid_0's binary_logloss: 0.255758\n",
      "[400]\tvalid_0's binary_logloss: 0.233207\n",
      "[450]\tvalid_0's binary_logloss: 0.222895\n",
      "[500]\tvalid_0's binary_logloss: 0.217534\n",
      "[550]\tvalid_0's binary_logloss: 0.214871\n",
      "[600]\tvalid_0's binary_logloss: 0.211043\n",
      "[650]\tvalid_0's binary_logloss: 0.210963\n",
      "[700]\tvalid_0's binary_logloss: 0.204793\n",
      "[750]\tvalid_0's binary_logloss: 0.205956\n",
      "[800]\tvalid_0's binary_logloss: 0.202511\n",
      "[850]\tvalid_0's binary_logloss: 0.200712\n",
      "[900]\tvalid_0's binary_logloss: 0.198131\n",
      "[950]\tvalid_0's binary_logloss: 0.197342\n",
      "Early stopping, best iteration is:\n",
      "[888]\tvalid_0's binary_logloss: 0.19637\n",
      "All your scores are: \n",
      "[0.22040332257874667, 0.18249043901388842, 0.25498751280356657, 0.21661243660298216, 0.19637007231856204]\n",
      "The average of your score\n",
      "0.214172756664\n",
      "[0.21209785679961737, 0.2114405468021831, 0.2082691348397549, 0.20947403281359683, 0.20735934979482673, 0.20830659939167645, 0.20737162094031231, 0.20953477621474897, 0.22119093362169501, 0.21244587251466615, 0.21510781415181177, 0.21206875965869987, 0.21226718534426356, 0.21427253605641411, 0.21797358358285068, 0.21417275666354918]\n"
     ]
    }
   ],
   "source": [
    "#results\n",
    "avg_result = []\n",
    "#training\n",
    "# test_ratio = 0.2\n",
    "# nr_runs = 3\n",
    "# split_seed = 25\n",
    "# kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "\n",
    "ran_num = 463465 #463465#56491\n",
    "for ran_num in  [1123, 463465]:#  [1123,4677,6745 ,2312, 56491,463465]:\n",
    "    split_seed= np.random.RandomState(ran_num)\n",
    "    print('The seed we are using is: %d' % ran_num)\n",
    "    nr_runs = 5\n",
    "    kf = KFold(n_splits=nr_runs, random_state=split_seed)\n",
    "\n",
    "    for param in [6,8,10,12,14,18,20,22]:\n",
    "        result = []\n",
    "        for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "            print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "            tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "            x1, x2 = train_X[train_index], train_X[test_index]\n",
    "            y1, y2 = train_y[train_index], train_y[test_index] \n",
    "\n",
    "            ##LightGBM\n",
    "            lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "            #gbdt\n",
    "            params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "            params['boosting'] = 'dart'\n",
    "            params['metric'] = 'binary_logloss'\n",
    "            params['learning_rate'] = 0.04\n",
    "            params['max_depth'] = 5\n",
    "            params['num_leaves'] = param # higher number of leaves\n",
    "            params['feature_fraction'] = 0.8 # Controls overfit\n",
    "            params['bagging_fraction'] = 0.9    \n",
    "            params['bagging_freq'] = 3\n",
    "            params['seed'] = ran_num + r\n",
    "            #dart\n",
    "            params['drop_rate'] = 0.1\n",
    "            params['skip_drop'] = 0.5\n",
    "            params['max_drop'] = 10\n",
    "            params['verbose'] = -1 \n",
    "\n",
    "            model3 = lgb.train(params, \n",
    "                           lgb_train, \n",
    "                           nr_round, \n",
    "                           lgb_valid, \n",
    "                           verbose_eval=50, early_stopping_rounds=min_round)\n",
    "            result.append(model3.best_score['valid_0']['binary_logloss'])\n",
    "            \n",
    "        print('All your scores are: ')\n",
    "        print(result)\n",
    "        print('The average of your score')\n",
    "        print(np.mean(result))\n",
    "        avg_result.append(np.mean(result))\n",
    "print(avg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "num_leaves here: 16\n",
    "\n",
    "0.20996463972458032, 0.2105201451940987, 0.21304611830042508, 0.21343599728787993, 0.21106262003875184, 0.21354386772253284\n",
    "\n",
    "num_leaves here: 9\n",
    "\n",
    "0.21011925200129097, 0.215387241291573, 0.21029209937609511, 0.21529853022367157, 0.21635515450387191, 0.21704195707060975\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed we are using is: 52204\n",
      "\n",
      "round 0001 of 0005, seed=<mtrand.RandomState object at 0x7f26846964c8>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.677142\tvalid-logloss:0.67987\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.200635\tvalid-logloss:0.276155\n",
      "[200]\ttrain-logloss:0.106665\tvalid-logloss:0.222632\n",
      "[300]\ttrain-logloss:0.064316\tvalid-logloss:0.205287\n",
      "[400]\ttrain-logloss:0.041729\tvalid-logloss:0.195431\n",
      "[500]\ttrain-logloss:0.028727\tvalid-logloss:0.192955\n",
      "[600]\ttrain-logloss:0.020455\tvalid-logloss:0.191053\n",
      "[700]\ttrain-logloss:0.015365\tvalid-logloss:0.190849\n",
      "Stopping. Best iteration:\n",
      "[640]\ttrain-logloss:0.018225\tvalid-logloss:0.189769\n",
      "\n",
      "\n",
      "LightGBM: gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM: dart\n",
      "\n",
      "round 0002 of 0005, seed=<mtrand.RandomState object at 0x7f26846964c8>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.67773\tvalid-logloss:0.677893\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.202642\tvalid-logloss:0.258654\n",
      "[200]\ttrain-logloss:0.107838\tvalid-logloss:0.199357\n",
      "[300]\ttrain-logloss:0.064817\tvalid-logloss:0.18259\n",
      "[400]\ttrain-logloss:0.042206\tvalid-logloss:0.173318\n",
      "[500]\ttrain-logloss:0.028425\tvalid-logloss:0.173133\n",
      "Stopping. Best iteration:\n",
      "[472]\ttrain-logloss:0.031731\tvalid-logloss:0.171771\n",
      "\n",
      "\n",
      "LightGBM: gbdt\n",
      "\n",
      "LightGBM: dart\n",
      "\n",
      "round 0003 of 0005, seed=<mtrand.RandomState object at 0x7f26846964c8>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.675441\tvalid-logloss:0.677959\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.191374\tvalid-logloss:0.318283\n",
      "[200]\ttrain-logloss:0.099524\tvalid-logloss:0.277155\n",
      "[300]\ttrain-logloss:0.060916\tvalid-logloss:0.265633\n",
      "[400]\ttrain-logloss:0.039756\tvalid-logloss:0.261547\n",
      "[500]\ttrain-logloss:0.026688\tvalid-logloss:0.262039\n",
      "Stopping. Best iteration:\n",
      "[433]\ttrain-logloss:0.03481\tvalid-logloss:0.259703\n",
      "\n",
      "\n",
      "LightGBM: gbdt\n",
      "\n",
      "LightGBM: dart\n",
      "\n",
      "round 0004 of 0005, seed=<mtrand.RandomState object at 0x7f26846964c8>\n",
      "splitted: (1283, 265), (321, 265)\n",
      "[0]\ttrain-logloss:0.677175\tvalid-logloss:0.677518\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.198964\tvalid-logloss:0.280067\n",
      "[200]\ttrain-logloss:0.107017\tvalid-logloss:0.234195\n",
      "[300]\ttrain-logloss:0.065847\tvalid-logloss:0.219187\n",
      "[400]\ttrain-logloss:0.041964\tvalid-logloss:0.212217\n",
      "[500]\ttrain-logloss:0.028238\tvalid-logloss:0.210273\n",
      "Stopping. Best iteration:\n",
      "[458]\ttrain-logloss:0.033443\tvalid-logloss:0.208777\n",
      "\n",
      "\n",
      "LightGBM: gbdt\n",
      "\n",
      "LightGBM: dart\n",
      "\n",
      "round 0005 of 0005, seed=<mtrand.RandomState object at 0x7f26846964c8>\n",
      "splitted: (1284, 265), (320, 265)\n",
      "[0]\ttrain-logloss:0.675648\tvalid-logloss:0.68004\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.197222\tvalid-logloss:0.293598\n",
      "[200]\ttrain-logloss:0.105363\tvalid-logloss:0.226455\n",
      "[300]\ttrain-logloss:0.064338\tvalid-logloss:0.21025\n",
      "[400]\ttrain-logloss:0.04164\tvalid-logloss:0.203058\n",
      "Stopping. Best iteration:\n",
      "[371]\ttrain-logloss:0.046521\tvalid-logloss:0.202127\n",
      "\n",
      "\n",
      "LightGBM: gbdt\n",
      "\n",
      "LightGBM: dart\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# This will be the version changed based on my own understanding\n",
    "def save_blend(preds={}, loc='./'):\n",
    "    target = 'is_iceberg'\n",
    "    \n",
    "    w_total = 0.0\n",
    "    blend = None\n",
    "    df_corr = None\n",
    "    print('\\nBlending...')\n",
    "    for k, v in preds.items():\n",
    "        if blend is None:\n",
    "            blend = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            \n",
    "            df_corr = pd.DataFrame({'id': blend['id'].tolist()})\n",
    "            df_corr[k[16:-4]] = blend[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] = blend[target] * v\n",
    "                \n",
    "        else:\n",
    "            preds_tmp = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            df_corr[k[16:-4]] = preds_tmp[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] += preds_tmp[target] * v\n",
    "            del preds_tmp\n",
    "            \n",
    "    print('\\n{}'.format(df_corr.corr()), flush=True)\n",
    "    #write submission\n",
    "    blend[target] = blend[target] / w_total\n",
    "    print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "    blend.to_csv('{}subm_blend{:03d}_{}.csv'.format(loc, len(preds), tmp), index=False, float_format='%.6f')\n",
    "\n",
    "def run_lgb(params={}, lgb_train=None, lgb_valid=None, lgb_test=None, test_ids=None, nr_round=2000, min_round=100, file=''):\n",
    "\n",
    "    print('\\nLightGBM: {}'.format(params['boosting'])) \n",
    "    model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=False, early_stopping_rounds=min_round)\n",
    "    \n",
    "    pred = model2.predict(lgb_test, num_iteration=model2.best_iteration)\n",
    "    #\n",
    "#     if model2.best_score['valid_0']['binary_logloss']<=0.195:\n",
    "    subm = pd.DataFrame({'id': test_ids, 'is_iceberg': pred})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    #   \n",
    "    df = pd.DataFrame({'feature':model2.feature_name(), 'importances': model2.feature_importance()})\n",
    "    \n",
    "    return pred, df\n",
    "\n",
    "\n",
    "#results\n",
    "freq = pd.DataFrame()\n",
    "subms = []\n",
    "\n",
    "#training\n",
    "# test_ratio = 0.2\n",
    "# nr_runs = 3\n",
    "# split_seed = 25\n",
    "# kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "seed_list=[]\n",
    "# final_dict ={}\n",
    "# final_dict['xgb_re'] = []\n",
    "# final_dict['lgb_re'] = []\n",
    "# final_dict['lgb_dart_re'] =[]\n",
    "for rep in range(1):\n",
    "    ran_num =  np.random.randint(50000,60000,size=1)[0]\n",
    "    seed_list.append(ran_num)\n",
    "    split_seed= np.random.RandomState(ran_num)\n",
    "    print('The seed we are using is: %d' % ran_num)\n",
    "    nr_runs = 5\n",
    "    kf = KFold(n_splits=nr_runs, random_state=split_seed)\n",
    "    tree_lim =0\n",
    "#     xgb_re = []\n",
    "#     lgb_re =[]\n",
    "#     lgb_dart_re= []\n",
    "    for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "        print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "        tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "        x1, x2 = train_X[train_index], train_X[test_index]\n",
    "        y1, y2 = train_y[train_index], train_y[test_index]\n",
    "        #x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=test_ratio, random_state=split_seed + r)\n",
    "        print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "        test_X_dup = test_X.copy()\n",
    "\n",
    "        #XGB\n",
    "        xgb_train = xgb.DMatrix(x1, y1)\n",
    "        xgb_valid = xgb.DMatrix(x2, y2)\n",
    "        #\n",
    "        watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "        params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "        params['eta'] = 0.03\n",
    "        params['max_depth'] = 4\n",
    "        params['subsample'] = 0.9\n",
    "        params['eval_metric'] = 'logloss'\n",
    "        params['colsample_bytree'] = 0.8\n",
    "        params['colsample_bylevel'] = 0.8\n",
    "        params['max_delta_step'] = 3\n",
    "        #params['gamma'] = 5.0\n",
    "        #params['labmda'] = 1\n",
    "        params['scale_pos_weight'] = 1.0\n",
    "        params['silent'] = False\n",
    "        params['seed'] = ran_num + r\n",
    "        nr_round = 2000\n",
    "        min_round = 100\n",
    "\n",
    "        model1 = xgb.train(params, \n",
    "                           xgb_train, \n",
    "                           nr_round,  \n",
    "                           watchlist, \n",
    "                           verbose_eval=100\n",
    "                           ,\n",
    "                           early_stopping_rounds=min_round)\n",
    "\n",
    "        pred_xgb = model1.predict(xgb.DMatrix(test_X_dup), ntree_limit=model1.best_ntree_limit+tree_lim)\n",
    "\n",
    "        #\n",
    "        file = 'gbm/subm_xgb{}{}.csv'.format(rep, r+1)\n",
    "#         if model1.best_score<=0.195:\n",
    "        subm = pd.DataFrame({'id': test['id'].values, target: pred_xgb})\n",
    "        subm.to_csv(file, index=False)\n",
    "        subms.append(file)    \n",
    "\n",
    "        \n",
    "        lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "        lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "        #gbdt\n",
    "        params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "        params['boosting'] = 'gbdt'\n",
    "        params['metric'] = 'binary_logloss'\n",
    "        params['learning_rate'] = 0.03\n",
    "        params['max_depth'] = 5\n",
    "        params['num_leaves'] = 9 # higher number of leaves\n",
    "        params['feature_fraction'] = 0.8 # Controls overfit\n",
    "        params['bagging_fraction'] = 0.9    \n",
    "        params['bagging_freq'] = 3\n",
    "        params['seed'] = ran_num + r\n",
    "        params['silent'] = False\n",
    "        params['verbose'] = 1000\n",
    "\n",
    "        file = 'gbm/subm_orilgb{}{}.csv'.format(rep, r+1)\n",
    "        subms.append(file)\n",
    "\n",
    "        pred, f_tmp = run_lgb(params=params, \n",
    "                              lgb_train=lgb_train, \n",
    "                              lgb_valid=lgb_valid, \n",
    "                              lgb_test=test_X_dup, \n",
    "                              test_ids=test['id'].values, \n",
    "                              nr_round=nr_round, \n",
    "                              min_round=min_round, \n",
    "                              file=file)\n",
    "        \n",
    "        \n",
    "        ##LightGBM\n",
    "        #dart\n",
    "        params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "        params['boosting'] = 'dart'\n",
    "        params['metric'] = 'binary_logloss'\n",
    "        params['learning_rate'] = 0.04\n",
    "        params['max_depth'] = 5\n",
    "        params['num_leaves'] = 16 # higher number of leaves\n",
    "        params['feature_fraction'] = 0.8 # Controls overfit\n",
    "        params['bagging_fraction'] = 0.9    \n",
    "        params['bagging_freq'] = 3\n",
    "        params['seed'] = ran_num + r\n",
    "        #dart\n",
    "        params['drop_rate'] = 0.1\n",
    "        params['skip_drop'] = 0.5\n",
    "        params['max_drop'] = 10\n",
    "        params['verbose'] = 1000\n",
    "        params['silent'] = False\n",
    "        \n",
    "        file = 'gbm/subm_lgb{}{}.csv'.format(rep, r+1)\n",
    "        subms.append(file)\n",
    "\n",
    "        pred, f_tmp = run_lgb(params=params, \n",
    "                              lgb_train=lgb_train, \n",
    "                              lgb_valid=lgb_valid, \n",
    "                              lgb_test=test_X_dup, \n",
    "                              test_ids=test['id'].values, \n",
    "                              nr_round=nr_round, \n",
    "                              min_round=min_round, \n",
    "                              file=file)\n",
    "    if rep%5==0:\n",
    "        print(rep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm/subm_lgb02.csv\n",
      "gbm/subm_orilgb05.csv\n",
      "gbm/subm_orilgb02.csv\n",
      "gbm/subm_orilgb01.csv\n",
      "gbm/subm_orilgb03.csv\n",
      "gbm/subm_orilgb04.csv\n",
      "gbm/subm_lgb03.csv\n",
      "gbm/subm_lgb01.csv\n",
      "gbm/subm_xgb01.csv\n",
      "gbm/subm_xgb03.csv\n",
      "gbm/subm_xgb02.csv\n",
      "gbm/subm_xgb04.csv\n",
      "gbm/subm_xgb05.csv\n",
      "gbm/subm_lgb04.csv\n",
      "gbm/subm_lgb05.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#print(os.listdir('gbm'))\n",
    "waiting_list= [os.path.join('gbm',i) for i in os.listdir('gbm') if 'csv' in i]\n",
    "len(waiting_list)\n",
    "for i in waiting_list:\n",
    "    print(i)\n",
    "#w_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blending...\n"
     ]
    }
   ],
   "source": [
    "k = pd.DataFrame()\n",
    "blend = None\n",
    "df_corr = None\n",
    "print('\\nBlending...')\n",
    "v=1\n",
    "for num,path in enumerate(waiting_list):\n",
    "    if blend is None:\n",
    "        blend = pd.read_csv(path)\n",
    "\n",
    "        w_total += v\n",
    "        blend[target] = blend[target] * v\n",
    "\n",
    "    else:\n",
    "        preds_tmp = pd.read_csv(path)\n",
    "        preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "        msg = \"is_iceberg%d\"% (num+1)\n",
    "        blend[msg] = preds_tmp[target] * v\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend.to_csv('gbm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blending...\n"
     ]
    }
   ],
   "source": [
    "target = 'is_iceberg'\n",
    "\n",
    "w_total = 0.0\n",
    "blend = None\n",
    "df_corr = None\n",
    "print('\\nBlending...')\n",
    "v=1\n",
    "for num,path in enumerate(waiting_list):\n",
    "    if blend is None:\n",
    "        blend = pd.read_csv(path)\n",
    "\n",
    "        w_total += v\n",
    "        blend[target] = blend[target] * v\n",
    "\n",
    "    else:\n",
    "        preds_tmp = pd.read_csv(path)\n",
    "        preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "        \n",
    "        \n",
    "        w_total += v\n",
    "        msg = 'is_iceberg%d' %num\n",
    "        blend[msg] = preds_tmp[target] * v\n",
    "        del preds_tmp\n",
    "\n",
    "# blend[target] = blend[target] / w_total\n",
    "# print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "# blend.to_csv('submission1010.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp11 = blend.drop(['id'],axis=1)\n",
    "temp11['is_iceberg_max'] = temp11.iloc[:, :15].max(axis=1)\n",
    "temp11['is_iceberg_min'] = temp11.iloc[:, :15].min(axis=1)\n",
    "temp11['is_iceberg_median'] = temp11.iloc[:, :15].median(axis=1)\n",
    "temp11['is_iceberg_mean'] = temp11.iloc[:, :15].mean(axis=1)\n",
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2\n",
    "\n",
    "\n",
    "temp11['is_iceberg'] = np.where(np.all(temp11.iloc[:,0:15] > cutoff_lo, axis=1), \n",
    "                                    temp11['is_iceberg_max'], \n",
    "                                    np.where(np.all(temp11.iloc[:,0:15] < cutoff_hi, axis=1),\n",
    "                                             temp11['is_iceberg_min'], \n",
    "                                             temp11['is_iceberg_median']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame()\n",
    "k['id'] = blend['id']\n",
    "k['is_iceberg'] = temp11['is_iceberg']\n",
    "k.to_csv('22.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m.\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[34m..\u001b[m\u001b[m\r\n",
      ".DS_Store\r\n",
      "\u001b[1m\u001b[34m.git\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "36_plain_cnn.csv\r\n",
      "41_plain_cnn.csv\r\n",
      "50_plain_fcn.csv\r\n",
      "67_plain_cnn.csv\r\n",
      "6_retrain_inception.csv\r\n",
      "Image preprocess testing.ipynb\r\n",
      "README.md\r\n",
      "Ship-Iceberg Discrimination with Convolutional Neural Networks in High Resolution SAR Images.pdf\r\n",
      "The Effectiveness of Data Augmentation in Image Classification using Deep Learning.pdf\r\n",
      "Training_log.ipynb\r\n",
      "\u001b[1m\u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "all_14_inception.csv\r\n",
      "cnn.ipynb\r\n",
      "cnn.py\r\n",
      "cnn_angle.ipynb\r\n",
      "cnn_angle.py\r\n",
      "\u001b[1m\u001b[34mdata\u001b[m\u001b[m\r\n",
      "densenet.py\r\n",
      "densenet121.ipynb\r\n",
      "densenet121_pseudl.ipynb\r\n",
      "densenetBC.py\r\n",
      "densenetbc100.ipynb\r\n",
      "fcn.ipynb\r\n",
      "fcn.py\r\n",
      "final ensemble.ipynb\r\n",
      "gbm.ipynb\r\n",
      "inception.ipynb\r\n",
      "inception.py\r\n",
      "\u001b[1m\u001b[34mothers\u001b[m\u001b[m\r\n",
      "pre_resnet.py\r\n",
      "pre_vgg.py\r\n",
      "r2_11_plain_cnn.csv\r\n",
      "r2_fcn_11_models.csv\r\n",
      "resnet.py\r\n",
      "resnet101.ipynb\r\n",
      "resnet101_4feat.ipynb\r\n",
      "resnet152.ipynb\r\n",
      "resnet18.ipynb\r\n",
      "resnet34.ipynb\r\n",
      "resnet34_4feat.ipynb\r\n",
      "resnet34_onlygoodretrain.csv\r\n",
      "resnet34_pseudolb.ipynb\r\n",
      "resnet34_retrain_all.csv\r\n",
      "resnet50.ipynb\r\n",
      "resnet50_temp.ipynb\r\n",
      "save_for_use.csv\r\n",
      "squeezenet.py\r\n",
      "squeezenet1.ipynb\r\n",
      "submissionlasttd.csv\r\n",
      "test.txt\r\n",
      "utils.py\r\n",
      "vgg.ipynb\r\n",
      "vgg.py\r\n",
      "vgg_mobile.py\r\n"
     ]
    }
   ],
   "source": [
    "def save_blend(preds={}, loc='./'):\n",
    "    \n",
    "    target = 'is_iceberg'\n",
    "    \n",
    "    w_total = 0.0\n",
    "    blend = None\n",
    "    df_corr = None\n",
    "    print('\\nBlending...')\n",
    "    for k, v in preds.items():\n",
    "        if blend is None:\n",
    "            blend = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            \n",
    "            df_corr = pd.DataFrame({'id': blend['id'].tolist()})\n",
    "            df_corr[k[16:-4]] = blend[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] = blend[target] * v\n",
    "                \n",
    "        else:\n",
    "            preds_tmp = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            df_corr[k[16:-4]] = preds_tmp[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] += preds_tmp[target] * v\n",
    "            del preds_tmp\n",
    "            \n",
    "    print('\\n{}'.format(df_corr.corr()), flush=True)\n",
    "    #write submission\n",
    "    blend[target] = blend[target] / w_total\n",
    "    print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "    blend.to_csv('{}subm_blend{:03d}_{}.csv'.format(loc, len(preds), tmp), index=False, float_format='%.6f')\n",
    "\n",
    "def run_lgb(params={}, lgb_train=None, lgb_valid=None, lgb_test=None, test_ids=None, nr_round=2000, min_round=100, file=''):\n",
    "\n",
    "    print('\\nLightGBM: {}'.format(params['boosting'])) \n",
    "    model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "    \n",
    "    pred = model2.predict(lgb_test, num_iteration=model2.best_iteration)\n",
    "    #\n",
    "    subm = pd.DataFrame({'id': test_ids, 'is_iceberg': pred})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    #   \n",
    "    df = pd.DataFrame({'feature':model2.feature_name(), 'importances': model2.feature_importance()})\n",
    "    \n",
    "    return pred, df\n",
    "\n",
    "\n",
    "#results\n",
    "freq = pd.DataFrame()\n",
    "subms = []\n",
    "\n",
    "#training\n",
    "test_ratio = 0.2\n",
    "nr_runs = 3\n",
    "split_seed = 25\n",
    "kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "\n",
    "for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "    print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "    tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "    x1, x2 = train_X[train_index], train_X[test_index]\n",
    "    y1, y2 = train_y[train_index], train_y[test_index]\n",
    "    #x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=test_ratio, random_state=split_seed + r)\n",
    "    print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "    test_X_dup = test_X.copy()\n",
    "\n",
    "    #XGB\n",
    "    xgb_train = xgb.DMatrix(x1, y1)\n",
    "    xgb_valid = xgb.DMatrix(x2, y2)\n",
    "    #\n",
    "    watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "    params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "    params['eta'] = 0.03\n",
    "    params['max_depth'] = 4\n",
    "    params['subsample'] = 0.9\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['colsample_bytree'] = 0.8\n",
    "    params['colsample_bylevel'] = 0.8\n",
    "    params['max_delta_step'] = 3\n",
    "    #params['gamma'] = 5.0\n",
    "    #params['labmda'] = 1\n",
    "    params['scale_pos_weight'] = 1.0\n",
    "    params['seed'] = split_seed + r\n",
    "    nr_round = 2000\n",
    "    min_round = 100\n",
    "\n",
    "    model1 = xgb.train(params, \n",
    "                       xgb_train, \n",
    "                       nr_round,  \n",
    "                       watchlist, \n",
    "                       verbose_eval=50, \n",
    "                       early_stopping_rounds=min_round)\n",
    "\n",
    "    pred_xgb = model1.predict(xgb.DMatrix(test_X_dup), ntree_limit=model1.best_ntree_limit+45)\n",
    "\n",
    "    #\n",
    "    file = 'subm_{}_xgb_{:02d}.csv'.format(tmp, r+1)\n",
    "    subm = pd.DataFrame({'id': test['id'].values, target: pred_xgb})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    subms.append(file)    \n",
    "\n",
    "    ##LightGBM\n",
    "    lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "    lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "    #gbdt\n",
    "    params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "    params['boosting'] = 'gbdt'\n",
    "    params['metric'] = 'binary_logloss'\n",
    "    params['learning_rate'] = 0.03\n",
    "    params['max_depth'] = 5\n",
    "    params['num_leaves'] = 16 # higher number of leaves\n",
    "    params['feature_fraction'] = 0.8 # Controls overfit\n",
    "    params['bagging_fraction'] = 0.9    \n",
    "    params['bagging_freq'] = 3\n",
    "    params['seed'] = split_seed + r\n",
    "    #\n",
    "    params['verbose'] = -1\n",
    "\n",
    "    file = 'subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "    subms.append(file)\n",
    "\n",
    "    pred, f_tmp = run_lgb(params=params, \n",
    "                          lgb_train=lgb_train, \n",
    "                          lgb_valid=lgb_valid, \n",
    "                          lgb_test=test_X_dup, \n",
    "                          test_ids=test['id'].values, \n",
    "                          nr_round=nr_round, \n",
    "                          min_round=min_round, \n",
    "                          file=file)\n",
    "\n",
    "    ##LightGBM\n",
    "    #dart\n",
    "    params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "    params['boosting'] = 'dart'\n",
    "    params['metric'] = 'binary_logloss'\n",
    "    params['learning_rate'] = 0.04\n",
    "    params['max_depth'] = 5\n",
    "    params['num_leaves'] = 16 # higher number of leaves\n",
    "    params['feature_fraction'] = 0.8 # Controls overfit\n",
    "    params['bagging_fraction'] = 0.9    \n",
    "    params['bagging_freq'] = 3\n",
    "    params['seed'] = split_seed + r\n",
    "    #dart\n",
    "    params['drop_rate'] = 0.1\n",
    "    params['skip_drop'] = 0.5\n",
    "    params['max_drop'] = 10\n",
    "    params['verbose'] = -1 \n",
    "\n",
    "    file = 'subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "    subms.append(file)\n",
    "\n",
    "    pred, f_tmp = run_lgb(params=params, \n",
    "                          lgb_train=lgb_train, \n",
    "                          lgb_valid=lgb_valid, \n",
    "                          lgb_test=test_X_dup, \n",
    "                          test_ids=test['id'].values, \n",
    "                          nr_round=nr_round, \n",
    "                          min_round=min_round, \n",
    "                          file=file)\n",
    "\n",
    "\n",
    "#blending\n",
    "preds = {k: 1.0 for k in subms}\n",
    "save_blend(preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52161])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=  torch.Tensor([1,2,3])\n",
    "a.size()\n",
    "a=a.unsqueeze(1)\n",
    "a.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
